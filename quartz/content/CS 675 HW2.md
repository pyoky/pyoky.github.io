---
aliases: []
tags:
  - Courses
origins:
  - "[[CS 675 Deep Learning]]"
---
## Problem 1

Let $h_{3}=\hat{y}$ for consistencey in notation. Assume vectors are column vectors. First we calculate:
$$
\begin{align}
\frac{ \partial \ell }{ \partial h_{3,i} }&= \frac{-2}{N}(y_{i}-h_{3,i})  \\
\frac{ \partial \ell }{ \partial h_{3} } &= -\frac{2}{N}(y-h_{3})^{\top}\overset{ \text{let} }{ = }\delta_{3}^{\top}  & \text{shape $1\times D_{3}$}
\end{align}
$$
Then we consider the tree of computation as in class. Let $a_{k}=W_{k}^{\top}h_{k-1}+b_{k}$
1. $\frac{ \partial h_{3} }{ \partial W_{3}^{\top} }=h_{2}$ to get $\frac{ \partial \ell }{ \partial W_{3}^{\top} }=h_{2}\delta_{3}^{\top}$ ðŸ”´
2. $\frac{ \partial h_{3} }{ \partial b_{3} }=1$ to get $\frac{ \partial \ell }{ \partial b_{3} }=\delta_{3}^{\top}$ ðŸ”´
3. $\frac{ \partial h_{3} }{ \partial h_{2} }=W_{3}$ to get $\frac{ \partial \ell }{ \partial h_{2} }=W_{3}\delta_{3}^{\top}\overset{ let }{ = }\delta_{2}$
Next layer:
4. $\frac{ \partial h_{2} }{ \partial a_{2} }=\frac{ \partial g(\cdot) }{ \partial (\cdot) }$
5. $\frac{ \partial a_{2} }{ \partial h_{1} }=W_{2}^{\top}$ to get $\frac{ \partial \ell }{ \partial h_{1} }=W_{2}^{\top}g'(\cdot)\delta_{2}\overset{ let }{ = }\delta_{1}$
6. $\frac{ \partial h_{2} }{ \partial W_{2}^{\top} }=h_{1}$ to get $\frac{ \partial \ell }{ \partial W_{2}^{\top} }=h_{1}\delta_{2}^{\top}$ ðŸ”´
7. $\frac{ \partial h_{2} }{ \partial b_{2} }=1$ to get $\frac{ \partial \ell }{ \partial b_{2} }=\delta_{2}^{\top}$ ðŸ”´
Similarly:
8. get $\frac{ \partial \ell }{ \partial W_{1}^{\top} }=h_{0}\delta_{1}^{\top}=x\delta_{1}^{\top}$ ðŸ”´
9. get $\frac{ \partial \ell }{ \partial b_{1} }=\delta_{1}^{\top}$ ðŸ”´

Results marked with ðŸ”´
