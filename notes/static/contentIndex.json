{"(Article)-Equality-of-What-q":{"title":"(Article) Equality of What?","links":["Utilitarianism","Utility","Efficiency-(Statistics)","Microeconomics"],"tags":["article","Economics/Game-Theory","Philosophy/Political-Philosophy"],"content":"(DevonThink) Sen,Equality\n\nEquity is about asking â€œwhat should be equal?â€\n\nLibertarians: Equality of Rights\nUtilitarians: Equal Weighting of Utility\nProgressive Taxation: Equality of Need Satisfaction\netc.\n\n\nâ‡’ The question then becomes: â€œEquality of What?â€\n\nPursuit of equality in one domain often damages another domain\n\nâ‡’ arguments are often in the form of â€œInequality in space A is acceptable, because it increases equality in space B.â€\n\n\nCommon framing is between equality and liberty\n\ne.g. left: equality in needs. right: liberty and freedom\nThis is the wrong framing because there are lots of other candidates anyways\n\n\n\n\nAlternative framing: Efficiency (Statistics)\n\nEfficiency of utility â‡’ Pareto Optimum\nEfficiency of liberty â‡’ Libertarian Government\netc.\n\n\n"},"(Article)-Magic-Ink---Information-Software-and-the-Graphical-Interface":{"title":"(Article) Magic Ink - Information Software and the Graphical Interface","links":["Color-as-an-Extra-Dimension"],"tags":["Design","Computing/Human-Interface"],"content":"Notes on Magic Ink: Information Software and the Graphical Interface\n\n\n                  \n                  What You See is All You Get (WYSIAYG) \n                  \n                \n\n\nUI design is:\n\nHow information is presented: Graphic Design\n\nPersonal accounting, Health app visualization\n\n\nHow to manipulate and create: Industrial design\n\nPhotoshop, Illustrator\n\n\n\n\nUsers mostly want to learn something, not create something.\nâ‡’ Graphic design &gt; Industrial design.\nâ‡’ How information is presented &gt; How to create new things\nThus, paper graphic design is not only relevant, but is a baseline\n\n\n\n                  \n                  Example \n                  \n                \nIf a person is in the mood for a movie, what questions might she have?\n\nWhat movies are showing today, at which times?\nWhat movies are showing around a particular time?\nWhere are they showing?\nWhat are they about?\nAre they good?\n\nConsider this redesign.\n\n\n\nTimeline visualizes and invites time comparisons\nâ€œWhat is showingâ€ is boldly presented\nCinemas are color-coded for easy comparison\n\nContext-Sensitive Graphics Â§\n\nDigital interfaces are better than paper because information is context-sensitive.\n\nIt can link to more information\n(instead of having to search paper)\nIt can present data in different ways according to what the user needs\n(instead of being static data on paper)\n\n\n\nInteractivity is Bad Â§\n\nFor all information software, interaction == navigation in data-space\n\nContextual software should already know what user wants\nNavigation is effortful and bad.\n\n\nTo reduce manipulationâ€¦\n\nContext-Sensitive Specialized Controls:\nTight Feedback loops (immediate results)\n\n\n\n"},"(Book)-The-Case-for-Economic-Democracy":{"title":"The Case for Economic Democracy","links":[],"tags":["Economics/Game-Theory","Philosophy/Political-Philosophy"],"content":""},"(HowTo)-Cost-Minimization":{"title":"(HowTo) Cost Minimization","links":["Profit-Maximization","Lagrangian-Optimization"],"tags":["Economics/Micro-Economics"],"content":"See also Profit Maximization\nLong Run Cost Minimization Â§\nminl,kâ€‹Â C=wl+rkÂ suchÂ thatÂ x=f(x)\n\nLagrangian Optimization\nOptimal when Isoquant is tangent to the isocost\n\nHigher isoquant is not always better! it just means youâ€™re producing more\n\n\n\n\n\n                  \n                  Warning \n                  \n                \nBeware when MC is monotonically decreasing. This means that the firm will produce zero or infinity, which is means it is a special case which you need to analyze separately.\n\n"},"(Philosopher)-Alexandre-Kojeve":{"title":"(Philosopher) Alexandre Kojeve","links":[],"tags":["People","Philosophy"],"content":"\nAlexandre KojÃ¨ve (koh-ZHEV, French: [alÉ›ksÉ‘ÌƒdÊ kÉ”Ê’É›v]; 28 April 1902â€“4 June 1968) was a Russian-born French philosopher and statesman whose philosophical seminars had an immense influence on 20th-century French philosophy, particularly via his integration of Hegelian concepts into twentieth-century continental philosophy. As a statesman in the French government, he was instrumental in the formation of the European Union.\nWikipedia\n"},"(Philosopher)-Edmund-Husserl":{"title":"(Philosopher) Edmund Husserl","links":["Phenomenology"],"tags":["People"],"content":"See Phenomenology."},"(Philosopher)-G.-W.-F.-Hegel":{"title":"(Philosopher) G. W. F. Hegel","links":["(Book)-Phenomenology-of-Spirit"],"tags":["People","Philosophy"],"content":"\nGeorg Wilhelm Friedrich Hegel (; German: [ËˆÉ¡eËÉ”Êk ËˆvÉªlhÉ›lm ËˆfÊiËdÊÉªÃ§ ËˆheËÉ¡lÌ©]; 27 August 1770â€“14 November 1831) was a German philosopher and one of the most influential figures of German idealism and 19th-century philosophy.\nBorn in 1770 in Stuttgart, Holy Roman Empire, during the transitional period between the Enlightenment and the Romantic movement in the Germanic regions of Europe, Hegel lived through and was influenced by the French Revolution and the Napoleonic wars. His fame rests chiefly upon (Book) Phenomenology of Spirit, The Science of Logic, his teleological account of history, and his lectures at the University of Berlin on topics from his Encyclopedia of the Philosophical Sciences.\nGuided by the Delphic imperative to â€œknow thyself,â€ Hegel presents free self-determination as the essence of humankindâ€“a conclusion from his 1806â€“07 Phenomenology that he claims is further verified by the systematic account of the interdependence of logic, nature, and spirit in his later Encyclopedia. He asserts that the Logic at once preserves and overcomes the dualisms of the material and the mentalâ€“that is, it accounts for both the continuity and difference marking of the domains of nature and cultureâ€“as a metaphysically necessary and coherent â€œidentity of identity and non-identity.â€\nWikipedia\n"},"(Philosopher)-Martin-Heidegger":{"title":"(Philosopher) Martin Heidegger","links":["Phenomenology"],"tags":["People"],"content":"See Phenomenology."},"10-09-Notes":{"title":"10-09 Notes","links":["Normative-Scripts","Ground-Truth","Emergent-Phenomena","Validating-Emotions","Gender-is-a-performance","Optimistic-Nihilism","tags/Computing","tags/Economics","tags/Literature","Phenomenology","emergent-phenomena","tags/sociability","tags/Sociability/Dating","Communication","Solipcism","Honesty"],"tags":["Journal-Entry","Computing","Economics","Literature","sociability","Sociability/Dating"],"content":"\nNormative Scripts of gender are grounded on biology but unfounded. Emergence of diverse modes of social interaction necessitate better ways of interaction\nYour Validating Emotions: your desire to be percieved as the cute girl, to perform that role (Gender is a performance) is built upon\n\nYour history in korea and japan\nyour past relationships\n\n\nOptimistic Nihilism. The problem is that you have it all figured out. Donâ€™t be humble, donâ€™t shy away from facing the void that there is not much else out there. This is all there is, and thatâ€™s okay. Facing the void, saying that thatâ€™s okay, and then to build something from it.\nBuilding:\n\n\n#Computing as a method of building the mechanized world\n\n\n#Economics as the elegant dance of these emergently rational parts\n\n\n#Literature as the observation, the phenomelogical stance of taking the grand experience in its entirety (Oh me! oh life!)\n\n\nPhysics as the futile goal of a bygone era of human excellence, humanism that trumped it all, that rationality could conquer the forces of all emergent phenomena. And we couldnâ€™t.\n\n\n#sociability and#Sociability/Dating as a construction of a Communication channel between humans\n\nCommunication is humanityâ€™s resolution with Solipcism. Fundamental Misunderstanding can be resolved through Communication\n\n\n\nYour brain as a linear machine that cannot inherently focus on the graph, the whole picture in a visual, direct way but only in an intuitive way.\n\n\n\nMethodollogical issues\n\nThe importance of being purely honest with your own emotions\n\n\n\n"},"581-Exam-Topics":{"title":"581 Exam Topics","links":[],"tags":["Courses"],"content":"Chapter 2: Time Value of Money Â§\n\n Simple vs compound interest\n From compound interest to continuous compounding\n Formulas for PV and FV of an annuity\n Amortization (payment towards interest and principal)\n PV and FV of Bonds\n Stock valuation (DDM)\n\nChapter 3: Portfolio Theory Â§\n\n 2-securities: finding the global minimum variance portfolio using 1variable calculus\n Cases for Ï = 0, Ï = Â±1\n N-securities: finding the global minimum variance portfolio using Lagrange\n Understanding matrices V and H, quantities A, B, and C\n\nChapter 4: Capital Market Theory Â§\n\n Understanding CML and SML lines\n Finding the sharp ratio and equation of the CML\n Deriving weight and risk-return of the Market Portfolio\n Deriving the formula for the Beta\n\nChapter 5: Binomial Tree Models Â§\n\n Understanding the definition of a general binomial tree\n Deriving formulas for u_n, d_n, and p_n for the CRR tree\n From Binomial Tree to the Lognormal Model\n\nChapter 6: Stochastic Calculus Â§\n\n Definition of SBM and GBM\n Intuition behind SBM: the symmetric random walk\n Properties of SBM in relation to the random walk\n Properties of the Lognormal Model for security prices\n Definition of the stochastic integral\n Using Itoâ€™s formula in simple cases\n\nChapter 7&amp;8: Derivatives and the BSM Model Â§\n\n Terminal payoff diagrams for Call and Put\n Put- []Call parity\n Binomial tree model for call options\n From Binomial tree model to the BSM formula\n Deriving the BSM PDE\n Understanding the BSM formula for Call and Put\n"},"Abstraction":{"title":"Abstraction","links":["Mooreâ€™s-law","Abstraction","Pipelining","Branching-(Computer-Science)","Instruction-Set"],"tags":["Computing/Computer-Architecture"],"content":"1.2. 8 Great Ideas from Computer Science Â§\n\nMooreâ€™s law\nAbstraction\nOptimize for the Common Case\nParallelism â†’ thruput increase\nPipelining â†’ thuput increase\nPrediction\nMemory Heirarchy\nRedundancy\n\nAbstraction: Application Software &gt; Systems Software &gt; Hardware.\nAbstraction: High Level Language &gt; Assembly Language &gt; Binary Machine Language\nComponents of a Computer Â§\nComponents of a Computer: Input/Output, Memory, Datapath, Control. Datapath &amp; Control are sometimes combined as the CPU. Examples of I/O Devices: LCD displays (with frame buffers as pixels), touchscreens, etc.\nMemory is built from DRAM (Dynamic Random Access Memory) (â†” Sequential random access memory, which is old technology). Memory Heirarchy: Main Memory (DRAM) &gt; Seconday Memory (magnetic disks, flash memory).\nInstruction Set Architecture (=architecture) is the information developers need to develop a proper binary machine language program, including I/O, memory layout, etc. ABI (Application Binary Interface) is the combination of the instruction set and the OS interface.\n\nTransistor: a electric switch\nVISI (Very Large-Scale Integrated Circuit): ICs with millions and billions of trasnsistors\n(Mooreâ€™s law predicts the geometric increase in the number of transistors per area.)\n\nManufacturing process of ICs\nSilcon Ingot â‡’ Wafers â‡’ (processing steps) â‡’ Patterned Wafers â‡’ Diced Wafers (Dies) â‡’ Packaged Dies (patterned wafers, diced wafers and packaged wafers are each tested.)\n\nDefects can occur in each testing process. Yield measures the percentage of good dies from total # of dies on wafer.\nCost of manufactoring, due to defects, is generally proportional to the square of each die area. Which means itâ€™s impractical to design very big dies.\n\nParallelism Â§\nImprovement of response time fo CPUs began to slow around 2002. Since then cpu architects started to use multicore processors to augment performance. But since programmers had to rewrite programs for them it was hard to adoptâ€”due to the overhead of communication &amp; synchronization.\n1.9. Real Stuff: Benchmarking the Intel Core I7 Â§\nSPEC (System Performance Evaluation Cooperative) released standard benmarks for common programs. Types: integer benchmark / floating point benchmark. They give a score called a SPECratio per program which is calculated by: SPECratio=executionÂ timereferenceÂ timeâ€‹ where reference time is from a reference processor and execution time is from the processor being benchmarked. The higher the better. Overall SPECratio of the CPU is a geometric mean of all programsâ€™ SPECratios.\nSPEC also released a SPECpower power consumption benchmark. It measures average power consumption and ssj_ops (server side Java operations per second), at load increments from 10%, 20%, â€¦, 100%. The final number given is:\noverallÂ ssj_opsÂ perÂ watt=âˆ‘i=010â€‹poweriâ€‹âˆ‘i=110â€‹ssj_opsiâ€‹â€‹"},"Ackerman-Function":{"title":"Ackerman Function","links":["Limits-of-Math-and-Computing"],"tags":["Computing/Algorithms","Math"],"content":"def. Ackerman Function. The Ackerman function satisfies the following recurrence relations:\n\nA(k,n)=A(kâˆ’1,A(k,nâˆ’1))\nA(k,1)=2\nA(1,n)=2n\n\n\nExample:\n\nA(2,n)=A(1,A(2,nâˆ’1))=â‹¯=A(1,A(1,â€¦A(2,1)))=2n\nA(3,n)=2â†‘n\n\n\n\nProperties Â§\n\nGrows really fast\nAppears in Limits of Math and Computing\n"},"Agents-of-the-Macro-Economy":{"title":"Agents of the Macro Economy","links":["Profit-Function","Cobb-Douglas-Utility-(Two-Goods)"],"tags":["Economics/Macro-Economics"],"content":"Agents Â§\n\n\n                  \n                  Weâ€™re doing static analysis; i.e. itâ€™s very LR or very SR. \n                  \n                \n\nNumerous agents of each sector are grouped into a representative agent.\n\n\nRepresentative household\nObjective: maximize utility over consumption (C) and Leisure (L) within the utility function\nâ†’ Labor Supply SN and # of laborers N\nâ†’ Goods Demanded D\n\n\nRepresentative Firm\nObjective: maximuze profit (Ï€) over capital (K) and Labor (N) within the production function\nâ†’ Labor Demand DN\nâ†’ Goods Supplied S\n\n\nGovernment\nRole: collect taxes and pay transfers (NT); spend remaining on the goods market G\n\n\nHousehold Optimization Â§\n\nFor households the price of consumption goods and the price of leisure [=wage] is an exogenous variable; i.e. it cannot be controlled\nHouseholds have a time endownment of h which they can use for leisure (L) or consumption (C)\n\nThe Household Utility Function u(C,L)\nAssumptions:\n\nâˆ‚Câˆ‚uâ€‹,âˆ‚Lâˆ‚uâ€‹&gt;0 â€¦i.e. More consumption/leisure is always better\nâˆ‚C2âˆ‚2uâ€‹,âˆ‚K2âˆ‚2uâ€‹&lt;0\nâ€¦i.e. the Marginal Utility always diminishes\nâˆƒâˆ‚Câˆ‚uâ€‹\n[= utility function is differentiable] â€¦i.e. C,L are somewhat substitutable\nâ†’ MRS=âˆ‚u/âˆ‚Lâˆ‚u/âˆ‚Câ€‹âˆ£uË‰â€‹\n\nHousehold Budget Constraint\nwN+Ï€âˆ’NT=C\n\nw is the representative wage\nN is the hours of labor a HH chooses\nÏ€ is profit or dividends if the HH is also an owner of a firm\nNT is the net transfers (+transfers-taxes)\nC is consumption (in units: # of goods)\n\n\nFirm Optimization Â§\n\nThe representative firm employs Factors of Production (K,N) to produce YS=f(K,N) output\nProfit of the firm is Ï€=f(K,N)âˆ’wNâˆ’rK\nThe firm is the average firm of the whole economy, which is unlike a microecon firm in many ways\n\nThe Firm Production Function f(z,K,N)\nAssumptions:\n\nConstant Returns to Scale (M&amp;A is useless)\nxÎ»f(z,K,N)=f(z,Î»K,Î»N)\nâ†’ This is probable, since output as a whole in general has CRS\nMore capital or more labor always means more output\nâˆ‚Kâˆ‚Yâ€‹,âˆ‚Nâˆ‚Yâ€‹&gt;0, equivalently MPKâ€‹,MPNâ€‹&gt;0\nâ†’ Probable; throw another pencil into the economy, itâ€™ll produce more\nDiminishing Marginal Product\nâˆ‚K2âˆ‚2Yâ€‹,âˆ‚K2âˆ‚2Yâ€‹&lt;0\nMarginal product of capital increase with more labor, and vice versa\nâˆ‚Kâˆ‚Nâˆ‚Yâ€‹&gt;0 [= positive cross-derivative]\n\nProfit Function\nâˆ‚Kâˆ‚Ï€â€‹=âˆ‚Kâˆ‚fâ€‹âˆ’r=0\nâˆ‚Nâˆ‚Ï€â€‹=âˆ‚Nâˆ‚fâ€‹âˆ’w=0\nâ†‘ Must satisfy both conditions\n\nâ‡’ The Cobb-Douglas Production Function satisfies all these assumptions:\nf(z,K,N)=zKÎ±N1âˆ’Î±Â whereÂ Â 0&lt;Î±&lt;1\n\nProfit Ï€=zKÎ±N1âˆ’Î±âˆ’wNâˆ’rK\nCapital Demand, âˆ‚Kâˆ‚Ï€â€‹=0 at zâ‹…Î±(NKâ€‹)Î±âˆ’1=r\nLabor Demand, âˆ‚Nâˆ‚Ï€â€‹=0 at zâ‹…(1âˆ’Î±)(NKâ€‹)Î±=w\n\nGovernment Plans Â§\nThe governmentâ€™s goals are more vague, threefold:\n\nAllocative: resources are used in certain proportions\nDistributive: income, wealth is distributed at tolerable equalities\nStabilization: business cycle is smoothed out\n\nAutomatic stabilizers; e.g. unemployment benefits\ngovernment purchases (G)\n\n\n"},"Algorithm-Problem-Tips":{"title":"Algorithm Problem Tips","links":["Scratchpad","Problem-Sets","Python-Common-Operations","Time-Complexity","Priority-Queue","Hash-Table","Dynamic-Programming","Sliding-Window-Technique"],"tags":["Computing/Algorithms","Computing/Data-Structures","Meta-Learning"],"content":"During Practice Â§\n\nThere are only two ways to store data structures: as arrays (sequential storage) or as linked lists (linked storage).\n\n\nFirst of all, it should be clear that data structures are tools, and algorithms are methods to solve specific problems with appropriate tools.\n\n\nUse a plain-text editor as Scratchpad\nRecord new techniques/algorithms\nItâ€™s okay to look at solutions after a certain period of trying.\nUse syntactic sugar &amp; libraries. Python has lots.\nComment above every line while coding\n\nDuring Testing Â§\n\nBrute Force â†’ Better Data Structures/Algorithms â†’ Even better time complexity\n\nAlways ask: can reduce Time Complexity even further?\n\nExponential is never good. Polynomial is not enough. Linear time!\n\n\nPriority Queue / Hashmap / Dynamic Programming / Sliding Window Technique\nTry thinking: What property doesnâ€™t change? What variable is constant?\nTry thinking: Invert the search; find the contrapositive\n\n\nAre you {python}returning?\nEdge cases\n\ninfinite loops are probably not it\nâ‡’ make the while loops conditioned on index boundaries\n\n\nTest the program yourself on a text editor\nTry to defeat the problem (find very weird test inputs)\n"},"Algorithm":{"title":"Algorithm","links":["Complexity","Mathematical-Proof","Mathematical-Induction","Proof-by-contradiction","Testing-Principle"],"tags":["Computing","Math"],"content":"Loose definition\n\n\n                  \n                  Note \n                  \n                \nAn algorithmâ€¦\n\nfinishes in finite number of steps\nits answer is consistent\nit always gives the correct answer\n\n\nAlgorithm Design Principles Â§\n\nDesign\n\nWhat to compute\nHow it computes what we want it to compute\n\n\nCorrectness\n\nWhy does it compute what we want it to compute\n\n\nAnalysis &amp; Efficiency\n\nHow much resources does it use? (Complexity)\n\n\n\nMost algorithms follow the following two standard models of computation\n\nRecursion\nIteration\n\nVerifying Correctness Â§\n\n\n                  \n                  Warning \n                  \n                \nThere is no way to find out if an algorithm is correct.\n\n\nMathematical Proof\n\nDirect Proof\n\nMathematical Induction\n\nâ‡’ Recursive algorithms looks similar to proof by induction\n\n\n\n\nIndirect Proof [=Proof by contradiction]\n\n\nTest experimentally\n"},"Alienation":{"title":"Alienation","links":["Proletatriat-(Marxism)","Alienation","Species-being"],"tags":["Philosophy/Marxism"],"content":"Commoditization of human labor Â§\n\nTrading labor\n\n\nDifferences of age and sex have no longer any distinctive social validity for the working class. All are instruments of labour, more or less expensive to use, according to their age and sex.\n\nâ‡’ The wage-laborer is homogenized into a single indistinguishable set\nEstrangement/Alienation Â§\n\nAlienation of the Commodity, the production\n\n\nIt is the same in religion. The more man puts into God, the less he retains within himself. The worker places his life in the object; but now it no longer belongs to him, but to the object. [â€¦] not only that his labour becomes an object, an external existence, but that it exists outside him, independently of him and alien to him, and begins to confront him as an autonomous power; that the life which he has bestowed on the object confronts him as hostile and alien.\n\n\nAlienation of Human Creativity\n\n\nSo if the product of labour is alienation, production itself must be active alienation, the alienation of activity, the activity of alienation.\n\n\nHence the worker feels himÂ­ self only when he is not working; when he is working he does not feel himself. [â€¦] It is therefore not the satisfaction of a need but a mere means to satisfy needs outside itself. Its alien character is clearly demonstrated by the fact that as soon as no physical or other compulsion exists it is shunned like the plague.\n\n\nJust as in religion the spontaneous activity of the human imagination, the human brain and the human heart detaches itself from the individual and reappears as the alien activity of a god or of a devil, so the activity of the worker is not his own spontaneous activity. It belongs to another, it is a loss of his self.\n\nâ‡’ Thus ultimately alienation from the Species-being"},"Amartya-Sen":{"title":"Amartya Sen","links":["Human-Development-Index","(Article)-Equality-of-What-q","Martha-Nussbaum"],"tags":["People"],"content":"\nDeveloper of the Human Development Index\nAuthor of (Article) Equality of What?\nFrequent interactions with Martha Nussbaum\n"},"Analytic-Philosophy":{"title":"Analytic Philosophy","links":[],"tags":["Philosophy/Analytic"],"content":""},"Anarcho-Syndicalism":{"title":"Anarcho-Syndicalism","links":["Noam-Chomsky","Decentralization","Capital-(Marxism)","Karl-Marx"],"tags":["Philosophy/Political-Philosophy","Economics/Game-Theory"],"content":"Noam Chomsky\n\nAnarcho-: Decentralization of power\nSyndicalism: Workerâ€™s unionâ€™s ownership of Means of Production\nA realistic alternative to Marxism\n"},"Annuity":{"title":"Annuity","links":["assets/Proof.png","Future-Value-Calculations"],"tags":["Economics/Finance"],"content":"Annuities areâ€¦\n\nMoney you borrowed: mortgages, etc. â‡’ pay regularly to pay off large amount\nMoney you lent: social security credit, etc. â‡’ give large money, get regular payments later\n\nAmortization is the same thing but from a different perspective\nâ‡’ Youâ€™re spreading a one-time cost into multiple years. Formulae are same if the recurring payments are of the same amount.\nTypes of Annuities\n\nOrdinary Annuity: payment occurs at the end of each period\nSimple Ordinary Annuity:\nCurrentÂ balance=Prev.Â balance+InterestÂ onÂ previousÂ balanceâˆ’Payment\n\nFormulae for Constant Payment P Â§\n\nn: Term; time from first payment to last payment (in years)\nAnâ€‹: Present value of annuity of n terms.\nSiâ€‹: Total payment accrued after i periods (not a present value!)\ny=1+krâ€‹ for formula simplification\n\n\nPreset value of annuity (=Anâ€‹) formula. (see below for more)\n\n(i.e. the principal loan amount, mortgage loan amount, etc.)\n\n\n\nAnâ€‹:=(1+r/k)Pâ€‹+(1+r/k)2Pâ€‹+â€¦(1+r/k)nPâ€‹\n\nPayment accrued after all n periods (=Snâ€‹ =Future value of annuity after all payments made)\n(Demonstration, use geometric sum formula)\n\nSnâ€‹â€‹=P+(1+krâ€‹)P+(1+krâ€‹)2P+â‹¯+(1+krâ€‹)nâˆ’1â‹…P=r/k(1+r/k)nâˆ’1â€‹â‹…P=yâˆ’1ynâˆ’1â€‹â‹…Pâ€‹â€¦(0)â€‹â€‹\n\nSimplified formula of PV using 1. and 2.\n\nAnâ€‹â€‹=(1+r/k)nSnâ€‹â€‹=r/k1âˆ’(1+r/k)âˆ’nâ€‹â‹…P=yâˆ’11âˆ’yâˆ’nâ€‹â‹…Pâ€‹timeÂ valuefromÂ (0)â€‹â€‹\n\nRemaining balance after i periods (=Biâ€‹)\n\nBiâ€‹â€‹=(1+krâ€‹)nâˆ’1(1+krâ€‹)nâˆ’(1+krâ€‹)iâ€‹Anâ€‹=ynâˆ’1ynâˆ’yiâ€‹Anâ€‹â€‹â€‹â€‹\nPortion of the i-th payment Piâ€‹ that goes toâ€¦\nPrincipal\nBiâ€‹=krâ€‹ynâˆ’1yiâˆ’1â€‹Anâ€‹\n\nTotal Principal â‡’ âˆ‘i=1nâ€‹Biâ€‹=Anâ€‹\n\nInterest\n\nEvery period, interest is fully paid.\nInterest is applied to the remaining balance B (not to be confused with B)\n\nIiâ€‹=krâ€‹Biâˆ’1â€‹=krâ€‹ynâˆ’1ynâˆ’yiâˆ’1â€‹Anâ€‹\n\nTotal Interest â‡’ âˆ‘i=1nâ€‹Iiâ€‹=nPâˆ’Anâ€‹\n\nâ‡’ Thus the total payment: âˆ‘i=1nâ€‹Piâ€‹=nP\n\nConsider k-periodic compounding (=k times every year)\nCost of Loan: ignoring the time value of money, sum of all interest payments nPâˆ’Anâ€‹\nAs montly payment P increases, number of payment periods n decays exponentially.\n\n\nFormulae for Variable Interest Rates Â§\nVariables are same as above, except:\n\nPiâ€‹: payment after period i\nriâ€‹: interest rate during period i\n\n\nPresent value of annuity (Anâ€‹)\n\nAnâ€‹â€‹=l=1âˆ‘nâ€‹âˆj=1lâ€‹(1+krjâ€‹â€‹)Plâ€‹â€‹=âˆj=1nâ€‹(1+krjâ€‹â€‹)Snâ€‹â€‹â€‹â€‹"},"Approximating-Distributions":{"title":"Approximating Distributions","links":["Normal-Distribution","Poisson-Distribution"],"tags":["Math/Probability"],"content":"thm. A Normal Distribution with Î¼=np,Ïƒ=np(1âˆ’p)â€‹ will approximate a Binomial distribution with n trials and success probability p when np&gt;1\nP(aâ‰¤Xâ‰¤b)=k=aâˆ‘bâ€‹P(X=k)â‰ƒâˆ«abâ€‹fnormalâ€‹(Î¼=np,Ïƒ=np(1âˆ’p)â€‹)dx\nREMARK. A Normal Distribution is equivalent to the following standard normal distribution:\nâˆ«aâˆ’0.5b+0.5â€‹Normal(Î¼,Ïƒ)dx=âˆ«a+0.5b+0.5â€‹Ïƒ2Ï€â€‹eâˆ’21â€‹(Ïƒxâˆ’Î¼â€‹)2â€‹dx=âˆ«Ïƒaâˆ’0.5âˆ’Î¼â€‹Ïƒb+0.5âˆ’Î¼â€‹â€‹Normal(0,1)du=âˆ«Ïƒaâˆ’0.5âˆ’Î¼â€‹Ïƒb+0.5âˆ’Î¼â€‹â€‹2Ï€â€‹eâˆ’x2/2â€‹dx\nwhere the factor of +0.5 to the integrandâ€™s range is the continuity correction.\nthm. A Poisson Distribution with parameters Î»=np will approximate a Binomial distribution with n trials and success probability p when npâ‰¤1.\nXâˆ¼B(n,p)â‡’P(X=k)=k!Î»keâˆ’Î»â€‹=k!(np)keâˆ’(np)â€‹\nthm. A Binomial Distrubition with parameters p=NKâ€‹ will approxmiate a Hypergeometric Distribution when N&gt;&gt;n\nXâˆ¼Binomial(n,p)â‡“P(X=k)â‰ƒ(knâ€‹)(NKâ€‹)k(NNâˆ’Kâ€‹)nâˆ’kâ€‹â€‹\nx1â€‹Ã—x2â€‹âˆ«f(x1â€‹,x2â€‹)dx"},"Approximation-Algorithm":{"title":"Approximation Algorithm","links":[],"tags":["Computing/Algorithms"],"content":"def. Approximation Factor. Î±(n)-level approximation. For optimization problem Ï€, ALG is a Î±-level optimization algorithm iff for input I of size n:\nmax[OPT(I)ALG(I)â€‹,ALG(I)OPT(I)â€‹]=Î±(n)\n\nSmaller is better!\nConstant approximation factor: if approximation factor doesnâ€™t depend on n, ALG is a constant Î±-level approximation\n"},"Artificial-Needs":{"title":"Artificial Needs","links":["private-property","abstraction"],"tags":["Philosophy/Marxism"],"content":"Normally itâ€™s human nature from which arises naturally the needs, and capital should be appropriated for\n\nUnder the system of private property their significance is reversed. Each person speculates on creating a new need in the other, with the aim of forcing him to make a new sacrifice, placing him in a new dependence and seducing him into a new kind of enjoyment and hence into economic ruin.\n\n\nMan becomes ever poorer as a man, and needs ever more money if he is to achieve mastery over the hostile being.\n\nand this extends to all aspects of human life\n\nMoreover, the worker has no more than a precarious right to live in it, for it is for him an alien power that can be daily withdrawn and from which, should he fail to pay, he can be evicted at any time. He actually has to pay for this mortuary.\n\nâ€¦ultimately our lives are deprived of natural human needs\n\nworker. Light, air, etc. - the simplest animal cleanliness - ceases to be a need for man. [â€¦] Dirt - this pollution and putrefaction of man, the sewage of civilization - becomes an element o f life for him.\n\nâ€¦and captial even justified this:\n\nThe fact that the multiplication of needs and of the means of fulfilling them gives rise to a lack of needs and of means is proved by the political economist:\n\n\nBy reducing the workerâ€™s needs to the paltriest minimum necessary to maintain his physical existence and by reducing his activity to the most abstract mechanical movement.\nBy taking as his standard - his universal standard, in the sense that it applies to the mass of men - the worst possible state of privation which life (existence) can know.\n\n\n\n\nâ€¦and ultimately â€œsavingâ€ or â€œnot feelingâ€ is now a virtue:\n\nPolitical economy, this science of wealth, is therefore at the same time the science of denial, of starvation, of saving, and it actually goes so far as to save man the need for fresh air or physical exercise.\n\n\nThe less you eat, drink, buy books, go to the theatre, go dancing, go drinking, think, love, theorize, sing, paint, fence, etc., the more you save and the greater will become that treasure which neither moths nor maggots can consume - your capital The less you are, the less you give expression to your life, the more you have, the greater is your alienated life and the more you store up of your estranged life.\n\nMoney, Specifically Â§\n\nincreases. The need for money is for that reason the real need created by the modem economic system, and the only need it creates.\n\nabstraction above the thing:\n\nJust as it reduces everything to its own form of abstraction, so it reduces itself in the course of its own movement to something quantitative.\n\nand thus this requires its production\n\nthis is manifested partly in the fact that the expansion of production and needs becomes the inventive and ever calculating slave of inhuman, refined, unnatural and imaginary appetites - for private property does not know how to transform crude need into human need. Its idealism is fantasy, caprice and infatuation.\n"},"Ascending-Price-Auction":{"title":"Ascending Price Auction","links":["VCG-Auction","Combinatorial-Auction","Rationality-(Economics)","Types-of-Goods-(Economics)"],"tags":["Economics/Game-Theory"],"content":"Motivation. The VCG Auction is DSIC and Welfare-maximizing. But itâ€™s also very complicated to explain to all agents. Instead, letâ€™s think of a simpler, intuitive idea: ascending price auctions. Now, in a Combinatorial Auction setting, there are two ways to ascend the price:\n\nAscending item price\nAscending bundle price\nBefore we proceed, we need to introduce definitions and properties.\n\n\ndef. Demand. For valuation function v, let item prices p1â€‹,â€¦,pnâ€‹. Agent demands bundle Sâˆ— of this valuation if S the utility-maximizing bundle, i.e:\nSâˆ—=argmaxSâ€‹v(S)âˆ’jâˆˆSâˆ‘â€‹pjâ€‹\nRemark. There may be multiple utility-maximizing bundle. Therefore we often collect all bundles that are utility-maximizing, and make it into a demand set D\nAscending Item Price Auction Â§\n\nAn Ascending item price auction has prices for each item, and increase the price of each item.\ndef. Walrasian Equilibrium. (WE) In a Combinatorial Auction, given the prices p1âˆ—â€‹,â€¦,pjâˆ—â€‹, let goods in X partitioned into S1â€‹,â€¦,Snâ€‹. This allocation this is a W.E. if:\n\nSiâ€‹ is demanded by i, (=Siâ€‹ maximizes iâ€™s utility =Siâ€‹âŠ†Diâ€‹)\nIf pjâˆ—â€‹&gt;0 then item j has an owner.\n\nthm. First Welfare Theorem. (FWT) Given price p1âˆ—â€‹,â€¦,pjâˆ—â€‹, if Allocation W.E. is welfare-maximizing.\nProof. Let S1âˆ—â€‹,â€¦,Snâˆ—â€‹ be the welfare-maximizing partition/price to a Combinatorial Auction, i.e. the W.E. Then consider any other partition T1â€‹,â€¦,Tnâ€‹. Then:\nâ– \nThus, we need only show that the allocation is a WE in order to show that it is welfare-maximizing. Now:\ndef. Ascending Item Price Auction.\n\nStart at pjâ€‹=0 for all items\nfor all agents, agent i â€œpoints toâ€ all items (Diâ€‹) that maximizes Î¼iâ€‹(Diâ€‹)=viâ€‹(Diâ€‹)âˆ’âˆ‘jâˆˆDiâ€‹â€‹pjâ€‹ at that price\nIf there are two agents that choose the same item, increase that itemâ€™s price by a small amount, Ïµ.\n\n&amp; You can choose which item price to raise firstâ€”different choices will lead to different final allocations.\n\n\nRepeat, until for all items there is only one agent pointing to it.\nGive that agent all the items they are pointing to at that price.\nWe define a property (subset of Rational Taste) to assist the proof:\n\ndef. Substitutes Property. A value function v satisfies the substitutes property if, the increase of one itemâ€™s price does not remove any other items from the bundle it demands.\nExample. In other words, there is no situation of â€œleft shoe, right shoeâ€ (complement goods). If the price of left shoe increases above what they want to pay, this person will drop out of the left shoe and right shoe both. This does not satisfy the substitutes property.\nthm. (Ascending Item Price Auction Maximizes Welfare) If all agentâ€™s value function viâ€‹ satisfies the substitutes property, and no two agent values the good within Ïµ of each other the Ascending Item Price Auction terminates in a WE (and thus is welfare-maximizing via the FWT.)\nProof.\n\nAuction will terminate, because the item price is only increased when it is in someoneâ€™s demand set.\nAt termination, if the price of item j is non-zero, it is in somebodyâ€™s demanded bundle D)iâ€‹. This is because\n\nthe price was raised from zero because somebody was pointing to it\ntwo people cannot simultaneously drop out of it (Â±Ïµ)\nThe raise of another itemâ€™s price does not cause any agent to drop j\nâ‡’ therefore if termination price pjâˆ—â€‹&gt;0 then it is in somebodyâ€™s demand bundle Diâ€‹ (Second property of WE).\n\n\nAt every point in time, all agents point to only their demanded bundle. (First property of WE)\nâ– \n\nAscending Personalized Bundle Price Auction. Â§\nAn Ascending bundle price auction has an individualized price for every bundle. We describe an alternative type of equilibrium and prove that such an allocation is maximizing. It is not DSIC.\ndef. Competitive Equilibrium. (CE) let personalized prices piâ€‹(Siâ€‹) for every agent, for every bundle, and allocation S1â€‹,â€¦Snâ€‹ be a partition of goods X. This price and allocation is a competitive equilibrium iff:\n\nSiâ€‹ is demanded by i, i.e. it utility maximizes for i, i.e. Siâ€‹âŠ†Diâ€‹\n\nThis is same as WE above.\n\n\nIt maximizes sellerâ€™s total revenue: maxSâ€‹âˆ‘âˆ€iâ€‹piâ€‹(Siâ€‹)\n\nthm. Competitive Equilibrium maximizes social welfare.\nâ– \ndef. Ascending Bundle Price Auction. \n\nlet pijâ€‹ be current prices, individualized for each bidder, for each bundle\nThen find the revenue-maximizing partition S1â€‹,â€¦,Snâ€‹\n\nThere may be many, arbitrarily choose one.\n\n\nlet â€œLoser Setâ€ L:={iâˆ£Siâ€‹î€ =âˆ…}, i.e. agents that donâ€™t get anything\n\nFor every loser iâˆˆL get their demand bundle Diâ€‹ at these prices\nIncrease customized price of that bundle for i by Ïµ, i.e. piâ€‹(Diâ€‹)â†piâ€‹(Diâ€‹)+Ïµ.\n\n\nRepeat from 2, until L=âˆ… or no agents demand anything.\nThis all seems very arbitrary, but it will magically terminate at the CE.\n"},"Assets-(Finance)":{"title":"Assets (Finance)","links":["Equity","Commodities","Derivatives-(Finance)","Futures","Real-Estate"],"tags":["Economics/Finance"],"content":"Assets are anything thatâ€™s tradable.\n\nEquity\nCommodities\nDerivatives (Finance)\n\nFutures\n\n\nReal Estate\n\n\n\n                  \n                  Note \n                  \n                \nA debt for one person is an asset for the lender.\n"},"Assumptions-in-Derivative-Pricing":{"title":"Assumptions in Derivative Pricing","links":["Options-(Finance)","Present-Value-Calculations","Assumptions-in-Derivative-Pricing"],"tags":["Economics/Finance"],"content":"\nPayoff: the gross outcome of an investment or trade. The amount you earned from that trade, regardless of commissions, extraneous costs, etc.\nProfits: the gross outcome of an investment or trade, including commissions, extraneous cost\n\nâ†’ the distinction happens in Options (Finance). Payoffs donâ€™t consider the option premium, while the profits do.\n\n\nReturn: short for â€œrate of returnâ€. The percentage of profit (not payoff!) per original investment. Quoted in percentage (%) or log-returns.\n\nRisk-Neutral Assumption Â§\nA risk-neutral world is where there is no risk premium on return. This implies:\n\nAll Present Value Calculations are done at the risk-free rate\nAll assets have risk-free rate of return (=zero riAssumptions in Derivative Pricingitrage Condition]] holds\n&amp; This is not really realistic, but simplifies calculations a lot.\n\nNo Arbitrage Condition (=Law of One Price) Â§\nNo arbitrage condition means without any risk, there cannot be excess return (=return above risk-free rate).\nLaw of One Price states that:\n\nlet security A have payoff pAâ€‹, cost cAâ€‹ and B payoff pBâ€‹, cost cBâ€‹.\nIf pAâ€‹=pBâ€‹ then cAâ€‹=cBâ€‹\n"},"Atomic":{"title":"Atomic","links":["(Article)-Evergreen-notes"],"tags":["Computing","Meta-Learning"],"content":"Atomicity means indivisibility. Useful in a variety of contexts:\n\nProgramming &amp; Concurrency. atomic operations cannot have any operation happen between it during the operation i.e. it cannot be paused until completion\n(Article) Evergreen notes should be atomic for better, densely connected notes.\n"},"Atsugi":{"title":"Atsugi","links":[],"tags":["Computing"],"content":"AWS John the Ripper Instance Â§\nKey name is `ssh-key`\nLogin as User `ec2-user` \nHamonikr Vs ff.sh Â§\nSetting a custom resolution via cmdline\nChanging cinnamon desktop wallpaper from the terminal\nAtsugi Linode VM Â§\nManagement Console\nIP: 172.104.89.111 (ports 22, 8080 open for sshd)\nDomain: atsugi.pyoky.me\nusers: root (pw: oniichan) \n\nUsing a keyboard with Astugi (Phone) is immensly beneficial.\nAtsugi Moving to Chrome Â§\nenv LANGUAGE=en_US /usr/bin/chromium-browser --password-store=basic\nConfig is in ~/.config/chromium (This is the one you have to zip.)"},"Attention-is-Currency":{"title":"Attention is Currency","links":["Nudging","Stream-of-Content"],"tags":["Computing/Internet"],"content":"Your attention is the currency of the modern, corporate internet.\n\nIt is valued, monetized, and traded (as with your personal information)\nChoose how to give attention\nBuild in Friction to keep yourself from being consumed by the wealth of information.\nThere is always a Stream of Content. Choose what is important and stands out. Quality &gt; Quantity.\n"},"Auction-Theory":{"title":"Auction Theory","links":["Vickery-Auction","Revenue-Maximizing-Auctions","VCG-Auction","Ascending-Price-Auction"],"tags":["Economics/Game-Theory"],"content":"def. Sealed Bid Auction. An auction is a game where there are a certain number of buyers, buyers each have their value, viâ€‹ and bid, biâ€‹. The auction process takes in the bids of all buyers b, and outputs the allocation x(b) and price pâ€‹(b).\n\nx=âŸ¨x1â€‹,â€¦,xiâ€‹,â€¦,xnâ€‹âŸ© where xiâ€‹ is the allocation for buyer i\npâ€‹=âŸ¨p1â€‹,â€¦,piâ€‹,â€¦,pnâ€‹âŸ© where piâ€‹ is the price charged for buyer i\ne.g. if there is one item to be sold, and the i-th player gets it, then:\n\nx=âŸ¨0,â€¦,0,1,0,â€¦,0âŸ©\n\\vec{p}= \\langle 0,\\dots,0,\\9.37,0,\\dots0 \\rangle$\n\n\nNobody except i knowns their true value: viâ€‹\n\ndef. Quasilinear Utility Model. Each bidder, after the auction process finishes, has utility and welfare:\nutilityÎ¼iâ€‹(b)â€‹â€‹=welfare=valueviâ€‹xiâ€‹(b)â€‹â€‹âˆ’piâ€‹(b)\nTypes of Auctions Â§\nRemark. An auction can be not DSIC and welfare-maximizing ğŸ¤¯.\n\nSingle-Item\n\nDeterministic Valuations\n\nSecond Price (DSIC, Welfare-Max)\nFirst-Price (Revenue-Max)\n\n\nBayesian values\n\nVickery Auction with Reserve (DSIC if regular, Revenue-max)\n\n\n\n\nMulti-Item\n\nSingle-item Demand, Indivisible (=sponsored search)\n\nGeneralized Second Price (Welfare-Max)\nVirtual Second Price (Revenue-Max)\n\n\nCombinatorial Demand, Indivisible\n\nVCG Auction (DSIC, Welfare-Max)\nAscending Item Price â†’ W.E. (Welfare-Max)\n\n\nCombinatorial Demand, Indivisibleâ€”Price discriminatory\n\nAscending Individual Bundle Price â†’ C.E. (Welfare-Max)\n\n\nCombinatorial Demand, Indivisible, Bayesian\n\n? (Welfare-max)\n? (Revenue-max)\n\n\n\n\n\nProperties of an Auction Â§\nMotivation. An auctionâ€™s goal is to:\n\nMake sure each person tells the truth, i.e. viâ€‹=biâ€‹\nMaximize total utility, i.e. âˆ‘Î¼iâ€‹\nSometimes, to maximize seller revenue.\nTherefore, we want an auction that will satisfy the following two properties.\n\ndef. Welfare Maximizing (=Socially Efficient). An auction is welfare-maximizing iff Given all bidders are truthful, then it maximizes âˆ‘âˆ€iâ€‹viâ€‹xiâ€‹(b)\ndef. Dominant Strategy Incentive Compatibility (DISC). Intuition: all bidders are incentivized to tell the truth. An auction is DISC iff:\nâˆ€i,âˆ€b,regardlessÂ ofÂ bâˆ’iâ€‹,utilityÂ forÂ tellingÂ truthÎ¼iâ€‹(viâ€‹,bâˆ’iâ€‹)â€‹â€‹â‰¥utilityÂ forÂ lyingÎ¼iâ€‹(biâ€‹,bâˆ’iâ€‹)â€‹â€‹\ndef. Revenue Maximizing (=Optimal). See Revenue-Maximizing Auctions.\nMyersonâ€™s Lemma (or, How to Be DSIC) Â§\nMotivation. Instead of directly showing that an auction mechanism is DSIC, it is enough for it to satisfy the properties of the following Myersonâ€™s lemma.\nthm. Myersonâ€™s Lemma. An auction is DSIC (=truthful) if and only if it satisfies the following to properties:\n\nGiven other agentâ€™s bids bâˆ’iâ€‹, the allocation function xiâ€‹(biâ€‹,) is a monotonically increasing function\n\ni.e. if biâ€²â€‹&gt;biâ€‹ then xiâ€‹(bâ€™iâ€‹,bâˆ’iâ€‹)â‰¥xiâ€‹(biâ€‹,bâˆ’iâ€‹)\n\n\nGiven bâˆ’iâ€‹, the optimal price piâ€‹(biâ€‹)=biâ€‹xiâ€‹(biâ€‹)âˆ’âˆ«0biâ€‹â€‹xiâ€‹(z)dz\n\nProof.\nProperty 1. Allocation is monotonic w.r.t. bid amount. (=bid more, get more)\nproof. By definition of DSIC, both of the following holds:\n\nreports biâ€‹, actual value viâ€‹: viâ€‹xiâ€‹(viâ€‹)âˆ’piâ€‹(viâ€‹)â‰¥viâ€‹xiâ€‹(biâ€‹)âˆ’piâ€‹(biâ€‹) â‡’ viâ€‹[xiâ€‹(viâ€‹)âˆ’xiâ€‹(biâ€‹)]â‰¥piâ€‹(viâ€‹)âˆ’piâ€‹(biâ€‹)\nreports viâ€‹, actual value biâ€‹: biâ€‹xiâ€‹(biâ€‹)âˆ’piâ€‹(biâ€‹)â‰¥biâ€‹xiâ€‹(viâ€‹)âˆ’piâ€‹(viâ€‹) â‡’ piâ€‹(viâ€‹)âˆ’piâ€‹(biâ€‹)â‰¥biâ€‹[xiâ€‹(viâ€‹)âˆ’xiâ€‹(biâ€‹)]\n\nThis is an argument from the fact that for any b,v DSIC guara ntees itâ€™s the best possible\nFrom the two inequalities we get\n\n\n\nviâ€‹[xiâ€‹(viâ€‹)âˆ’xiâ€‹(biâ€‹)]â‰¥â‹¯â‰¥biâ€‹[xiâ€‹(viâ€‹)âˆ’xiâ€‹(biâ€‹)]â€‹â€‹\nThus (viâ€‹âˆ’biâ€‹)[xiâ€‹(viâ€‹)âˆ’xiâ€‹(biâ€‹)]â‰¥0 â– \nIntuition. viâ€‹âˆ’biâ€‹ and xiâ€‹(viâ€‹)âˆ’xiâ€‹(biâ€‹) have the same signs. Which means xiâ€‹ is monotonically increasing.\n\nProperty 2. Optimal Price.\nFrom the two inequalities in property 1 we get\nviâ€‹[xiâ€‹(viâ€‹)âˆ’xiâ€‹(biâ€‹)]â‰¥piâ€‹(viâ€‹)âˆ’piâ€‹(biâ€‹)â‰¥biâ€‹[xiâ€‹(viâ€‹)âˆ’xiâ€‹(biâ€‹)]\nWe take the limit by pushing viâ€‹,biâ€‹â†’v\nvxiâ€²â€‹(v)â‰¥piâ€²â€‹(v)â‰¥vxiâ€²â€‹(v)\nThus vxiâ€²â€‹(v)=piâ€²â€‹(v). And integrating both sides\nvxiâ€²â€‹(v)=piâ€²â€‹(v)â€‹âŸ¹âˆ«0vâ€‹zâ‹…xiâ€²â€‹(z)dz=âˆ«0vâ€‹piâ€²â€‹(z)dxâŸ¹âˆ«0vâ€‹zd(xiâ€‹(z))=piâ€‹(v)âŸ¹piâ€‹(v)=vâˆ«0vâ€‹1d(xiâ€‹(z))âˆ’âˆ«0vâ€‹1â‹…xiâ€‹(z)dzâŸ¹piâ€‹(v)=vxiâ€‹(v)âˆ’âˆ«0vâ€‹xiâ€‹(z)dzâ€‹substituteÂ zintegrationÂ byÂ partsâ€‹â€‹\nâ– \nIntuition. The geometric intuition for this is that the price for the allocated person is the rectangle minus the area under the graph, i.e. the blue region.\n"},"BEM-Method":{"title":"BEM Method","links":[],"tags":["Computing"],"content":"â€¦for naming CSS selectors.\nblock__name-of-content__status--on { ; }\n// e.g.\ndiv-input__first-name__input--enabled { ; }\nhttps://www.devbridge.com/articles/implementing-clean-css-bem-method/"},"Balance-Sheet":{"title":"Balance Sheet","links":[],"tags":["Economics/Finance"],"content":"The Balance Sheet is a table showing all the firmâ€™s assets and liabilities.\nItems on a balance sheet:\n\n\nCash &amp; Equivalents: highly liquid assets on hand by a firm\nRecieveables &amp; Payables: unofficial debts, e.g., regular grocery purchases, etc.\nInventories: Items not sold\nProperty, Plant, &amp; Equipment (PP&amp;E), i.e. Durable capital assdets\nStockholderâ€™s Equity: money recieved by purchasers of stock\n\nProperties.\n\nAssets and liabilities must always sum to zero.\ncounts book value, not market value â‡’ hard to measure the â€œvalueâ€ of a firm\nsoft skills (e.g. brand image, reputation) are not reflected (the market may better reflect intangibles).\n"},"Balance-of-Payments":{"title":"Balance of Payments","links":[],"tags":["Economics/Macro-Economics"],"content":"Trade balance"},"Banker's-Rule":{"title":"Banker's Rule","links":[],"tags":["Economics/Finance"],"content":"\nâ€œExact Timeâ€: number of days from t0â€‹\nâ€œOrdinary interestâ€: 1Â year=360Â days,1Â month=30Â days\n"},"Bankrolling":{"title":"Bankrolling","links":[],"tags":["Economics/Finance"],"content":"\nBankrolling refers to the act of providing financial support or funding to a person, organization, or project. It involves supplying the necessary monetary resources to enable the individual or entity to carry out their activities or achieve their goals. Bankrolling often implies providing substantial financial backing or resources to ensure the success or sustainability of the supported venture.\n"},"Base-&-Superstructure":{"title":"Base & Superstructure","links":["Phenomenology"],"tags":["Philosophy/Marxism"],"content":"Phenomenology"},"Basis-Points":{"title":"Basis Points","links":[],"tags":["Economics/Finance"],"content":"100bp=1%"},"Beige-Book":{"title":"Beige Book","links":["Federal-Reserve"],"tags":["Economics/Finance"],"content":"The Beige Book is a report published by the Federal Reserve that provides qualitative information on current economic conditions across the 12 Federal Reserve Districts. It is published eight times per year and is used by policymakers, economists, and investors to gain insights into the state of the economy. The report relies on information gathered from various sources, including surveys of businesses and interviews with key contacts in each district."},"Bernouilli-Distribution":{"title":"Bernouilli Distribution","links":[],"tags":["Math/Statistics"],"content":"\n\n                  \n                  Note \n                  \n                \nAn experiment with two outcomes, success and failure, with probability p and (1âˆ’p) respectively.\n\n\nE(X)=p\nVar(X)=pq\n"},"Bertrand-Price-Competition":{"title":"Bertrand Price Competition","links":[],"tags":["Economics/Micro-Economics"],"content":"Firms will choose price as the strategic variable.\n\nMarket Demand x(p)=Aâˆ’bp where A,b are constants\nSimultaneous game\nFirm with lower price captures all of demand\n\nCase: Constant and Same Marginal Cost Â§\n\nMarginal Cost is constant for both firms: c(x)=cx, MC=c\nBoth firms will attempt to undercut each other.\n\nBRC1â€‹:p1â€‹(p2â€‹)=max(p2â€‹âˆ’Ïµ,MC)\nBRC2â€‹:p2â€‹(p1â€‹)=max(p1â€‹âˆ’Ïµ,MC)\nNE={p1â€‹=c,p2â€‹=c} where both firms have zero profit\n\n\n\n\nCase: Different but Constant Marginal Cost Â§\n\nMarginal Cost is constant, but different for both firms\n\nc1â€‹(x)=c1â€‹x, c2â€‹(x)=c2â€‹x, c1â€‹&lt;c2â€‹\n\n\nThenâ€¦\n\nBRC1â€‹:p1â€‹(p2â€‹)=max(p2â€‹âˆ’Ïµ,c1â€‹)\nBRC2â€‹:p2â€‹(p1â€‹)=max(p1â€‹âˆ’Ïµ,c2â€‹)\nNE={p1â€‹=c2â€‹âˆ’Ïµ,p2â€‹=c2â€‹}\n\n&amp; firm 1 can set undercut the price because they still have c1â€‹&lt;c2â€‹âˆ’Ïµ\n\n\nFirm 1 will make positive profit; firm 2 will make zero profit.\n\n\n\nCase: Sequential Move Â§\n\nChange assumption: Dynamic game; firm 1 sets price first, then firm 2 sets price. (c1â€‹&lt;c2â€‹)\n\nThen, there cannot be a best response curve. Instead, consider the following subgame perfect Nash equilibirum:\n\n\n\n12â€‹:p1â€‹=c2â€‹âˆ’Ïµ:p2â€‹={min(p2Mâ€‹,p2â€‹âˆ’Ïµ)c2â€‹â€‹ifÂ c2â€‹&lt;p1â€‹ifÂ c2â€‹â‰¥p1â€‹â€‹(canÂ undercutÂ price)(canâ€™tÂ b/cÂ MC)â€‹â€‹â€‹\n- The following is a non-subgame perfect Nash equilibirum. The non-credible threat is when firm 2 threatens &quot;I&#039;m just gonna lose money if you don&#039;t listen.&quot;. Given a constant $k$, \n\n12â€‹:p1â€‹=p2Mâ€‹+k:p2â€‹={p2Mâ€‹0â€‹ifÂ p1â€‹Â setsÂ whatÂ IÂ wantifÂ p1â€‹Â isnâ€™tÂ whatÂ IÂ wantâ€‹â€‹â€‹\n\nDifferent order: Dynamic game; firm 2 sets price first, then firm 1 sets price. (c1â€‹&lt;c2â€‹ still assumed)\n\nThen, SPNE\n\n\n\n21â€‹:p2â€‹=c2â€‹:p1â€‹(p2â€‹)={min(p1Mâ€‹,p2â€‹âˆ’Ïµ)c1â€‹â€‹ifÂ p2â€‹&gt;c1â€‹elseÂ p2â€‹&lt;c1â€‹â€‹â€‹â€‹\nIf Product Can Be Differentiated Â§\nWhen we assume that products can be differentiated (=diversified), then we can improve on the Bertrand model;.\n\nConsumersâ€™ preferences are uniformly distributed across differentiation space R\nFirms can produce a product with a certain value P of differentiated characteristic PâˆˆR\nA consumer with preference C will pay a cost when consuming P which is proportional to the distance Cost=âˆ£Pâˆ’Câˆ£\n\n\nAssume there exists a possibility of differentiation space (âˆƒRâˆˆ[0,1])\nHowever firms are not allowed change product characteristics.\nThe only strategic variable is price.\n\n\n\nFirst consider firm 1â€™s BRC:\n\nIf firm 1 gives away products for free p1â€‹=0\n\nâ€¦firm 2 can still charge a price since some consumers will prefer their products\nâ€¦and p2â€‹&gt;MC because firm 1 will exit otherwise.\n\n\nIf firm 2 charges a price p1â€‹&gt;0\n\nâ€¦firm 2 can charge an even higher price since some consumers will prefer their products\n\n\nTherefore the BRC is a positively sloping curve\n\n\nFirm 2â€™s BRC is symmetrical:\n\nâ†’ Equilibrium is at the intersection of the two BRCs, and at this point p1âˆ—â€‹=p2âˆ—â€‹.\nâ†’ Equilibirum price is above marginal cost, unlike pure Bertrand Price Competition\n\n\n\n\n\n                  \n                  Info \n                  \n                \n\nDifferentiation â€œsoftensâ€ price competition. Therefore firms want more differentiation\nDetermining Firm 2â€™s Best Response Curve: Â§\n\n\nwhen firm 1â€™s price &lt; MC, firm 2â€™s best response is set price at MC\nwhen firm 2â€™s price &gt; MC, firm 2â€™s best response is the undercut firm 1â€™s price by a very small amount (Ïµ)\n\n\nFirm 2â€™s BRC is symmetric\nâ†’ Firmsâ€™ prices will unravel to both pricing to p = MC (Bertrand price = MC)\nâ†’ At p=MC, market will purchase 2xM, and firms produce xM each.\n\np_{1}&amp;=max[MC_{2}-\\epsilon,MC_{1}] \\\\\np_{2}&amp;=max[MC_{1}-\\epsilon,MC_{2}]\n\\end{align}\nHotelling Model Â§\n\nProducts can be differentiated by one characteristic variable which ranges from 0 to 1.\nDifferentiation is the only strategic variable; i.e. price, etc. cannot be changed.\n\n\n\n\n                  \n                  Tip \n                  \n                \nThe graph and its corresponding explaination in the textbook is wrong; the following is the correct explaination.\n\nThinking about Firm 1â€™s BRC:\n\nwhen firm 2 produces a product with characteristic &lt; 0.5, then firm 1 will produce a product that is just closer to 0.5 [=larger] to capture more consumers\nwhen firm 2 produces a product with characteristic &gt; 0.5, then firm 1 will produce a product that is just closer to 0.5 [=smaller] to capture more consumers\nwhen firm 2 produces a product with characteristic = 0.5, then firm 1 will produce a product with characteristic = 0.5.\n\n\n\n                  \n                  Info \n                  \n                \nIn a single axis (1-dim. differentiation space)\n\n\nâ†’ Firm 2â€™s BRC is symmetrical; this unravels to the equilibrium where both firms produce product with characteristic = 0.5\nCircle Model Â§\nThe circle model combines the Price Competition and Differentiation.\n\nThis is a sequential game where firms will enter [first move] and then it will compete with price [second move]\n\nFirms who enter incurs entry cost (an economic cost) of FC when they enter.\n\n\nPrice and differentiation are the two strategic variables.\n\nProduct differentiation space is around a circle whose circumference is 1.\n\n\n\nThen the following conclusions:\n\n\n                  \n                  Info \n                  \n                \n\nEach firm is respresented as a point on the circle.\n\n\nFirms will enter as long as FC&gt;Ï€ â€¦â‘ \nFirms compete with their immediate neighbors\nâ†’ Firms will space themselves out around the circle\n\nThe number of firms entering N and the equilibrium price given that N firms have entered p are determined in the following order:\n\nFCâ†¦Nâˆ— where NâˆFC1â€‹ (âˆµ â‘ )\nNâˆ—â†¦pâˆ— where pâˆN1â€‹ but p&gt;MC. Specifically:\n\n"},"Besset-Correction":{"title":"Besset Correction","links":["Bias-(Statistics)"],"tags":["Math/Statistics"],"content":"Review and intuition why we divide by n-1 for the unbiased sample | Khan Academy - YouTube\nNaiive sample variance estimator:\ns^2=nâˆ‘i=1nâ€‹(xiâ€‹âˆ’xË‰)â€‹\nâ‡’ Sample variance is biased.\nBesset Corrected sample variance estimator:\ns^2=nâˆ’1âˆ‘i=1nâ€‹(xiâ€‹âˆ’xË‰)â€‹\n\nLarger than the naiive sample estimator\n"},"Beveridge-Curve":{"title":"Beveridge Curve","links":["Unemployment"],"tags":["Economics/Macro-Economics"],"content":"Beveridge Curve Â§\n:= description of the inverse correlation between Unemployment and job openings\n\n\n\nIt may shift due to: increased in unemployment benefits, participation rate changes, etc.\nBeveridge curve\n\nThe curve, named afterÂ William Beveridge, is hyperbolic-shaped and slopes downward, as a higher rate of unemployment normally occurs with a lower rate of vacancies.\n\n\n\nThe more inwards, the more efficient the labor market is.\n\ni.e. the matchmaking between employer and employee is done well.\n\n\n"},"Bias-(Statistics)":{"title":"Bias (Statistics)","links":[],"tags":["Math/Statistics"],"content":"\n\n                  \n                  Note \n                  \n                \nBias is the difference between the expected value [=mean] of an estimator and the ground truth.\n\nBias[Î¸^]=E[Î¸^]âˆ’Î¸0â€‹\nthm. Linear Transformation Preserves Bias. If Î¸^ is unbiased, g(Î¸^) is unbiased if g is a linear transformation.\nâ†’ For estimators without bias, we can compute the precision to evaluate how good it is."},"Big-Oh-Notation":{"title":"Big-Oh Notation","links":[],"tags":["Math/Calculus","Computing/Algorithms"],"content":"Alternative formulation of parts of calculus.\ndef. Big-Oh Notation. for functions f,g, we say f(n)=O(g(n)) iff:\n\nDefinition 1:\n\nâˆƒcâˆˆR+Â âˆ€nâˆˆN+,f(n)â‰¤câ‹…g(n)\n\nDefinition 2:\n\nnâ†’âˆlimâ€‹sup(f(n))&lt;âˆ\n\nâ‡’ Intuitive Understanding: f=O(g)â‰ˆf&lt;g\n\ndef. Big-Omega Notation. For functions f,g we say f=Î©(g) iff g=O(f)\ndef. Big-Theta Notation\nf=O(g)Â andÂ f=Î©(g)âŸ¹f=Î˜(g)"},"Binomial-Distribution":{"title":"Binomial Distribution","links":[],"tags":["Math/Common-Distributions"],"content":"Binomial Distribution Â§\ndef. Binomial Distribution. For random variable X which denotes the number of successes within n trials with success probability p:\nXP(X=k)â€‹âˆ¼Binom(n,p)=(knâ€‹)â‹…pkâ‹…(1âˆ’p)nâˆ’kâ€‹\n\nE[X]=np\nVar[X]=nâ‹…p(1âˆ’p)\n"},"Binomial-Option-Pricing-Model":{"title":"Binomial Option Pricing Model","links":["No-Arbitrage","Present-Value-Calculations","Binomial-Security-Pricing-Model","Stochastic-Process","Approximating-Distributions","Normal-Distribution"],"tags":["Economics/Finance"],"content":"Binomial Option Pricing Model Â§\nQ. What is the fair price (=No-Arbitrage) of a European call option at time t0â€‹?\n\nYou canâ€™t really just use Present Value Calculations because itâ€™s a derivative.\nUsing the same Binomial Security Pricing Model but in options.\n\n\nFind the purchase of stock and borrow of money that would have the equivalent payoff as the call option (=reproducing portfolio)\nUse that to price the stock\nThen, according to the No-Arbitrage that must be the same as the current price of the call option\nDo this for n periods for a binomial tree\n\nCall Option Details Â§\nPayoff (=price of call option at time t1â€‹)\nC(t1â€‹)={max[S(t1â€‹)â‹…uâˆ—â€‹K,0]max[S(t1â€‹)â‹…dâˆ—â€‹K,0]â€‹probabilityÂ pprobabilityÂ 1âˆ’pâ€‹\n\nu,d is the uptick factor and the downtick factor\n\nReproducing Portfolio Details Â§\n\nÎ”(t): number of stocks you purchase\n\nwill increase due to dividend payouts: Î”(t1â€‹)=Î”(t0â€‹)eq(t1â€‹âˆ’t0â€‹)\nq is the dividend rate\n\n\nb: amount you borrow at time t0â€‹\nâ‡’ Value of portfolio\n\nV(t0â€‹)V(t1â€‹)â€‹=Î”(t0â€‹)â‹…S(t0â€‹)âˆ’b=Î”(t1â€‹)â‹…S(t1â€‹)âˆ’ber(t1â€‹âˆ’t0â€‹)â€‹â€‹\nCalculating Fair Call Price Â§\nâ‡’ Equate V(t1â€‹)=C(t1â€‹) and solve for Î”(t),b to obtain the reproducing portfolio.\nÎ”(t0â€‹)bâ€‹=(uâˆ’d)S(t0â€‹)Cuâ€‹(t1â€‹)âˆ’Cdâ€‹(t1â€‹)â€‹eâˆ’q(t1â€‹âˆ’t0â€‹)=uâˆ’ddCuâ€‹(t1â€‹)âˆ’uCdâ€‹(t1â€‹)â€‹eâˆ’r(t1â€‹âˆ’tâˆ—0)â€‹â€‹\n\nCalculate V(0):\n\nV(t0â€‹)=eâˆ’q(t1â€‹âˆ’t0â€‹)(uâˆ’d)S(t0â€‹)Cuâ€‹(t1â€‹)âˆ’Cdâ€‹(t1â€‹)â€‹S(t0â€‹)âˆ’eâˆ’r(t1â€‹âˆ’t0â€‹)uâˆ’ddCuâ€‹(t1â€‹)âˆ’uCdâ€‹(t1â€‹)â€‹\n\nâ‡’ Thus V(t0â€‹)=C(t0â€‹) and simplifying:\n\nC(t0â€‹)=eâˆ’r(t1â€‹âˆ’t0â€‹)[uâˆ’de(râˆ’q)(t1â€‹âˆ’t0â€‹)âˆ’dâ€‹Cuâ€‹(t1â€‹)+uâˆ’duâˆ’e(râˆ’q)(t1â€‹âˆ’t0â€‹)â€‹Cdâ€‹(t1â€‹)]\nGeneralizing into n terms Â§\n\nWith the No-Arbitrage we have E[C(t1â€‹)]=C(t0â€‹)e(râˆ’q)(t1â€‹âˆ’t0â€‹).\nThen define the risk-neutral probability of an uptick such that\n\npâˆ—â€‹:=uâˆ’de(râˆ’q)(t1â€‹âˆ’t0â€‹)âˆ’dâ€‹\nthm. Risk-Neutral Binomial Call Pricing Formula\nC(t0â€‹;n)=eâˆ’(nh)ri=0âˆ‘nâ€‹(inâ€‹)pâˆ—iâ€‹(1âˆ’pâˆ—â€‹)nâˆ’iCuiâ€‹dnâˆ’iâ€‹â€‹(tnâ€‹)\nwhere\n\nCuidnâˆ’iâ€‹(tnâ€‹):=max[C(t0â€‹)uidnâˆ’iâˆ’K,0]\nunâ€‹â‰ˆeÏƒhnâ€‹â€‹\ndnâ€‹â‰ˆeâˆ’Ïƒhnâ€‹â€‹\nh:=t1â€‹âˆ’t0â€‹\nr,q is the risk-free rate and dividend rate\n\nBy taking nâ†’âˆ we see\n\nS(t) becomes a Stochastic Process\nBinomial sum can be approximated by a Normal Distribution\n"},"Binomial-Security-Pricing-Model":{"title":"Binomial Security Pricing Model","links":["Bernouilli-Distribution","Binomial-Distribution","Dividend-Discount-Model","Central-Limit-Theorem"],"tags":["Economics/Finance"],"content":"\nModel Definition Â§\n\nConsider time interval [t0â€‹,tfâ€‹]\n\ntotal time Ï„=tfâ€‹âˆ’t0â€‹\nn intervals\nhnâ€‹: duration of one interval (=ntfâ€‹âˆ’t0â€‹â€‹)\n\n\nStâ€‹: price of security at time t.\n\nS0â€‹ is given as a constant\n\n\nGross return Sjâˆ’1â€‹Sjâ€‹â€‹\n\nItâ€™s called gross because its in the form of 1.xx or 0.xx, not Sjâˆ’1â€‹Sjâ€‹âˆ’Sjâˆ’1â€‹â€‹\nIs defined as a Bernouilli Distribution:\n\n\n\nSjâˆ’1â€‹Sjâ€‹â€‹={unâ€‹dnâ€‹â€‹withÂ probabilityÂ pnâ€‹withÂ probabilityÂ (1âˆ’pnâ€‹)â€‹(stockÂ uptick)(stockÂ downtick)â€‹\n\nN: number of upticks. Is a random variable with Binomial Distribution Nâˆ¼Binom(n,pnâ€‹)\n\nP(N=k)=(knâ€‹)Â pnkâ€‹Â (1âˆ’pnâ€‹)nâˆ’k\n\n\nSample Space Î©nâ€‹\n\nÎ©={U,D}\nÎ©2â€‹={UU,UD,DU,DD}\nÎ©3â€‹={UUU,UUD,â€¦,DDD}\nÎ©nâ€‹ is for n-period binomial tree\nPr(Ï‰):=pnN(Ï‰)â€‹(1âˆ’pnâ€‹)N(Ï‰)\n\n\nFinal Price Snâ€‹=S0â€‹Â unkâ€‹Â dnnâˆ’kâ€‹\n\nSnâ€‹ is a random variable. P(Snâ€‹=S0â€‹Â unkâ€‹Â dnnâˆ’kâ€‹)=P(N=k)\ni.e. probability that price will be equal to there being k upticks is the probability that there will be k upticks. (no shit)\n\n\nExpectation of final price: E(Snâ€‹)=S0â€‹(pnâ€‹unâ€‹+(1âˆ’pnâ€‹)dnâ€‹)n\nTo find number of upticks k from final price Snâ€‹ we use\n\nk=ln(S0â€‹dnSnâ€‹â€‹)/ln(duâ€‹)\n\nDividends: D(tjâˆ’1â€‹,tjâ€‹)=qS(tjâˆ’1â€‹)hnâ€‹\n\nSee Dividend Discount Model for dividends in non-binomial tree model\nTotal Return (incl. dividends): R(tjâˆ’1â€‹,tjâ€‹)=S(tjâ€‹)S(tjâ€‹)âˆ’S(tjâˆ’1â€‹)+D(tjâˆ’1â€‹,tjâ€‹)â€‹=Rjâ€‹+qhnâ€‹\nCapital Gains Return (excl. dividends): Riâ€‹:=S0â€‹S1â€‹âˆ’S0â€‹â€‹\n(Dividends Return qhnâ€‹)\n\n\n\nAssumptions &amp; Definitions Â§\n\nLog returns: Yn,jâ€‹:=ln(Sjâˆ’1â€‹Sjâ€‹â€‹) Is also a random variable\n\nLog normal is another indicator of how well the stock is performing\nIt is similar in value to the percentage return\nSee What does the average log-return value of a stock mean? - Personal Finance &amp; Money Stack Exchange for the intuition\n\n\nunâ€‹dnâ€‹=1 i.e. the stock ticking up then down is same as no movement at all\nInstantaneous Rate of Return\n\nm=limnâ†’âˆâ€‹hnâ€‹E[R(t0â€‹,t1â€‹)]â€‹\n\n\nDrift: Instantaneous Expected Log-Return\n\nÎ¼=limnâ†’âˆâ€‹Yn,jâ€‹=limnâ†’âˆâ€‹hnâ€‹E[lnS0â€‹S1â€‹â€‹]â€‹\n\n\nLog Variance: Instantaneous Variance of Log-Return = Volatility (Ïƒ)\n\nÏƒ2=limnâ†’âˆâ€‹Ïƒn2â€‹=limnâ†’âˆâ€‹hnâ€‹Var[lnS0â€‹S1â€‹â€‹]â€‹\n\n\nDividend Rate q\n\nLemmas Â§\n\nÎ¼nâ€‹hnâ€‹=pnâ€‹lnunâ€‹+(1âˆ’p)lndnâ€‹\nÏƒn2â€‹hnâ€‹=pnâ€‹(1âˆ’pnâ€‹)[lndnâ€‹unâ€‹â€‹]2\nÎ¼=mâˆ’qâˆ’2Ïƒ2â€‹\n(Proofs in notes)\n\nthm. Parameter Triple. Given a security with Î¼,Ïƒ2,m,q we determine that:\n\nunâ€‹â‰ˆeÏƒhnâ€‹â€‹\ndnâ€‹â‰ˆeâˆ’Ïƒhnâ€‹â€‹\npnâ€‹â‰ˆ21â€‹(1+ÏƒÎ¼â€‹hnâ€‹â€‹)=unâ€‹âˆ’dnâ€‹e(mâˆ’q)hnâ€‹âˆ’dnâ€‹â€‹\n\nContinuous Time Model Â§\nModel Definition Â§\nInstead of assuming an uptick-downtick gross return is a Bernouilli Distribution, we instead think of the log returns. (Use Lindenberg CLT)\nSnâ€‹(t)â€‹=S0â€‹exp(lnS0â€‹Snâ€‹â€‹)=S0â€‹exp(j=1âˆ‘nâ€‹lnSjâˆ’1â€‹Sjâ€‹â€‹)=S0â€‹exp(Yn,jâ€‹)=S0â€‹exp(Î¼t+Ïƒtâ‹…Z)â€‹LindenbergÂ CLTYâˆ¼N(nÎ¼nâ€‹hnâ€‹,nÏƒn2â€‹hnâ€‹)Zâˆ¼N(0,1)â€‹â€‹\nâ‡’ Thus we have\nln(S0â€‹Stâ€‹â€‹)âˆ¼N(Î¼t,Ïƒ2t)\nProperties\n\nS(t) is a lognormal random variable with\n\ni.e. S(t)=S0â€‹eÎ¼t+Ïƒtâ€‹Zt where Z is the standard normal random variable\n\n\nln(Stâˆ’1â€‹Stâ€‹â€‹) are i.i.d.\n"},"Binomial-Theorem":{"title":"Binomial Theorem","links":[],"tags":["Math"],"content":"(x+y)n=k=0âˆ‘nâ€‹(knâ€‹)xnâˆ’kyk=k=0âˆ‘nâ€‹(knâ€‹)xkynâˆ’k."},"Binomial-Tree-Model-of-Security-Pricing":{"title":"Binomial Tree Model of Security Pricing","links":["Bernouilli-Distribution","Binomial-Distribution","Dividend-Discount-Model","Central-Limit-Theorem"],"tags":["Economics/Finance"],"content":"\nModel Definition Â§\n\nConsider time interval [t0â€‹,tfâ€‹]\n\ntotal time Ï„=tfâ€‹âˆ’t0â€‹\nn intervals\nhnâ€‹: duration of one interval (=ntfâ€‹âˆ’t0â€‹â€‹)\n\n\nStâ€‹: price of security at time t.\n\nS0â€‹ is given as a constant\n\n\nGross return Sjâˆ’1â€‹Sjâ€‹â€‹\n\nItâ€™s called gross because its in the form of 1.xx or 0.xx, not Sjâˆ’1â€‹Sjâ€‹âˆ’Sjâˆ’1â€‹â€‹\nIs defined as a Bernouilli Distribution:\n\n\n\nSjâˆ’1â€‹Sjâ€‹â€‹={unâ€‹dnâ€‹â€‹withÂ probabilityÂ pnâ€‹withÂ probabilityÂ (1âˆ’pnâ€‹)â€‹(stockÂ uptick)(stockÂ downtick)â€‹\n\nN: number of upticks. Is a random variable with Binomial Distribution Nâˆ¼Binom(n,pnâ€‹)\n\nP(N=k)=(knâ€‹)Â pnkâ€‹Â (1âˆ’pnâ€‹)nâˆ’k\n\n\nSample Space Î©nâ€‹\n\nÎ©={U,D}\nÎ©2â€‹={UU,UD,DU,DD}\nÎ©3â€‹={UUU,UUD,â€¦,DDD}\nÎ©nâ€‹ is for n-period binomial tree\nPr(Ï‰):=pnN(Ï‰)â€‹(1âˆ’pnâ€‹)N(Ï‰)\n\n\nFinal Price Snâ€‹=S0â€‹Â unkâ€‹Â dnnâˆ’kâ€‹\n\nSnâ€‹ is a random variable. P(Snâ€‹=S0â€‹Â unkâ€‹Â dnnâˆ’kâ€‹)=P(N=k)\ni.e. probability that price will be equal to there being k upticks is the probability that there will be k upticks. (no shit)\n\n\nExpectation of final price: E(Snâ€‹)=S0â€‹(pnâ€‹unâ€‹+(1âˆ’pnâ€‹)dnâ€‹)n\nTo find number of upticks k from final price Snâ€‹ we use\n\nk=ln(S0â€‹dnSnâ€‹â€‹)/ln(duâ€‹)\n\nDividends: D(tjâˆ’1â€‹,tjâ€‹)=qS(tjâˆ’1â€‹)hnâ€‹\n\nSee Dividend Discount Model for dividends in non-binomial tree model\nTotal Return (incl. dividends): R(tjâˆ’1â€‹,tjâ€‹)=S(tjâ€‹)S(tjâ€‹)âˆ’S(tjâˆ’1â€‹)+D(tjâˆ’1â€‹,tjâ€‹)â€‹=Rjâ€‹+qhnâ€‹\nCapital Gains Return (excl. dividends): Riâ€‹:=S0â€‹S1â€‹âˆ’S0â€‹â€‹\n(Dividends Return qhnâ€‹)\n\n\n\nAssumptions &amp; Definitions Â§\n\nLog returns: Yn,jâ€‹:=ln(Sjâˆ’1â€‹Sjâ€‹â€‹) Is also a random variable\n\nLog normal is another indicator of how well the stock is performing\nIt is similar in value to the percentage return\nSee What does the average log-return value of a stock mean? - Personal Finance &amp; Money Stack Exchange for the intuition\n\n\nunâ€‹dnâ€‹=1 i.e. the stock ticking up then down is same as no movement at all\nInstantaneous Rate of Return\n\nm=limnâ†’âˆâ€‹hnâ€‹E[R(t0â€‹,t1â€‹)]â€‹\n\n\nDrift: Instantaneous Expected Log-Return\n\nÎ¼=limnâ†’âˆâ€‹Yn,jâ€‹=limnâ†’âˆâ€‹hnâ€‹E[lnS0â€‹S1â€‹â€‹]â€‹\n\n\nLog Variance: Instantaneous Variance of Log-Return = Volatility (Ïƒ)\n\nÏƒ2=limnâ†’âˆâ€‹Ïƒn2â€‹=limnâ†’âˆâ€‹hnâ€‹Var[lnS0â€‹S1â€‹â€‹]â€‹\n\n\nDividend Rate q\n\nLemmas Â§\n\nÎ¼nâ€‹hnâ€‹=pnâ€‹lnunâ€‹+(1âˆ’p)lndnâ€‹\nÏƒn2â€‹hnâ€‹=pnâ€‹(1âˆ’pnâ€‹)[lndnâ€‹unâ€‹â€‹]2\nÎ¼=mâˆ’qâˆ’2Ïƒ2â€‹\n(Proofs in notes)\n\nthm. Parameter Triple. Given a security with Î¼,Ïƒ2,m,q we determine that:\n\nunâ€‹â‰ˆeÏƒhnâ€‹â€‹\ndnâ€‹â‰ˆeâˆ’Ïƒhnâ€‹â€‹\npnâ€‹â‰ˆ21â€‹(1+ÏƒÎ¼â€‹hnâ€‹â€‹)=unâ€‹âˆ’dnâ€‹e(mâˆ’q)hnâ€‹âˆ’dnâ€‹â€‹\n\nContinuous Time Model Â§\nModel Definition Â§\nInstead of assuming an uptick-downtick gross return is a Bernouilli Distribution, we instead think of the log returns. (Use Lindenberg CLT)\nSnâ€‹(t)â€‹=S0â€‹exp(lnS0â€‹Snâ€‹â€‹)=S0â€‹exp(j=1âˆ‘nâ€‹lnSjâˆ’1â€‹Sjâ€‹â€‹)=S0â€‹exp(Yn,jâ€‹)=S0â€‹exp(Î¼t+Ïƒtâ‹…Z)â€‹LindenbergÂ CLTYâˆ¼N(nÎ¼nâ€‹hnâ€‹,nÏƒn2â€‹hnâ€‹)Zâˆ¼N(0,1)â€‹â€‹\nâ‡’ Thus we have\nln(S0â€‹Stâ€‹â€‹)âˆ¼N(Î¼t,Ïƒ2t)\nProperties\n\nS(t) is a lognormal random variable\n\ni.e. S(t)=S0â€‹eÎ¼t+Ïƒtâ€‹Zt where Z is the standard normal random variable\n\n\nln(Stâˆ’1â€‹Stâ€‹â€‹) are i.i.d.\n"},"Bivariate-Ordinary-Least-Squares-Regression":{"title":"Bivariate Ordinary Least Squares Regression","links":["Mean-Squared-Error"],"tags":["Math/Statistics"],"content":"Motivation. Letâ€™s say that there is a relationship between GDP per capita and life expectancy. Maybe god has declared a perfect formula describing this relationship:\nGDPÂ PerÂ Capita=200â‹…LifeÂ Expectancy+1000+Noise\nWhile we humans may never truly know the parameters of the formula, 200 and 1000, we can still make a good guess about it. Therefore, assuming this is a linear relationship, we have the Bivariate Ordinary Least Squares Model.\nYiâ€‹=Î²0â€‹+Î²1â€‹Xiâ€‹+Ïµiâ€‹\nwhere (X1â€‹,Y1â€‹),â€¦,(Xnâ€‹,Ynâ€‹) are observations (=regressors). The OLS algorithm will minimize the squared sum of residuals:\nminÎ²1â€‹^â€‹,Î²0â€‹^â€‹â€‹i=1âˆ‘Nâ€‹Ïµiâ€‹^â€‹2\nwhere Ïµiâ€‹^â€‹:=Yiâ€‹âˆ’=Y^(Î²0â€‹^â€‹+Î²1â€‹^â€‹Xiâ€‹)â€‹â€‹. Note the square.\nthm. Parameter OLS Estimator for N observations (Xiâ€‹,Yiâ€‹)\nÎ²1â€‹^â€‹Î²0â€‹^â€‹â€‹:=âˆ‘i=1Nâ€‹(Xiâ€‹âˆ’XË‰)2âˆ‘i=1Nâ€‹(Xiâ€‹âˆ’XË‰)(Yiâ€‹âˆ’YË‰)â€‹:=ÏƒX2â€‹ÏƒXYâ€‹â€‹=ÏXYâ€‹ÏƒXâ€‹ÏƒYâ€‹â€‹:=YË‰âˆ’Î²1â€‹^â€‹XË‰â€‹â€‹\nProperties.\n\nPredictor: Yiâ€‹^â€‹=Î²0â€‹^â€‹+Î²1â€‹^â€‹Xiâ€‹\nResidual: Ïµ^:=Yiâ€‹âˆ’Y^ is the estimator for the error term, i.e. how good the predictor is.\n\nN1â€‹âˆ‘iNâ€‹Ïµiâ€‹^â€‹=0 i.e. the mean of residuals is zero in OLS algorithm.\n\n\nOLS results in assuming that X is exogenous, i.e. ÏX,Ïµâ€‹=0.\n\nÏ\n\n\nRegression Variance: Ïƒ^2=Nâˆ’kâˆ‘i=1Nâ€‹Ïµiâ€‹^â€‹2â€‹=Nâˆ’kâˆ‘i=1Nâ€‹(Yiâ€‹âˆ’YË‰)2â€‹ where k is the number of parameters (k=2 in this case)\n\nbasically the Mean Squared Error. The lower the better.\nÏƒ^ is also the standard error of the residuals.\nIn Stata, Ïƒ^ is called the Root MSE\n\n\n\nEvaluation of Estimators.\n\nMean of Î²1â€‹^â€‹: E(Î²1â€‹^â€‹)=Î²1â€‹+ÏX,Ïµâ€‹ÏƒXâ€‹ÏƒÏµâ€‹â€‹\n\nThus bias is ÏX,Ïµâ€‹ÏƒXâ€‹ÏƒÏµâ€‹â€‹\nIf ÏX,Ïµâ€‹=0 then exogenous (this is the definition of exogeniety)\nIf ÏX,Ïµâ€‹&gt;0 then thereâ€™s some 3rd factor positively correlated with X, thus bias is positive.\nIf ÏX,Ïµâ€‹&lt;0 then v.v.\n&amp; Thus the bias characterizes exogeniety\n\n\nVariance of Î²1â€‹^â€‹: Var(Î²1â€‹^â€‹)=Nâ‹…Var(X)Ïƒ^2â€‹\n\nThis is also called precision\nVar(Î²1â€‹^â€‹)â€‹ is also called standard error of Î²1â€‹^â€‹.\n! For random variables, Var(X)â€‹ is called standard deviation. For estimator random variables, it is called standard error. An abuse of terminology.\n\n\n\nOther Data when Regression is Run Â§\nThere are a bunch of other variables that may matter, that is not included in the above core set of variables of the regression. Here are a few:\ndef. Coefficient of Determination (R-Squared). Intuition: The proportion of the variation in Y^ that can be determined from X. We define it as:\nR2:=1âˆ’SStotâ€‹SSresâ€‹â€‹\nwhere\n\nSSresâ€‹:=âˆ‘iâ€‹Ïµiâ€‹^â€‹2=âˆ‘iâ€‹(Yiâ€‹âˆ’Yiâ€‹^â€‹)2 residual sum of squares\nSStotâ€‹:=âˆ‘iâ€‹(Yiâ€‹âˆ’YË‰)2 total sum of squares\n\nExample. A R2 of 0.67 means that around 67% of the variation in Y^ is explained by X. Therefore, the higher it is, the better the regression is (=has more explanatory power).\nRemark. It can also be shown that:\nR2=ÏY,Y^2â€‹\nMeasurement Error Â§\nMotivation. There are measurement errors in every data; it can be both in the independent variable X or the dependent variable Y. We can characterize measurement error (in this case a measurement error in X) as:\nXiâ€‹=Xiâˆ—â€‹+viâ€‹\nwhere viâ€‹ is randomly distributed with E(viâ€‹)=0 and std. dev. Ïƒvâ€‹, which is the measurement error. In this case, the regression in the model Yiâ€‹^â€‹=Î²0â€‹^â€‹+Î²1â€‹^â€‹Xiâ€‹+Ïµ^iâ€‹ will also change, into:\nÎ²1â€‹^â€‹=nâ†’âˆâ€‹Î²1â€‹Ïƒv2â€‹+ÏƒXâˆ—2â€‹ÏƒXâˆ—2â€‹â€‹\nWe can extract a couple of facts from this relationship:\n\nAttenuation bias: the greater the Ïƒvâ€‹, the closer Î²1â€‹^â€‹ is to zero.\nif Ïƒvâ€‹=0 then Î²1â€‹^â€‹=Î²1â€‹, i.e. no measurement error\n\nAlternatively, if there is a measurement error in Yiâ€‹, then:\n\nMeasurement error: Yiâ€‹=Yiâˆ—â€‹+viâ€‹ where E(viâ€‹)=0 and std. dev. Ïƒvâ€‹\nError term viâ€‹ is absorbed by error term Ïµiâ€‹^â€‹\nThis will increase Ïƒ^ (variance of regression) and thus Var(Î²1â€‹^â€‹), but does not bias the estimator.\n\nIssues to Watch out for Â§\nHeteroskedasticity is when the variance of data is different for some subsets of data than other subsets. â‡’ Use heteroskedatic-consistent standard errors by using robust in stata. This does not affect value of Î²1â€‹^â€‹ (how!) and does not bias it.\nAutocorrelation often occurs in time series data where the error terms are sticky. For example, attendance at a NY yankees game will be sticky, because people who watched a good year will probably come back next year, even if the yankees arenâ€™t as good as the year before. â†’ used lagged variables"},"Black-Scholes-European-Option-Pricing-Formula":{"title":"Black Scholes European Option Pricing Formula","links":["Normal-Distribution","Binomial-Option-Pricing-Model","Risk-Neutral-Derivation-of-BSM","Forwards","No-Arbitrage","Bonds-(Finance)"],"tags":["Economics/Finance"],"content":"thm. BSM Formula for European Call Options The Fair price of a European call option is C(t) given by\nC(t)d+â€‹dâˆ’â€‹Ï„â€‹=eâˆ’Ï„qS(t)N(d1â€‹)âˆ’eâˆ’Ï„rKN(dâˆ’â€‹)=ÏƒÏ„â€‹ln(S(t)/K)+[(râˆ’q)+2Ïƒ2â€‹]Ï„â€‹=d+â€‹âˆ’ÏƒÏ„â€‹=ÏƒÏ„â€‹ln(S(t)/K)+[(râˆ’q)âˆ’2Ïƒ2â€‹](Ï„)â€‹=Tâˆ’tâ€‹where...timeÂ toÂ expirationâ€‹â€‹\nwhere\n\nt is entry date, T is execution date\nr is the risk-free rate\nK is the strike price\nN(d) is the CDF of the Standard Normal Distribution\nS(t) are the price of the underlier, modeled as log-normal R.V.s (=geometric brownian motion) as S(t)=S0â€‹eÎ¼t+Ïƒtâ€‹Btâ€‹\n\n\n\n                  \n                  There are other derivations of BSM, notably: \n                  \n                \n\nUsing the Binomial Option Pricing Model\nRisk-Neutral Derivation of BSM\n\n\nDerivation Using Replicating Portfolio Â§\nProof (Derivation) Sketch. We use a similar strategy to when we priced Forwardsâ€”by constructing a portfolio whose value is always equal to the derivative we want to price, and then using the Law of One Price to find its current price.\nWe first outline the replicating portfolio as a combination of cash and a certain number of securities. We have btâ€‹ units of cash and ntâ€‹ units of cash. We model them as the following:\n\nCash value: Btâ€‹\n\n! Not Btâ€‹. Itâ€™s just denoted B because itâ€™s a bond with risk-free\nbtâ€‹ units; changes along time. (How? See below)\nBtâ€‹=B0â€‹ert where r is the risk-free rate\n\nThus dBtâ€‹=rBtâ€‹dt\n\n\n\n\nStock value: Stâ€‹\n\nntâ€‹ units; changes along time. (How? See below)\nStochastic process with dStâ€‹=(mâˆ’q)Stâ€‹dt+ÏƒStâ€‹dBtâ€‹\n\nThis is a simple geometric brownian motion process. m is the instantaneous rate of return, and q is the dividend yield\n\n\nSimplify the stock paying the dividend by re-modeling it as StCâ€‹=Stâ€‹eqt\n\n\nStock value with dividend: StCâ€‹\n\nsame ntâ€‹ units\nStochastic process with dStCâ€‹=(mâˆ’q)Stâ€‹dt+ÏƒStâ€‹dBtâ€‹\nThus we have the following value of our portfolio Vtâ€‹\n\n\n\nVtâ€‹=btâ€‹Btâ€‹+ntâ€‹StCâ€‹=mustÂ bef(Stâ€‹,t)\nValuing the Self-fiancing Portflio\nThis portfolio must be self-financing; i.e. we must use cash to buy stock, or sell stock to buy cash, in order to exactly track the value of the derivative. This condition translates to: \nÂ beforeÂ dtÂ ntâ€‹St+dtCâ€‹+btâ€‹Bt+dtâ€‹â€‹â€‹Â changeÂ inÂ assetÂ valueÂ (dntâ€‹)St+dtCâ€‹â€‹â€‹dVtâ€‹â€‹=Â afterÂ dtÂ nt+dtâ€‹St+dtCâ€‹+bt+dtâ€‹Bt+dtâ€‹â€‹â€‹=Â changeÂ inÂ cashÂ valueÂ âˆ’(dbtâ€‹)Bt+dtâ€‹â€‹â€‹=ntâ€‹dStCâ€‹+btâ€‹dBtâ€‹â€‹self-financingÂ cond.compactÂ formtrustÂ theÂ textbookâ€‹â€‹\nNow, expanding this using the properties of dStCâ€‹, dBtâ€‹ , and also that btâ€‹=mustÂ beBtâ€‹f(Stâ€‹,t)âˆ’ntâ€‹StCâ€‹â€‹, we simplify to:\ndVtâ€‹=â€‹Â AÂ ntâ€‹(mâˆ’r)StCâ€‹+rf(Stâ€‹,t)â€‹â€‹â€‹dt+Â BÂ ntâ€‹ÏƒStCâ€‹â€‹â€‹dBtâ€‹\nValuing the Security Itself\nAlternatively, we can use Itoâ€™s lemma to value f(Stâ€‹,t) directly. (Recall that we always have âˆ‚xâˆ‚fâ€‹(Stâ€‹,t):=âˆ‚xâˆ‚fâ€‹(x,t)âˆ£x=Stâ€‹â€‹\ndf(Stâ€‹,t)=â€‹Â CÂ âˆ‚tâˆ‚fâ€‹+(mâˆ’q)Stâ€‹âˆ‚xâˆ‚fâ€‹(Stâ€‹,t)+21â€‹Ïƒ2St2â€‹âˆ‚x2âˆ‚2fâ€‹(Stâ€‹,t)â€‹â€‹â€‹dt+Â DÂ ÏƒStâ€‹âˆ‚xâˆ‚fâ€‹â€‹â€‹(Stâ€‹,t)dBtâ€‹\nEquating the two\nNow, due to the fact that an Ito process as a unique representation in the differential form, we know that A=C and B=D in the above formulae. Using the latter:\nntâ€‹=StCâ€‹Stâ€‹â€‹:=Î”fâ€‹âˆ‚xâˆ‚fâ€‹(Stâ€‹,t)â€‹â€‹\nUsing the former:\nntâ€‹(mâˆ’r)StCâ€‹+rf(Stâ€‹,t)=setâ€‹âˆ‚tâˆ‚fâ€‹+(mâˆ’q)Stâ€‹âˆ‚xâˆ‚fâ€‹(Stâ€‹,t)+21â€‹Ïƒ2St2â€‹âˆ‚x2âˆ‚2fâ€‹(Stâ€‹,t)\nAnd substituting the former ntâ€‹ into the latter, we have the partial differential equation:\n21â€‹Ïƒ2St2â€‹âˆ‚x2âˆ‚2fâ€‹(Stâ€‹,t)+(râˆ’q)Stâ€‹âˆ‚xâˆ‚fâ€‹(Stâ€‹,t)+âˆ‚tâˆ‚fâ€‹(Stâ€‹,t)âˆ’rf(Stâ€‹,t)=0\nNow, this PDE will satisfy any derivative; we can use any boundary conditions on it. But if we solve it for a European Call option, we will get the BSM formula.\n\nf(Stâ€‹,t):=C(Stâ€‹,t) starting at t and ending at T. Strike price is K\nC(x,T)=max{xâˆ’K,0}\nC(0,t)=0 and C(x,t)â†’xâ†’âˆeâˆ’q(Tâˆ’t)\n\nâ– "},"Black-Scholes-Merton-Derivative-Pricing-Formula":{"title":"Black-Scholes-Merton Derivative Pricing Formula","links":["Stochastic-Process","Dividend-Discount-Model","Interest-Rate"],"tags":["Economics/Finance"],"content":"thm. BSM Derivative Pricing. Generalized pricing of any derivative. Using different constraints, one can price any derivative.\nâˆ‚Sâˆ‚fâ€‹+2Ïƒ2S2â€‹âˆ‚S2âˆ‚2fâ€‹+(râˆ’q)Sâˆ‚Sâˆ‚fâ€‹âˆ’rf=0\nwhereâ€¦\n\nf[S(t),t] is the price of the derivative at time t\nS(t) is a Geometric Brownian Motion s.t. dS=(mâˆ’q)Sâ‹…dt+ÏƒSâ‹…dB(t) with B(t) a standard brownian motion\n\nÏƒ is the scale of process S\nÎ¼ is the drift of process S\nm is the rate of return of process S\nq is the dividend rate (any dividend is immediately reinvested)\n\n\nr is the Discount Rate\n"},"Bond-Price":{"title":"Bond Price","links":["Bonds-(Finance)","Treasury"],"tags":["Economics/Finance"],"content":"thm. The price of a bond is the following:\nB(n)=ryâ€‹/21âˆ’(1+ryâ€‹/2)âˆ’nâ€‹C+(1+2ryâ€‹â€‹)nMâ€‹\nwhereâ€¦\n\nB(n) is the current market price of the bond\nn=2Ï„ is the periods left to maturity (where Ï„ is the years left to maturity)\n\nnot periods passed! periods left\n\n\nM is the Principal amount\n\nNormally use 100or1000\n\n\nC is the per-period (=semi-annual) coupon payment\n\nnormally, coupon is quoted at annual coupon rate rCâ€‹ (in percent) so C=2rCâ€‹â€‹M\n\n\nryâ€‹ (or y) is the yield to maturity (â‰ˆdiscount rate)\n\nr is the current yield. r=B(n)2Câ€‹\n\n\nn is the number of coupon payments (semi-annual for Treasury bonds)\n\nThe Three Rates of Bonds\n\nryâ€‹: Yield to Maturityâ€”â€œWhatâ€™s the return rate for the coupons if I hold until maturity?â€\nr: Current Yieldâ€”â€œCoupon rate, but at the current bond priceâ€\nrCâ€‹: Coupon Rateâ€”â€œCoupon rate (at principal price).â€\n\n\nPrice and rates:\n\nTrades at premium B(n)&gt;M â‡” ryâ€‹&lt;r&lt;rCâ€‹\nTrades at discount B(n)&lt;M â‡” ryâ€‹&gt;r&gt;rCâ€‹\n\n\n\nObserveâ€¦\n\n\nB(n)âˆyield1â€‹.\n\n\nlimnâ†’0â€‹B(n)=M\n\n\nCausality: Exogenous factors â†’ Î”yield â†’ Î”price.\n\n\n\nIn a portfolio of bondsâ€¦\n\n\nMarketÂ Value=100PriceÂ ofÂ parâ€‹Ã—#Â ofÂ pars\nThe causality of the variables of a bond. The marketâ€™s expected rate of return of a bond is the yield. With this yield we can calculate its price.\nPriceâ€”Yield Curve (mathematical) Â§\nPrice and Yield are inversly correlated â†’ Price-yield curve looks like this:\n\nDuration is the gradient of this price-yield function:\nDuration:=dydPâ€‹\nDollar Duration (DV01) is the change in price due to 1% change in yield [=$1 change in yield per par]\nDV01:=Â±1%â‹…yÎ”Pâ€‹\n\nDollar Duration can be only used to approximate price changes for small changes in yield (~50bp)\nDuration is used to estimate risk (Price sensitivity against yield = DV01 risk\nDollar Duration is quoted as an absolute value. (We all know that itâ€™s mathematically negative)\nDV01 Risk:= Î”1%yieldÎ”MarketÂ Valueâ€‹ = â€œÎ” market value for 1% yield changeâ€ = 100#parâ€‹â‹…DV01\nDV01 has no relationship with volatility\n\n\n\n                  \n                  Example calculation \n                  \n                \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTime to MaturityDV01Yield Vol.e.g. change in yieldchange in price2 year$1.810%p20bp$0.3610 year$7.25%p10bp$0.72\nYield Curve (empirical) Â§\n\nâ‡’ Yield âˆ Maturity, because the farther away the cash flows are, the more risky it is [âˆµ uncertainty]\n\nInverted Yield Curve: Bond investors think a recession is looming â†’ Treasury will increase rates\nLeft intercept is the fed rates &amp; short-mat bonds â†’ high movement\nright side is long-mat bonds â†’ low movement\n\nRisk &amp; Volatility Â§\ndef. Price[rate of return] volatility = SD[Price] (in $)\ndef. Yield volatility = SD[Yield] (in %p)\ndef. DV01 Risk = Change in MV per change in 1% yield\n\nYield Vol &gt; RoR Vol â† mathematical relationship (price formula)\nMaturity âˆ Price Vol.\n"},"Bonds-(Finance)":{"title":"Bonds (Finance)","links":["Bond-Price","Tradable-Inflation-Protected-Securities-(TIPS)","Treasury","Investment-Bank"],"tags":["Economics/Finance"],"content":"\nSee Bond Price for details on pricing.\nTradable Inflation-Protected Securities (TIPS) are inflation protected bonds.\n\nHow Bonds Work Â§\n\n\nLender lends money to the government (usually US Treasury)\nCoupon payments pay regularly:\n\nSemi-annually for US Treasury\nAnnually for other countries\n\n\nPrincipal (=par, base) amount is paid at the maturity;\nTime To Maturity (TTM) is time from now to when the principal pays\nYield\n\nCurrent Yield\nYield to Maturity: Expectation Hypothesis defines yield to maturity as the expected rate of return if held til maturity.\n\n\n\nCash Flow Structure of a Bond Â§\nGovernments are the borrowers of money in this transaction.\n\nGovernment â€œissuesâ€ bonds regularly, which is\n\nPrimary Market: Treasury sells bonds (millions of $ worth) mostly to private Investment Banks\nSecondary Market: Investment banks sell smaller chunks to private investors / bond holders sell to each other\n\n\nGovernments pay coupon and principal through\n\nTax revenue\nIssuing more bonds\n\n\n\nBonds are an important part of a portfolio becauseâ€¦\n\nAre near-riskless investments as they generate stable cash flows. The only risks are:\ninflation riskâ€”when the government doesnâ€™t have the money, theyâ€™ll just print more money. This causes inflation which devalues the bonds.\nAre very liquid, since many people are willing to buy bonds in most scenarios, even in recessions.\n"},"Boolean-Decision-Problem":{"title":"Boolean Decision Problem","links":[],"tags":["Computing/Algorithms"],"content":"Q. CNF Satisfiability Problem. (=CNF-SAT =Circuit Satisfiability) Given a conjunctive normal form, is there a way to set the variables to True or False such that the formula evaluates to True?\n(x1â€‹âˆ¨Â¬x2â€‹âˆ¨x3â€‹)âˆ§(Â¬x1â€‹âˆ¨x4â€‹)âˆ§(x2â€‹âˆ¨Â¬x3â€‹âˆ¨x5â€‹âˆ¨Â¬x6â€‹)\n\nLiteral: xiâ€‹ or xiâ€‹Ë‰â€‹\nClause: (x1â€‹âˆ¨x2â€‹âˆ¨x3â€‹Ë‰â€‹) a set of or-connected literals\n\nthm. Cooke-Levin Theorem. The Boolean Satisfiability problem is NP-complete.\n\nThe first problem to be determined to be NP-complete.\n\nQ. 3-Satisfiability Problem. (3-SAT)\n\nThe CNF-SAT problem, but every set of ORs has only three variables\n3-SAT â‰¤pâ€‹ 4-SAT\n\nalg. Reduction CNF-SAT â‰¤pâ€‹ 3-SAT\n\nIdea: aâˆ¨bâ‰¡(aâˆ¨c)âˆ©(bâˆ¨cË‰)â€¦â€¦(1)\n\n\nConstruction\n\nâˆƒ{x1â€‹â€¦xnâ€‹} variables that satisfies Q:q1â€‹â€¦qmâ€‹ where qiâ€‹ is a clause\nQâ€²:q1â€²â€‹â€¦qmâ€²â€²â€‹ constructed to satisfy (1).\n\nmâ€²&gt;m (obviously)\nNew variables v1â€‹â€¦vkâ€‹ thus Q has variables {x1â€‹â€¦xnâ€‹,v1â€‹â€¦,vkâ€‹}\n\n\n\n\nCNF-SAT â‡’ 3-SAT\n\nlet X1â€‹â€¦Xnâ€‹âˆˆ{0,1} that satisfies Q. Then these values will satisfy Qâ€² regardless of viâ€‹ â€™s values, so choose them arbitrarily. These values satisfy Qâ€²\n\n\n3-SAT â‡’ CNF-SAT\n\nlet X1â€‹â€¦Xnâ€‹,V1â€‹â€¦Vnâ€‹âˆˆ{0,1} that satisfies Qâ€². Then X1â€‹â€¦Xnâ€‹ will satisfy Q.\n\n\nThus proven.\n\nQ. DNF Satisfiability Problem. Given a disjunctive normal form, is there a way to set the variables to True or False such that the formula evaluates to True?\n\nExists a Polynomial time algorithm\nOnly one clause need be satisfied\n\nQ. Tautology. Given a Boolean formula Q, is Q always True regardless of what the variables are set to?\n\nThe verification procedure for True itself is NP-Complete, and it is exactly the CNF Satisfiability problem\nThe verification procedure for False is also NP-hard\nThe whole problem is not in NP (and is Co-NP Complete)\n"},"Branching-(Computer-Science)":{"title":"Branching (Computer Science)","links":[],"tags":["Computing/Computer-Architecture"],"content":"\n20% of instructions are branches\n30% of branches take an extra cycle\naverage CPI is 1+0.2*(0*.*3***1) = 1.06 cycles\n"},"Budget-Lines":{"title":"Budget Lines","links":["assets/Screen_Shot_2022-09-01_at_15.34.06.png","assets/Screen_Shot_2022-09-01_at_15.31.59.png"],"tags":["Economics/Micro-Economics"],"content":"\nâ‡’ Similar to the Possibility Frontier (PPF), but like a â€œconsumption possibility frontierâ€.\n\n\n                  \n                  Info \n                  \n                \n\nYou will often plot all other consumed goods into one combined good, as the **â€œofotherconsumptionâ€âˆ—âˆ—withunit.\nI=p1â€‹x1â€‹+p2â€‹x2â€‹â€”Equation of the budget constraint\n\ny-intercept: p2â€‹Iâ€‹ â†’ if you buy only x2â€‹\nx-intercept: p1â€‹Iâ€‹ â†’ if you buy only x1â€‹\ngradient: âˆ’p2â€‹p1â€‹â€‹\n\nâ†’ Opportunity cost of one unit of x1â€‹ in terms of x2â€‹.\nnegative, since for additional consumption of x1â€‹ you lose your ability to consume x2â€‹.\n\n\n\nChange in Budget Lines Â§\n\nExogenous change in income I\nChnage in price p1â€‹ or p2â€‹ Graph\n\nWhen price of good x1â€‹ decreases (i.e. p1â€‹ decreases) intercept p2â€‹Iâ€‹ stays the same, gradient p2â€‹p1â€‹â€‹ increases. Vice versa when p2â€‹ changes.\nâ‡’ Real income changes\n\n\nEndowments\n\nEndowments are a particular basket of goods you get for free; itâ€™s a single point in the graphâ€”in this case, (5 pants, 10 shirts) is the endowment.\n\n\nProgressive Taxes\nInter-temporal Budgets\n"},"Buffett-Indicator":{"title":"Buffett Indicator","links":[],"tags":["Economics/Finance"],"content":"Buffett Indicator Valuation Model\n\nThe Buffett Indicator (aka, Buffett Index, or Buffett Ratio) is the ratio of the total United States stock market to GDP.\n\nGDPStockÂ MarketÂ âˆ‘MCAPâ€‹\n\n\n\n1: Stock is overvalued â†’ Bubble\n\n\n&lt;1: Stock is undervalued â†’ Buy Now\n"},"CAPM-Model":{"title":"CAPM Model","links":["Security-(Finance)","Regression","Risk-(Finance)","Market-Beta","Leverage","Portfolio-Theory","Measuring-Security-Performance","Lagrangian-Optimization"],"tags":["Economics/Finance"],"content":"Gentle Introduction Â§\ndef. The Capital Asset Pricing Model (CAPM) is a method of predicting the returns of an asset, by using regression analysis between it and the marketâ€™s returns.\n\nThe regression line has the equation:\nriâ€‹âˆ’rfâ€‹=Î±+Î²â‹…(rmâ€‹âˆ’rfâ€‹)\nData correlates between market excess return (rmâ€‹âˆ’rfâ€‹) and asset excess return (=riâ€‹âˆ’rfâ€‹). The statistics produces the following data:\n\nCoefficient of Determination [=R-value] 0â‰¤R2â‰¤1, measures the goodness of fit. Bigger means the model is a better fit.\nStandard deviations [=Risk (Finance)] Ïƒmâ€‹,Ïƒiâ€‹\nCorrelation coefficient âˆ’1&lt;Ï&lt;1, measures the degree of correlation between the two variables\nMarket Beta [=slope â‰ˆ1] Î²:=Ïƒmâ€‹Ïi,mâ€‹â‹…Ïƒiâ€‹â€‹, which measures the sensitivity of one variable to another. It doesnâ€™t deviate much from 1.\nAlpha [=intercept â‰ˆ1], which measures the excess return against all odds (of the prediction of the CAPM model.) It should, theoretically, always be zero. But it is not (See Jensonâ€™s Alpha below.)\n\nIf we plot riskless assets with a riskful asset:\n\n\nrfâ€‹ is the riskless return, rpâ€‹ is the riskful assetâ€™s return, and w is the weight of riskful assets in portfolio.\nÏƒpâ€‹ is the volatility for the riskful asset, and Ïƒfâ€‹ the volatility of riskless asset, is zero by definition\nGradient of the blue line is Ïƒpâ€‹rpâ€‹âˆ’rfâ€‹â€‹ â† this is a constant. Thus the blue frontier is linear.\n\nâ‡’ With riskless assets, you can short-sell the riskless asset to go beyond the risk/return:\n\n(2) is achieved by short-selling the risk-free asset and purchasing more of the riskfull asset.\n\nThis is also called Leverage.\nThis means that the weight on the risk-free asset is negative\n\nâ€¦and the weight on the risk-full asset is &gt;1\n\n\nIf the risk-free rate ever eclipses the risk-ful rate, disaster insues. (This is what happened during the financial crisis of 2008; banks were highly levered.)\n\nCombination of Risk-fulâ€”Risk-free &amp; Risk-fulâ€”Risk-ful Â§\n\n\n\n                  \n                  6~7%.\n                  \n                \n\n\nNote that the axes are not market returns, but **excess returns**. This means usually the y-intercept will be zero, unless as we later discuss $\\alpha &gt;0$.\n\nSensitivity vs. Asset Return. If the data shows the assetâ€™s return is higher, then the sensitivity should increase.\n\n\nM is when the market is measuring against itself.\n\n\nRisks. In the CAPM model, there are two types of risks we care about.\n\nSystematic Risk [=market risk, beta risk]. This is the risk due to the market recessions.\n\nDiversification cannot solve beta risk.\nHigh beta implies higher returns in good times, worse returns in bad times.\n\n\nIdiosyncratic Risk. This is the risk due to individual firmsâ€™ characteristics (tech, organization, etc.)\n\nIdiosyncratic risk âŸ¶nâ†’âˆâ€‹0 i.e. diversification solves this\nUncorrelated with market risk.\n\n\n\n\n\n                  \n                  Industries that do well despite a recession: Pharmacuticals, Consumer necessities, Defense industries. \n                  \n                \n\nTechnical Reference Â§\nUse terminology from Portfolio Theory.\n\nMarket Beta: correlation of portfolio with market.\nCapital Allocation Line (CAL)\n\nSecurity (Ïƒiâ€‹,Î¼iâ€‹)\nRisk-free security (0,Î¼fâ€‹)\nEquation of Possible Portfolios (=Capital Allocation Line): Î¼pâ€‹=Ïƒiâ€‹Î¼iâ€‹âˆ’Î¼fâ€‹â€‹Ïƒpâ€‹+Î¼fâ€‹\n\nThis is a line â‡’ Capital Allocation Line.\nSlope: Ïƒiâ€‹Î¼iâ€‹âˆ’Î¼fâ€‹â€‹=PortfolioÂ RiskExcessÂ Returnâ€‹=SharpeÂ Ratio\nHigher slope (=higher Measuring Security Performance) is better (more return per unit risk)\n\n\n\n\nCapital Market Line (CML)\n\nMarket Security (Ïƒiâ€‹,Î¼Mâ€‹)\nRisk-free security (0,Î¼fâ€‹)\n\n\n\nInvestor Utility Function\n\nRed: risk-seeking\nBlack: risk-neutral\nBlue: risk-averse\n\n\n\n\nLagrangian Optimization problem maxÎ¼,Ïƒâ€‹E[u(Rpâ€‹)]Â s.t.Â g(Î¼,Ïƒ)=k\nâ‡’ to get optimal portfolio Rpâˆ—â€‹ \n\n\n\n\n"},"CS-250-Architecture":{"title":"CS 250 Architecture","links":["Abstraction"],"tags":["Courses"],"content":"\nAbstraction\n"},"CS-316-Database-Systems":{"title":"CS 316 Database Systems","links":["Database-Management-System","Relational-Algebra","Entity-Relationship-Model","Database-Design-Theory","SQL-Basics","SQL-Constraints","Extensible-Markup-Language","Document-Type-Definition","XPath-and-XQuery","MongoDB-Reference","Physical-Data-Organization","Database-Indexing","SQL-Query-Processing-Algorithms","SQL-Query-Optimization","SQL-Transaction-Guarantees"],"tags":["Courses"],"content":"Theoretical Foundations Â§\n\nDatabase Management System\nRelational Algebra\nEntity-Relationship Model\nDatabase Design Theory\n\nSerializable Query Language Â§\n\nSQL Basics\nSQL Constraints\n\nNoSQL Databases Â§\n\nExtensible Markup Language (XML)\nDocument Type Definition\nXPath and XQuery\nMongoDB Reference\n\nQuery Processing Â§\n\nPhysical Data Organization\nDatabase Indexing\nSQL Query Processing Algorithms\nSQL Query Optimization\nSQL Transaction Guarantees\n"},"CS-330-Advanced-Algorithms":{"title":"CS 330 Advanced Algorithms","links":["CS330-HW03","CS330-HW04","CS330-HW05","CS330-HW07","CS330-HW08","CS330-HW10","Time-Complexity","Recurrence-Relation","Peak-Element","Undominated-Points","Sorting-Algorithms","Priority-Queue","Parallel-Algorithms","Matrix-Multiplication","Inner-Product","Dynamic-Programming","Longest-Common-Sequence","Knapsack-Problem","Matrix-Chain-Multiplication","Depth-First-Search","Directed-Graph","Directed-Acyclical-Graph","Shortest-Path","Greedy-Algorithm","Scheduling-Problem","Huffman-Text-Compression-Algorithm","Minimal-Spanning-Tree-Problem","Ackerman-Function","Maximum-Flow-Problem","Computational-Tractability","Boolean-Decision-Problem","Common-Graph-Problems","Subset-Sum","Linear-Programming","Approximation-Algorithm","Set-Cover","Traveling-Salesperson-Problem","K-Clustering-Problem","Hashing-Algorithms"],"tags":["Courses"],"content":"Homeworks\n\n\nCS330 HW03\n\n\nCS330 HW04\n\n\nCS330 HW05\n\n\nCS330 HW07\n\n\nCS330 HW08\n\n\nCS330 HW10\n\n\nAsymptotic Analysis\n\nRecurrence Relation\n\n\n\nDivide and Conquer\n\nPeak Element\nUndominated Points\nQuick Sort\n\nTournament Tree\n\n\nMerge Sort\n\n\n\nParallel Algorithms\n\nParallel Sum\nMatrix Multiplication\n\nParallel Inner Product\n\n\nParallel Merge Sort\n\n\n\nDynamic Programming\n\nFibonacci Sequence\nLongest Common Sequence\nKnapsack Problem\nMatrix Chain Multiplication: increasing in gaps\n\n\n\nDepth First Search\n\nReachability and Connectivity\nDirected Graph\n\nPreand Post-time\nStrongly Connected Component algorithm (Kosarajuâ€™s)\nCycle detection â†’ DAG\nTopological Sort of DAG\n\n\n\n\n\nShortest Path\n\nSingle Source Shortest Path\n\nBFS Shortest Path (vertex creation, alarm clock method)\nDijkstraâ€™s\nA*\nBellman-Ford\n\n\nAll-Source Shortest Path: Floyd-Warshall\n\n\n\nGreedy Algorithm\n\nScheduling Problem\nHuffman Text Compression Algorithm\nMinimal Spanning Tree Problem\nAckerman Function\n\n\n\nMaximum Flow Problem (=Min-cut, Edge matching)\n\nMin Cut\nEdge Matching\n\n\n\nComputational Tractability\n\nPolynomial Reduction\nBoolean Decision Problem\n\nCooke-Levin Theorem\nCNF-SAT â‰¤pâ€‹ 3-SAT\nVertex Cover â‰¤pâ€‹ Subset Sum\nSubset Sum â‰¤pâ€‹ Knapsack Problem\n\n\nCommon Graph Problems\n\nIndependent Set\nClique\nVertex Cover\nTriangle Cover\n\n\nLinear Programming\n\n\n\nApproximation Algorithms\n\nLoad Balancing\nSet Cover\nTraveling Salesperson Problem\n\nChristofides Approximation (1.5-level)\n\n\nK-Clustering Problem\n\nK-Max: Maximum distance to closest center\nK-Means: Mean per center\n\nLlyodâ€™s Approximation (2-level)\nK-Means++ Approximation (&lt;2-level)\n\n\n\n\n\n\n\nHashing Algorithms\n\nUniformity\nUniversality\nLinear Congruence Hashing\nMultiply Shift Binary Hashing\n\n\n"},"CS-334-Formal-Languages":{"title":"CS 334 Formal Languages","links":["Finite-Automata","Regular-Expressions","Regular-Grammar","Regular-Languages","Pushdown-Automata","Context-Free-Grammar","Context-Free-Language","Turing-Machine","Recursively-Enumerable-Languages","Unrestricted-Grammar","Formal-Grammar","Formal-Languages","Chompsky-Heirarchy","Greibach-Normal-Form","Chompsky-Normal-Form"],"tags":["Courses"],"content":"Finite Automata Â§\n\nFinite Automata\nRegular Expressions\nRegular Grammar\nRegular Languages\n\nPushdown Autotmata Â§\n\nPushdown Automata\nContext-Free Grammar\nContext-Free Language\n\nTuring Machines Â§\n\nTuring Machine\nRecursively Enumerable Languages\nUnrestricted Grammar\n\nBackground Knowledge Â§\n\nFormal Grammar, Formal Languages\nChompsky Heirarchy\nGreibach Normal Form, Chompsky Normal Form\n"},"CS-535-Algorithmic-Game-Theory":{"title":"CS 535 Algorithmic Game Theory","links":["Game-Theory","Equilibria-in-Game-Theory","Zero-Sum-Game","Potential-Game","Traffic-Routing","No-Regret-Dynamics","Auction-Theory","Vickery-Auction","Sponsored-Search-Auction","Revenue-Maximizing-Auctions","Combinatorial-Auction","VCG-Auction","Ascending-Price-Auction","Optimal-Stopping-Problem","Fairness-(Economics)","Utility-Function","Fractional-Allocation","Integer-Allocation","Ordinal-Allocation","Property-Exchange","Stable-Marriage-Problem","Ski-Rental-Algorithm","Online-Matching","CS535-HW1","CS535-HW2","CS535-HW3","CS535-HW4","CS535-HW5","CS535-Midterm","(Paper)-Roughgarden,-Transaction-Fee-Mechanism-Design"],"tags":["Courses"],"content":"Games, Learning, and Dynamics Â§\n\nGame Theory\n\nEquilibria in Game Theory\nZero Sum Game, min-max theorem\n\n\nPotential Games\n\nTraffic Routing\n\n\nNo-Regret Dynamics\n\nAuctions Â§\n\nAuction Theory (directory of auctions)\n\nVickery Auction\nSponsored Search Auction\nRevenue-Maximizing Auctions\nCombinatorial Auction\n\nVCG Auction\nAscending Price Auction\n\n\n\n\nOptimal Stopping Problem\n\nAllocations Â§\n\nFairness (Economics) (directory of allocation methods)\n\nUtility Function\n\n\nCardinal Allocation\n\nFractional Allocation\nInteger Allocation\n\n\nOrdinal Allocation\n\nProperty Exchange\nStable Marriage Problem\n\n\nOnline Algorithms\n\nSki Rental Algorithm\nOnline Matching\n\n\n\n\n\nCS535 HW1\nCS535 HW2\nCS535 HW3\nCS535 HW4\nCS535 HW5\nCS535 Midterm\n(Paper) Roughgarden, Transaction Fee Mechanism Design\n"},"CS-Course-Requirements-(1-left)":{"title":"CS Course Requirements (1 left)","links":[],"tags":["Courses"],"content":"Bachelor of Science (BS) Degree\nCourse Substitutions for CS Majors or Minors\nGraduation with Distinction\nPrerequisites (Done) Â§\n\nOne of the following introductory COMPSCI courses or equivalent:\n\nCOMPSCI 101L (Introduction to Computer Science)\nCOMPSCI 102 (Interdisciplinary Introduction to Computer Science)\nCOMPSCI 116 (Foundations of Data Science)\n\n\nMATH 111L (Introductory Calculus I) or equivalent\nMATH 112L (Introductory Calculus II) or equivalent\n\nBase Requirements (Done) Â§\n\nCOMPSCI 201 (Data Structures and Algorithms)\n==COMPSCI 230 (Discrete Math for Computer Science)Â see substitutions==\nCOMPSCI 250 (Computer Architecture)\nCOMPSCI 330 (Design &amp; Analysis of Algorithms)\n\nOne Of the following COMPSCI Courses on Systems: (Done) Â§\n\nCOMPSCI 310 (Introduction to Operating Systems) or 510 (Advanced Operating Systems)\nCOMPSCI 316 (Introduction to Databases) or 516 (Database Systems)\nCOMPSCI 350 (Digital Systems, cross-listed as ECE 350) or 550 (Advanced Computer Architecture, cross-listed as ECE 552)\nCOMPSCI 351 (Computer Security) or 551 (Advanced Computer Security)*\nCOMPSCI 356 (Computer Network Architecture) or 514 (Computer Networks)\n\nTwo Courses in MATH/STA: (Done) Â§\n\nOne STA course at or above STA 111**, including the cross-listed MATH 230\nOne of MATH 202, 216, 218, or 221***\n\nFive Electives at 200-level or Higher (beyond Those Counted towards the Requirements above): (1 left) Â§\n\n\nThree COMPSCI courses that are not independent study courses\n\nCS 334 Formal Languages\nCS 545 Algorithmic game theory\n??\n\n\n\nTwo in COMPSCI (independent study possible), MATH, STA, or a related area approved by the Director of Undergraduate Studies\n\nMath 212 (this is allowed, see below)\nSTAT 432 Stat. Inference &amp; Learning\n\n\n\nBothÂ courses haveÂ been offered as a 290 and 590 course with the same name, and will satisfy this requirement.\n\nSTAÂ 111 will not be offered after Summer 2020. We recommend you take STAÂ 199 or higher.\n\n**MATH 212 does not count towards this requirement, but can count towards an elective."},"CS330-HW03":{"title":"CS330 HW03","links":[],"tags":["Courses"],"content":"Problem 2 Â§\nSubproblem (a) Â§\nIdea: a majority element must be majority in either of the two halves of an array\nAlgorithm:\n# array to check\nA[1..n]\n \nfunction Count(l, r, elem)\n\t# base case\n\tif l = r\n\t\treturn 1\n \n\t# divide array into two, and count there\n\tm = ceiling((l+r)*0.5)\n\tl_count = PCount(l, m, elem)\n\tr_count = PCount(m+1, r, elem)\n \n\t# return the sum of left and right counts\n\treturn l_count + r_count\n \nfunction MajorityElem(l,r)\n\t# base case\n\tif l = r\n\t\treturn A[l] \n \n\t# check left, right half majority\n\tm = ceiling((l+r)*0.5)\n\tleft_majority = MajorityElem(l, m)\n\tright_majority = MajorityElem(m+1, r)\n \n\t## check consensus\n \n\t# check no consensus first; if one is null return the non-null\n\tif left_majority == NULL and right_majority != NULL:\n\t\treturn right_majority\n\tif left_majority != NULL and right_majority == NULL:\n\t\treturn left_majority\n \n\t# there cannot be a both no consensus case\n \n\t# consensus agrees\n\tif left_majority == right_majority:\n\t\treturn left_majority\n\t\n\t# consensus disagrees\n\telse if left_majority != right_majority:\n \n\t\t# count the majority\n\t\tleft_count = Count(l, r, left_majority)\n\t\tright_count = Count(l, r, right_majority)\n\t\t\n\t\t# if tied, no consensus\n\t\tif left_count == right_count\n\t\t\treturn NULL\n\t\t\n\t\t# winner exists, return the winner\n\t\treturn left_count &gt; right_count ? left_majority : right_majority\n\t\t\n\nCount function: T(n)â‰¤2T(2nâ€‹)+O(1)=O(n)\nMajorityElement function: T(n)â‰¤2T(2nâ€‹)+2â‹…O(n)\n\nFirst term: recursive calls\nSecond term: calls Count\nSolution: T(n)=O(nlogn) (same recurrence relation as mergesort)\n\n\nCorrectness (Brief argument):\n\nBase case: in n=1 the element is majority element\nIH: Assume MajorityElement(k/2) is correct.\nIS:\n\nIf one of them has no majority but the other ones does, the one with majority must be the true majority because of an element exists in more than half of the total array it must be that in one of the halves it will be the majority.\nIf both halves have a majority, then the one that has more counts in the total array wins\nThere cannot be a both halves no-majority case as explained in (1)\n\n\n\n\n\nSubproblem (b) Â§\nParallel version of algorithm\n# array to check\nA[1..n]\n \nfunction PCount(l, r, elem)\n\t# base case\n\tif l = r\n\t\treturn 1\n \n\t# divide array into two, and count there\n\tm = ceiling((l+r)*0.5)\n\tspawn l_count = PCount(l, m, elem)\n\tspawn r_count = PCount(m+1, r, elem)\n\tsync\n\t\n\t# return the sum of left and right counts\n\treturn l_count + r_count\n \ndef MajorityElem(l,r)\n\t# base case\n\tif l = r\n\t\treturn A[l] \n \n\t# check left, right half majority\n\tm = ceiling((l+r)*0.5)\n\tparallel left_majority = MajorityElem(l, m)\n\tparallel right_majority = MajorityElem(m+1, r)\n \n\t## check consensus\n \n\t# check no consensus first; if one is null return the non-null\n\tif left_majority == NULL and right_majority != NULL:\n\t\treturn right_majority\n\tif left_majority != NULL and right_majority == NULL:\n\t\treturn left_majority\n \n\t# there cannot be a both no consensus case\n \n\t# consensus agrees\n\tif left_majority == right_majority:\n\t\treturn left_majority\n\t\n\t# consensus disagrees\n\telse if left_majority != right_majority:\n\t\t# count the majority\n\t\tleft_count = PCount(l, r, left_majority)\n\t\tright_count = PCount(l, r, right_majority)\n\t\t\t\t\n\t\t# if tied, no consensus\n\t\tif left_count == right_count\n\t\t\treturn NULL\n\t\t\n\t\t# winner exists, return the winner\n\t\treturn left_count &gt; right_count ? left_majority : right_majority\n \n\nPCount analysis\n\nSpan: Tâˆâ€‹(n)â‰¤T(2nâ€‹)+O(1)=O(logn)\nWork: Wâˆâ€‹(n)â‰¤2T(2nâ€‹)+O(1)=O(n)\nmajority element determination can be run in parallel\n\n\nSpan: Tâˆâ€‹(n)â‰¤T(2nâ€‹)+O(logn)=O(log2n)\n\nFirst term: parallel recursive call\nSecond term: compare the majority\nSolution\n\nUsing the master theorem, we see logbâ€‹a=log2â€‹1=0 and the for the residual term ccritâ€‹=0.\nThis is the second case from which we infer Tâˆâ€‹(n)=O(log2n)\n\n\n\n\nWork: Wâˆâ€‹â‰¤2T(2nâ€‹)+O(n)=O(nlogn)\n\nProblem 3 Â§\nfunction PCountAndArrange(l,r) =&gt; int\n\t# base case; if zero, return count 1; else return count 0\n\tif l=r\n\t\treturn A[l] == 0 ? 1 : 0\n \n\t# recursive call &amp; count\n\tm = ceiling((l+r)*0.5)\n\tk = spawn PCountAndArrange(l, m)\n\tn = spawn PCountAndArrange(m+1, r)\n\tsync\n\tzerocount = k + n\n \n\t# rearrange the left half zeros with right half numbers\n\tparallel for i = m-k+1 .. m\n\t\tB[i+k] = A[i]\n\tparallel for i = m .. m+k\n\t\tB[i-k] = A[i]\n\tparallel for i = m-k+1 .. m+k\n\t\tA[i] = B[i]\n \n\t# return the count\n\treturn zerocount\n\t\n\nProcessor count: O(n)\n\nPCountAndArrange recursive calls take O(n) processors\nrearrange takes O(n) processors for each parallel for loop\n\n\nSpan: Tâˆâ€‹(n)â‰¤T(2nâ€‹)+O(1)=O(logn)\nWork: Wâˆâ€‹(n)=2T(2nâ€‹)+O(n)=O(n)\n\nFirst term for recursive call\nSecond term for rearranging\n\n\n\nProblem 4 Â§\n# A[(int, int)] is the structure of the array\n \nfunction FindMaximal()\n\tmax_y = -Infinity\n\t\n\t\n\t# Sort the points in decreasing order by x-coordinate\n\tReverseMergeSort(A[])\n\tmax_y = A[0]\n\tresult = [A[0]]\n\t\n\t# traverse in reverse x direction (right to left)\n\tfor p in A\n\t\t# if y is bigger than anything seen before it&#039;s maximal\n\t\tif p.y &gt; max_y then\n\t\t\tresult.append(p)\n\t\t\tmax_y = p.y\n\t\t\t\n\treturn result\n\nReverseMergeSort O(nlogn)\nFindMaximal T(n)=O(n)+O(nlogn)=O(nlogn)\nCorrectness (Brief argument):\n\nThe rightmost element must be the maximal element\nIf the current element has a higher y value than any other element on the right side of it, it must be a maximum\nIf the current element has a lower y value than another point on the right of it, it is dominated by that point and thus cannot be a maximum\n\n\n\n# A[(int, int)] is the structure of the array\n \nfunction isDominant((x1,y1),(x2,y2))\n\t# first is dominant\n\tif (x1 &gt;= x2 and y1 &gt; y2) or (x1 &gt; x2 and y1 &gt;= y2)\n\t\treturn 1\n\t# second is dominant\n\tif (x2 &gt;= x1 and y2 &gt; y1) or (x2 &gt; x1 and y2 &gt;= y1)\n\t\treturn -1\n\t# none are dominant\n\telse\n\t\treturn 0\n\t\t\n \nfunction PSortedSubtract(A[1..n],B[1..m])\n\tparallel for i = 1..n\n\t\tif BinarySearch[A[i],B] == False\n\t\t\tC.append(A[i])\n \nfunction PFindDoms(l, r)\n\t# base case\n\tif l=r\n\t\treturn l\n\t\n\t# get indicies of domannt points from left and right half\n\tm = ceiling((l+r)*0.5)\n\tldoms = spawn PFindDoms(l,m)\n\trdoms = spawn PFindDoms(m+1,r)\n\tsync\n \n\tnondoms = []\n\tparallel for i = l..m\n\t\tparallel for j= m+1..r\n\t\t\t# either one is dominant drop the non-dominant\n\t\t\tif isDominant[A[i],A[j]] == 1\n\t\t\t\tnondoms.add(j)\n\t\t\tif isDominant[A[i],A[j]] == -1\n\t\t\t\tnondoms.add(i)\n\t\t\t\t\n\tPMergeSort(nondoms)\n\t\n\treturn SortedSubstract((ldoms + rdoms), nondoms)\n \nfunction FindMaximal()\n\t# mergesort based on the x values of the array\n\tXMergeSort(A)\n\treturn FindDoms(l, r)\n \n\nisDominant span: O(1)\nPSortedSubtract\n\nspan: Tâˆâ€‹(n)=O(logn)\nwork: Wâˆâ€‹(n)=O(nlogn)\n\n\nPFindDoms\n\nspan: T(n)=T(2nâ€‹)+O(1)+O(log3n)+O(logn)=O(log4n)\n\nfirst term: parallel recursion\nsecond term: parallel comparison of dominant points\nthird term: PMergeSort\nfourth term: SortedSubtract\nSecond case using master theorem: O(log4n) time.\n\n\n\n\n"},"CS330-HW04":{"title":"CS330 HW04","links":[],"tags":["Courses"],"content":"Problem 2 Â§\nfunction VC(v)\n\t# including v\n\tin = 1\n\tfor child c of v:\n\t\tin += min(c.in, c.ex)\n\t\n\t# not including v\n\tex = 0\n\tfor child c of v:\n\t\tex += c.in\n\t\t\n\tv.in = in\n\tv.ex = ex\n\t\n\treturn min(v.in, v.ex)\n\nBase case: for a leaf node leaf, leaf.in = 1, leaf.ex = 0\nIH: for node v with leaves u1..uk, assume ui.in, ui.ex is correct\nIS: for node v,\n\nCase including: VC including v does not require u1..uk to be included, but including it may be more minimal. IH guarantees ui.in, ui.ex is correct so take the minimum\nCase excluding: VC excluding v requires all of u1..uk to be included, so in that case sum all the ui.in values to guarantee counting all cases where children are included\n\n\nTime complexity: T(n)â‰¤#childrenâ‹…T(#childrennâ€‹)+O(1)=O(n)\n\nProblem 3 Â§\ndef PalindromeDecomposition\n \n\t# memo[n][n] is a 2-d array whose value is all &quot;N&quot;\n\t\n\t# in increasing order of gap\n\tfor gap=1..n\n\t\tfor i=0..n-gap-1\n\t\t\tj = i + gap\n\t\t\t\n\t\t\t# base case\n\t\t\tif i==j\n\t\t\t\tmemo[i][j] = Y\n\t\t\t\tcontinue\n\t\t\t\t\n\t\t\t# if edges are same, check the inner\n\t\t\tif A[i] == A[j]\n\t\t\t\tif memo[i+1][j-1] == Y\n\t\t\t\t\tmemo[i][j] == Y\n\t\t\t\telse\n\t\t\t\t\tmemo[i][j] == N\n\t\t\t\t\t\n\t\t\t# if edges are diff, not palindrome\n\t\t\telse A[i] != A[j]\n\t\t\t\tmemo[i][j] == N\n\t\n\t# memo_count[n][n] is a 2-d array whose value is all 0.\n\t\n\t# in increasing order of gap\n\tfor gap=1..n\n\t\tfor i=0..n-gap-1\n\t\t\tj = i + gap\n\t\t\t\n\t\t\t# if the whole length i-j is palindrome, 1\n\t\t\tif memo[i][j] == Y\n\t\t\t\tmemo_count[i][j] = 1\n\t\t\t\t\n\t\t\t# if the whole length isn&#039;t palindromic...\n\t\t\tminPcount = +infty\n\t\t\tfor k=0..j-i:\n\t\t\t\t# get the minimum palindrome split of all possible splits\n\t\t\t\tmin(minPcount, memo[i][i+k-1] + memo[i+k][j])\n\t\t\tmemo_count[i][j] = minPcount\n\t\n\treturn memo_count[0][n]\n \n\n\nPart 1:\n\nBase case: a length-1 string is a palindrome\nIH1: substring A[i+1][jâˆ’1] is a palindrome\n\nIS1: then if A[i]=A[j], the string A[i][j] is a palindrome\n\n\nIH2: substring A[i+1][jâˆ’1] is not a palindrome\n\nIS2: then the string A[i][j] cannot be a palindrome\n\n\n\n\n\nPart 2:\n\nBase case: If the string A[i][j] is a palindrome, then it is the minimum palindromic split of count 1\nIH: palindromic substring count has been computed correctly from all proper substrings of A[i][j]\nIS: the minimum palindromic substring if A[i][j] is the minimum of the sums A[i][i+kâˆ’1]+A[i+k][j] for kâˆˆ[i,j]\n\n\n\nThus proved\n\n\nPart 1 span: O(n2) as filling a 2-d array with O(1) calculation per subarray\n\n\nPart 2 span: O(n3) as filling a 2-d array with O(n) calculation per subarray\n\n\nâ‡’ Total time complexity: O(n3)\n\n"},"CS330-HW05":{"title":"CS330 HW05","links":[],"tags":["Courses"],"content":"Problem 1 Â§\nV = [] # all vertices\nE = [] # all edges\n# A[1..m] holds the preference list\n \ndef graphCreation():\n\t# for every friend\n\tfor k = 1..m:\n\t\tprevNode = None\n\t\tfor i = 1..len(A[k]):\n\t\t\tnode = A[k][i]\n\t\t\tif node not in V:\n\t\t\t\tV.append(node)\n\t\t\t# if this is the first node\n\t\t\tif prevNode != None:\n\t\t\t\t# add the edge\n\t\t\t\tE.append((node, prevNode))\n\t\t\tprevNode = node\n \npost = [] # post-time\nvisited = [] # add visited verticies\nclock = 0\n \n# in-class algorithm\ndef DFS(u):\n\tvisited[u] = True\n\tclock += 1\n\tfor (u -&gt; v) in E:\n\t\tif visited[v] == False:\n\t\t\tDFS(v)\n\tclock += 1\n\tpost = (u, clock)\n\t\ndef AllDFS(V, E):\n\tfor v in V:\n\t\tif visited[v] == False:\n\t\t\tDFS(v)\n \n# in-class proof\ndef TopologicalSort():\n\ttopological = Mergesort(post) # reverse merge sort of post-time\n\t# will be sorted by clock time:\n\t# e.g. [(v1, 0), (v4, 3), (v2, 7), ...]\n\treturn [v for v, time in topological]\n\t\t\t\t\nHigh-Level Algorithm Â§\nThis problem resembles the computation of a Topological Sorting on a Directed Acyclic Graph (DAG) that is created from the preference lists, which may contain contradictions.\n\nWe create a graph where each vertex represents a restaurant and each directed edge from vertex i to j signifies that restaurant i is preferred over restaurant j by some friend. We let n be the number of vertices (restaurants), m the number of edges (preferences), and N the total length of all preference lists.\nWe perform a Depth-First Search (DFS) on this graph to detect a cycle. If there is a cycle (contradictions in the preference lists), we report that no such ordering of restaurants exists.\nIf there is no cycle, we carry out a Topological Sort on this graph which gives the required ordering of restaurants.\n\nProof of Correctness Â§\n\nLetâ€™s represent the preference list of each friend as a directed path in the graph. The direction from i to j (iâ†’j) represents that restaurant i is preferred over restaurant j. Therefore, if there is an ordering that satisfies all friendsâ€™ preferences, the directed graph has to be acyclic.\nWe perform DFS on the graph, and if we find a back edge (which forms a cycle), it means the preferences are contradictory, and no solution exists. So, our DFS serves as a mechanism to validate if such an ordering can exist.\nIf DFS completes without detecting a cycle, we then apply Topological Sorting on this graph. The use of DFS ensures that all vertices are explored and included in the final ordering.\n\nRunning Time Â§\n\nCreating the graph takes O(N) time as we are examining each preference and creating an edge for it.\nRunning a DFS on the constructed graph takes O(n+m) time, where n is the number of vertices, and m is the number of edges, visited exactly once.\nThe Topological sorting takes O(nlogn) time as uses mergesort via post-time\nâ‡’ Total running time of the algorithm is O(N)+O(n+m)+O(nlogn)=O(nlogn+m+N).\n\nProblem 2 Â§\nV = [] # all verticies\nE = [] # all edges, undirected graph\nfor c in Constraints:\n\t# unpack the constraint into the two verticies of a graph\n\tu, v = c\n \n\t# add both verticies\n\tif v not in V:\n\t\tV.append(v)\n\tif u not in V:\n\t\tV.append(u)\n \n\t# add the edge if it doesn&#039;t exist\n\t# note that this is an undirected graph\n\tif both (u, v) and (v, u) not in E:\n\t\tE.append((u, v))\n \n \n \nvisited = []\nteam = [-1] * len(V) # create a team array initialized with -1\n# there is team 0 and team 1\nbipartite = True # assume true until disproven\n \ndef partitionDFS(u):\n\tvisited.append(u)\n\tfor all neighbours v of u:\n\t\t# if same team, not bipartite\n\t\tif v in visited and team[v] == team[u]:\n\t\t\t\tbipartite = False\n\t\t\t\treturn\n\t\t# if different team and not in visitied\n\t\telif v not in visited:\n\t\t\t# assign v the opposite team as u\n\t\t\tteam[v] = 1 - team[u]\n\t\t\tpartitionDFS(v)\n \ndef AllDFS():\n\tfor v in V:\n\t\tif v not in visited:\n\t\t\tteam[v] = 0 # start coloring from team 0\n\t\t\tpartitionDFS(v)\n \nIdea Â§\nThis problem can be seen as a variant of Bipartite Graph Checking problem, where every edge represents the constraint that two players cannot be in the same team.\n\nWe construct a graph where each vertex corresponds to a player and each edge corresponds to the constraint between players. Let n be the number of vertices (players) and m be the number of edges (constraints).\nWe then perform a Depth-First Search (DFS) on this graph aiming to 2-color the graph where color should alternate between vertices. If during this process we encounter a vertex that has already been visited and has the same color as the current vertex, it means players with existing constraints are in the same team, thus, no valid partition can exist.\nIf the DFS completes without detecting such a situation, the created 2-color partitions are the required team allocations.\n\nProof of Correctness Â§\nThe underlying premise for this solution relies on the properties of Bipartite Graphs.\n\nIf itâ€™s possible to divide players into two distinct groups such that no two players from the same team have constraints between them, the graph is bipartite.\nDuring the 2-color DFS check, if we come across an already visited and colored node that has the same color as the current node, we conclude that the graph isnâ€™t bipartite - thus, such a partition doesnâ€™t exist. If DFS completes without such contradictions, it means the graph is bipartite and weâ€™ve found a valid partition.\n\nRunning Time Â§\n\nConstructing the graph takes O(m) time as every constraint creates an edge in the graph.\nRunning DFS across all vertices and edges of our graph takes O(n+m) time.\nâ‡’ Total running time of the algorithm: O(m)+O(n+m)=O(n+m).\n"},"CS330-HW07":{"title":"CS330 HW07","links":[],"tags":["Courses"],"content":"Problem 1 Â§\nAlgorithm Â§\n# each item is in format (time, start/end, event_index)\n# order priosity: smaller time -&gt; start -&gt;\nQ = sort(L, R)\nEvents = []\n\nwhile Q has elements:\n\n\tif Q.next is a start time\n\t\tt &lt;- Q.dequeue\n\n\t\t# if there is a tie in start times\n\t\twhile Q.next.start_time == t.start_time:\n\t\t\tt &lt;- max_end_time(t, Q.dequeue)\n\t\t\t\n\t\t# t is now the earliest starting time with maximum duration\n\t\n\telse Q.next is an end time\n\n\t\t# get latest end time\n\t\twhile Q.next is an end time\n\t\t\tt &lt;- Q.dequeue\n\t\t\t\n\t\t# t is now the latest end time\n\t\t\n\tadd t&#039;s event to Events\n\t\n\tend if\nend while\n\nComplexity Â§\n\nSorting: O(nlogn)\nLoop: O(n)\nâ‡’ Total: O(nlogn)\n\nCorrectness Â§\n\nBase case\n\nLet Yâˆ—=(y1â€‹,â€¦) the optimal solution\nAssume Yâˆ—â€™s y1â€‹ is not the earliest start timeâ€¦â€¦(1)\nAlgorithm chooses earliest start time x1â€‹.\n\n[x1â€‹.start,y1â€‹.start] is in total cover, but not in Yâˆ—â€™s cover.\nThis means Yâˆ— cannot be optimal. This is a contradiciton\nThus Assumption (1) must be wrong\n\n\n\n\nInductive Step\n\nLet Yâˆ—=(x1â€‹â€¦xkâˆ’1â€‹,ykâ€‹,â€¦) is the optimal solution\nYâˆ—â€™s ykâ€‹ is the optimal next choice after xkâˆ’1â€‹\nCase 1: next item in priority queue is an end time\n\nAlgorithm chooses xkâ€‹ whereâ€¦\n\nxkâ€‹.start&lt;xkâˆ’1â€‹.end\nxkâ€‹.end&lt;yk+1â€‹.start\namong such points, max(xkâ€‹.end)\n\n\nAssume ykâ€‹ is an event that doesnâ€™t satisfy the maximum endtime requirementâ€¦â€¦(2)\n\nThen, [ykâ€‹.end,xkâ€‹.end] is in total cover, but not in Yâˆ—â€™s cover. This is a contradiction.\nThus assumption (2) must be wrong\n\n\n\n\nCase 2: next item in priority queue is a start time\n\nAlgorithm chooses xkâ€‹ with the earliest starting time and longest duration\nThis is at least as optimal as ykâ€‹, becauseâ€¦\n\nxkâ€‹.startâ‰¤ykâ€‹.start\nxkâ€‹.endâ‰¤ykâ€‹.end\nThus the cover of xkâ€‹ is as large as ykâ€‹\n\n\nThus xkâ€‹ is as optimal as ykâ€‹\n\n\n\n\nQED\n\nProblem 2 Â§\n// Idea: Reverse the order of weights in the graph,\n// then run minimum spanning tree.\n\n// First, reverse the weight ordering of the graph\n\n// negate weights...\nfor e in E\n\te&#039; &lt;- e\n\te&#039;.weight &lt;- -e.weight\n\tadd e&#039; to E&#039;\n\nlet m be the edge with minimum weight in E&#039;\n\n// then monotonically increase so all weights are positive \n// (to use MST algorithm)\nfor e in E&#039;\n\te&#039;.weight += m.weight + 1\n\n// Then, run MST algorithm (Prim or Kruskal)\nV_mst, E_mst &lt;- MST(V, E&#039;)\n\n// the minimum spanning tree in (V, E&#039;) is\n// same as the maximum spanning tree in (V, E)\n\n// Return the edges that are not in the MST.\nreturn E \\ E_mst\nCorrectness Â§\n\nThe problem is equivalent to getting a tree whose sum of edge weights is maximal.\n\nThis is because the remaining graph must be acyclic (a tree) andâ€¦\nâ€¦because the sum of removed weights is minimal thus the sum of remaining weights must be maximal.\n\n\nWe can convert the original graph in question to a weight order reversed graph:\n\nSuppose E={e1â€‹,e2â€‹,â€¦,emâ€‹} where eiâ€‹ has weight wiâ€‹\nThen, Eâ€²={e1â€²â€‹,â€¦emâ€²â€‹} where eiâ€²â€‹ has weight wmâˆ’i+1â€‹\n\n\nThen, we can leverage the correctness of the MST algorithm (primâ€™s or kruskalâ€™s) in order to get the minimum spanning tree of this new weight-order-reversed-graph.\nThe edges in this MST is the maximum spanning tree in the original graph\nTherefore, removing these edges we are left with the subset F which is minimal\n\nComplexity Â§\n\nnegating weights: O(m)\nmonotonically raising weights positive: O(m)\nMST algorith: O(mlogn)\nTotal: O(mlogn)\n"},"CS330-HW08":{"title":"CS330 HW08","links":[],"tags":["Courses"],"content":"Problem 1 Â§\nAs outlined in This Ed Discussion I assume I will have available the whole flow function at my disposal.\n// Find the min-cut edges\n// let f[e] the max-flow capacity by the flow function\n// let e.cap be the capacity of edge e\n\nRESIDUAL(V, E, f):\n    let r_E = [] // for residual edges\n    for edge e (u-&gt;v) in E:\n        forward_res = e.cap - f[e] // forward residual capacity\n        if forward_res &gt; 0:\n            add edge e (u-&gt;v) with e.cap = forward_res to r_E\n        if f[e] &gt; 0:\n            add edge e&#039; (v-&gt;u) with e&#039;.cap = f[e] to r_E // Only add reverse edge if flow &gt; 0\n    return r_E\n\n// Run DFS to find reachable vertices in residual graph\nreachable = DFS(s, r_E)\nunreachable = V - reachable\n\n// Find min-cut edges\nmin_cut_E = []\nfor a in reachable:\n    for b in unreachable:\n        if edge e (a-&gt;b) in E:\n            add e to min_cut_E\n\nINCREMENT(e):\n    if e not in min_cut_E:\n        f[e] = f[e] + 1\n    else:\n        r_E = RESIDUAL(V, E, f)\n        path = BFS(s, t, r_E) // augmenting path in res graph\n        if path exists:\n            augment_flow(path, 1) // flow augmentation from class\n            // Augment flow along path by 1\n    return f\n\nDECREMENT(e):\n    if f[e] &gt; 0 and e in min_cut_E:\n        f[e] = f[e] - 1\n    else:\n        r_E = RESIDUAL(V, E, f)\n        path = BFS(s, t, r_E) // augmenting path in res graph\n        if path exists:\n            augment_flow(path, -1) \n            // Decrease flow along path by 1\n    return f\n\nCorrectness Â§\n\nThis leverages the correctness of the max-flow and min-cut algorithm\n\n\nIncrement function\n\nIf the increment is in not in a min-cut the graph is still bottlenecked at the min-cut, and the maximum flow cannot increase. The flow function is the same\nIf the increement is in the min-cut, there may be more flow to be had. T\n\nhere is need only to construct and update using the residual network once because the increment is by 1, which means any path found by BFS on the residual graph is guaranteed to increase the max-flow.\nAlternatively, if the BFS doesnâ€™t find any path in the residual network, this means that the graph has a different min-cut due to the capacity change. But the flow function wouldnâ€™t change because there would be nothing to update (again, leveraging the correctness of the max-flow augmentation step.)\n\n\n\n\nDecrement function\n\nIf the decrement is in a min-cut the graphâ€™s bottleneck is reduced. The max flow will be reduced by 1\nIf the decrement is not in a min-cut the graphâ€™s bottleneck is not reduced, but there may be a change in flow. Use the flow augmentation step (symmetric to the increment in-min-cut situation) to update the flow function\n\n\n\nComplexity Â§\n\nResidual calculation: O(V+E) but assume V&lt;E thus O(E)\nUsing BFS shortest augmenting path: O(E)\nTotal: O(E)\n\nProblem 2 Â§\nN = Set of visitors, where n in N is the set of demographics\n// e.g. N[0] = {male, 40-50}\n\nM = Set of advertisers and their preferences and number of ads\n// e.g. M[0] = {male, female}, M[0].showCount = 3\n\n// Construct graph G = (V,E) such that\nfor n in N:\n\tadd n to V\nfor m in M:\n\tadd m to V\n\n// for every advertiser...\nfor m in M:\n\t// check if each visitor has any acceptable demographic\n\tfor n in N:\n\t\tfor dem in M:\n\t\t\tif n contains dem:\n\t\t\t\tadd (n-&gt;m,1) to E // directed edge n-&gt;m weight 1\n\n// Add start and end vertex for max-flow\n\nadd s, t to V\nfor n in N:\n\tadd (s-&gt;n, 1)\nfor m in M:\n\t// by allowing bigger capacity here, required # of visitors\n\t// accessed by the advertisers\n\tadd (m-&gt;t, m.showCount)\n\n// Calculate the max-flow with algorithm from class\nMaxFlow(G)\n\nfor every vertex m such that (m-&gt;t) in E:\n\tif edge (m-&gt;t) is at capacity:\n\t\tcontinue\n\telse // not at capacity; advertiser isn&#039;t satisfied\n\t\treturn False\nreturn true\n\nCorrectness Â§\n\nIdea is to transform the problem into the matching edges problem described in class, which is a variant of the max-flow problem\n\n\nVisitor is guarateed to be shown only one ad, because sâ†’nâˆˆN has capacity 1, meaning that for any edge nâ†’mâˆˆM only one of them can be used in max-flow (recall all edges nâ†’m for any nâˆˆN,mâˆˆM has capacity 1)\nAdvertiser is guaranteeed to be shown their ad only to the right demographic group, due to the edge matching conditions in line 13-19.\nIf all edges mâ†’t where mâˆˆM is at capacity, it means that the ads have the shown as much as the advertiser requested (showCount). This is because all edges nâ†’m for any nâˆˆN,mâˆˆM has capacity 1, and thus max-flow must use showCount number of nâ†’m edges for max-flow.\n\nThus, if the max-flow algorithm ends up using the full capacity of these edges, the conditions of the problem are feasible\nElse, the advertisers requested showCount has not been satisfied and the conditions are not feasible.\n\n\n\nComplexity Â§\n\nlet âˆ£Nâˆ£=n,âˆ£Mâˆ£=m. Note that both max(âˆ£M[i]âˆ£),max(âˆ£N[i]âˆ£)=O(k) where k is the number of demographic groups\nGraph Construction: line 8-11 O(n+m), line 14-19 O(nâ‹…mâ‹…max(âˆ£M[i]âˆ£)â‹…max(âˆ£N[i]âˆ£))=O(nmk2)\nMax-flow using BFS shortest augmenting path: O((n+m)(nm+n+m))\n\nn+m+2 is the number of vertices\nnm is the number of edges between nâˆˆN,mâˆˆM\nn+m is the number of edges between sâ†’n, mâ†’t\nâ‡’ Total O(nm(n+m))\n\n\nChecking mâ†’t is at max capacity: O(m)\nTotal: O(nm(n+m+k2))\n"},"CS330-HW10":{"title":"CS330 HW10","links":[],"tags":["Courses"],"content":"Problem 1 Â§\nAlgorithm is one that assigns every one element to the set with the smaller sum.\n(a) Â§\n\nWe first establish that the cost of the algorithm ALG=âˆ‘xâˆˆSâ€‹x where S is the bigger one of A,B.\n\nlet X={x1â€‹â€¦xnâ€‹} where xiâ€‹ is the i-th processed element by ALG.\n\n\nALG=âˆ‘xâˆˆSâ€‹xâˆ’xjâ€‹+xjâ€‹ where xjâ€‹ is the last item added to set S\n\n! Looking at the first term, we can establish âˆ‘xâˆˆSâ€‹xâˆ’xjâ€‹â‰¤21â€‹(âˆ‘i&lt;jâ€‹xiâ€‹)â€¦â€¦(1)\n\ni.e. SumÂ inÂ SÂ beforeÂ xjâ€‹â‰¤AverageÂ ofÂ totalÂ beforeÂ xjâ€‹\nWe know this because SumÂ inÂ SÂ beforeÂ xjâ€‹ is the smaller sum of A,B, and thus the average is bigger than the minimum of the two.\n\n\nThen we also establish âˆ‘i&lt;jâ€‹xiâ€‹â‰¤âˆ‘i&lt;jâ€‹xiâ€‹+âˆ‘i&gt;jâ€‹xiâ€‹=âˆ‘xâˆˆXâ€‹xâˆ’xjâ€‹\n\ni.e. Sum before xiâ€‹ â‰¤ sum before xjâ€‹ and sum after xjâ€‹ = total sum excluding xjâ€‹\n! This implies 21â€‹âˆ‘i&lt;jâ€‹xiâ€‹â‰¤21â€‹(âˆ‘xâˆˆXâ€‹xâˆ’xjâ€‹)â€¦â€¦.(2)\n\n\n&amp; (1) and (2) together shows âˆ‘xâˆˆSâ€‹xâˆ’xjâ€‹â‰¤21â€‹(âˆ‘xâˆˆXâ€‹xâˆ’xjâ€‹)=21â€‹âˆ‘xâˆ’21â€‹xjâ€‹â€¦â€¦(3)\n\n\nWe thus show ALGâ‰¤21â€‹âˆ‘xâˆ’21â€‹xjâ€‹+xjâ€‹=21â€‹âˆ‘x+21â€‹xjâ€‹â€¦â€¦(4)\n\nWe know from the lecture (makespan, lemma 1 and 2) that 21â€‹âˆ‘xâ‰¤OPT and xjâ€‹â‰¤OPT\n\nfirst, because optimal solution cannot be smaller than the total / 2\nsecond, because optimal solution cannot be smaller than any element\n\n\n\n\nThus we establish ALGâ‰¤OPT+21â€‹OPT=23â€‹OPT\n\n\n\n\nThus proven\n\n(b) Â§\n\nWe first investigate the trivial cases when X has repectively 1,2 and 3 elements\n\nCase n=1\n\nOPT=x1â€‹, ALG=x1â€‹ thus Î±=1\n\n\nCase n=2\n\nOPT=max[x1â€‹,x2â€‹], ALG=max[x1â€‹,x2â€‹] thus Î±=1\n\n\n\n\nWe then investigate the case when nâ‰¥3\n\nAs we also know that x1â€‹&gt;x2â€‹&gt;x3â€‹&gt;â‹¯&gt;xnâ€‹ in the order of assignment by ALG, we can state both that:\n\nix1â€‹+â‹¯+xiâ€‹â€‹â‰¥xiâ€‹ thus x1â€‹+â‹¯+xiâ€‹â‰¥ixiâ€‹â€¦â€¦(1)\nxjâ€‹â‰¥nâˆ’jxi+1â€‹+â‹¯+xnâ€‹â€‹ thus xjâ€‹â‰¥xi+1â€‹+â‹¯+xnâ€‹â€¦â€¦(2)\n(1)âˆ’(2) yields âˆ‘k=1â€¦iâ€‹xkâ€‹âˆ’xjâ€‹â‰¥\n\n\n\n\n\nProblem 2 Â§\nCode Â§\nimport csv\nfrom typing import List, Tuple\nimport time\nfrom math import radians, cos, sin, asin, sqrt\nimport random\n \n# Function to load data from CSV file\ndef load_data(riders_filepath) -&gt; List[Tuple[float, float]]:\n    passengers = []\n    with open(riders_filepath, &#039;r&#039;) as file:\n        csv_reader = csv.reader(file)\n        next(csv_reader, None)  # Skip the header\n        for row in csv_reader:\n            sourceLat = float(row[1])\n            sourceLon = float(row[2])\n            passengers.append((sourceLat, sourceLon))\n    return passengers\n \n# Assuming the Haversine function is replaced by a simple Euclidean distance for this simulation\ndef euclidean_distance(point1, point2):\n    return sqrt((point1[0] - point2[0]) ** 2 + (point1[1] - point2[1]) ** 2)\n \n# 2-approximation algorithm for k-center clustering using Euclidean distance\ndef k_center_clustering_euclidean(passengers, k, n):\n \n    # sample n elements from passengers\n    passengers = random.sample(passengers, n)\n \n    start_time = time.time()\n \n    # Choose an arbitrary point as the first center\n    hubs = [random.choice(passengers)]\n    for _ in range(1, k):\n        # Find the next hub as the point farthest from any existing hub\n        next_hub = max(passengers, key=lambda p: min(euclidean_distance(p, hub) for hub in hubs))\n        hubs.append(next_hub)\n \n    end_time = time.time()\n    \n    # Assign each point to the closest hub and calculate the cost\n    assignments = {hub: [] for hub in hubs}\n    for passenger in passengers:\n        closest_hub = min(hubs, key=lambda hub: euclidean_distance(passenger, hub))\n        assignments[closest_hub].append(passenger)\n \n    \n    # The cost is the maximum distance of any point to its assigned hub\n    cost = max(euclidean_distance(passenger, closest_hub)\n               for closest_hub, passengers in assignments.items() for passenger in passengers)\n    \n    return hubs, assignments, cost, end_time - start_time\n \n# Example passengers data (replacing the real CSV loading)\npassengers = load_data(&quot;./passengers.csv&quot;)\nprint(len(passengers))\n \n# Run the algorithm for different values of k and record the results\nprint(&quot;K&quot;)\nresults = {}\nfor k in range(50,200,10):\n    hubs, assignments, cost, runtime = k_center_clustering_euclidean(passengers, k, 100)\n    print(k, &quot;,&quot;, runtime)\n \nprint(&quot;N&quot;)\nfor n in range(1000, 5000, 100):\n    hubs, assignments, cost, runtime = k_center_clustering_euclidean(passengers, 10, n)\n    print(n, &quot;,&quot;, runtime)\n \nResults Â§\n\nProblem 3 Â§\nimport csv\nfrom typing import List, Tuple\nimport time\nfrom math import sqrt\nimport random\nimport numpy as np\n \n# Function to load data from CSV file\ndef load_data(riders_filepath) -&gt; List[Tuple[float, float]]:\n    passengers = []\n    with open(riders_filepath, &#039;r&#039;) as file:\n        csv_reader = csv.reader(file)\n        next(csv_reader, None)  # Skip the header\n        for row in csv_reader:\n            sourceLat = float(row[1])\n            sourceLon = float(row[2])\n            passengers.append((sourceLat, sourceLon))\n    return passengers\n \n# Euclidean distance function\ndef euclidean_distance(point1, point2):\n    return sqrt((point1[0] - point2[0]) ** 2 + (point1[1] - point2[1]) ** 2)\n \n# Function to initialize centroids randomly\ndef initialize_random(passengers, k):\n    return random.sample(passengers, k)\n \n# Function to initialize centroids using k-means++\ndef initialize_kmeans_plusplus(passengers, k):\n    centroids = [random.choice(passengers)]\n    # probabilistic initialization\n    for _ in range(1, k):\n        distances = [min(euclidean_distance(p, c) for c in centroids) for p in passengers]\n        probabilities = [d ** 2 for d in distances]\n        total = sum(probabilities)\n        probabilities = [p / total for p in probabilities]\n        next_centroid = random.choices(passengers, weights=probabilities, k=1)[0]\n        centroids.append(next_centroid)\n    return centroids\n \n# Assign passengers to the nearest centroid\ndef assign_passengers(passengers, centroids):\n    assignments = {}\n    for passenger in passengers:\n        closest_centroid = min(centroids, key=lambda centroid: euclidean_distance(passenger, centroid))\n        if closest_centroid in assignments:\n            assignments[closest_centroid].append(passenger)\n        else:\n            assignments[closest_centroid] = [passenger]\n    return assignments\n \n# Update centroids based on the mean of assigned points\ndef update_centroids(assignments):\n    centroids = []\n    for points in assignments.values():\n        centroids.append(tuple(np.mean(points, axis=0)))\n    return centroids\n \n# Calculate the quality of solution\ndef calculate_quality(assignments):\n    total_distance = 0\n    for centroid, points in assignments.items():\n        total_distance += sum(euclidean_distance(centroid, p) ** 2 for p in points)\n    return total_distance / len(assignments)\n \n# k-means algorithm\ndef k_means(passengers, k, initialize_func):\n    # Initialize centroids\n    centroids = initialize_func(passengers, k)\n    assignments = {}\n    for _ in range(20):  # fixed number of iterations for simplicity\n        # Assign passengers to the nearest centroid\n        assignments = assign_passengers(passengers, centroids)\n        # Update centroids\n        centroids = update_centroids(assignments)\n    return centroids, assignments\n \n# Run the k-means algorithm with different initializations\ndef run_k_means(passengers, k_values):\n    results = {k: {&#039;random&#039;: int, &#039;k-means++&#039;: int} for k in k_values}\n    for k in k_values:\n        for _ in range(3):  # Repeat the experiment 3 times\n            temp_results = {init: {&#039;runtime&#039;: 0, &#039;quality&#039;: 0} for init in (&#039;random&#039;, &#039;k-means++&#039;)}\n            for init, func in [(&#039;random&#039;, initialize_random), (&#039;k-means++&#039;, initialize_kmeans_plusplus)]:\n                start_time = time.time()\n                centroids, assignments = k_means(passengers, k, func)\n                runtime = time.time() - start_time\n                quality = calculate_quality(assignments)\n                temp_results[init][&quot;runtime&quot;] += runtime\n                temp_results[init][&quot;quality&quot;] += quality\n        # average the results\n        results[k][&#039;random&#039;] = (temp_results[&#039;random&#039;][&#039;runtime&#039;] / 3, temp_results[&#039;random&#039;][&#039;quality&#039;] / 3)\n        results[k][&#039;k-means++&#039;] = (temp_results[&#039;k-means++&#039;][&#039;runtime&#039;] / 3, temp_results[&#039;k-means++&#039;][&#039;quality&#039;] / 3)\n    return results\n \n# Example passengers data (replacing the real CSV loading)\n# Here we need to load the data from the file provided by the user\n# passengers = load_data(&quot;/path/to/passengers.csv&quot;)\n \npassengers = load_data(&quot;./passengers.csv&quot;)\nprint(len(passengers))\n \n# Define k values to test\nk_values = [2, 4, 6, 8]\n \n# Run the k-means algorithms and print the results\nresults = run_k_means(passengers, k_values)\nprint(results)\n \nResults Â§\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNumber of ClustersInitializationRuntimeQuality2random0.098172.265082k-means++0.097902.265084random0.156750.771634k-means++0.159210.721646random0.205300.395366k-means++0.215130.350478random0.265860.233318k-means++0.289570.20059"},"CS535-HW1":{"title":"CS535 HW1","links":[],"tags":["Courses"],"content":""},"CS535-HW2":{"title":"CS535 HW2","links":["No-Regret-Dynamics"],"tags":["Courses"],"content":"(DevonThink) Assignment 2\nProblem 1 Â§\nIn class algorithm uses regret bound of â‰¤2TlnNâ€‹. Now consider this modified RWM algorithm. The game ends at time Ï„ but we have no knowledge of it.\n\nInitially pitâ€‹=N1â€‹âˆ€iâˆˆX\nLet interval bound Tiâ€‹=2i. We start in the interval T0â€‹&lt;tâ‰¤T1â€‹\n\nIn this interval, we set Î·=min(Tiâ€‹lnNâ€‹â€‹,21â€‹)\nThen within this interval the regret â‰¤2Tiâ€‹lnNâ€‹\n\n\nOnce we reach the end of this interval, we move onto the next interval.\nWe reach the end of the algorithm when time is Ï„. We are in the interval Tkâ€‹&lt;t&lt;Tk+1â€‹ where k is the largest integer that satisfies 2kâ‰¤Ï„.\nNow, the regret at this point can be obtained by summing all regret from previous and current intervals:\n\nRegretâ€‹â‰¤i=1âˆ‘kâ€‹22ilnNâ€‹â‰¤22k+1lnNâ€‹=2Tk+1â€‹lnNâ€‹â€‹â€‹\nThus we have regret bound 2Tk+1â€‹lnNâ€‹ at time interval Ï„â‰¤Tk+1â€‹. \nProblem 2 Â§\nProblem 3 Â§\nThis is formulated as the online prediction problem, with the seller having the option to choose a price k1â€‹,k2â€‹,â€¦,kkâˆ’1â€‹,kkâ€‹ with the loss function what represents the foregone profit (that could have been captured).\nlitâ€‹={viâ€‹âˆ’kviâ€‹â€‹ifÂ sold,Â butÂ atÂ lowerÂ thanÂ willingÂ toÂ payifÂ notÂ soldâ€‹\n\nLoss is zero when price is set to perfectly match the current buyerâ€™s willingness to pay.\nThen, there are n iterations of the game (since there are n buyers), with k different options for the seller. Thus the regret bound for a RWM Formulation of the game will be â‰¤2nlnkâ€‹.\n\nProblem 4 Â§\nProblem 5 Â§\nBNE Â§\nThe utility of player i is\nÎ¼iâ€‹={viâ€‹âˆ’biâ€‹0â€‹ifÂ getsÂ itemelseâ€‹\nThen, assume other person bids bjâ€‹=2vjâ€‹â€‹ where vjâ€‹âˆ¼Unif(0,1). Then, to maximize their expected utility player i will:\nmaxbiâ€‹â€‹E(Î¼iâ€‹)=max(viâ€‹âˆ’biâ€‹)â‹…Â iâ€™sÂ bidÂ isÂ greaterÂ P(biâ€‹&gt;2vjâ€‹â€‹)â€‹â€‹\nWhere P(biâ€‹&gt;2vjâ€‹â€‹)=2biâ€‹ since vjâ€‹ is a uniform distribution. Then solve the maximization problem:\nmaxbiâ€‹â€‹(viâ€‹âˆ’biâ€‹)2biâ€‹\nSolving this problem will yield biâ€‹=2viâ€‹â€‹. This is shown symmetrically for the other agent.\nRevenue Â§\nThe revenue of the seller is\nRE(R)â€‹={2v1â€‹â€‹2v2â€‹â€‹â€‹givenÂ v1â€‹&gt;v2â€‹givenÂ v1â€‹&lt;v2â€‹â€‹=E(2v1â€‹â€‹âˆ£v1â€‹&gt;v2â€‹)+E(2v2â€‹â€‹âˆ£v1â€‹&lt;v2â€‹)=2â‹…âˆ«01â€‹2v1â€‹â€‹â‹…=f(v1â€‹)f(v1â€‹&gt;v2â€‹âˆ£v1â€‹)â€‹p(v1â€‹&gt;v2â€‹)=2v1â€‹â€‹p(v1â€‹âˆ£v1â€‹&gt;v2â€‹)â€‹â€‹dx=â€‹â€‹"},"CS535-HW3":{"title":"CS535 HW3","links":[],"tags":["Courses"],"content":"Problem 4 Â§\nLet agents 1 (Alice) and 2 (Bob). The optimal case is when 1 gets a and 2 gets b if Î±&gt;Î², and vice versa, thus maximum welfare for efficient allocation is\nÂ byÂ agentÂ 2Â 2â€‹â€‹+Â byÂ agentÂ 1Â max(Î±,Î²)â€‹â€‹\n1 will demand both initially when paâ€‹=pbâ€‹=0 but will drop out once\n2âˆ’(paâ€‹+pbâ€‹)â€‹&lt;max(Î±âˆ’paâ€‹,Î²âˆ’pbâ€‹)â€‹â€‹\nCase Î±âˆ’paâ€‹&gt;Î²âˆ’pbâ€‹. Then\npaâ€‹+pbâ€‹pbâ€‹pbâ€‹â€‹&gt;2âˆ’Î±+paâ€‹&gt;2âˆ’Î±&gt;1â€‹asÂ 1&lt;2âˆ’Î±&lt;2Â sinceÂ Î±âˆˆ(0,1)â€‹â€‹\nAnd 1 will not demand b anymore. This will lead to two cases:\n\nIf paâ€‹&lt;pbâ€‹ auction continues since both chooses a. 1 will drop out eventually, as paâ€‹ will be raised until paâ€‹&gt;Î± while 2 still demands a as long. Total welfare is 2.\nIf pbâ€‹&lt;paâ€‹ then 1 will drop out, 2 will get b with total welfare 2.\nSame can be shown for Î±âˆ’paâ€‹&lt;Î²âˆ’pbâ€‹.\n\nProblem 5 Â§\nâ€‹â€‹"},"CS535-HW4":{"title":"CS535 HW4","links":[],"tags":["Courses"],"content":"Problem 1 Â§\nProblem 2 Â§\nSubproblem 1 Â§\nSimply reporting âˆ utility on every item will result in the agent getting all items and thus maximum utility.\nSubproblem 2 Â§\nMechanism A will calculate MNW xâˆ—=argmaxxâ€‹âˆ‘âˆ€iâ€‹lnUiâ€‹(x) with the final allocation for agent i being:\nxiFâ€‹=xiâˆ—â€‹âˆjî€ =iâ€‹Ujâ€‹(xâˆ’iâˆ—â€‹)âˆjî€ =iâ€‹Ujâ€‹(xâˆ—)â€‹\nwhere, per the problem xâˆ’iâˆ—â€‹=argmaxxâ€‹âˆ‘jî€ =iâ€‹lnUjâ€‹(x), i.e. running MNW without agent i. For agent i, their final utility is\nUiFâ€‹=Uiâ€‹(xiâˆ—â€‹âˆjî€ =iâ€‹Ujâ€‹(xâˆ’iâˆ—â€‹)âˆjî€ =iâ€‹Ujâ€‹(xâˆ—)â€‹)=Uiâ€‹(xiâˆ—â€‹)â‹…âˆjî€ =iâ€‹Ujâ€‹(xâˆ’iâˆ—â€‹)âˆjî€ =iâ€‹Ujâ€‹(xâˆ—)â€‹\ndue to the utilities being additive utilities.\nOn the other hand, a VCG auction will allocate xâˆ—=argmaxxâ€‹âˆ‘âˆ€iâ€‹lnbiâ€‹(x) where biâ€‹ is the reported utility that may not be truthful. We consider agent i, while fixing everybody elseâ€™s reported utilities bâˆ’iâ€‹â€‹. The payment charged to agent i is:\npiâ€‹â€‹=jî€ =iâˆ‘â€‹lnbjâ€‹(xâˆ’iâˆ—â€‹)âˆ’=âˆ‘jî€ =iâ€‹lnbjâ€‹(xâˆ—)â€‹âˆ€jâˆ‘â€‹lnbjâ€‹(xâˆ—)âˆ’lnbiâ€‹(xâˆ—)Uâ€‹â€‹â€‹=lnjî€ =iâˆâ€‹bjâ€‹(xâˆ’iâˆ—â€‹)âˆ’lnjî€ =iâˆâ€‹bjâ€‹(xâˆ—)=âˆ’ln(âˆjî€ =iâ€‹bjâ€‹(xâˆ’iâˆ—â€‹)âˆjî€ =iâ€‹bjâ€‹(xâˆ—)â€‹)â€‹perÂ definitionÂ ofÂ VCGâ€‹\nThus for agent i their final utility is\nUiFâ€‹â€‹=lnUiâ€‹(xâˆ—)âˆ’piâ€‹=lnUiâ€‹(xâˆ—)+ln(âˆjî€ =iâ€‹bjâ€‹(xâˆ’iâˆ—â€‹)âˆjî€ =iâ€‹bjâ€‹(xâˆ—)â€‹)=ln(Uiâ€‹(xâˆ—)âˆjî€ =iâ€‹bjâ€‹(xâˆ’iâˆ—â€‹)âˆjî€ =iâ€‹bjâ€‹(xâˆ—)â€‹)â€‹perÂ theÂ questionâ€‹\nSubproblem 2a\nNow, the correspondence comes from the fact that the subtraction of final utility due to VCG payment corresponds to the scaling down of utility in mechanism A.\nSpecifically:\nlnfiâ€‹=lnjî€ =iâˆâ€‹Ujâ€‹(xâˆ—)âˆ’lnjî€ =iâˆâ€‹Ujâ€‹(xâˆ’iâˆ—â€‹)â‰¤0â€‹â€‹\nSince product of optimal utility allocation with j divided by Ujâ€‹(xâˆ—), cannot be better than product of optimal utility allocation without j in the first place (adaptation of logic from lecture). Thus we have fiâ€‹â‰¤1.\nSubproblem 2b\nThe correspondence between utilities will be:\nlnUiF,Mech.Aâ€‹=UiF,VCGâ€‹\nAnd since ln(x) is monotonic maximizing one will maximize the other. (Used in next proof)\nSubproblem 2c\nConsidering the VCG mechanism, agent i will attempt to maximize their own final utility, expressed as\nUiF,VCGâ€‹maxUiF,Mech.Aâ€‹â€‹=lnUiâ€‹(xâˆ—)âˆ’Â iÂ cannotÂ influenceÂ lnjî€ =iâˆâ€‹bjâ€‹(xâˆ’iâˆ—â€‹)â€‹â€‹+lnjî€ =iâˆâ€‹bjâ€‹(xâˆ—)âŸºmaxÂ UiF,VCGâ€‹âŸºmaxâ€‹lnUiâ€‹(xâˆ—)+lnjî€ =iâˆâ€‹bjâ€‹(xâˆ—)â€‹âŸºmaxlnâˆ€jâˆâ€‹bjâ€‹(xâˆ—)=maxâˆ€jâˆ‘â€‹lnbjâ€‹(xâˆ—)â€‹establisedÂ inÂ 2bsinceÂ bâˆ’iâ€‹â€‹Â isÂ fixedNashÂ welfareÂ max.â€‹â€‹\nWhich is to say, in mechanism A it is also in iâ€™s best interest to maximize the nash welfare objective. Thus mechanism A is DSIC. â– \nSubproblem 2d\nAs outlined in the problem statement, for any allocation x^:\nâˆ€iâˆ‘â€‹Uiâ€‹(xâˆ—)Uiâ€‹(x^)â€‹jî€ =iâˆ‘nâˆ’1â€‹(Ujâ€‹(xâˆ—)Ujâ€‹(xâˆ’iâˆ—â€‹)â€‹âˆ’1)â€‹â‰¤nâ‰¤1â€‹removeÂ specificÂ agentÂ isetÂ x^:=xâˆ’iâˆ—â€‹â€‹â€‹\nNow, using the hint from problem statement, set diâ€‹:=Ujâ€‹(xâˆ—)Ujâ€‹(xâˆ’iâˆ—â€‹)â€‹âˆ’1 Then since âˆ‘jî€ =inâˆ’1â€‹diâ€‹&lt;1, âˆjî€ =inâˆ’1â€‹(diâ€‹+1)â‰¤(1+nâˆ’11â€‹)nâˆ’1. Then:\n(nâˆ’1nâ€‹)nâˆ’1nâ†’âˆlimâ€‹(nâˆ’1nâ€‹)nâˆ’1e1â€‹â€‹â‰¥jî€ =iâˆnâˆ’1â€‹Ujâ€‹(xâˆ—)Ujâ€‹(xâˆ’iâˆ—â€‹)â€‹=âˆjî€ =iâ€‹Ujâ€‹(xâˆ’iâˆ—â€‹)âˆjî€ =iâ€‹Ujâ€‹(xâˆ—)â€‹=fiâ€‹1â€‹â‰¥nâ†’âˆlimâ€‹fiâ€‹1â€‹â‰¤nâ†’âˆlimâ€‹fiâ€‹â€‹â€‹\nâ– \nProblem 3 Â§\nSubproblem 1 Â§\nLet allocation A be EF1, i.e. âˆ€iâˆ€jâˆƒgÂ s.t.Â viâ€‹(Aiâ€‹)â‰¥viâ€‹(Ajâ€‹âˆ–{g}). Now, if we sum over all agents j that is not i on both sides:\nâˆ€iâˆƒgâ€‹Â s.t.Â (nâˆ’1)viâ€‹(Aiâ€‹)nviâ€‹(Aiâ€‹)â€‹â‰¥jî€ =iâˆ‘â€‹viâ€‹(Ajâ€‹âˆ–{gijâ€‹})â‰¥jî€ =iâˆ‘â€‹viâ€‹(Ajâ€‹âˆ–{gijâ€‹})+viâ€‹(Aiâ€‹)=jî€ =iâˆ‘â€‹(viâ€‹(Ajâ€‹)âˆ’viâ€‹({gijâ€‹}))+viâ€‹(Aiâ€‹)=jî€ =iâˆ‘â€‹viâ€‹(Ajâ€‹)+viâ€‹(Aiâ€‹)âˆ’jî€ =iâˆ‘â€‹viâ€‹(gijâ€‹)=âˆ€jâˆ‘â€‹viâ€‹(Ajâ€‹)âˆ’jî€ =iâˆ‘â€‹viâ€‹(gijâ€‹)â€‹addingÂ viâ€‹(Aiâ€‹)Â toÂ bothÂ sidesâ€‹\nTo bound each of these terms, we use:\njî€ =iâˆ‘â€‹viâ€‹(gijâ€‹)â€‹â‰¤jî€ =iâˆ‘â€‹maxgijâ€‹âˆˆAjâ€‹â€‹viâ€‹(gijâ€‹)â‰¤(nâˆ’1)maxgâ€‹viâ€‹(g)â€‹takeÂ itemÂ iÂ valuesÂ mostÂ fromÂ everybodyÂ elsejustÂ takeÂ maximumÂ valueÂ itemâ€‹â€‹\nThen returning to our original inequality:\nnviâ€‹(Aiâ€‹)Â valueÂ ofÂ EF1Â allocationÂ toÂ iÂ viâ€‹(Aiâ€‹)â€‹â€‹â€‹â‰¥=viâ€‹(â‹ƒâˆ€jâ€‹Ajâ€‹)âˆ€jâˆ‘â€‹viâ€‹(Ajâ€‹)â€‹â€‹âˆ’(nâˆ’1)maxgâ€‹viâ€‹(g)â‰¥Â valueÂ ofÂ proportionalÂ allocationÂ toÂ iÂ nviâ€‹(â‹ƒâˆ€jâ€‹Ajâ€‹)â€‹â€‹â€‹âˆ’Â someÂ constantÂ nnâˆ’1â€‹maxgâ€‹viâ€‹(g)â€‹â€‹â€‹â€‹\nâ– \nProblem 4 Â§\n\nlet Xijâ€‹ be the the utility of i getting item j. Per the question this is Unif[0,1].\nlet Yâˆ’ijâ€‹ be the largest utility an agent gives for item j, i.e. Yâˆ’ijâ€‹:=maxkî€ =iâ€‹Xkjâ€‹.\nFrom this we know that the probability that agent i will get item j is P(Xijâ€‹&gt;Yâˆ’ijâ€‹)\nWe first calculate iâ€™s expected utility, Uiâ€‹ from getting its own bundle:\n\nE(Uiâ€‹):=â€‹Eâ€‹âˆ€jâˆ‘â€‹Xijâ€‹Â iÂ bidÂ max?Â 1Xijâ€‹&gt;Yâˆ’ijâ€‹â€‹â€‹â€‹â€‹=âˆ€jâˆ‘â€‹=n+1nâ€‹Â ,Â seeÂ explainationÂ belowE(Xijâ€‹âˆ£Xijâ€‹&gt;Yâˆ’ijâ€‹)â€‹â€‹=n1â€‹P(Xijâ€‹&gt;Yâˆ’ijâ€‹)â€‹â€‹=mâ‹…n+1nâ€‹â‹…n1â€‹â€‹â€‹\nNote that\nE(Xijâ€‹âˆ£Xijâ€‹&gt;Yâˆ’ijâ€‹)â€‹=E(Xijâ€‹Â givenÂ itÂ isÂ largestÂ bidÂ forÂ j)=E(n-thÂ smallestÂ bidÂ fromÂ nÂ i.i.dÂ uniformÂ r.v.Â 0Â toÂ 1)=n+1nâ€‹â€‹PerÂ theÂ givenÂ hintâ€‹â€‹\nIn a similar fashion, we can calculate iâ€™s expected utility from getting another agent kâ€™s bundle, Uikâ€‹:\nE(Uikâ€‹)â€‹:=Eâ€‹âˆ€jâˆ‘â€‹Xijâ€‹â‹…1Xkjâ€‹&gt;Yâˆ’kjâ€‹â€‹â€‹=âˆ€jâˆ‘â€‹E(Xijâ€‹âˆ£Â doesnâ€™tÂ matterÂ Xkjâ€‹&gt;Yâˆ’kjâ€‹â€‹â€‹)â‹…P(Xkjâ€‹&gt;Yâˆ’ijâ€‹)=mâ‹…21â€‹â‹…n1â€‹â€‹â€‹\nNow, since the product Xijâ€‹â‹…1Xiâ€‹&gt;Yâˆ’ijâ€‹â€‹ themselves are independent random variables for all i, bounded from [0,1], and considering that Hoeffdingâ€™s inequality doesnâ€™t require identical distribution), we can use it to state:\nP(Uiâ€‹â‰¥E(Uiâ€‹)âˆ’t)P(Uikâ€‹â‰¤E(Uikâ€‹)+t)â€‹â‰¤eâˆ’2t2/âˆ‘âˆ€itemsâ€‹(1âˆ’0)=eâˆ’2t2/mâ‰¤eâˆ’2t2/mâ€‹Equivalentlyâ€‹â€‹\nReplacing E(Uiâ€‹),E(Uikâ€‹) with the values we calculated above, as well as set t:=2(n+1)mâ€‹ we get:\nP(Uiâ€‹â‰¥2(n+1)mâ€‹)â‰¤eâˆ’m/2(n+1)2P(Uikâ€‹â‰¤2(n+1)3mâ€‹)â‰¤eâˆ’m/2(n+1)2â€‹â€‹\nNow, the probability that i will envy k can be stated P(Uiâ€‹&lt;Uikâ€‹). Using the union bound inequality:\nP(Uiâ€‹&lt;Uikâ€‹)â€‹â‰¤P(Uiâ€‹â‰¤2(n+1)mâ€‹andÂ Uikâ€‹â‰¥2(n+1)3mâ€‹)â‰¤P(Uiâ€‹â‰¤2(n+1)mâ€‹)+P(Uikâ€‹â‰¤2(n+1)3mâ€‹)â‰¤2eâˆ’m/2(n+1)2â€‹â€‹\nThen, we calculate the probability that there will be no envy between any two agents i,k:\nP(i,kâ‹ƒâ€‹Uiâ€‹&lt;Uikâ€‹)â€‹â‰¤nÂ totalÂ agents,Â iâˆ‘â€‹â€‹â€‹nÂ totalÂ agentskâˆ‘â€‹â€‹â€‹P(Uiâ€‹&lt;Uikâ€‹)=n22eâˆ’m/2(n+1)2âŸ¶mâ†’âˆâ€‹0â€‹â€‹\nâ– "},"CS535-HW5":{"title":"CS535 HW5","links":[],"tags":["Courses"],"content":"Problem 1 Â§\nProof by induction\nProblem 2 Â§\nThe following case has all n women settle for their last proposer: m1â€‹ prefers w1â€‹ most, m2â€‹ prefers w2â€‹ most, etc. s.t. miâ€‹ prefers wiâ€‹ the most. Then every woman settles for their last proposer.\nProblem 3 Â§\nSubproblem 1 Â§\nWhere âˆ£Hâˆ£&gt;âˆ£Sâˆ£, a matching Ï€ is stable if :\n\nthere exists no unmatched pair (sâˆˆS,hâˆˆH) such that both would prefer to be with each other than their current match in Ï€\nthere exists no hospital slot that would prefer an unmatched student s rather than its current match.\n\nSubproblem 2 Â§\nWe can extend this problem to create âˆ£hâˆ£âˆ’âˆ£sâˆ£ new dummy hospital slots in set D, and add to every student sâ€™s preference list:\nÂ preexistingÂ preferenceÂ â‹¯â€‹â€‹â‰»sâ€‹âˆˆD,Â inÂ randomÂ orderh1â€‹â‰»sâ€‹h2â€‹â‰»â‹¯â‰»hâˆ£Dâˆ£â€‹â€‹â€‹\nAnd also for every hâˆˆD construct a randomly ordered preference set of all students as well, and then match students S with Hâ€²=HâˆªD.\nBy the same proof that we discussed during class (Gale-Shapely), this algorithm always has a stable matching including the dummy hospitals. When we remove the dummy hospitals, this will not create an unstable matching. This is because in every studentâ€™s preference ordering the dummy hospitals are lower than any real hospital in all studentâ€™s preferences, therefore no real-matched pair (s,tâˆˆHâˆ–D) will be unstable.\nProblem 4 Â§\nSubproblem 1 Â§\nWe run the Gale-Shapely algorithm on a partition with preferences by breaking ties arbitrarily. In this situation it is trivial to see that a variation on the lemma from class holds:\nLemma. If a woman w rejects man m, in all future scenarioes, w is engaged to man mâ€² who is not less preferred than m (i.e. w may be indifferent between m,mâ€²).\nThen, proof by contradiction. Suppose the Gale-Shapely algorithm terminates in a match with a strongly unstable match (m1â€‹,w2â€‹),(m2â€‹,w1â€‹) but w1â€‹â‰»m1â€‹â€‹w2â€‹ and m1â€‹â‰»w1â€‹â€‹m2â€‹. Then, since m1â€‹ proposes in order of his preferance he must have proposed and gotten rejected by w1â€‹ before proposing and being accepted by w2â€‹. By the lemma, since w1â€‹ rejected m1â€‹ she must have the preference m2â€‹âª°w1â€‹â€‹m1â€‹, but this is a contradiction.\nâ– \nSubproblem 2 Â§\nCounterexample. Suppose matching m1â€‹,m2â€‹ and w1â€‹,w2â€‹, whose preferences are such that:\n\nm1â€‹: w1â€‹â‰»w2â€‹\nm2â€‹: w1â€‹âˆ¼w2â€‹\nw1â€‹: m2â€‹â‰»m1â€‹\nw2â€‹: m2â€‹â‰»m1â€‹\nConsider matching (m1â€‹,w1â€‹),(m2â€‹,w2â€‹). This weakly unstable because (m2â€‹,w1â€‹) is a better match since m2â€‹ is indifferent and w1â€‹ prefers m2â€‹.\nThe only other possible matching (m1â€‹,w2â€‹),(m2â€‹,w1â€‹) is also unstable because w2â€‹ will prefer m2â€‹ and m2â€‹ is indifferent about this.\n\nProblem 4 Â§\nSubproblem 1 Â§\nConsider an algorithm which, on timestep i, moves distance (âˆ’2)iâˆ’1; in other words, moves right 1 step, then left 2 steps, then right 4 steps, then left 8 steps, etc. Suppose also that the car is located at point kâˆˆR. We can then say:\n\nmoveiâ€‹:=(âˆ’2)iâˆ’1, the movement at time i\ntraveliâ€‹:=2iâˆ’1, the total travel distance after time i\nAnd position (=displacement) after time i:\n\n\\frac{1}{3}(1-2^{i}) &amp; \\text{if i is even}  \\\\\n\\frac{1}{3}(1+2^{i}) &amp; \\text{if i is odd} \n\\end{cases}\nWe consider both cases:\n\nIf k&gt;0, the worst case is when on timestep i we have searched until point kâˆ’1 and then turn left on timestep i+1, then meet kâˆ’1 before timestep i+2. In this case:\n\nSince we move right on the first step, and k is set as one step to the right of posiâ€‹ i must be odd\nk=posiâ€‹+1, which means i=log2â€‹(3(kâˆ’1)âˆ’1)\n\n\nIf k&lt;0, the worst case is symmetric:\n\ni must be even\nk=posiâ€‹âˆ’1, which means i=log2â€‹(1âˆ’3(k+1))\nIn both cases the total travel distance is\n\n\n\nâ€‹=traveli+1â€‹+âˆ£posi+1â€‹âˆ£+âˆ£kâˆ£={âˆ’10+8kâˆ’316â€‹âˆ’8kâ€‹ifÂ k&gt;0,iÂ isÂ evenifÂ k&lt;0,iÂ isÂ oddâ€‹â€‹â€‹\nSince the optimal algorithm which knows k will always have a cost âˆ£kâˆ£:\nkâˆ’10+8kâ€‹âˆ’kâˆ’16/8âˆ’8kâ€‹â€‹&lt;8&lt;8â€‹k&gt;0k&lt;0â€‹â€‹\nThis is a 9-competitive algorithm.\nComputation:\n\nSubproblem 2 Â§\nConsider an algorithm which with 21â€‹ chance chooses the first step to be positive, and with 21â€‹ to be negative. After the decision the algorithm deterministically behaves like in subproblem 1. We consider the case when k&gt;0 (the analysis when k&lt;0 is symmetric):\nWhen âˆ£posiâ€‹âˆ£&lt;k&lt;âˆ£posi+1â€‹âˆ£, we have two cases for right-first or left-first:\n\nMoved right on the i-th step: the total travel distance is: traveli+1â€‹+âˆ£posi+1â€‹âˆ£+âˆ£kâˆ£\nMoved left on the i-th step: the total travel distance is traveliâ€‹+âˆ£posiâ€‹âˆ£+âˆ£kâˆ£\nSince each case have 21â€‹ chance, the expected travel distance is:\n\nE[totalÂ travel]â€‹=21â€‹(traveli+1â€‹+âˆ£posi+1â€‹âˆ£+âˆ£kâˆ£)+21â€‹(traveliâ€‹+âˆ£posiâ€‹âˆ£+âˆ£kâˆ£)â€‹â€‹\nTo bound this competitiveness we recall âˆ£posiâ€‹âˆ£&lt;k&lt;âˆ£posi+1â€‹âˆ£. We try to find k which maximizes the competitive ratio. Since iâ‰¥1:\n\\frac{d}{dk}\\frac{\\mathbb{E}[\\text{total travel}]}{|k|}=\\begin{cases}\n\\frac{8-11\\cdot 2^i}{6 k^2} \\text{if $i$ is even} \\\\\n\\frac{4-11\\cdot 2^i}{6 k^2} \\text{if $i$ is odd}\n\\end{cases} &lt;0\n$$(computation below) Thus regardless of if $k$ is positive or negative, the worst case scenario is when $k$ is smaller, or $k=|\\text{pos}_{i}|$. Then:\n$$\\begin{align}\n\\frac{\\mathbb{E}[\\text{total travel}]}{|k|}&amp;=\\frac{\\mathbb{E}[\\text{total travel}]}{|\\text{pos}_{i}|}\n \\\\\n&amp;=\\frac{1}{2|\\text{pos}_{i}|}(\\text{travel}_{i+1}+|\\text{pos}_{i+1}|+|\\text{pos}_{i}|)+\\frac{1}{2|\\text{pos}_{i}|}(\\text{travel}_{i}+2|\\text{pos}_{i}|) \\\\\n&amp;= \\begin{cases}\n\\frac{13\\cdot 2^i-10}{2 \\left(2^i-1\\right)}&amp; \\text{if $i$ is even}\\\\\n\\frac{13\\cdot 2^i-2}{2 \\left(2^i+1\\right)} &amp; \\text{if $i$ is odd}\n\\end{cases}\\\\\n\\lim_{ i \\to \\infty } \\frac{\\mathbb{E}[\\text{total travel}]}{|k|}&amp;\\leq 6.5&lt;7\n\\end{align}\nTherefore, the algorithm is 7-competitive. â– \nComputation of derivative (divided between i even or odd):\n\nComputation of competitive ratio (divided between i even or odd)"},"Cache":{"title":"Cache","links":["LRU-algorithm"],"tags":["Computing/Computer-Architecture"],"content":"#Â ofÂ Framesâ€‹=BlockÂ SizeCacheÂ Sizeâ€‹=(#Â ofÂ sets)Ã—(#Â ofÂ ways)=(2#Â ofÂ indexÂ bits)Ã—(assoc.)â€‹\n\nMost popular caching method: LRU algorithm\n"},"Capital-(Marxism)":{"title":"Capital (Marxism)","links":[],"tags":["Philosophy/Marxism"],"content":"Defining Capital Â§\nCapital is both\n\nstored up labor (as labor produces capital goods), and\npower to command labor:\n\n\nThe capitalist possesses this power not on account of his personal or human properties but in so far as he is an owner of capital. His power is the purchasing power of his capital, which nothing can withstand.\n\nConsider Capital profit and labor wage as fundamentally different products:\n\nprofits are in proportion to the amount of capital, but\nwage is determined by the amount of required subsistence:\n\n\nFirstly, the profits of capital are regulated altogether by the value of the stock employed, [â€¦] Furthermore, in many large factories the whole labour of this kind is committed to some principal clerk, whose wages never bear any regular proportion to the capital of which he oversees the management.\n\n\n[Laborer] becomes an appendage of the machine, and it is only the most simple, most monotonous, and most easily acquired knack, that is required of him. Hence, the cost of production of a workman is restricted, almost entirely, to the means of subsistence that he requires for maintenance,\n"},"Cardinality":{"title":"Cardinality","links":["Zermelo-Frankle-Set-Theory-with-Axiom-of-Choice-(ZFC)","Limits-of-Math-and-Computing"],"tags":["Math"],"content":"Referencing How Infinity Works (And How It Breaks Math) - YouTube\ndef. â„¶0â€‹ is the cardinality of natural numbers\ndef. â„¶1â€‹ is the cardinality of real numbers\n\nâ„¶n+1â€‹=2â„¶nâ€‹ i.e. â„¶n+1â€‹ is the cardinality of all the subsets of â„¶nâ€‹\n\nContinuum Hypothesis Â§\nhyp. There is no set whose cardinality is between that of integers and real numbers.\n\nExpressed using above notation: â„¶1â€‹=?â„µ1â€‹\nThis hypothesis is proved to be unprovable within ZFC, according to Limits of Math and Computing\n"},"Cartels-and-Collusion":{"title":"Cartels and Collusion","links":["Prisoner's-Dillemma"],"tags":["Economics/Game-Theory","Economics/Micro-Economics"],"content":"Cartels and the Natural Incentive to Defect Â§\ndef. Cartels are when firms collude to act as a single monopolistic firm.\nHowever, cartels cooperating is not a stable set of strategies, because it has a tendency to unravel, as it is a Prisonerâ€™s Dillemma situation.\nWe can analyze this for two firms in the following two ways:\n\n\n\nUsing the profit for the hypothetical monopoly firm (graph a)\n\nTwo firms each produce 21â€‹xM, and thus together produce xM at pM.\nIf I secretely produces one more unit of good:\nâ€¦both will lose red area together [=half each]\nâ€¦I will gain the profit of selling the additional units [blue area]\n\nâ†’ Thus I am incentivized to defect and produce more.\n\n\nUsing residual demand for one of the firms\n\nAssume the other firm is diligently cooperating to produce their 21â€‹xM.\nI will face a residual demand curve [=Dr] which is shifted left 0.5xM\nmy best option is to produce at MRr=MC which is 0.75xM, bigger than the promised 0.5xM\n\nâ†’ Thus I am incentivized to defect and produce more\n\n\n\n\n                  \n                  Prisonerâ€™s Dillemma situation:â€»\n                  \n                \n\n\nAside on Prisonerâ€™s Dilemma Â§\n\n\n                  \n                  Quote \n                  \n                \ndef. Prisonerâ€™s Dillemma (PD) is any game where the following payoff structure holdsâ€¦\nâ€¦where T&gt;R&gt;P&gt;S:\n\n\nFinitely Iterated PD Â§\nIn a finitely iterated PD, the Subgame Perfect Nash Equilibrium is to defect every game.\n\nSolving from the last game:\n\nLast Game: Knowing there will be no more games [= same as one-shot game], your dominant strategy is defection.\n2nd to last: Knowing that next game both will defect, your dominant strategy is defection.\nâ€¦\nThe whole game unravels into a defection.\n\nInfinitely Iterated PD Â§\nGame design with:\n\nInfinitely many games\nprobability that one will meet [Î³]\ndiscount parameter [PV=rFVâ€‹]\n\nIn this case there are multiple Nash Equilibirum Strategies\n\nALL C is a BR to ALL C â†’ (ALL C, ALL C) is an NE\nTRIGGER is a BR to TRIGGER â†’ (TRIGGER, TRIGGER) is an NE\nTrigger Strategy:= strategy where the opponentâ€™s current action triggers my future behavior. e.g. â€œI will coop. until opp. defects, and defect always after that.â€\nTFT is a BR to TFT â†’ (TFT, TFT) is an NE\n\n\n\n                  \n                  These strategies are subgame perfect. Letâ€™s prove that for (TRIGGER, TRIGGER): \n                  \n                \n\n\nIf weâ€™ve always cooperated before, this subgame is same as original game\nâ†’ (TRIGGER, TRIGGER) is an NE\nIf there was non-cooperation before, this subgame has NE:\nâ†’ (ALL D, ALL D) is an NE\n\nâ†’ All subgames have NE (TRIGGER, TRIGGER).\nâˆ´ (TRIGGER, TRIGGER) is a SPNE"},"Cash-Sweep":{"title":"Cash Sweep","links":[],"tags":["Economics/Finance"],"content":"when money is automatically moved into a bank account based on a certain threshold. The money is then put into a higher interest-earning account such as a high interest saving account, money market mutual funds, or short-term certificates or can be used to payoff debt."},"Central-Limit-Theorem":{"title":"Central Limit Theorem","links":[],"tags":["Math/Probability"],"content":"\n\n                  \n                  Intuition: Selecting from a box of 1 to 10, \n                  \n                \n\nAs the sample size (n) increases, observe the following:\n\nÎ¼ is constant\nVar is increasing\nThe distribution apporoaches a bell curve\n\n\nthm. Law of Averages (=Law of Large Numbers) let X1â€‹,â€¦,Xnâ€‹ be random variables that are i.i.d. If E(X)=Î¼, and XË‰nâ€‹=nX1â€‹+â‹¯+Xnâ€‹â€‹ then for any small value of Ïµ:\nnâ†’âˆlimâ€‹[P(âˆ£Xâˆ’Î¼âˆ£&lt;Ïµ)]=1\n\nthm. Central Limit Theorem (for averages) let X1â€‹,â€¦,Xnâ€‹ be random variables that are i.i.d. If E(X)=Î¼, SD(X)=Ïƒ and XË‰nâ€‹=nâˆ‘Xiâ€‹â€‹ then for a big value of n:\nXË‰nâ€‹âˆ¼Normal(Î¼,nÏƒ2â€‹)\nâˆµ for XË‰nâ€‹ where n is just a constant\n\nMean: E(XË‰nâ€‹)=E(nX1â€‹+â‹¯+Xnâ€‹â€‹)=n1â€‹â‹…nâ‹…E(Xiâ€‹)=Î¼\nVariance: Var(XË‰nâ€‹)=Var(nX1â€‹+â‹¯+Xnâ€‹â€‹)=n21â€‹â‹…nâ‹…Var(Xiâ€‹)=nÏƒ2â€‹\nStd. Dev: SD(XË‰nâ€‹)=Var(XË‰nâ€‹)â€‹=nâ€‹Ïƒâ€‹\n\nthm. Central Limit Theorem (for sums) let X1â€‹,â€¦,Xnâ€‹ be random variables that are i.i.d. If E(X)=Î¼, SD(X)=Ïƒ and Snâ€‹=X1â€‹+â‹¯+Xnâ€‹ then for a big n:\nSË‰nâ€‹âˆ¼Normal(nÎ¼,nÏƒ2)\nâˆµ for Snâ€‹ where n is just a constant\n\nMean: E(Snâ€‹)=E(X1â€‹+â‹¯+Xnâ€‹)=nâ‹…E(Xiâ€‹)=nÎ¼\nVariance: Var(Snâ€‹)=Var(X1â€‹+â‹¯+Xnâ€‹)=nâ‹…Var(Xiâ€‹)=nÏƒ2\nStd. Dev: SD(Snâ€‹)=Var(Snâ€‹)â€‹=nâ€‹â‹…Ïƒ\n\n\n\n                  \n                  Abstract \n                  \n                \nTo Summarize, for a big enough value of n, and XË‰nâ€‹ the average and Snâ€‹ the sum:\n\nP(a&lt;XË‰nâ€‹&lt;b)â‰ƒâˆ«abâ€‹Normal[Î¼,n2Ïƒâ€‹]=âˆ«Ïƒ/nâ€‹aâˆ’Î¼â€‹Ïƒ/nâ€‹aâˆ’Î¼â€‹â€‹Normal[0,1]=Î¦(Ïƒ/nâ€‹bâˆ’Î¼â€‹)âˆ’Î¦(Ïƒ/nâ€‹aâˆ’Î¼â€‹)P(a&lt;Snâ€‹&lt;b)â‰ƒâˆ«abâ€‹Normal[nÎ¼,nÏƒ2]=âˆ«nâ€‹Ïƒaâˆ’nÎ¼â€‹nâ€‹Ïƒbâˆ’nÎ¼â€‹â€‹Normal[0,1]=Î¦(nâ€‹Ïƒbâˆ’nÎ¼â€‹)âˆ’Î¦(nâ€‹Ïƒaâˆ’nÎ¼â€‹)\nrmk. Binomal Approximtion using Normal Distribution. let the following:\n\nXâˆ¼Binom[n,p]\nIndicator functions s.t. X=I1â€‹+â‹¯+Inâ€‹ where Iiâ€‹ defines the i-th event is successful.\nNote that I1â€‹,â€¦,Inâ€‹ are all i.i.d.\nthenâ€¦\nE(Iiâ€‹)=p\nVar(Iiâ€‹)=E(Ii2â€‹)âˆ’[E(Iiâ€‹)]2=E(Iiâ€‹)âˆ’p2=pâˆ’p2\n(âˆµâˆ€I=Indicator,Â E(I2)=E(I))\nFor a large enough n, Xâˆ¼Normal[np,np(1âˆ’p)]\n(âˆµI1â€‹,â€¦,Inâ€‹ are i.i.d., see the additional rule for expectated value and variance)\n\nLindenberg CLT Â§\nthm. Lindenberg Central Limit Theorem. Given random variables X1â€‹â€¦Xnâ€‹, with each E(Xkâ€‹)=Î¼kâ€‹, Var(Xkâ€‹)=Ïƒk2â€‹and the following conditions:\n\nThey are independent (No need to be identically distributed)\nlimnâ†’âˆâ€‹âˆ‘Ïƒk2â€‹1â€‹E((Xkâ€‹âˆ’Î¼kâ€‹)21âˆ£Xkâ€‹âˆ’Î¼kâ€‹&gt;Ïµâˆ‘Ïƒk2â€‹â€‹) i.e. variance is not too big\nâ‡’ Then\n\nâˆ‘k=1nâ€‹Ïƒk2â€‹â€‹âˆ‘k=1nâ€‹(Xkâ€‹âˆ’Î¼kâ€‹)â€‹âŸ¶nâ†’âˆdâ€‹N(0,1)"},"Centralized-Power":{"title":"Centralized Power","links":[],"tags":["Philosophy/Political-Philosophy"],"content":""},"Change-of-Variable-(Probability)":{"title":"Change of Variable (Probability)","links":[],"tags":["Math/Probability"],"content":"thm. Linear Change of Variable. let XÂ s.t.Â P(X=x)=fXâ€‹(x). let Y=aX+b. Thenâ€¦:\nfYâ€‹(y)=âˆ£aâˆ£1â€‹fXâ€‹(ayâˆ’bâ€‹)\nthm. Change of Variable (bijective function). let XÂ s.t.Â P(X=x)=fXâ€‹(x). let Y=g(X) where g(x) is an inversible function (=bijective). Thenâ€¦:\nfYâ€‹(y)=âˆ£dy/dxâˆ£fXâ€‹[gâˆ’1(y)]â€‹\n\nThe bottom is a x-axis reflective version of fXâ€‹\nThe left is a 90 degrees counterclockwise rotation of fYâ€‹\nThe graph is of Y=g(X) where g(x)=xâ€‹\n\nthm. Change of Variable (injective function). let:\n\nX,Y,fXâ€‹,fYâ€‹,Y=g(X)\nDomain(X) is partitioned [x1â€‹,x2â€‹),[x2â€‹,x3â€‹),â€¦ s.t. g(x) is bijective in each interval.\n\nthen fYâ€‹(y) can be defined on interval [xiâ€‹,xi+1â€‹)â€¦:\nfYâ€‹(y)=x:y=g(x)âˆ‘â€‹âˆ£dy/dxâˆ£fXâ€‹[gâˆ’1(y)]â€‹Â ,Â whenÂ yâˆˆg([xiâ€‹,xi+1â€‹))"},"Chebyshev's-Inequality":{"title":"Chebyshev's Inequality","links":[],"tags":["Math/Statistics"],"content":"\nthm. Chebyshevâ€™s Inequality. let X s.t. E[X]=Î¼, Var[X]=Ïƒ2 where Ïƒ is not infinite. Then:\n\nâˆ€Ïµ&gt;0,P(âˆ£Xâˆ’Î¼âˆ£&gt;Ïµ)â‰¤ÏµÏƒ2â€‹\n\nIntuitively, it means that â€œonly fewâ€ data points are â€œfar awayâ€ from the mean for any â€œreasonableâ€ distribution:\n\nâ€œonly fewâ€: â€œâ‰¤ÏµÏƒ2â€‹â€\nâ€œfar awayâ€: â€œâˆ£Xâˆ’Î¼âˆ£&gt;Ïµâ€\nâ€œreasonableâ€: Ïƒ is not infinite.\n\n\n"},"Chi-Squared":{"title":"Chi-Squared","links":["Gamma-Distribution"],"tags":["Math/Common-Distributions"],"content":"Ï‡n2â€‹âˆ¼i=1âˆ‘nâ€‹Zi2â€‹\nalso related to the Gamma Distribution:\n\nÎ“(n,2)âˆ¼Ï‡n2â€‹\n"},"Chinese-101":{"title":"Chinese 101","links":["Pinyin-Rules"],"tags":["Courses"],"content":"\nPinyin Rules\n\n"},"Chompsky-Heirarchy":{"title":"Chompsky Heirarchy","links":["Formal-Grammar","Formal-Languages","Turing-Machine","Unrestricted-Grammar","Recursively-Enumerable-Languages","Linear-Bound-Automata","Context-Sensitive-Grammar","Recursive-Languages","Pushdown-Automata","Context-Free-Grammar","Context-Free-Language","Finite-Automata","Regular-Expressions","Regular-Grammar"],"tags":["Computing/Formal-Languages"],"content":"The Chompsky Heirarchy is the levels of capabilities of automata=grammar=languages.\nCapabilities of Automata Â§\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nType of AutomataMemoryCanâ€¦Canâ€™t..Finite AutomataNonerecognize integersrecgz. arith. expr.Push-down AutomataStackrecgz. arith. expr.compute arith. expr.Turing MachineInfinitecompute arith. expr.determine halting probl.\nThe Heirarchy Â§\n\nTuring Machine == Unrestricted Grammar == Recursively Enumerable Languages\nLinear Bound Automata == Context Sensitive Grammar == Recursive Languages\nPushdown Automata == Context-Free Grammar == Context-Free Language\nFinite Automata == Regular Expressions == Regular Grammar\n\n"},"Chompsky-Normal-Form":{"title":"Chompsky Normal Form","links":[],"tags":["Computing/Formal-Languages"],"content":""},"Circular-Flow-of-Income":{"title":"Circular Flow of Income","links":[],"tags":["Economics/Macro-Economics"],"content":""},"Class-Traitors":{"title":"Class Traitors","links":[],"tags":["Philosophy/Marxism"],"content":""},"Cobb-Douglas-Utility-(Two-Goods)":{"title":"Cobb-Douglas Utility (Two Goods)","links":["Uncompensated-Demand-curve","Utility-Function","Marginal-Willingness-to-Pay","Expenditure-Function"],"tags":["Economics"],"content":"def. Two-goods Cobb-Douglas Utility function:\nu(x1â€‹,x2â€‹)=x1Î±â€‹x21âˆ’Î±â€‹\nlet the income:\nI(p1â€‹,p2â€‹)=p1â€‹x1â€‹+p2â€‹x2â€‹\nUtility Maximization Â§\nmaxx1â€‹,x2â€‹â€‹u=x1Î±â€‹x21âˆ’Î±â€‹Â Â suchÂ thatÂ Â I=p1â€‹x1â€‹+p2â€‹x2â€‹\nOrdinary Demand: Â§\nâ©â¨â§â€‹x1â€‹(p1â€‹,p2â€‹,I)=p1â€‹Î±Iâ€‹x2â€‹(p1â€‹,p2â€‹,I)=p2â€‹(1âˆ’Î±)Iâ€‹â€‹\nIndirect Utility: Â§\nv(p1â€‹,p2â€‹,I)â€‹:=u(x1â€‹(p1â€‹,p2â€‹,I),x2â€‹(p1â€‹,p2â€‹,I))=p1Î±â€‹Â p21âˆ’Î±â€‹(1âˆ’Î±)1âˆ’Î±Â Î±Î±â€‹â‹…Iâ€‹â€‹\nExpenditure Minimization Â§\nminx1â€‹,x2â€‹â€‹I=p1â€‹x2â€‹+p2â€‹x2â€‹Â Â suchÂ thatÂ Â u=x1Î±â€‹x21âˆ’Î±â€‹\nCompensated Demand: Â§\nâ©â¨â§â€‹h1â€‹(p1â€‹,p2â€‹,uË‰)=(p2â€‹p1â€‹â€‹Î±1âˆ’Î±â€‹)Î±uË‰h2â€‹(p1â€‹,p2â€‹,uË‰)=(p1â€‹p2â€‹â€‹1âˆ’Î±Î±â€‹)1âˆ’Î±uË‰â€‹\nExpenditure Function: Â§\nE(p1â€‹,p2â€‹,uË‰)â€‹:=p1â€‹h1â€‹+p2â€‹h2â€‹=(1âˆ’Î±)1âˆ’Î±Â Î±Î±p1Î±â€‹Â p21âˆ’Î±â€‹â€‹â‹…uË‰â€‹â€‹"},"Cobb-Douglas-Utility":{"title":"Cobb-Douglas Utility","links":["Uncompensated-Demand-curve","Utility-Function","Marginal-Willingness-to-Pay","Expenditure-Function"],"tags":["Economics"],"content":"def. Two-goods Cobb-Douglas Utility function:\nu(x1â€‹,x2â€‹)=x1Î±â€‹x21âˆ’Î±â€‹\nlet the income:\nI(p1â€‹,p2â€‹)=p1â€‹x1â€‹+p2â€‹x2â€‹\nUtility Maximization Â§\nmaxx1â€‹,x2â€‹â€‹u=x1Î±â€‹x21âˆ’Î±â€‹Â Â suchÂ thatÂ Â I=p1â€‹x1â€‹+p2â€‹x2â€‹\nOrdinary Demand: Â§\nâ©â¨â§â€‹x1â€‹(p1â€‹,p2â€‹,I)=p1â€‹Î±Iâ€‹x2â€‹(p1â€‹,p2â€‹,I)=p2â€‹(1âˆ’Î±)Iâ€‹â€‹\nIndirect Utility: Â§\nv(p1â€‹,p2â€‹,I)â€‹:=u(x1â€‹(p1â€‹,p2â€‹,I),x2â€‹(p1â€‹,p2â€‹,I))=p1Î±â€‹Â p21âˆ’Î±â€‹(1âˆ’Î±)1âˆ’Î±Â Î±Î±â€‹â‹…Iâ€‹â€‹\nExpenditure Minimization Â§\nminx1â€‹,x2â€‹â€‹I=p1â€‹x2â€‹+p2â€‹x2â€‹Â Â suchÂ thatÂ Â u=x1Î±â€‹x21âˆ’Î±â€‹\nCompensated Demand: Â§\nâ©â¨â§â€‹h1â€‹(p1â€‹,p2â€‹,uË‰)=(p2â€‹p1â€‹â€‹Î±1âˆ’Î±â€‹)Î±uË‰h2â€‹(p1â€‹,p2â€‹,uË‰)=(p1â€‹p2â€‹â€‹1âˆ’Î±Î±â€‹)1âˆ’Î±uË‰â€‹\nExpenditure Function: Â§\nE(p1â€‹,p2â€‹,uË‰)â€‹:=p1â€‹h1â€‹+p2â€‹h2â€‹=(1âˆ’Î±)1âˆ’Î±Â Î±Î±p1Î±â€‹Â p21âˆ’Î±â€‹â€‹â‹…uË‰â€‹â€‹"},"Combination-(Probability)":{"title":"Combination (Probability)","links":[],"tags":["Math/Probability"],"content":"Notation Â§\ndef. Number of Choosing k from n items:\n(xnâ€‹)=â©â¨â§â€‹(nâˆ’k)!â‹…k!n!â€‹0â€‹nâ‰¥xelseâ€‹\nNOTATION. Nâ‹…(Nâˆ’1)â‹…(Nâˆ’2)â‹¯(Nâˆ’k)=Nkâˆ’1â€‹"},"Combinatorial-Auction":{"title":"Combinatorial Auction","links":["VCG-Auction","Ascending-Price-Auction"],"tags":["Economics/Game-Theory"],"content":"Motivation. When a government auctions of wireless spectrums to AT&amp;T, Sprint, etc., they are not simply allocating one item per bidder. Instead the wireless carriers may want two spectrums but not one individually, or they might want all the spectrums to monopolize. We model these cases as a combinatorial auction.\ndef. Combinatorial Auction.\n\n1â€¦n bidders\nM={1â€¦m} items\nÎ©={(S1â€‹,â€¦,Snâ€‹)âˆ£isÂ partitionÂ ofÂ M} â† â€œoutcomesâ€\nEach bidder i has valuation viâ€‹ for every Siâ€‹âˆˆ2M; i.e. every possible allocation they can get\n\nThe following type of auction mechanisms are applicable in a combinatorial auction situation.\n\nVCG Auction\nAscending Price Auction\n"},"Combined-Income-&-Substitution-Effects":{"title":"Combined Income & Substitution Effects","links":["Income-Effect-(IE)","Substitution-Effect-(SE)"],"tags":["Economics/Micro-Economics"],"content":"Income Effect (IE)\nSubstitution Effect (SE)\nCombined Income/Substitution Effects Â§\nIn cases where price of one good changes, income and substitution effects happen together. Imagine when gasoline prices rise:\n\n\nGraph (a) shows the change in the budget line due to the increase in price of gasoline.\nGraph (b) shows the compensated budget line to maintain the level of utility.\nGraph (c) shows the ultimate, uncompensated bundle C.\n\nThe process for both effect is as follows\n\nMove along the same utility curve from bundle A â†’ B; substitution effect\nMove to the new budget line from bundle B â†’ C; income effect\nâ†’ this determines if good is normal (homo-thetic or not), quasi-linear, inferior; see below)\n\nIncome and Substitution Effects on Types of Goods Â§\nThe above case was when gasoline was a normal good. When gasoline is inferior the move due to income effect (B â†’ C) is to the right. The degree to which this occurs coincidentally determines if the good is regular inferior, or (the strange case of) a Giffen good.\n\nObserve that for both graphs B â†’ C is a rightward move, because lowering income (blue â†’ red) increased consumption, meaning this is an inferior good. If C has more of gasoline than A, it is the strange Giffen good.\nBringing it Together Â§\nThe final is combining all of these movements together. In the following graph, the consumer consumes only shirts and pants. Then theyâ€™re given a coupon that discounts the price of shirts (blue â†’ red). Using the compensated budget we determine the substitution effect (b, A â†’ B). Then, depending on whether shirts/pants are normal, inferior (or quasilinear) we can determine where the final income effect (B â†’ C) will lie.\n\nMathematicallyâ€¦ Â§\nAssume:\n\nUtility curve uAâ€‹=u(x1â€‹,x2â€‹)\nBudget line I=p1â€‹x1â€‹+p2â€‹x2â€‹\nYour bundle A(x1Aâ€‹,x2Aâ€‹),\n\nThen occurs a change in price p1â€‹â†’p1â€²â€‹, causing a change in the budget line from Iâ†’Iâ€². Then, consider how much you should compensate your income, to stay in the same indifference curve with utility uAâ€‹. That is, what is the minimum income that I can spend to reach a certain indifference curve?\nminÂ p1â€²â€‹x1â€‹+p2â€‹x2â€‹Â s.t.uAâ€‹=u(x1â€‹,x2â€‹)\nThus you find the bundle B(x1Bâ€‹,x2Bâ€‹), with the size of the substitution effect x1Aâ€‹â†’x1Bâ€‹\nSince this compensated budget is a hypothetical scenario, we will need to move back to the original budget.\nmaxÂ u(x1â€‹,x2â€‹)Â s.t.Iâ€²=p1â€²â€‹x1â€‹+p2â€‹x2â€‹\nto find bundle C(x1Câ€‹,x2Câ€‹)."},"Commodities":{"title":"Commodities","links":["Futures"],"tags":["Economics/Finance"],"content":"\nOften traded at the Chicago Mercantile Exchange (CME)\nTraded in Futures\n"},"Common-Graph-Problems":{"title":"Common Graph Problems","links":["Traveling-Salesperson-Problem","Minimal-Spanning-Tree-Problem","Common-Graph-Problems"],"tags":["Computing/Algorithms"],"content":"See also:\n\nTraveling Salesperson Problem\nMinimal Spanning Tree Problem\n\nQ. Clique Problem. Given a graph G=(V,E) what is the maximum set of vertices C such that all vertices v in C are fully connected, i.e. for every u,vâˆˆC, there exists edge (u,v)âˆˆE\n\n\nNP-complete problem\n\nQ. Independent Set Problem. (=Stable set =anti-clique) Given a graph G=(V,E) what is the maximum set of vertices C such that no edges connect any two vertices in this set? \n\nComplement with vertex cover.\n\nC is an maximal independent set â‡” Vâˆ’C is a minimal vertex cover\nReduction both ways is trivial\nthm. 3-SAT â‰¤pâ€‹ Independent Set\n\n\nConstruction: each clause to a fully connected tri-vertex component, and connect the variable and its negations between tri-vertex components. \nâˆƒx1â€‹â€¦xnâ€‹ that satisfies Q where Q has k clauses â‡” âˆƒ Independent Set of size k.\n\n\n\nQ. Vertex Cover. Given G=(V,E) find the minimal subset CâŠ†V such that it covers all edges in the graph.\n\n\ne.g. graph that has a vertex cover comprising 2 vertices (bottom), but none with fewer.\nNP-complete problem\nC is a minimal vertex cover â‡” Vâˆ’C is a maximal Independent Set\n\nRed is vertex cover, and white is independent set: \n\n\n\nalg. Approximate Vertex Cover.\n\nChoose any edge e that connects vertices u,v\nremove edge e from graph, as well as any edges that connected to u and v\n\nu,v are added to the vertex cover set\n\n\nRepeat until no edges remain\n\n\nIs a 2-approximation\n\nalg. Approximate Greedy Vertex Cover.\n\nChoose vertex with maximum degree\nAdd this as part of vertex cover. Remove edges connected to this vertex\nRepeat until no edges remain\n\n\nIs not optimal.\n\nQ. Triangle Cover. Given G=(V,E) find the minial subset of vertices that it covers at least one vertex per triangle, for every triangle in graph.\n\nTriangle Cover is NP-complete (reduce from vertex cover)\n\nQ. Dominating Set. Given G=(V,E) find the minial subset S of vertices such that, every vertex in G is either in S or is a neighbor of S\nQ. Critical Vertices. Given connected graph G=(V,E) find all vertices that when removed will disconnect the graph."},"Communism":{"title":"Communism","links":["Private-Property"],"tags":["Philosophy/Marxism"],"content":"â€œCrudeâ€ Communism Â§\n\nThe first positive abolition of private property - crude comÂ­ munism - is therefore only a manifestation of the viieness of private property trying to establish itself as the positive comÂ­ munity.\n\n\nPhysical, immediate possession is the only purpose of life and existence as far as this communism is concerned; the category of worker is not abolished but extended to all men [â€¦] The crude communist is merely the culmination of this envy and desire to level down on the basis of a preconceived minimum. It has a definite, limited measure.\n\n\n(2) Communism (a) still of a political nature, democratic or despotic; (b) with the abolition of the state, but still essentially incomplete and influenced by private property, i.e. by the estrangeÂ­ ment of man.\n\nActual Communism Â§\n\nCommunism is the positive supersession of Private Property as human self-estrangement, and hence the true appropriation of the human essence through and for man\n\n\nit is the.genuine resolution of the conflict between man and nature, and between man and man, the true resolution of the conflict between existence and being, between objectification and self-affirmation, between freedom and necessity, between individual and species. It is the solution of the riddle of history and knows itself to be the solution.\n\nand thus\n\nIf we characterize communism itself - which because of its character as negation of the negation, as appropriation of the human essence which is mediated with itself through the negation of private property\n"},"Comparable-Company-(Comps)-Analysis":{"title":"Comparable Company (Comps) Analysis","links":["Income-Statement","EBITDA-Multiple","Price-to-Earnings-Ratio","Balance-Sheet","Free-Cashflow"],"tags":["Economics/Finance"],"content":"Comps Analysis:= comparing companies with multiples.\n\n\n                  \n                  More growth potential = Better.\n                  \n                \n\nBut make sure that the companies being compared are similar in size/industry/geographic regions.\nMultiples Analysis Â§\n:= using the ratios of accounting line items (like EBITDA, income, etc.) to evaluate the potential growth of a firm.\n\nRatios are calculated from estimations of future balance sheet line items.\nWe use rate of return to compare investments, not price. r=P1â€‹P2â€‹âˆ’P1â€‹â€‹. You canâ€™t compare price.\n\nThe following are commonly used multiples:\n\nEBITDA Multiple\nPrice to Earnings Ratio\n\nAccounting Sheets Â§\n\nBalance Sheet\nIncome Statement\nFree Cashflow\n"},"Compensating-and-Equivalent-Variation":{"title":"Compensating and Equivalent Variation","links":["Utility-Function"],"tags":["Economics/Micro-Economics"],"content":"Q. Coupon Exchange Problem. Josh and Andrew have identical utility functions u(x1â€‹,x2â€‹) where x1â€‹ is milkshakes and x2â€‹ is toys.\n\nTheir incomes are the same\nJosh has a 50% off coupon for x1â€‹.\nâ‡’ Can Josh and Andrew work out a trade where Andrew buys the coupon?\nFigure out\nLeast Josh would take for the coupon using the expenditure function\nMost Andrew would pay for the coupon (also using the expenditure function)\nâ‡’ Trade occurs when (least Josh would sell for) &lt; (most Andrew would pay for)\n\n\n\n                  \n                  Idea \n                  \n                \nCV and EV - YouTube\nOh no! the price of good x1â€‹ increased!\n\nğŸ¥º Sheâ€™s now at a lower Indifference Curve. How much should we give as compensation to get her back on the original indifference curve? â‡’ Compensating Variation\nğŸ˜ˆ Sheâ€™s at a lower indifference curve now. What if instead of having the price of good x1â€‹ increase, we just take money away from her directly? â‡’ Equivalent Variation\n\n\ndef. Compensating Variation (CV). When a price of a good changes, the Compensating variation is the change in expenditure (Â±) required to maintain the utility.\ndef. Equivalent Variation (EV). An individual may trade a change in income (Â±) for a change in prices.\n\n\n\nCompensating Variation (CV) is how much money an individual would have to get (or have taken away) to be indifferent to the change in prices"},"Computational-Tractability":{"title":"Computational Tractability","links":["CS-330-Advanced-Algorithms","Chompsky-Heirarchy","Turing-Machine","Independent-Set-Problem","Common-Graph-Problems","Subset-Sum","Traveling-Salesperson-Problem","Hamiltonian-Path/Cycle"],"tags":["Computing/Algorithms","Computing/Formal-Languages"],"content":"Definitions Â§\nthm. Satisfiability Reducibility. All problems can be reduced to boolean satisfiability problems.\n\nOptimization problems: choose some k, then ask â€œis there a solution â‰¤k?, â‰¥k?â€ =&gt; Then do a binary search on [0,k] or [k,upperÂ bound]\n\ndef. Computationally tractable problems. There exists a polynomial time algorithm O(nk) for the solution. The set of all computationally tractable problems is denoted P.\n\nMost problems in CS 330 Advanced Algorithms\n\nthm. Polynomial Reduction. Problem Ï€1â€‹:X1â€‹â†¦{0,1} that is an element of P can be reduced to problem Ï€2â€‹:X2â€‹â†¦{0,1} problem which is also in P, if there exists a function f:X1â€‹â†¦X2â€‹ such that:\n\nÏ€1â€‹(x1â€‹)=1âŸºÏ€2â€‹(f(x1â€‹))=1\nf(x) takes polynomial time to complete\n\nf(x) can be a many-to-one function\n\n\n\n\nThis is denoted Ï€1â€‹â‰¤pâ€‹Ï€2â€‹\nVisually: \nImplications of when Ï€1â€‹â‰¤pâ€‹Ï€2â€‹\n\nÏ€2â€‹ is at least as hard as Ï€1â€‹.\nP-time:\n\nIf Ï€2â€‹ is a P-time problem and\n! If the input size to Ï€2â€‹ which is âˆ£f(x)âˆ£ is bounded by âˆ£xâˆ£c\nThen Ï€1â€‹ is also a P-time problem\n\n\nNP-hardness:\n\nIf Ï€1â€‹ is NP hard â†’ Ï€2â€‹ is also NP-hard\n\n\n\n\n&amp; Techniques for reduction of Ï€1â€‹â‰¤pâ€‹Ï€2â€‹\n\nProcess:\n\n\nIf Ï€1â€‹,Ï€2â€‹ is a min/maximization problem, convert it to a decision problem\nIf construction is needed, construct from Ï€1â€‹ to Ï€2â€‹: domain Gâ†’Gâ€²\n\n! The construction may not suppose you know the answer Ï€1â€‹.\nIf itâ€™s a graph, it should apply to any graph\nIf itâ€™s a set, it should apply to any set\n\n\nIf there is something like â€œexists solution of size kâ€ in Ï€1â€‹, this k will probability be present in Ï€2â€‹ as well\n\n\n\n\nProve that if âˆƒ answer to Ï€1â€‹ in domain G, that implies âˆƒ answer to Ï€2â€‹ in domain Gâ€².\nProve that if âˆƒ answer to Ï€2â€‹ in domain Gâ€², that implies âˆƒ answer to Ï€1â€‹ in domain G.\nProven!\n\n\n\nComplexity Classes Â§\nComplexity classes are an extension of the Chompsky Heirarchy.\n\n\n\nP (Polynomial Time)\nNP (Nondeterministic Polynomial Time) The certificate exists that can be verified in polynomial time. A non-deterministic Turing Machine can solve it in polynomial time because it has many paths.\nco-NP\n\nproblem Ï€âˆˆNPâŸ¹Ï€câˆˆco-NP:luc_check_circle:\nproblem Ï€âˆˆNPâŸºÏ€âˆˆCo-NP is an open problem\nSee Whats the difference between NP and co-NP - Stack Overflow\n\n\nNP-complete: Problems where any NP problem can be reduced into in polynomial time.\n\nIf there is any NP-complete problem that can be shown to be solved in polynomial time, then P=NP.\nthm. Cook-Levin Theorem. CNF-SAT is NP-complete.\n&amp; To prove a decision problem Ï€ is NP-complete\n\nShow Ï€âˆˆNP i.e. certificate can be checked in poly-time\nShow Ï€0â€‹â‰¤pâ€‹Ï€ where Ï€0â€‹ is known NPC problem byâ€¦\n\nfrom solution I0â€‹ of Ï€0â€‹, construct solution I of Ï€\nshow that I0â€‹ is solution for Ï€0â€‹ if and only if I is solution for Ï€ (both ways needed to show that non-solutions are non-solutions)\n\n\n\n\nâ€œCompletenessâ€ can apply to any complexity class. It means that it is the â€œhardestâ€ problem in that class.\n\n\nNP-hard: Problems that are at least as hard as all NP (and NP-complete) problems\n\nEquivalently, Problems that are as hard or harder than all NP problems\n\n\n\nList of Problems and Reductions Â§\nNP-Complete Problems Â§\n\nCNF-SAT (Cooke-Levin Theorem)\n3-SAT\nIndependent Set Problem\nCommon Graph Problems Problem\nSubset Sum Problem\nCommon Graph Problems\nTraveling Salesperson Problem\n\nCycle\n\n\n\nKarpâ€™s 21 NP-complete problems - Wikiwand\nCategory:NP-complete problems - Wikipedia\n(DevonThink) NP-complete Reductions"},"Computer-Architecture":{"title":"Computer Architecture","links":["Instructions-(Computer-Science)","Instruction-Set"],"tags":["Computing/Computer-Architecture"],"content":"Term Definitions Â§\n\nInstruction: a single operation a processor can perform\nInstruction Set\nArchitecture: An abstract specification of a computerâ€™s hardwareâ€”an interfaceâ€”in order to be able to write software for it. (a contract between HW and SW to interact)\nMicro-architecture: the actual implementation of the architecture design\nComputer: machine that follows simple instructions deterministically\n\n\n\n                  \n                  technology of the time, programming language design, operating system design, the applications to write, and the history of the architecture design.\n                  \n                \n\n\nOSes and languages may also be influenced by the design of the architecture\n\nThe Five Component of a Computer are: Processor(CPU) / Control / Datapath / Memory / IO.\nMooreâ€™s Law determines the trend of\n\nC Programming Language Â§\nUnix invented by: Ken Thompson\nC language by: Dennis Ritche\n(Think of it as: Newton, to create a new branch of scienceâ€”physicsâ€”, invented calculus to make it possible.)\n\n\n                  \n                  The contraints of technology of the time shaped the design of C. \n                  \n                \n\nLimitations of: compiler size / code size / performance / portability\nâ†’ became a portable assembly language\nDidnâ€™t consider: security / robustness / maintainability / legacy code"},"Conditional-Distribution":{"title":"Conditional Distribution","links":["Joint-Distributions"],"tags":["Math/Probability"],"content":"def. Conditional Distribution. let X,Y be jointly distributed. Then the conditional probability distribution of Y given a specific value of X is the conditional probability distribution.\n\nX,Y are discrete:\n\npmfYâˆ£X=xâ€‹(y):=P(Y=yâˆ£X=x)=P(X=x)P(Y=yâˆ§X=x)â€‹\n\n\nX,Y are continuous:\n\n\nfYâˆ£X=xâ€‹=fXâ€‹(x)fX,Yâ€‹(x,y)â€‹\n\nif XâŠ¥Y:\n\nfYâˆ£X=xâ€‹(y)=fYâ€‹(y)\n\n\n                  \n                  Visually: \n                  \n                \n\nâ€¦the red line height divided by the orange line is the p.d.f conditional distribution fXâˆ£Y=yâ€‹(x).\nâ€¦the orange line is the value of the marginal distribution fYâ€‹ at Y=y.\n\nthm. Continuous Multiplication Rule. let X,Y be jointly distributed. Then:\nfX,Yâ€‹(x,y)=fXâˆ£Y=yâ€‹(x)â‹…fYâ€‹(y)\nthm. Rule of Average Conditional Probability. let X,Y, Then:\nfXâ€‹=âˆ«âˆ’âˆâˆâ€‹fXâˆ£Y=yâ€‹â‹…fYâ€‹dyP(X=x)=âˆ«P(X=xâˆ£Y=y)â‹…fYâ€‹(y)dy"},"Conditional-Probability":{"title":"Conditional Probability","links":["Conditional-Distribution"],"tags":["Math/Probability"],"content":"See also: Conditional Distribution\ndef. Conditional Probability. The probability of event A given that event B has occurred is:\nP(Aâˆ£B):=P(B)P(Aâˆ©B)â€‹\n\nIf Î©â€™s elements are all equally likely: P(Aâˆ£B)=#B#(Aâˆ©B)â€‹\nMultiplication Rule: P(Aâˆ©B)=P(Aâˆ£B)â‹…P(B)=P(Bâˆ£A)â‹…P(A)\nCompliment Rule: P(Aâˆ£B)=1âˆ’P(ACâˆ£B)\n\nthm. Chained Conditional Probability. For three events A,B,C:\nP(ABC)=P(A)â‹…P(A)P(AB)â€‹â‹…P(AB)P(ABC)â€‹=P(A)â‹…P(Bâˆ£A)â‹…P(Câˆ£AB)\ndef. Bayesâ€™ Theorem. For events A, B:\nP(Bâˆ£A)=P(A)P(Aâˆ£B)â‹…P(B)â€‹â‡”P(Bâˆ£A)P(A)=P(Aâˆ£B)P(B)\nVisualization.\n"},"Confidence-Intervals-and-Hypothesis-Testing-in-OLS-Linear-Regression":{"title":"Confidence Intervals and Hypothesis Testing in OLS Linear Regression","links":["Confidence-Intervals","Hypothesis-Testing","Central-Limit-Theorem","Student's-t-test","Student's-T-Distribution"],"tags":["Math/Statistics"],"content":"See also: Confidence Intervals and Hypothesis Testing\nMotivation. Assume we have our estimators for our sample size N using OLS, Î²0â€‹,Î²1â€‹^â€‹^â€‹. Now, assuming we have the true population data (impossible in real life) and take 100 samples of size N from the whole population, we get 100 different tuple of estimators (Î²0â€‹^â€‹,Î²1â€‹^â€‹). If we plot these on a graph, we get an approximate bell curve. This is due to the Central Limit Theorem. Knowing this fact, we can deduce if there is a correlation between X and Y.\n\nRemark. Nâ‰¥30 is the minimum required for CLT. Nâ‰¥100 is a conservative requirement for CLT to apply.\nRemark. We will only look at Î²1â€‹^â€‹ since it is the more important parameter.\nHypothesis Testing Â§\ndef. The Null hypothesis in regression is H0â€‹:Î²1â€‹=0, i.e. there is no correlation.\ndef. Regression T-test. See Studentâ€™s t-test. A T-test is a test for rejecting the null hypothesis. let the T-statistic T=Var(Î²1â€‹^â€‹)â€‹Î²1â€‹^â€‹âˆ’Î²1Nullâ€‹â€‹. Then\n{H0â€‹H1â€‹â€‹ifÂ âˆ£Tâˆ£&gt;Kotherwiseâ€‹\n\nThe cutoff value K is determined by how powerful (=Î±) you want the test to be. This is determined by the Studentâ€™s T-Distribution.\n\nThis is because T=dâ€‹tNâˆ’1â€‹\n\n\nThis is Studentâ€™s t-test but with only one random variable.\nNormally, we set the cutoff K=2, i.e. two standard deviations away. This is around an Î±=0.05 test.\n\nTable of common T-Statistic values\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nValue of TSignificanceSidednessâˆ¥Tâˆ¥&gt;1.95P(Î²1â€‹=0)&lt;0.05Two-sideâˆ¥Tâˆ¥&gt;2.58P(Î²1â€‹=0)&lt;0.01Two-side\nA Large-sample critical value is simply using the idea that as Nâ†’âˆ the Tâ†’dNâ†’âˆâ€‹N i.e. the T statistic becomes a normal distribution. Thus the cutoff values are using the standard normal table.\nIntuition. \nConfidence Interval Â§\nIntuition.\nBias:\nstandard error of regression: mean squared of residuals; also the estimator for the error\nStandard error ofâ€¦\n\nResiduals â†’ standard error of regression\nbe\nVaraince of Î²1â€‹^â€‹ is also the variance of CLT limit with the same sample size\n\nRemark. Substantive significance does not imply statistical significance, nor does vice versa. The two are irrelevant."},"Confidence-Intervals":{"title":"Confidence Intervals","links":["Fisher-Information"],"tags":["Math/Statistics"],"content":"Simple Definition Â§\ndef. Confidence Interval of the parameter Î¸âˆˆ[f(X,Ïˆ),g(X,Ïˆ)] in the probability distribution of a random variable Xâˆ¼pdf(Î¸,Ïˆ) is defined as the following:\nC.I.=Î³:=P[f(X,Ïˆ)&lt;Î¸&lt;g(X,Ïˆ)]\n\nwhere functions f(X),g(X) are able to be derived from the random variable X.\n\nThe most common use of confidence interval problems is with CLT, where a parameter of a binomial distribution is estimated. e.g.:\nlet Xâˆ¼Binom(n,p) where p is the parameter to be estimated.\nFormal Definition Â§\ndef. Confidence Interval. For Xiâ€‹ distributed with an unknown parameter Î¸, a Î³-level confidence interval:\n\nâ€¦is an interval in which the probability of Î¸0â€‹ being in the interval is Î³ [=1âˆ’Î±-level CI]\n\nthink of Î³ big is good, Î± small is good.\n\n\nâ€¦is formalized as the following where L,U is a statistic of X:\n\nâ€‹P(L&lt;Î¸&lt;U)=Î³âŸ¹2L+Uâ€‹Â±2Uâˆ’Lâ€‹âŸ¹ConfidenceÂ Interval=[L,U]â€‹â€‹\ndef. Observed Information. For X1â€‹,â€¦,Xnâ€‹âˆ¼iidf(x1â€‹,â€¦,xnâ€‹;Î¸), observed information is:\nJ(Î¸)=âˆ’lâ€²â€²(Xiâ€‹;Î¸)\nAnd for X1â€‹,â€¦,Xnâ€‹âˆ¼iidf(x;Î¸)\nJnâ€‹(Î¸)=i=1âˆ‘nâ€‹âˆ’lâ€²â€²(Xiâ€‹;Î¸)\nRemark. This is Fisher Information, but gathered on data (Xiâ€‹)\nthm. (approximating a confidence interval using Fisher Information) In general, if Î¸^MLEâ€‹ can be found and the log-likelihood is twice-differentiable, an approximate CI of level Î³=1âˆ’Î± can be approximated by:\nÎ¸^MLEâ€‹Â±Jnâ€‹(Î¸^)â€‹z1âˆ’2Î±â€‹â€‹â€‹\nthm Delta Method. Let unknown parameter Î¸ of r.v. X1â€‹,â€¦,Xnâ€‹â€™s distribution. If Fisherâ€™s approximation [=asymptotically efficient and asymptotically unbiased] conditions are satisfied, the following holds for all g which gâ€™(Î¸)î€ =0:\nnâ€‹(g^â€‹MLEâ€‹âˆ’g0â€‹)dâŸ¶â€‹nâ†’âˆâ€‹N(0,[gâ€²(Î¸)]2â‹…Ïƒ2)\nand due to Fisherâ€™s Approximation (asymptotic normality):\nnâ€‹(g^â€‹MLEâ€‹âˆ’g0â€‹)dâŸ¶â€‹nâ†’âˆâ€‹N(0,I(Î¸0â€‹)gâ€²(Î¸0â€‹)2â€‹)\nExample. To construct a standard normal distributionâ€™s confidence interval of level Î³=1âˆ’Î±:\nP(z2Î±â€‹â€‹&lt;Z&lt;z1âˆ’2Î±â€‹â€‹)=1âˆ’Î±"},"Consistency":{"title":"Consistency","links":["Chebyshev's-Inequality"],"tags":["Math/Statistics"],"content":"def. Consisteny. An estimator Î¸^(X1â€‹,â€¦,Xnâ€‹) is consistent for parameter Î¸ if:\nâˆ€Ïµ&gt;0,Â Â Î¸^Â Â pâŸ¶â€‹nâ†’âˆâ€‹Â Â Î¸i.e.nâ†’âˆlimâ€‹P(âˆ£Î¸^âˆ’Î¸âˆ£&lt;Ïµ)=1nâ†’âˆlimâ€‹P(âˆ£Î¸^âˆ’Î¸âˆ£&gt;Ïµ)=0\n![[ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆ 2023-02-21 15.40.01.png|center|250]]\ndef. Asymptotic Unbiasedness. An estimator Î¸^ is asymptotically unbiased if:\nE[Î¸^nâ€‹]âŸ¶nâ†’âˆâ€‹Â Î¸\nRemark. You can use the Chebyshevâ€™s Inequality for determining Consistency."},"Constrained-Optimization":{"title":"Constrained Optimization","links":["Budget-Lines","Monotonic-Transformation","Utility-Function","Utility-Maximization"],"tags":["Economics/Micro-Economics","Math/Calculus"],"content":"Lagrangian Method Â§\nAlg. Lagrangian Optimization.\nLet:\n\nf(x) the target function to optimize\ng(x)=c is the constraint function\nÎ» is the Lagrange multiplier.\n\n\n(when optimizing for budget constraint) Do a Monotonic Transformation on the Utility Function to make the function easier to manipulate\nThe Lagrangian function is constructed to find the maximum or minimum of a target function subject to constraints:\n\nThe Lagrangian: L(x,Î»)=f(x)âˆ’Î»(g(x)âˆ’c)\nÎ» is an unknown constant\n\n\nThe first-order necessary conditions (also known as KKT conditions) are found by taking the derivative of the Lagrangian with respect to all variables and the Lagrange multipliers, and setting them equal to zero:\n\nFor all i, âˆ‚xiâ€‹âˆ‚Lâ€‹=0\nâˆ‚Î»âˆ‚Lâ€‹=0\n\n\nFeasibility condition:\n\nIs it in the feasible region: g(x)=c?\n\n\nSolve for x,Î» â† this is the optimal point\n\n\n\n                  \n                  Example \n                  \n                \nWorked Example\n![[Pasted image 20230905153050.png|Worked Example|625]]\nUtility Maximization\n"},"Consumer-Sentiment-Index":{"title":"Consumer Sentiment Index","links":[],"tags":["Economics"],"content":"University of Michigan performs a monthly telephone survey about how the households feel about the economic climate."},"Consumer-Surplus":{"title":"Consumer Surplus","links":["Marginal-Willingness-to-Pay"],"tags":["Economics/Micro-Economics"],"content":"Consumer Surplus Â§\nMarginal Willingness to Pay Curve leads naturally to the concept of consumer surplus. Follow the following line of logic:\n\nThe area under the MWTP curve is the Total Willingness to Pay (TWTP)â€”the amount the consumer was willing to pay to get q amount of goods.\nSince they didnâ€™t have to actually pay that amount (they only paid pÃ—q), theyâ€™re better off.\nThe quantitative amount that theyâ€™re better off is the Consumer Surplus\n\n\nDeadweight Loss due to Taxation, Analyzed with MWTP Curves Â§\n\nConsier a distortionary tax on housing prices, per square feet. The blue line shows the price p per sqft of housing. The red line shows the post-tax budget line, and A is the optimal point.\n\nâ†’ What if instead the government took away a lump sum instead of a distortionary tax? The amount taken away is L and the green line shows the new budget. In this hypothetical, ideal case, the optimal is B.\nâ†’ In this case, the distortionary tax collected for bundle A is vertial distance T. As DWL:=Lâˆ’T, the vertical distance shows the Deadweight Loss for the taxation. (The lump sum was better.)\n\nAlternatively, consider graphing the MWTP for utility uA, using points A,B.\n\nâ†’ With the distortionary taxâ€”optimal bundle: A, CS=a. Govnâ€™t revenue is T=hÃ—(p+t)=b\nâ†’ With the lump sum taxâ€”optimal bundle: B, CS=a+b+c\n\nHow come the consumer has more surplus as B in the bottom graph? Arenâ€™t they indifferent in MWTP?\n\nâ†’ The consumer instead lost the collected lump sum tax, L; âˆ´L=(a+b+c)âˆ’(a)=b+c\nâ†’ âˆ´ DWL=Lâˆ’T=(b+c)âˆ’(b)=c\n"},"Contagion-(Finance)":{"title":"Contagion (Finance)","links":["leverage"],"tags":["Economics/Finance"],"content":":= a propogation of bear markets, due to the fact that banks lend and borrow from each other\nâ†’ The higher the leverage, the greater the degree of contagion in markets"},"Context-Sensitive-Grammar":{"title":"Context Sensitive Grammar","links":[],"tags":["Computing/Formal-Languages"],"content":""},"Context-Free-Grammar":{"title":"Context-Free Grammar","links":["Pushdown-Automata"],"tags":["Computing/Formal-Languages"],"content":"Section: Pushdown Automata\ndef. a Context-Free Grammar (CFG) is a grammar whose production rules consist of:\nAâ†’x\nâ€¦where A is a variable, and x is a string of variables and terminals.\n\n\n                  \n                  CFGs can check for syntactically correct programs \n                  \n                \n\n\nSimple Grammer: a CFG where any pair of (var,term) appear in no more than one rule.\nAmbiguous Grammar: there exists a string in the language that has more than one derivation.\n\ndef. a Parse Tree [=Derivation Tree] shows the derivation steps of a single string from a start symbol according to the rules of a grammar.\n\n\nThe leaves of the tree read right-to-left is the yield of the treeâ€”in this case, aaÏµb is the yield.\nThe yield should not contain the Î»s. (obviously)\n\ndef. Leftmost Derivation. Replace the leftmost variable in every step.\ndef. Rightmost Derivation. Replace the rightmost variable in every step.\n\nthm. Determinability. If the CFG doesnâ€™t contain rules of the form Aâ†’Î» or Aâ†’B, then we can determine for all w if it is in the language of the CFG.\nthm. a Context-Free Grammar is equivalent to an NPDA.\nNPDA â†’ CFG Â§\nalg. Given NPDA, you can define an equivalent CFG in the following steps:\n\nFor any transitions that pop/push more than one variable onto the stack:\n\nUse a new state to split out the transition, so that one transition only push/pops one variable onto the stack\n\n\nThen, for each transition arc:\n\nIf the transition arc is a pop arc that pops A off the stack, i.e.:\nfrom state i to j is in the form t,A;Î»,\nthen construct a production rule for the grammar as:\n(qiâ€‹,A,qjâ€‹)â†’t\nIf the transition arc is a push arc that pushes A onto the stack i.e.:\nfrom state i to j is in the form t,Î³,AÎ³\nthen construct a production rule for the grammar as:\n(qiâ€‹,Î³,qkâ€‹)â†’t(qjâ€‹Aqlâ€‹)(qlâ€‹Î³qkâ€‹), where qkâ€‹,qlâ€‹ is every possible combination of states in the PDA(!)\n\n\nFinally, of all the rules generated, if any variables on the right side of the arc donâ€™t appear on the left side, that rule is useless.\n\nCFG â†’ NPDA Â§\nalg. Given a CFG, you can build an LL-NPDA in the following steps. This is a top-down design:\n\nThere are 3 total states in the NPDA: 0, 1, 2\nMove from state 0 to state 1 by adding the start variable S onto the stack\nThe middle state has loops for every rule of the CFG. Pop off the LHS, add the RHS to stack while processing any beginning terminals\nMove from state 1 to final state 2 in a Î»-transition\n\n\nalg. Given CFG, you can build an LR-NPDA in the following steps. This is a bottom-up design:\n\nThere are 3 total states in the NPDA: 0, 1, 2\nState 0 has loops for:\n\nâ€¦every rule of the grammar. Each rule will pop the RHS and push the LHS of the rule\nâ€¦every terminal of the grammar. Each terminal will be pushed onto the stack while reading that terminal.\n\n\n\n\n\nLL Parsing Â§\ndef. LL(k) Parsing. Left-to-Right, Left-most derivation Parser with k lookaheads.\nalg. Given CFG G, LL(k) parsing occurs in the following steps:\n\nCreate the First(),Follow() sets for each of the each of the variables in the grammar.\n\nFirst() is the set of terminals (including Î») that can lead the string derived.\n\nCreated by checking the variable on the left side of the production: Aâ†’aX.\nCommon sense will be enough.\nDonâ€™t forget the check variables that go to Î» i.e. disappear. Î» is only included in the FIRST set if the whole variable can disappear to Î».\n\n\nFollows() is created by checking the variable on the right side of the production: Aâ†’aX.\n\nThe start variable always has the $\\\n\n\n\n\n\n      - Use the first sets to make life simpler. $\\lambda$ is always removed.\n2. Create the $LL(1)$ parse table.\n   1. For each variable, check the rules.\n   2. There must be an entry for **every element of the first set.** check which rule makes the most sense [= FIRST set of the RHS of the rule is the lookahead symbol]\n   3. If FIRST set includes a $\\lambda$ (and the variable can goto) $\\lambda$, â‡’ There must be a $\\lambda$ entry for **every element of the follows setâ€¦**\n   4. â€¦however, if the FIRST set includes a $\\lambda$ **but** the variable **cannot** goto $\\lambda$, **find another rule that makes sense to put there.**\n3. Use the table to do the necessary steps for parsing the string.\n\n![Untitled](Untitled%203%201.png)\n\n## LR Parsing\n\ndef. $LR(k)$ Parsing. **L**eft-to-Right, **R**ight-most **Reverse** derivation parser with $k$ lookaheads.\n\nalg. Given CFG $G$, $LR(k)$ parsing occurs in the following steps:\n\n1. Set up the grammar so that itâ€™s ready to parse:\n   1. Change the start symbol to $S&#039;\\rightarrow S$. This is rule #0.\n   2. Number the rules $1$ through $n$.\n2. Calculate the FIRST and FOLLOW sets of variables.\n3. Construct a $LR$ parsing DFA in the following steps:\n   1. The start state has **rule number 0 and rules for $S$**. Place markers ($\\_$) in the beginning.\n   2. For each rule, â€œprocessâ€ one _symbol_ at a time.\n      Processing means that to transition to another stateâ€¦\n      â€¦with arc labeled *symbol\n      â€¦*to create a new state with the marker jumped over that _symbol_.\n   3. You have a new state with one rule that has the jumped marker. Now, add to the state **the closure of that rule.** The closure of a rule is calculated as such:\n      1. If the marker is in front of a variable, the derivation rules for that variables is included\n      2. if the market is in front of a terminal, donâ€™t do anything\n4. Construct a $LR$ Parsing table from the DFA to use during parsing:\n   1. Do the following for every state of the DFA [=every row of the parse table]:\n      1. For every transition arc, put an entry in the table, for that **state number** and **arc label:**\n      2. If itâ€™s just a transition arc, put a **â€œshift to state #â€ or sN**\n      3. If itâ€™s a final state, only the entries for the elemetns of FOLLOW should be populated;\n         put a **â€œreduce by rule number #â€ or rN** and the rule number is the rule of the state (since itâ€™s a final state, there should be only one rule)\n      4. If itâ€™s a final state but its rule is $Sâ€™\\rightarrow S$, itâ€™s special; only populate the â€œ$â€ entry.\n         put a **â€œacceptâ€ or acc** in that place.\n      5. If the state contains a $**\\lambda$-rule,** then always put a **â€œreduce by rule #â€ or rN,** where the rule number is that lambda rule â† this should be in the **â€œ$â€ column\\*\\*\n\n![Untitled](Untitled%204.png)"},"Context-Free-Language":{"title":"Context-Free Language","links":["Pushdown-Automata"],"tags":["Computing/Formal-Languages"],"content":"Section: Pushdown Automata\nClosure Properties Â§\nContext-Free Languages are closed under:\n\nUnion\nConcat\nStar\nRegular Intersection (â†think: you have states &amp; one stack to combine. It makes sense)\n\nPumping Lemma Â§\nthm. Pumping Lemma for CFL.\n\n\n\n                  \n                  v,y. Divide it up into different cases and derive contradictions in all of them.\n                  \n                \n\n\nTransforming Context-Free Languages for Easy Parsing Â§\nYou can do the following modifications on CFLs:\n\nAdd Lambda\nRemove Î»-productions. â† Every CFG with Î» productions can be made into one w/o Î»-productions.\nSubstitution from Aâ†’wBv and Bâ†’y1â€‹âˆ£y2â€‹âˆ£..âˆ£ynâ€‹ into Aâ†’wy1â€‹vâˆ£wy2â€‹vâˆ£â€¦âˆ£wynâ€‹v\nRemoving Left-Recursion [e.g. Aâ†’Ax] â† Left-recursion is bad, because top-down parsers will get into an infinite loop\n\nUse the above modifications to produce CFLs that do not have useless productions.\nalg. Removing useless productions in CFLs. These steps must go in order!\n\nIdentify useless variables\nUseless variables are ones that: 1. cannot be reached by the start symbol 2. cannot derive a terminal\nRemove useless productions\ni.e. remove all productions that contain a useless variable\nRemove all Î»-rules\n\ncreate a set of variables that can ultimately derive a Î»\nfor every production that uses those variables on the RHS, derive the Î» now.\n\n\nRemove unit productions\n\ndraw the variable dependency graph (1 level)\nFor every production that uses unit production on the RHS, consolidate all into one; i.e. derive it now.\n\n\n\nNormal Forms Â§\n\n\ndef. Chompsky Normal Form\nEither: one terminal, or two variables. Easy to convert any grammar into CNF.\n\n\nAâ†’aAâ†’BC\n\n\ndef. Geribach Normal Form\nAll rules are the form:\n\n\nVâ†’ÏƒVâˆ—\n\nAll Î»-free CFGs can be expressed in GNF.\n"},"Continual-Procession-of-Technology":{"title":"Continual Procession of Technology","links":["Mooreâ€™s-law"],"tags":["Computing"],"content":"Mooreâ€™s law"},"Control-Problem":{"title":"Control Problem","links":[],"tags":["Computing"],"content":""},"Controlled-Experiments":{"title":"Controlled Experiments","links":["Dummy-Variables","Two-Stage-Lease-Squares-Regression"],"tags":["Math/Statistics"],"content":"Motivation. In theory we should be able to estimate the causal effect of a controlled experiment using Difference of Means model:\nYiâ€‹=Î²0â€‹+Î²1â€‹isTreated+Ïµiâ€‹\nBut we have the following issues in really (ABC issues):\n\nAttrition\nBalance\nCompliance\n\nBalance Â§\n\ndef. Balance means treatment and control groups are same in all other factors\ndef Blocking means to categorize into blocks (e.g. men and women) and randomize within groups.\n\nBlocking is harder to implement when there are lots of categories, and sample size is limited.\nTherefore, before running regression check for balance by running the Balance Test:\n\n\n\nXiâ€‹=Î³0â€‹+Î³1â€‹Â isAssigedTreatmentÂ Ziâ€‹â€‹â€‹+Î½iâ€‹\nwhere Xiâ€‹ is a covariate that weâ€™re worried is not randomized enough.\n\nğŸ˜Š If Î³1â€‹ is not statistically significant, it means treatment and unobserved factors are not correlated.\nğŸ˜ If Î³1â€‹ is statistically significant then (even if it was randomized) then ÏT,Ïµâ€‹î€ =0 itâ€™s a failure of randomization\n\nCompliance Â§\nMotivation. Some people donâ€™t comply, even through theyâ€™re offered treatment. What if people who donâ€™t comply are different from people who comply? If this is the case, then focussing on just the treated &amp; compliant people would be not indicative of the true effect of the treatment.\n\n\nZ is the binary â€œwas going to treat this personâ€\nT is the binary â€œis compliant personâ€\n\nIntention to Treat Approach Â§\nWe attempt to resolve this issue by not regressing against treated &amp; compliant people, but all people who were â€œsupposed to be treatedâ€ (=intent to treat), i.e. T=1âˆ§Z=1\n\nNon-ITT: Yiâ€‹=Î²0â€‹+Î²1â€‹Â hasCompliedÂ Tiâ€‹â€‹â€‹+Ïµiâ€‹\nITT: Yiâ€‹=Î´0â€‹+Î´1â€‹Â ITTÂ Ziâ€‹â€‹â€‹+Î½iâ€‹\n\nThis is a conservative estimate. âˆ£Î´1â€‹âˆ£â‰¤âˆ£Î²1â€‹âˆ£; the lower the compliance, the lower the coefficient. (Full compliance implies â€=â€œ)\n\n\n\n2SLS Approach Â§\nAlternatively, a better approach to dealing with non-compliance is using a 2SLS. You can use the ITT variable Z as the IV, since it satisfies the conditions that make a good IV:\n\nInclusion condition: Z is correlated with T\nExclusion condition: Z is uncorrelated Ïµ because treatment is randomly assigned\n\n\nThen, the first stage (reduced form): Tiâ€‹^â€‹=Î³0â€‹+Î³1â€‹Z+Î³2â€‹X2iâ€‹+Î½iâ€‹\nThen the second stage:Yiâ€‹=Î²0â€‹+Î²1â€‹Tiâ€‹^â€‹+Î²2â€‹X2iâ€‹+Ïµiâ€‹\n\nAttrition Â§\ndef. Attrition means dropping out.\nThe following regression assesses if treatment is correlated to attrition:\ndidAttritioniâ€‹=Î´0â€‹+Î´1â€‹isTreatediâ€‹+Î½iâ€‹\nâ†’ if Î´1â€‹ is statistically significant the attrition is correlated to treatment, thus we need to control for it.\nMethods to resolve attrition:\n\nAdd covariates that are significant when we test (interactive attrition test): didAttritioniâ€‹=Î´0â€‹+Î´1â€‹Ziâ€‹+Î´2â€‹X2iâ€‹+Î´3â€‹Ziâ€‹Ã—X2iâ€‹, where Z is the intention-to-treat binary variable.\n\nThis should also be significant Î³1â€‹^â€‹in the balance test: X2iâ€‹=Î³0â€‹+Î³1â€‹Ziâ€‹+Î½iâ€‹ \nAdd the significant covariates to the final analysis\n\n\nTrim either dataset so the attrition rate is the same\nSelection model. (not discussed)\n"},"Convex-Programming":{"title":"Convex Programming","links":[],"tags":["Computing/Algorithms","Math/Calculus"],"content":""},"Cornout-Quantity-Competition":{"title":"Cornout Quantity Competition","links":[],"tags":["Economics/Micro-Economics","Economics/Game-Theory"],"content":"Firms will choose quantity as the strategic variable.\n\n\nDetermining Firm 2â€™s Best Response Curve:\n\nWhen firm 1â€™s quantity = 0, firm 2â€™s best response is to produce xM (=monopoly quantity)\nWhen firm 1â€™s quantity &gt; 0, firm 2â€™s best response derived by the reduction in demand in graph (c):\n\nD (=full market demand) is shifted left by x1â€‹ (=firm 1â€™s produced quantity) to Dr; Firm 2â€™s BR is to optimize at MC=MR\nâ†’ This shows that when Firm 1 produces 2xM, D will shift left so much that MRÂ =Â MC at x1â€‹=0.\n\n\n\n\nFirm 1â€™s BRC is symmetrical, as shown in (b)\n\nâ†’ Firms produce xC (= cournot quantity)\nâ†’ 21â€‹xM&lt;xC&lt;xB\n\n\n\n\n\n                  \n                  Info \n                  \n                \n\nCornout Price pC converges to competitive prices p=MC as the number of firms increase. (Take my word for this; itâ€™s proven mathematically but not shown above)\nSequential Move: Stackleberg Competition Â§\n\nStackleberg Leader is Firm 1, Stackleberg Follower is Firm 2\n\n\nFirm 1 considers Firm 2â€™s expected BRC before making a move:\nProfit maximize knowing firm 2â€™s BRC:\n\nGraph (a) is the expected Firm 2â€™s BRC\nWhen Firm 1â€™s quantity &gt;xâˆ— then firm 2 produces nothing\nâ†’ Firm 2 faces the full market demand â‡’D=Dr\nWhen Firm 1â€™s quantity âˆˆ[0,xM] then firm 2 faces the residual demand Dr which is calculated by:\n\nat x1â€‹=xM,\n\nâ€¦then BR: x2â€‹=21â€‹xM and Î£x=23â€‹xM\nâ€¦thus Dr=Dâˆ’21â€‹xM\nâ€¦equivalently Dr(xM)=D(23â€‹xM)\n\n\nat x1â€‹=0,\n\nâ€¦then BR: x2â€‹=xM and Î£x=xM\nâ€¦thus Dr=Dâˆ’xM=0\nâ€¦equivalently Dr(x1â€‹[=0])=D(xM)\n\n\n\n\n\nSequential Move: Entry Deterrence Â§\nGame Structure Â§\n\nFirst move is Firm 2â€™s entry decision\nSecond move is either Cournot Quantity, Stackleberg Quantity competition (Bertrand isnâ€™t considered)\nIf firm 2 enters it must pay a Fixed Cost (FC) which is an economic cost to them (=matters in profit calculation).\n\n\n\nFirm 2 chooses entry;\n\nâ€¦if it enters it must pay FC, and two players cornout compete;\nâ€¦if it doesnâ€™t its profit is zero, and Firm 2 is a monopoly\n\n\nFirm 2 chooses entry;\n\nâ€¦if it enters it must pay FC, and two players stackleberg compete with firm 1 as stackleberg leader;\nâ€¦if it doesnâ€™t its profit is zero, and Firm 2 is a monopoly\n\n\nFirm 1 chooses quantity first;\n\nâ€¦Firm 2 enters, paying FC, and Firm 2 gets stackleberg follower profit\nâ€¦Firm 2 doensâ€™t enter, and Firm 1 gets profit from its original quantity\n\n\n\nâ‡’ The game structure of (c) allows for strateigic entry deterrance by firm 1:\nEntry Deterence Â§\n\nFirm 1 may deter entry to maximize profit by setting a certain quantity\nFC is an exogenous variable\nâ†’ firm 2â€™s entry decision will depend on how big FC is\nâ†’ thus, firm 1â€™s entry deterrence will depend on how big FC is\n\n\n(a) is the profit against a choice of production quantity for a monopoly.\nâ†’ Then, see (b):\n\nIf FC&gt;FC: Second firm will not enter no matter\nâ€¦when FC=Ï€M\nIf FCâ€‹&lt;FC&lt;FC: First firm will deter entry by increasing production\nâ€¦when FCâ€‹=(xÂ s.t.Â Ï€(x)=Ï€SL)\nâ€¦i.e. Firm will deter entry until Ï€ drops so much that itâ€™s better to compete (and get Stackelberg profit)\nIf FC&lt;FCâ€‹: normal stackleberg competition\nâ€¦where firm 1 is Stackelberg Leader (SL) and get Ï€SL\nâ€¦and firm 2 is Stackelberg Follower (SF) and get Ï€SF\n"},"Correlation":{"title":"Correlation","links":["Covariance"],"tags":["Math/Statistics"],"content":"def. Correlation (Correlation Coefficient). Correlation is Covariance, but standardized (unitless)\nÏXYâ€‹â€‹=Corr(X,Y)=Cov(ÏƒXâ€‹Xâˆ’Î¼Xâ€‹â€‹,ÏƒYâ€‹Yâˆ’Î¼Yâ€‹â€‹)=ÏƒXâ€‹ÏƒYâ€‹1â€‹Cov(Xâˆ’Î¼Xâ€‹,Yâˆ’Î¼Yâ€‹)=ÏƒXâ€‹ÏƒYâ€‹Cov(X,Y)â€‹â€‹\nthm. Correlation Identities.\n\nâˆ’1â‰¤Ïâ‰¤1\nÏXYâ€‹=1â‡”âˆƒa,bâˆˆRâˆ§a&gt;0âˆ£Y=aX+b\nÏXYâ€‹=âˆ’1â‡”âˆƒa,bâˆˆRâˆ§a&lt;0âˆ£Y=aX+b\nÏaX,bYâ€‹=Corr(X,Y) i.e. linearly invariant\n\nFor R.V. X,Y, the following means the Same Thing Â§\n\nX,YÂ areÂ uncorrelated\nCov(X,Y)=0\nVar(X+Y)=Var(X)+Var(Y)\nE(Xâ‹…Y)=E(X)â‹…E(Y)\n\nIndependence [XâŠ¥Y] implies all of the above, but any of the above does not imply independence."},"Cost-Function":{"title":"Cost Function","links":[],"tags":["Economics/Micro-Economics"],"content":"\n\n                  \n                  wl+rk. Needs derivation by optimization.\n                  \n                \n\nC:(w,r,xË‰)â†¦C\n\nProperties\n\nHD1 in input prices\nIncreasing in input prices\nIncreasing in output quantity\n\n\n"},"Cost-Minimization":{"title":"Cost Minimization","links":["Profit-Maximization","Lagrangian-Optimization"],"tags":["Economics/Micro-Economics"],"content":"See also Profit Maximization\nLong Run Cost Minimization Â§\nminl,kâ€‹Â C=wl+rkÂ suchÂ thatÂ x=f(x)\n\nLagrangian Optimization\nOptimal when Isoquant is tangent to the isocost\n\nHigher isoquant is not always better! it just means youâ€™re producing more\n\n\n\n\n\n                  \n                  Warning \n                  \n                \nBeware when MC is monotonically decreasing. This means that the firm will produce zero or infinity, which is means it is a special case which you need to analyze separately.\n\n"},"Course-List-(Landing-Page)":{"title":"Course List (Landing Page)","links":["CS-330-Advanced-Algorithms","CS-334-Formal-Languages","CS-535-Algorithmic-Game-Theory","CS-250-Architecture","ECON-205-Intermediate-Microeconomics-II","Math-581-Mathematical-Finance","Math-582-Financial-Derivatives","Econ-201-Intermediate-Microeconomics-I","Econ-204-Econometrics","Econ-210-Macroeconomics","Econ-371-Finance","Stat-432-Statistics","Stat-230-Probability","GSF-386-Politics-of-Sexuality","CulAnth-203-Marxism","Econ-361-Distributive-Justice","Phenomenology","Michel-Foucault","Judith-Butler"],"tags":["Courses"],"content":"Computer Science Â§\n\nğŸŒŸ CS 330 Advanced Algorithms\nğŸŒŸ CS 334 Formal Languages\nCS 535 Algorithmic Game Theory\nCS 250 Architecture\n\nEconomics Â§\n\nğŸŒŸ ECON 205 Intermediate Microeconomics II\nğŸŒŸ Math 581 Mathematical Finance\nMath 582 Financial Derivatives\nEcon 201 Intermediate Microeconomics I\nEcon 204 Econometrics\nCS 535 Algorithmic Game Theory\nEcon 210 Macroeconomics\nEcon 371 Finance\n\nMath Â§\n\nğŸŒŸ Stat 432 Statistics\nğŸŒŸ Math 581 Mathematical Finance\nğŸŒŸ Math 582 Financial Derivatives\nStat 230 Probability\n\nLiberal Arts Â§\n\nGSF 386 Politics of Sexuality\nCulAnth 203 Marxism\nEcon 361 Distributive Justice\nSee also:\nPhenomenology\nMichel Foucault\nJudith Butler\n"},"Covariance-&-Correlation":{"title":"Covariance & Correlation","links":[],"tags":["Math/Probability"],"content":""},"Covariance":{"title":"Covariance","links":["Variance"],"tags":["Math/Statistics"],"content":"def. Covariance. Covariance measures the joint variability of two R.V.s; let X,Y.\n\nWhen X,Y show similar behavior, Cov(X,Y)&gt;0\nWhen X,Y show opposite behavior, Cov(X,Y)&lt;0\n\nCov(X,Y):â€‹=E((Xâˆ’Î¼Xâ€‹)(Yâˆ’Î¼Yâ€‹))=E(Xâ‹…Y)âˆ’E(X)â‹…E(Y)â€‹\n\nWhen XâŠ¥Y, then Cov(X,Y)=0; but Cov(X,Y) does not imply XâŠ¥Y\nCovariance is a generalization of Variance: Var(X)=E((Xâˆ’Î¼Xâ€‹)2)=Cov(X,X)\n\nthm. Relationship between Covariance and Variance. let X,Y. then:\nVar(X+Y)â€‹=Var(X)+Var(Y)âˆ’2â‹…E((Xâˆ’Î¼Xâ€‹)(Yâˆ’Î¼Yâ€‹))=Var(X)+Var(Y)âˆ’2Cov(X,Y)â€‹â€‹\n\nWhen XâŠ¥Y then Var(X,Y)=Var(X)+Var(Y)\n\nthm. Bilinearity of Covariance.\n\nCov(aX,aY)=abâ‹…Cov(X,Y)\nCov(X,Y+Z)=Cov(X,Y)+Cov(X,Z)\n\nthm. Summed Variance. let X1â€‹,â€¦,Xnâ€‹. Then\nVar(iâˆ‘â€‹Xiâ€‹)=iâˆ‘â€‹Var(Xiâ€‹)+2âˆ€j,kÂ s.t.j&lt;kâˆ‘â€‹Cov(Xjâ€‹,Xkâ€‹)\nE.G. second summation has (23â€‹) terms:\nVar(X1â€‹+X2â€‹+X3â€‹)â€‹=Var(X1â€‹)+Var(X2â€‹)+Var(X3â€‹)+2â‹…Cov(X1â€‹,X2â€‹)+2â‹…Cov(X2â€‹,X3â€‹)+2â‹…Cov(X1â€‹,X3â€‹)â€‹"},"Cramer-Rao-Lower-Bound-(CRLB)":{"title":"Cramer-Rao Lower Bound (CRLB)","links":[],"tags":["Math/Statistics"],"content":"thm. Cramer-Rao lower bound. Given estimator Î¸^,\nIf:Â Â E[Î¸^]=g(Î¸)â‡’Var(Î¸^)â‰¥I(Î¸)gâ€²(Î¸)â€‹\nIf estimator Î¸^ is unbiased:\nVar(Î¸^)â‰¥I(Î¸)1â€‹\nâ‡’ CRLB is a statement about the bound on the best possible precision [=efficiency] we can get.\nâ†’ If an estimator reaches the CRLB, it is deemed most efficient."},"Critical-Point":{"title":"Critical Point","links":[],"tags":["Math/Calculus"],"content":"\n\n                  \n                  Critical Point \n                  \n                \nA critical point on function f(x) is all xiâ€‹ where dxdâ€‹f(xiâ€‹)=0\n"},"Critical-Theory":{"title":"Critical Theory","links":["Ideology","Normative-Scripts"],"tags":["Philosophy/Queer-Theory"],"content":"Critical Theory builds theoretical tools and methods to deconstruct Ideology and in general the harmful Normative Scripts of society."},"Critical-Vertex":{"title":"Critical Vertex","links":["Graph"],"tags":["Computing/Algorithms"],"content":"Graph"},"Cross-Price-Demand-Curve":{"title":"Cross-Price Demand Curve","links":[],"tags":["Economics/Micro-Economics"],"content":"Relates price of one good p1â€‹ to the quantity demanded of another good x2â€‹"},"CulAnth-203-Marxism":{"title":"CulAnth 203 Marxism","links":["Productive-Forces,-Relations-of-Production,-and-Historial-Materialism","Capital-(Marxism)","Proletatriat-(Marxism)","Communism","Private-Property","Sensuous-Activity","Alienation","Species-being","Artificial-Needs","Base-&-Superstructure","Valorization,-Surplus-Value","Worker-vs-Machine","Commodities","Use-value,-Exchange-value"],"tags":["Courses"],"content":"\nProductive Forces, Relations of Production, and Historial Materialism\nCapital (Marxism) and Proletatriat (Marxism)\nCommunism, Private Property, Sensuous Activity\nAlienation and Species-being\nArtificial Needs\nBase &amp; Superstructure\nValorization, Surplus Value\nWorker vs Machine\nCommodities - Use value, Exchange value\n"},"Curvature-(Math)":{"title":"Curvature (Math)","links":[],"tags":["Math/Calculus"],"content":""},"Data-is-Everything":{"title":"Data is Everything","links":["(Article)-Magic-Ink---Information-Software-and-the-Graphical-Interface","Personal-Computing","Functional-Programming","Turing-Machine"],"tags":["Computing"],"content":"Observe:\n\n(Article) Magic Ink - Information Software and the Graphical Interface\n\nâ‡’ UI Design is information design (not interactivity).\n\n\nEverything is a File (in Personal Computing)\nFunctional Programming treats programs as manipulation of data.\nTuring Machine take input and produce output on tape.\n\nAn â€œeffective methodâ€ [=algorithm] is just procedures on data\n\n\n\nThus data is what drives every computable process.\n\n\n                  \n                  Abstract \n                  \n                \nEverything is Data. Data is Everything.\n"},"Data-driven-or-Truth-driven":{"title":"Data-driven or Truth-driven","links":["Limits-of-Math-and-Computing","Turing-Machine","Phenomenology","Data-is-Everything","Perspective-Projections-Model","Analytic-Philosophy"],"tags":["Mental-Models","Math","Computing"],"content":"Data-Algorithm structure in the top-down approach; Truth-Proof in the bottom-up approach.\n\nThey merge at Godelâ€™s Incompleteness Theorem\n\nRelation between GÃ¶delâ€™s incompleteness theorem, the halting problem and universal Turing machines - Computer Science Stack Exchange\nLimits of Math and Computing.\nThink: the UTM takes a binary encoding of a TM and can simulate that TM. This is algorithm that is taken as input data to another algorithm.\n\n\nAxioms are fundamental bits of data. Using proofs we derive more data [=conjectures, theorems].\n\nData-Algorithm Â§\nPhenomenology and to a greater extent whole of Continental Philosophy. Data is Everything. Perspective Projections Model\nTruth-Proof Â§\nBertrand Russell, G. E. Moore and all of Analytic Philosophy\nAlso see (DevonThink) How to safely think in systems. | Irrational Exuberance"},"Database-Design-Theory":{"title":"Database Design Theory","links":["Relational-Algebra"],"tags":["Computing/Data-Science"],"content":"How to reduce a Relational Model to make it more compact.\nArmstrongâ€™s Axioms Â§\n\nReflexivity: YâŠ†XâŸ¹Xâ†’Y\nAugmentation: Xâ†’YâŸ¹XZâ†’YZ\nTransitivity: Xâ†’YÂ andÂ Yâ†’ZâŸ¹Xâ†’Z\n\nSecondary Rules Â§\n\nDecomposition: Xâ†’YZâŸ¹Xâ†’Y,Xâ†’Z\nComposition: Aâ†’B,Xâ†’YâŸ¹AXâ†’BY\nUnion: Xâ†’Y,Xâ†’ZâŸ¹Xâ†’YZ\nPseudo-transitivity: Xâ†’Y,YAâ†’ZâŸ¹XAâ†’Z\nIdentity: Xâ†’X\nExtensivity: Xâ†’YâŸ¹Xâ†’XY\n\nFunctional Dependency Â§\ndef. Functional Dependency. If for all tuples in a relation that has the same values for attribute X and attribute Y, then Y is functionally dependent on X.\nâˆƒf:Xâ†¦YâŸ¹Xâ†’YÂ ...readÂ &quot;YÂ DependsÂ onÂ X&quot;\ne.g. an address relation with street, city, state, zip\n\nzip â†’ (city, state)\n\nZip code determines city and state\n\n\n(zip, state) â†’ zip\n\nThis is a Trivial dependency:= RLHSâŠ‡RHS\n\n\nzip â†’ (state,zip)\n\nThis is non-trivial, but not complete,\nComplete Non-trivial dependency:= LHSâˆ©RHSî€ =âˆ…\n\n\n\nalg. BCNF decomposition procedure. Given a set of dependencies F and relation R, BCNF decomposition determines a minimally redundant (=row-redundant) Relation.\n\nChoose (non-determinisitcally) a dependency in F, let Xâ†’Y which is non-trivial (=X is not a superkey)\nDecompose using X into two relations R1â€‹,R2â€‹\n\nR1â€‹ has attributes XâˆªY\nR2â€‹ has attributes Xâˆª(attr(R)âˆ’Y)\n\n\nRecurse procedure for R1â€‹,R2â€‹\n\n\nItâ€™s a non-deterministic process (=there can be multiple ways to decompose a relation).\n\ndef. Closure. Given dependencies F, the closure Zâˆ— of set of attributes Z is all attributes determined by Z through those dependencies\n\nFinding a Key Using Functional Dependencies Â§\nalg. Given set of functional dependencies F on relation R, find the keys of the schema\n\nFor each dependencies LHSâ†’RHS, compute the closure of LHS such that LHSâ†’LHSâˆ—.\n\nIf LHSâˆ— doesnâ€™t contain all the attributes of R, then augment LHS such that it reaches all the attributes.\n\ni.e., let Remain=attr(R)âˆ’LHSâˆ—\nthen, it must be LHSâˆªRemainâ†’attr(R)\n\n\nThen, LHSâˆªRemain is a superkey of R. let this be S.\nCan you reduce this superkey S?\n\nTry taking out one attribute at a time from S to create Sâ€²\nIs Sâ€² reducible?\nâ†’ Repeat until we reach something unreducible.\nâ‡’ The final Sâ€² that is unreducible is a key.\n\n\n\n\nRepeat for all dependencies in F.\n\nMulti-value Dependency Â§\ndef. Multi-value Dependency (MVD). Y is a multi-value dependency of X ifâ€¦\n\nfor all tuples with the same values of Xâ€¦\nâ€¦if we swapped all the Y values of themâ€¦\nâ€¦those entries also exist in the database. then:\n\nXâ† Y\nIn colloquial terms, we can say that for every determined value of X, all tuples with values of Y â€œassociatedâ€ with that X must exist too.\n\ndef. Trivial MVD. Given relation R(A,B,C):\n\nA,Bâ† C: Obvious. LHSâˆªRHS=attrs(R)\nA,Bâ† A: Obvious. LHSâŠ‡RHS\n\ndef. 4th Normal Form (4NF). if every MVD in relation R is Xâ† Y such that X is always a superkey, then relation R is in the 4th Normal Form. Example\nMultivalue Dependency Rules Â§\n\nComplementation: Xâ† YâŸ¹Xâ† attrs(R)âˆ’Xâˆ’Y\nAugmentation: Xâ† Y,BâŠ†AâŸ¹XAâ† YB\nTransitivity: Xâ† Y,Yâ† ZâŸ¹Xâ† Zâˆ’Y\n\nAutomatically means Xâ† Y,Yâ† ZâŸ¹Xâ† Z\n\n\nReplication: Xâ†’YâŸ¹Xâ† Y\nCoalescence: If ğ‘‹ â†  ğ‘Œ and ğ‘ âŠ† ğ‘Œ and there is some ğ‘Š disjoint from ğ‘Œ such that ğ‘Š â†’ ğ‘, then ğ‘‹ â†’ ğ‘\n\nChase Â§\nProving theorems about chase. Example: \nalg. Tuple Generation. To enforce Xâ† Y on table R\n\nFor a determined X=xiâ€‹\n\nEnumerate all availble Y=y1â€‹,y2â€‹,â€¦,y?â€‹\nEnumerate all available\n\nlet Q:=attr(R)âˆ’Xâˆ’Y\nEnumerate all availalbe Q=q1â€‹,â€¦,q?â€‹\n\n\nAre all combinations YÃ—Q available in the table?\n\nIf not, add missing ones\n\n\n\n\nFor another determined X=x2â€‹, repeat\nRepeat for all X=x1â€‹â€¦x?â€‹\n\nalg. Chase. To prove Xâ† Yâ€¦\n\nInitialization: add two tuples (x,y1â€‹,â€¦),(x,y2â€‹,â€¦) to the initial table\nFor each MVD (order doesnâ€™t matter):\n\nTuple Generation: see above\n\n\nFor each FD (order doesnâ€™t matter):\n\nYou may infer equalities, e.g. e1â€‹=e2â€‹\n\n\nDoes Xâ† Y fully available? (=YÃ—RemainingÂ Attrs all in table)?\n\nYes â†’ proven\nNo â†’ disproven (counterexample)\n\n\n"},"Database-Indexing":{"title":"Database Indexing","links":[],"tags":["Computing/Data-Science"],"content":"Sequential Index Â§\n\nCan be dense or sparse\n\nPrimary Index: Key indices are often sparse, because the rows are ordered using the key index\nSecondary Index: Index on other attributes are often dense b/c/ v.v.\n\n\nYou can manually create indexes in SQL:\n{postgresql}CREATE INDEX indexname ON tablename(columnname)\nMulti-column index: Index (A,B) on R(A,B,C) has keys that have A,B concatenated and sorted together.\n\nSee: sql server - what does a B-tree index on more than 1 column look like? - Stack Overflow\nQuote: â€œWith most implementations, the key is simply a longer key that includes all of the key values, with a separator. No magic there;-). In your example the key values could look something like:&quot;123499|John Doe|Conway, NH&quot;,&quot;32144|Bill Gates| Seattle, WA&quot;\n\n\n\nIndex Sequential Access Method (ISAM) Â§\n\nLookup: \nInsert / Delete: \n\nB+ Trees Â§\n\nArchitectural Improvement on ISAM\n\nEach block can fan-out a specific amount n\nEach block containes nâˆ’1 entries to indicate ranges\nExample: \n\n\nLeaves are sequential â†’ Range queries are possible: \nGuaranteed to be well-balanced (=all nodes are at least half-full)\n\nGuaranteed by recursive node splitting (on insert) and recursive node coalescing or entry stealing (on delete)\nExample: \n\n\nPerformance: access time is O(height)=O(logfanoutâ€‹#Tuples)\n\nâ†’ You can fit this in memory (4-level B+ Trees are often good enough)\nâ€¦recall you also need to node-split of node-coalesce sometimes too\n\n\n"},"Database-Management-System":{"title":"Database Management System","links":["Performance-(Computing)"],"tags":["Computing/Data-Science"],"content":"DBMS must be able toâ€¦\n\nStore data persistently.\nHandle query of data by the user\nUpdate data as requested\n\nWhat do databases aim to be?\n\nPhysical Data Independence\n\nHow data is physically stored is abstracted away by the DBMS\n\n\nConcurrency Control\n\nMultiples accesses must be performant and conflict-free\n\n\nRecovery\n\nFailures should be handled and recovered\n\n\nPerformance (Computing)\n\nMust be performant with lots of accesses\n\n\n"},"Debt":{"title":"Debt","links":[],"tags":["Economics/Finance"],"content":"Secured debt:= debt backed by collateral"},"Debter-in-posession":{"title":"Debter in posession","links":[],"tags":["Economics/Finance"],"content":""},"Decentralization":{"title":"Decentralization","links":["Institutional-Design","Centralized-Power","Michel-Foucault","horizontal-organization","Living-With-the-Internet","Spontaneous-Organization","Game-Theory"],"tags":["Economics/Game-Theory","Philosophy/Political-Philosophy","Computing"],"content":"Decentralization is a type of Institutional Design that breaks up central powers into smaller autonomous organizations.\n\nIt distributes Centralized Power into the microphysics of power\nIt allows for horizontal organization\nComputers and the internet allows these structures to naturally form\nSpontaneous Organization\n\nExample\n\nGit (decentralized version control &amp; devops)\nBlockchain (decentralized ledger)\nIPFS &amp; BitTorrent (decentralized file hosting)\nGame Theory Concepts\nResource Regeimes\n\n(DevonThink) 4-3. Ostrom, Collective action and the evolution of social norms\n\n\n"},"Delta-and-Gamma-Hedging":{"title":"Delta and Gamma Hedging","links":["Options-(Finance)","Black-Scholes-European-Option-Pricing-Formula","Stochastic-Calculus","tags/task"],"tags":["Economics/Finance","task"],"content":"Motivation. Imagine you are an investment bank, selling (which is equivalent to short-selling) a call option. At the end, you have to pay to the holder CTâ€‹=max{STâ€‹âˆ’K,0}. When the option is on the money at expiration time T, you have to pay STâ€‹âˆ’K. You want to pay less, though; so you try to hedge against small changes in underlyer price.\nDelta Hedging for Call/Put Options Â§\nAt time t=0 (day 0) Â§\n\nSell the option âˆ’CtEâ€‹, and get the cash CtEâ€‹\nBorrow Ltâ€‹ amount of money to buy Î”tâ€‹ units of stock. (this is the hedging part)\n\n&amp; this Î”tâ€‹ is the same as the delta of the call option.\n\n\n\nVtâ€‹=Â short-sellÂ âˆ’CtEâ€‹â€‹â€‹+Â cashÂ CtEâ€‹â€‹â€‹âˆ’Â loanÂ Ltâ€‹â€‹â€‹+Â underlyerÂ Î”tâ€‹Stâ€‹â€‹â€‹\nIt is obvious that the value of this portfolio is Vtâ€‹=0, at time t=0, but to show that this portfolio at any time t always has value 0, we observe the fact that the last three terms (let Ctsynâ€‹:=+CtEâ€‹âˆ’Ltâ€‹+Î”tâ€‹Stâ€‹) is a self-financing portflio that tracks the call price exactly.\nObserve from BSM derivation that a portfolio Wtâ€‹=ntâ€‹StCâ€‹+btâ€‹Btâ€‹ (we already used V) is self-financing and replicates when:\n\nntâ€‹=Stcâ€‹Stâ€‹â€‹Î”fâ€‹\nbtâ€‹=Btâ€‹f(Stâ€‹,t)âˆ’ntâ€‹StCâ€‹â€‹\nIn our case, we have:\nntâ€‹=StCâ€‹Stâ€‹â€‹Î”tâ€‹\nbtâ€‹=Btâ€‹CtEâ€‹âˆ’Stâ€‹â€‹\nAnd thus =btâ€‹Btâ€‹CtEâ€‹âˆ’Ltâ€‹â€‹â€‹+=ntâ€‹Stâ€‹Î”tâ€‹Stâ€‹â€‹â€‹ by the above equation.\n\nAt time t=0+dt (day 1) Â§\n\nOption value changes to âˆ’Ct+dtâ€‹\nCash holding grows to CtEâ€‹erâ‹…dt\nWe must â€œRe-hedgeâ€ or â€œbalanceâ€ the loan and underlier such that we maintain Î”t+dtâ€‹ units of underlyer. We break it out into three cases:\n\nÎ”t+dtâ€‹=Î”tâ€‹ (delta stays same): time value of money, and use dividend to pay back loan\n\nLt+dtâ€‹=Ltâ€‹Â timeÂ valueÂ e(râˆ’q)â‹…dtâ€‹â€‹\n\n\nÎ”tâ€‹&lt;Î”t+dtâ€‹ (delta increases): Borrow more money to buy more stock:\n\nLt+dtâ€‹=Ltâ€‹e(râˆ’q)dt+âˆ£dÎ”tâ€‹âˆ£St+dtâ€‹\n\n\nÎ”t+dtâ€‹&gt;Î”tâ€‹ (delta decreases): Sell stock to reimburse loan.\n\nLt+dtâ€‹=Ltâ€‹e(râˆ’q)dtâˆ’âˆ£dÎ”tâ€‹âˆ£St+dtâ€‹\n\n\nIn all three cases, we can say:\n\n\n\nLt+dtâ€‹=Ltâ€‹e(râˆ’q)dt+(dÎ”tâ€‹)St+dtâ€‹\n\nWe then purchase or sell dÎ”tâ€‹ units of the security to get Î”t+dtâ€‹St+dtâ€‹\nAs we show above, Ct+dtsynâ€‹:=+Ct+dtEâ€‹âˆ’Ltâ€‹+Î”t+dtâ€‹St+dtâ€‹ is self-financing. This means that total value of the portfolio is:\n\nVt+dtâ€‹â€‹=âˆ’Ct+dtEâ€‹+CtEâ€‹erâ‹…dtâˆ’Lt+dtâ€‹=âˆ’Ct+dtEâ€‹+=Ct+dtEâ€‹CtEâ€‹erâ‹…dtâˆ’Ltâ€‹e(râˆ’q)dt+(dÎ”tâ€‹)St+dtâ€‹â€‹Â loanÂ â€‹+Î”t+dtâ€‹St+dtâ€‹â€‹â€‹=0â€‹â€‹\nAt time t=T, (expiration date) Â§\nOn expiration and before the call is cashed out, the value of the portfolio is:\nVTâ€‹=0=âˆ’max{STâ€‹âˆ’K,0}+C0Eâ€‹erÏ„âˆ’LTâ€‹L0â€‹e(râˆ’q)Ï„+(dÎ”Tâˆ’dtâ€‹)STâ€‹â€‹â€‹+Î”Tâ€‹STâ€‹\nWe then consider our customer cashing out their loan:\n\nIf STâ€‹&gt;K in the money,\n\nâˆ’CTEâ€‹ becomes âˆ’STâ€‹+K\nÎ”Tâ€‹=1\nThus VTâ€‹=âˆ’STâ€‹+K+C0Eâ€‹erÏ„âˆ’LTâ€‹+STâ€‹=0 since synthetic call still holds\n\ni.e., liquidate the stock to pay STâ€‹\n\n\nThus LTâ€‹=K+C0Eâ€‹erÏ„\n\ni.e., pay back the loan with remaining K and cash invested\n\n\n\n\nIf STâ€‹â‰¤K out of the money:\n\nâˆ’CtEâ€‹ becomes 0\nThus VTâ€‹=+C0Eâ€‹erÏ„âˆ’LTâ€‹+Î”Tâ€‹STâ€‹=0 since synthetic call still holds\nThus LTâ€‹=C0Eâ€‹erÏ„+Î”Tâ€‹STâ€‹\n\ni.e. pay back the loan with cash invested and liquidating the stock\n\n\n\n\n\nGreek Neutral Portfolio of Derivatives Â§\nAny derivative we can modify to make delta-neutral. For a security modeled by geometric brownian motion (with no dividends, q=0):\ndStâ€‹=mStâ€‹dt+ÏƒStâ€‹dBtâ€‹\n\n\n                  \n                  Notation \n                  \n                \nSince there are lots of notaions here, letâ€™s outline them first:\n\nStâ€‹ is the underlying security\nCtEâ€‹ is the call option\nV~ is the delta-neutral portfolio when parameter Nsâ€‹=Î”Câ€‹\nV^ is the gamma-neutral portflio when parameters Nsâ€‹=Î”Câ€‹, NCâ€‹=âˆ’Î“Câ€‹Î“~â€‹\nVâ€² is the delta-gamma neutral portflio when parameters\n\n\nlet us create a portfolio of a derivative of this stock by having one call option and Nsâ€‹ units of the underlier. The value of this portflio is:\nV~(Stâ€‹,t)=CtEâ€‹+Nsâ€‹Stâ€‹\n\nCtEâ€‹ have greeks Î”Câ€‹,Î“Câ€‹,Î˜Câ€‹\nwhich have greeks Î”~=Î”Câ€‹+NSâ€‹, Î“~=Î“Câ€‹, Î˜~=Î˜Câ€‹.\nUsing itoâ€™s formula, we get:\n\ndV~â€‹=â€‹Î˜~âˆ‚tâˆ‚V~â€‹â€‹â€‹+mStâ€‹Î”~âˆ‚Stâ€‹âˆ‚V~â€‹â€‹â€‹+21â€‹Ïƒ2St2â€‹Î“~âˆ‚St2â€‹âˆ‚2V~â€‹â€‹â€‹â€‹dt+ÏƒStâ€‹Î”~âˆ‚Stâ€‹âˆ‚V~â€‹â€‹â€‹dBtâ€‹=Î“~21â€‹Â SeeÂ belowÂ Ïƒ2St2â€‹dtâ€‹â€‹+Î˜~dt+Î”~(=dStâ€‹mStâ€‹dt+ÏƒStâ€‹dBtâ€‹â€‹â€‹)=21â€‹(dStâ€‹)2Î“~+Î˜~dt+Î”~dStâ€‹â€‹â€‹\nWhere from Ito Isometries\n(dS_{t})^{2}&amp;=m^{2}S_{t}^{2}\\underbrace{ (dt)^{2} }_{ =0 }+\\sigma^{2}S_{t}^{2}\\underbrace{ d\\mathfrak{B}_{t}^{2} }_{ = dt}+2m\\sigma S_{t}^{2}\\underbrace{ dtd\\mathfrak{B}_{t} }_{ =0 } \\\\\n&amp;= \\sigma^{2}S_{t}^{2}dt\n\\end{align}\nNow, from the above formula we see that there are three components that cause changes in dV~\n\nâˆ£Î”~âˆ£&gt;0 i.e. non-zero delta\nâˆ£Î“~âˆ£&gt;0, i.e. non-zero gamma\nâˆ£Î˜~âˆ£&gt;0, but considering Î˜:=âˆ‚tâˆ‚Sâ€‹ itâ€™s impossible for this to be zero.\n\nDelta hedging. Â§\nLets make Î”~=0. We can do this simply by setting Nsâ€‹â‰¡Î”Câ€‹:\nV~âˆ‚Stâ€‹âˆ‚V~â€‹â€‹=âˆ’CtEâ€‹+Î”Sâ€‹Stâ€‹=âˆ’âˆ‚Stâ€‹âˆ‚Vâ€‹+Î”Câ€‹=âˆ’Î”Câ€‹+Î”Câ€‹=0â€‹â€‹\nDelta-Gamma Hedging Â§\nAfter the delta hedging we still have a positive gamma. Lets make Î“~=0. We create a new portfolio of the delta-neutral portfolio, and NCâ€‹ units of the call:\nV^Î“^â€‹=V~+NCâ€‹CtEâ€‹=âˆ‚St2â€‹âˆ‚2V^â€‹=Î“~+NCâ€‹Î“Câ€‹â€‹â€‹\nSetting NCâ€‹â‰¡âˆ’Î“Câ€‹Î“~â€‹ will make Î“^=0. But this incurs a new problem: Î”^ is non-zero again. We add Nmoreâ€‹ more units of Stâ€‹ to combat this:\nVâ€²=V~+NCâ€‹CtEâ€‹+Nmoreâ€‹\n\n #task finish off gamma hedging\n"},"Demarcation-Problem":{"title":"Demarcation Problem","links":["Karl-Popper","Analytic-Philosophy"],"tags":["Philosophy/Epistemology"],"content":"Demarcation Problem. Problem in epistemology on how to distinguish science and non-science. Related to:\n\nFalsifiability Criterion\n\nKarl Popper is the modern analytic philosopher to discuss this\n\n\nEmpiricism\n"},"Depth-First-Search":{"title":"Depth First Search","links":["Shortest-Path","Directed-Acyclical-Graph"],"tags":["Computing/Algorithms"],"content":"alg. Depth First Search. DFS, but also record the preand post-times as it is convenient. From Class:\n\nTime Complexity: O(V+E)\nDFS is useful in most graph tasks except Shortest Path (thatâ€™s for BFS)\n\n\nthm. Identifying DAGs. If there is no back edge, the graph is a DAG.\nalg. DAG Topological Ordering. Perform DFS with postand pre-time. Check there are no back edges (i.e. no cycle)"},"Derivative-Rules":{"title":"Derivative Rules","links":["Integration-Rules"],"tags":["Math/Calculus"],"content":"\n\n                  \n                  Note \n                  \n                \n\n(DevonThink) IB Math HL Formula Booklet\nIntegration Rules\n\n\nDerivation Rules Â§\nChain Rule:\ny=g(u)âŸ¹u=f(g(x))âŸ¹dxdyâ€‹=dudyâ€‹â‹…dxduâ€‹\nf(g(x))=fâ€²(g(x))â‹…gâ€²(x)\nProduct Rule:\ndxdâ€‹f(x)g(x)=fâ€²(x)g(x)+f(x)gâ€²(x)\nFilliping:\ndxdyâ€‹=(dydxâ€‹)âˆ’1\n\nSpecial Functions Â§\nExponentials Â§\n\nf(x)=ax then fâ€²(x)=ln(a)â‹…ax\nf(x)=ex then fâ€²(x)=ex\nf(x)=ag(x) then fâ€²(x)=ln(a)â‹…ag(x)â‹…gâ€²(x)\nf(x)=eg(x) then fâ€²(x)=eg(x)â‹…gâ€²(x)\n\nTrigonometric Functions Â§\nFrom (DevonThink) Mnemonic diagram for trigonometric and hyperbolic functions\n\n\nFunctions and cofunctions are on horizontal lines.\nDerivatives of functions on the right have a negative sign; those on the left do not.\nFunctions and reciprocals are on diagonal lines.\n\ne.g. sin(x)=csc(x)1â€‹\n\n\nEach function is the ratio of the next two functions clockwise.\n\ne.g. tan(x)=cos(x)sin(x)â€‹\n\n\nEach function the the product of its two neighbors.\nThe two functions at the top are bounded. The rest are unbounded.\nThe functions that are vertices of a triangle with a Roman numeral inside are related by Pythagorean identities.\n\ne.g. sin(x)2+cos(x)2=1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFunctionDerivativeIntegralsin(x)cos(x)âˆ’cos(x)+Ccos(x)âˆ’sin(x)sin(x)+Ctan(x)sec2(x)$-\\lncot(x)âˆ’csc2(x)$\\lnsec(x)sec(x)tan(x)$\\lncsc(x)âˆ’csc(x)cot(x)$\\ln\n\n\nFunction and cofunctions are on lines that make a 120Â° angle with the horizontal.\nDerivatives of functions on the right have a negative sign; those on the left do not.\nFunctions and reciprocals are on diagonal lines.\nEach function is the ratio of the next two functions clockwise.\nEach function the the product of its two neighbors.\nThe two functions at the top are bounded. The rest are unbounded.\nThe functions that are vertices of a triangle with a Roman numeral inside are related by Pythagorean identities.\n"},"Derivatives-(Finance)":{"title":"Derivatives (Finance)","links":["Options-(Finance)","Futures","Forwards","Swaps"],"tags":["Economics/Finance"],"content":"Derivatives are tradable contracts.\nProperties of Derivatives Â§\nWhere is it traded?\n\nOver-the-Counter (OTC): the two parties arrage the terms by themselves. Harder to price.\nExchange-traded: everybody goes to the central exchange to trade. Higher liquidity.\n\nDo you need to execute?\n\nNon-contingent: No need to execute. Options (Finance)\nContingent: Must execute. Futures, Forwards, Swaps, etc.\n"},"Desire-as-the-Object-of-Desire":{"title":"Desire as the Object of Desire","links":["(Philosopher)-Alexandre-Kojeve","(Book)-Phenomenology-of-Spirit","Jealousy"],"tags":["Philosophy"],"content":"â€¦is (Philosopher) Alexandre Kojeveâ€™s interpretation of (Book) Phenomenology of Spirit.\n\nIt is what differentiates humans from others\nEssences of Jealousy and complex love.\n"},"Development-Documentation-for-Writing-Helper":{"title":"Development Documentation for Writing-Helper","links":[],"tags":["Computing","Documentation"],"content":"PDF.js usage\nHow to Build a React PDF Viewer with PDF.js | PSPDFKit\nHow to Build a TypeScript PDF Viewer with PDF.js | PSPDFKitlog\n\nPDF.js uses workers to parse and render the PDF file. To keep things simple, weâ€™ll avoid bundling the workers and instead copy them to our public folder (named public) using the following:\n\ncp ./node_modules/pdfjs-dist/build/pdf.worker.min.js ./public/\n\n{and then you can do:}\npdfJS.GlobalWorkerOptions.workerSrc =\n\t\t\t\twindow.location.origin + &#039;/pdf.worker.min.js&#039;;\nFeatures Â§\n\nList of past articles for the user\n\nIncludes what they learned, what they ignored\n\n\nWord order by frequency\n"},"Dialectical-Materialism":{"title":"Dialectical Materialism","links":[],"tags":["Philosophy/Political-Philosophy"],"content":"\nThe law of the unity and conflict of opposites\nThe law of the passage of quantitative changes into qualitative changes\nThe law of the negation of the negation\n"},"Dialectical-Synthesis":{"title":"Dialectical Synthesis","links":["(Philosopher)-G.-W.-F.-Hegel"],"tags":["Philosophy/Epistemology"],"content":"by (Philosopher) G. W. F. Hegel"},"Difference-In-Difference":{"title":"Difference In Difference","links":["Fixed-Effects-Model-for-Panel-Data"],"tags":["Math/Statistics"],"content":"Fixed Effects Model for Panel Data\nDiD analysis is a way of observing and doing statistics on natural experiments. Itâ€™s called difference-in-difference because weâ€™re comparing the differences in the change between the control and treatment groups. The model is:\nYitâ€‹=Î²0â€‹+Î²1â€‹isTreated+Î²2â€‹isAfter+Î²3â€‹isTreatedÃ—isAfter+Ïµitâ€‹\nwhere isTreated and isAfter each is a dummy variable. The regression will look something like this:\n\n(a) illustrated when there is no difference-in-difference. (b) illustrates when there is a difference-in-difference. Î²3â€‹, the coefficient that measures additional effect when there is treatment and is after treatment is the important coefficient."},"Differential-Equation":{"title":"Differential Equation","links":[],"tags":["Math/Calculus"],"content":""},"Directed-Acyclical-Graph":{"title":"Directed Acyclical Graph","links":["Algorithm-Problem-Tips","Directed-Graph","Depth-First-Search","Shortest-Path"],"tags":["Computing/Data-Structures"],"content":"def. Directed Acyclical Graph (DAG). No shit.\n\nDirected Trees are (obviously) DAGs.\n\nIt also has a topological ordering\n\n\n\nAlgorithm Problem Tips. Detecting if a Directed Graph is Acyclic.\n\nIdea: DFS with tree. If there is no back edge, it is a DAG.\n\nalg. Topological Sort (DFS). DFS with preand post-times. Order by decreasing post-time.\n\nSee Also course\nTopological Sort may not be unique\n\nalg. Shortest Path for DAG.\nIdea: Topological sort of DAG. Then, linearly calculate minimum distance to that.\nslides"},"Directed-Graph":{"title":"Directed Graph","links":["Directed-Acyclical-Graph","Depth-First-Search"],"tags":["Computing/Data-Structures","Computing/Algorithms"],"content":"Terminology\n\nGT: Transpose of directed graph; G with all the directions of edges reversed\nSource vertex: outgoing edges only\nSync vertex: incoming edges only\nStrongly connected directed graph: all edges can reach all other edges\n\nSource Component: only outgoing edges to any vertex of component\nSync Component: only incoming edges to any vertex of component\n\n\nIf directed graph has no cycles, it is a DAG\n\nalg. Kosarajuâ€™s Algorithm for Finding Strongly Connected Components.\n\nIdea: after performing a DFS on graph G, the\n\nlet v be the component with the maximum post-time\nReverse edges of G to get GT.\nlet VCâ€‹ be a sync component of GT\n**v must be an element of some sync component VCâ€‹\n\n\nSee also: course\n\n\nDFS on G\nDFS on GT butâ€¦\n\nwhen you run out of reachable componentsâ€¦\ncut off the DFS tree; thatâ€™s a strongly connected component; then\ngo in the next maximum unvisited post-time vertex\n\n\n\nthm. (no cycles implies no zero-degree vertex) Let G be a directed graph. If every vertex of G has one or more outgoing edges, the graph is cyclic.\nProof. graph theory - Having No Directed Cycles Guarantees a Vertex of Zero Outdegree - Mathematics Stack Exchange "},"Disjoint-Set":{"title":"Disjoint Set","links":["Tree","Ackerman-Function"],"tags":["Computing/Data-Structures"],"content":"Data structure containing multiple sets.\n\nStored as array and Tree\nMake set: Initialize singleton (=single element) set for each element\nUnion set\n\nFind owner of both element\nMake tree with one as parent\n\n\nFind owner of elem\n\nPath compression: once you find something, directly attach all nodes of the path to that root\nâ‡’ with path compression, a sequence of n union-find operations areÎ˜(nâ‹…Î±(n)) where Î±(n) is the minimum t such that the Ackerman Function A(t,t)â‰¥n"},"Distance-&-Expectation":{"title":"Distance & Expectation","links":["Evolutionary-Game-Theory","Distance-&-Expectation","Credit","Fetishization","Trust-Escrow-System","Favors","Mirroring-(Sociability)","(Youtube)-Why-You-Are-Lonely-and-How-to-Make-Friends","Grice's-Maxims","Relationship-Bank-Account","Asking-&-Giving-Advice","Building-a-Friendship","Stagecraft","Multidependence","Self-Before-Others","Be-Nice","Social-Environment","Communication","(Youtube)-Why-No-One-Can-Understand-Us-Unless-We-Speak","Ask-vs.-Guess-Culture","Pride","Solipcism","Social-Organization"],"tags":["Sociability","Economics","Economics/Game-Theory"],"content":"Evolutionary Game Theory perspective:\n(def) DistancTrustn (=Degree of Trust) is a Fetishization of personal interaction that comes from Trust Escrow Systems. When we meet an unknown person (but one from a shared cultural TES), then we rely on the TES and we trust it, instead of the person themselves. However through sharing and caring, i.e. the exchange of Favors, and the human instinct of mirroring there develops (=fetishizes) a form of bond/trust (and people who feel such bonds are evolutionarily advantaged (source).\nExamples of D&amp;E in action:\n\nYour communication doesnâ€™t break down because you assume the Cooperative Principle\nYou eat food grown, cooked and served by a stranger\nYou lend the bank your money, and expect them to return it to you in the future\nYou live in big apartments with hundreds of total strangers\n\nTrust in Sociability Â§\n\n\n                  \n                  (Youtube) Why You Are Lonely and How to Make Friends\n                  \n                \n\n\n\nRelationship Bank Account\n\n\nAsking &amp; Giving Advice\n\n\nConcentric Circles\n\n(Chosen) Family / Close Friends / Partnerships\n\nExpectation: Listening &amp; telling me important life situations/emotions. Being fully vulnerable.\nVulnerability.\n\nImportant in moving a casual friend to a close friend.\nEmotionally nurtures you. When the other person returns it, it nurishes you.\nDeposit &amp; withdrawal in a Relationship Bank Account\n\n\n\n\nFriends / Family / Relatives\n\nFavors are important. Donâ€™t hesitate to give and receive favors.\n\n\nAcquaintances / Business Relationships\n\nManners are to everybody. Stagecraft works for everybody that interacts with you.\n\n\n\n\n\nSimilar levels of people can be used for similar roles in your life. Multidependence.\n\n\nWhere to Draw Lines. Personal Priority\n\nYouâ€™re not responsible for other peopleâ€™s emotions, unless they cross the â€œinner circle.â€œEven then, you shouldnâ€™t work on fixing otherâ€™s emotions directly.\n\nYouâ€™re also not responsible for other peopleâ€™s emotions.\n\n\nRespecting Opinions is unnecessary for those below a certain level of expertise in the topic (but donâ€™t show your disrespect).\nYou need not allow any invasion of privacy of any emotional topics. What you share is completely your prerogative.\nEvents. Go to events thatâ€¦\n\nI have no personal priorities not to attend ANDâ€¦\nAre clearly beneficial to a relationship OR social organization inclusion\n\n\n\n\n\nQ. Being Nice vs Being Stupid\n\n\nA. It depends. Onâ€¦\n\nIf your expectations match\nSocial Environment and culture\nCommunication beforehand\nHow nice the other person is\n\n\n\nSaying what you want\n\n(Youtube) Why No One Can Understand Us Unless We Speak\nAsk vs. Guess Culture. Because youâ€™re International, you need to especially speak out in America, and speak indirectly in Asia.\nWeâ€™re notoriously bad at understanding each other. When we have something we want, we need to communicate it. Say it out loud, in a clear, concise way without loaded emotion. Do this early on, before the frustrations pile and liger and rot.\nThough communication does not demand the other person to gratify our needs immediately it guarantees that our desires are communicated and will be a data point for the other personâ€™s future decision-making.\n\n\n\nTrust Within Organizations Â§\nIn Social Organizations, all the above apply, including\n\nI am not responsible for the organizationâ€™s well-being\nBeing Nice vs. Being stupid depends\n"},"Distribution-(Math)":{"title":"Distribution (Math)","links":["Moment-(Probability)","Joint-Distributions","Conditional-Distribution","Uniform-Distribution","Bernouilli-Distribution","Gamma-Distribution","Exponential-Distribution","Normal-Distribution","Student's-T-Distribution","Poisson-Distribution","Binomial-Distribution","Multinomial-Distribution","Hypergeometric-Distribution"],"tags":["Math/Probability"],"content":"def. A distribution gives comprehensive information about an experiment. A distribution can be a table showing the probabilities of all outcomes, or a probability density function.\n\n\n                  \n                  Moment Generating Function\n                  \n                \n\ndef. let Î© be an outcome space. All functions P(x) satisfying the following criteria are probability distributions.\nCriteria:\n\nP(âˆ…)=0 and P(Î©)=1\nFor all AâŠ†Î©, 0â‰¤P(A)â‰¤1\nIf A and B are disjoint then P(AâˆªB)=P(A)+P(B)\n\nThe 3rd condition can also be generalized for any distributions:\n\nIf A1â€‹,â€¦,Anâ€‹ are pairwise disjoint, then P(A1â€‹âˆªâ‹¯âˆªAnâ€‹)=P(A1â€‹)+â€¦+P(Anâ€‹).\n\nRemark. The distribution P(A)=#Î©#Aâ€‹ for countable, discrete outcome spaces follow the above axiom.\nFor a random variable Xâˆ¼f(h) where h is the height of some population, the probability that a&lt;X&lt;b is the shaded area:\n\nCalculated by: P(a&lt;X&lt;b)=âˆ«abâ€‹f(h)dh\nProbability Mass Function Â§\ndef. Probability Mass Function. For a discrete random variable X, the probability mass function is the function that gies the probability of all values of X.\npmf(x)=P(X=x)\nthm. Addition Rule for Random Variables. For a discrete random variable X, the following is true:\nP(aâ‰¤Xâ‰¤b)=k=aâˆ‘bâ€‹P(X=k)=k=aâˆ‘bâ€‹pmf(k)\nProbability Density Function Â§\ndef. Probility Density Function. fXâ€‹(x) is a probility density function of random variable X iff:\n\nâˆ€x,fXâ€‹(x)â‰¥0\nâˆ€x,âˆ«âˆ’âˆâˆâ€‹fXâ€‹(x)dx=1\nP(aâ‰¤Xâ‰¤b)=âˆ«abâ€‹fXâ€‹(x)dx\n\ndef. Cumilitave Density Function. FXâ€‹(t) is the cumulative density function of random variable X:\nFXâ€‹(t):=âˆ«âˆ’âˆtâ€‹fXâ€‹(x)dxâ‰¡P(Xâ‰¤t)\nif and only if:\n\nâˆ€t,FXâ€‹(t)â‰¥0\nFXâ€‹(t) is never decreasing over its domain\nlimtâ†’âˆâ€‹FXâ€‹(t)=1\n\n\n\n                  \n                  Info \n                  \n                \n\nRelationship between fXâ€‹(x) and FXâ€‹(x) is a derivate and antiderivative.\n\n\n&gt;fXâ€‹(x)derivativeanti-derivativeâ€‹FXâ€‹(x)&gt;\n\nNote that when you get FXâ€‹(x) you will get a integration constant C. You can get rid of this by using the property limtâ†’âˆâ€‹FXâ€‹(t)=1.\n\n\nJoint Distributions\nConditional Distribution\n\nList of Common Distributions Â§\n\nUniform Distribution\nBernouilli Distribution\nGamma Distribution\nExponential Distribution\nNormal Distribution\nStudentâ€™s T-Distribution\nPoisson Distribution\nBinomial Distribution\nMultinomial Distribution\nHypergeometric Distribution\n"},"Dividend-Discount-Model":{"title":"Dividend Discount Model","links":["Equity","Interest-Rate"],"tags":["Economics/Finance"],"content":"Dividend at the end of i-th period: Diâ€‹=(1+kgâ€‹)iD0â€‹\n\nAssumption in this model is that dividend will grow at rate g per year\n\nPresent value of Equity\n\nr is the required rate\nSnâ€‹ is the stock price when you sell it (end of period n)\nR:=1+krâ€‹1+kgâ€‹â€‹\n\nS0â€‹Sâˆâ€‹â€‹=(1+krâ€‹)D1â€‹â€‹+(1+krâ€‹)2D2â€‹â€‹+â‹¯+ynâ€‹Snâ€‹â€‹=D1â€‹(1+krâ€‹)+â‹¯=i=1âˆ‘âˆâ€‹(1+krâ€‹)i(1+kgâ€‹)iD0â€‹â€‹=D0â€‹i=1âˆ‘âˆâ€‹Ri=D0â€‹â‹…1âˆ’RRâ€‹=D0â€‹krâ€‹âˆ’kgâ€‹1+kgâ€‹â€‹=krâ€‹âˆ’kgâ€‹D1â€‹â€‹â€‹sellingÂ afterÂ periodÂ nholdingÂ stockÂ foreverwhenÂ r&gt;gâŸ¹R&lt;1Â (geometricÂ sum)Â DDMâ€‹â€‹"},"Document-Type-Definition":{"title":"Document Type Definition","links":["Extensible-Markup-Language"],"tags":["Computing/Data-Science"],"content":"A schema definition language for XML\nDeclaration\n\nElement &lt;&gt;\n\nElement Declaration Â§\n&lt;!ELEMENT book (title, author*, publisher?, year?, section*)&gt;\n\nthe element book must contain the following child elements, in order:\n\none title\nzero or more authors\nzero or one publisher\nzero or one year\nzero or more sections\n\n\n\n&lt;!ELEMENT p (#PCDATA | p | ul | dl | table | h1 | h2 | h3)* &gt;\n\nelement p may contain:\n\n{dtd}#PCDATA pure text only (no child elements)\np elements\nul elements\netc.\n* â†’ and zero or more repetitions of them.\n\n\n\nAttribute Declaration Â§\n&lt;!ATTLIST img\n   src    CDATA          #REQUIRED\n   id     ID             #IMPLIED\n   sort   CDATA          #FIXED &quot;true&quot;\n   print  (yes | no)     &quot;yes&quot;\n&gt;\n\nType isâ€¦\n\nID: is the unique id of that element.\n\n! ID is globally unique, regardless of attribute name, element name, etc.\nSee xml - DTD - uniqueness of ID attributes - Stack Overflow\n\n\nIDREF: reference of some id\nCDATA: any string\n(val1|â€¦): can only be either of these values.\n\n\nValue isâ€¦\n\n#REQUIRED: necessary\n#IMPLIED: optional\n#FIXED: constant\nâ‡’ â€œFinal column &quot;default&quot;: default value of that attribute\n\n\n"},"Dominant-Strategy-Equilibrium":{"title":"Dominant Strategy Equilibrium","links":[],"tags":["Economics/Game-Theory"],"content":"Strategy A is dominant over strategy B iff all payoffs regardless of otherâ€™s actions.\n\nSometimes no strategy might be dominant\n"},"Dummy-Variables":{"title":"Dummy Variables","links":["Multivariate-Ordinary-Least-Squares-Regression"],"tags":["Math/Statistics"],"content":"Motivation. A treatment vs. Non-treatment group in medicine. A dummy variable in this case would be:\nTreatmentiâ€‹={10â€‹ifÂ treatedÂ groupifÂ controlÂ groupâ€‹\nAnd regression:\nYiâ€‹=Î²0â€‹+Î²1â€‹Treatmentiâ€‹+Ïµiâ€‹\n\nFitted value:\n\nY^iâ€‹=Î²^â€‹0â€‹ if Treatmentiâ€‹=0 â† â€œaverage of treatment groupâ€\nY^iâ€‹=Î²^â€‹0â€‹+Î²^â€‹1â€‹ if Treatmentiâ€‹=1 â† â€œaverage of control groupâ€\nThis is equivalent to performing a Difference of Means Test, which measures the difference of the mean of each group.\n\nThe difference of means is Î²^â€‹1â€‹ (=the treatment effect) \n\n\n\n\n\n\nMultiplicative Dummy Variables Â§\nMotivation. Gender pay gap is not an â€œadditiveâ€ factor but a â€œmultiplicativeâ€ factor, as it men are rewarded more for per unit experience than women. In this case we can model:\nSalaryiâ€‹=Î²0â€‹+Î²1â€‹Experienceiâ€‹+Â AdditiveÂ dummyÂ Î²2â€‹isMaleâ€‹â€‹+Â MultiplicativeÂ dummyÂ Î²3â€‹isMaleiâ€‹Ã—Experienceâ€‹â€‹+Ïµiâ€‹\nRegression Plot: \n\nÎ²1â€‹^â€‹ is the slope of non-treament group (=women)\nÎ²1â€‹^â€‹+Î²3â€‹^â€‹ is the slope of the treatment group (=men)\nTherefore Graph shape is:\n\nÎ²1â€‹^â€‹ determines the slope (upwards/downwards sloping)\nÎ²3â€‹^â€‹ will increase or decrease the magnitude of the slope in the treatment (men) group depending on its sign\n\n\n\n\n! When using multiplicative dummy regression, in order to test for statistical significance of isMale you must test additive and multiplicative term parameters together, i.e. using F-statistics to test H0â€‹:Î²2â€‹^â€‹=Î²3â€‹^â€‹=0\n\nThe total effect of isMale is Î²2â€‹+Î²3â€‹, and the statistical significance is tested by H0â€‹:Î²2â€‹^â€‹+Î²3â€‹^â€‹=0\nIn general, if just one of either Î²2â€‹^â€‹ or Î²3â€‹^â€‹ is individually significant the total effect is significant\n\n\n\n\n\n\nApplications of Dummy Variables Â§\nDummy Independent Variables in Multivariate OLS Â§\nModel:\nYiâ€‹=Î²0â€‹+Î²1â€‹Dummyiâ€‹+Î²2â€‹Xiâ€‹+Ïµiâ€‹\nâ†’ Î²1â€‹ will tell us the difference between the groups Dummy=1 and Dummy=0\nExample. How much does playing in home field create an advantage for the home team?\nGoalÂ Differentialiâ€‹=Î²0â€‹+Î²1â€‹isHomeiâ€‹+Î²2â€‹OpponentÂ Qualityiâ€‹+Ïµ\n\nAdding OpponentÂ Quality will control for opponent quality\nRegression Table \nRegression Plot \nAt OpponentÂ Quality=0, the difference in means in Î²^â€‹1â€‹\nÎ²^â€‹2â€‹ is irrelevant for this difference of means test. But if you want, itâ€™s the slope between opponent quality and goal differential\n\nCategorical to Dummy Variables. Â§\nMotivation. This is useful when you have categories like â€œ1 indicates a person is from the Northeast, 2 from the Midwest, 3 from the South, and 4 from the West,â€ and you want a difference of means test for all of them combined. You canâ€™t simply use the 1,2,3,4 as values because it â€œlocationâ€ is not a quantity but a category. You use binary dummy variables instead:\nWagesiâ€‹=Î²0â€‹+Î²1â€‹isNE+Î²2â€‹isMW+Î²3â€‹isSouth+Ïµ\n\nWe donâ€™t need a isWest because false on all three dummy variables indicates obviously that that datapoint is from the west. (i.e. avoid the â€œdummy perfect multicollinearity trapâ€ where e.g. isMale is perfectly negatively correlated with isFemale).\n\ni.e.g there cannot be any two categorical dummy variables which are both one.\n\n\nInterpretation, e.g. for Î²1â€‹: the unit rise in wages by moving from reference (West) to NE.\nRegression Table: \n\nObserve that all columns are symmetric. The model we used above is column (a), but since there are many other ways to define categories as dummy variables, we are showing that they all have the same result.\n&amp; Each row represents â€œhow better it is from the referenceâ€; in (a), â€œhow better is it from the westâ€.\n\n\n\nWe now have an example from the textbook that incorporates these.\nExample. Taxation vs Male suffrage, Year, War mobilization and location\nTax=Î²0â€‹+Î²1â€‹mSuffrageiâ€‹+Î²2â€‹Yeariâ€‹+Î²3â€‹Wariâ€‹+Â LocationÂ DummiesÂ Î²4â€‹isEuropeiâ€‹+Î²5â€‹isAsia+Î²6â€‹isOceaniaiâ€‹â€‹â€‹\n\nRegression Table: \n\nâ€œBivariateâ€ column is the stupid model.\n(a) only adds the year. Year is significant endogenous factor\n(b) adds war. War is also a significant endogenous factor\n(c) includes location dummies, with North America as the reference (therefore model doesnâ€™t include isNA).\n\n\n"},"Dynamic-Programming":{"title":"Dynamic Programming","links":["Knapsack-Problem","Path-Alignment","Matrix-Chain-Multiplication","Longest-Palindromic-Substring","tree","Vertex-Cover-and-Minimum-Independent-Set"],"tags":["Computing/Algorithms"],"content":"\n\n                  \n                  The name &quot;Dynamic Programming&quot; is a misnomer. \n                  \n                \n\n\n\n                  \n                  Motto of Dynamic Programming \n                  \n                \n\n\nDynamic Programming (DP) is a algorithm design paradigm that includes the following features:\n\nAlgorithms are recursive\nThere are overlapping recursive subproblems\nMemoization can be used to reduce re-solving overlapping subproblems\nYou can also write an iterative solution which can be easier to analyze\n\n\n\n                  \n                  Think of DP as a &quot;filling in a table&quot; problem \n                  \n                \n\nTo devise a DP solution to a problem, you must\n\nUnderstand which subproblems overlap\n\nRecursion trees help in identifying overlap\n\n\nUnderstand the subproblem dependencies (which subproblems to solve first)\n\nHow to break ties (e.g. minimum or maximum of two dependencies)\n\n\nChoose which order to iterate\n\nIterate from i=0..n,j=0..n\n\nKnapsack Problem, Path Alignment\n\n\nIterate for increasing gap=jâˆ’i from gap=0..n\n\nMatrix Chain Multiplication, Longest Palindromic Substring\n\n\nIterate on all notes of a tree, where the data is stored in the tree node itself.\n\nVertex Cover and Minimum Independent Set\n\n\n\n\n"},"EBITDA-Multiple":{"title":"EBITDA Multiple","links":[],"tags":["Economics/Finance"],"content":"def. Enterprise value. The amout of money you have to pay to buy off the company, including its financial oblications (net debt)\nEnterpriseÂ ValueÂ =Â EquityÂ ValueÂ +Â NetÂ Debt\nwhere NetÂ DebtÂ =Â SR,LRÂ debtÂ +Â min.inst.pref.stockâˆ’cash\n\nNet Debt &gt; 0 when firm has more debt\nNet Debt &lt; 0 when firm has more cash\n\ndef. EBITDA Multiple.\nEBITDAÂ Multiple=EBITDAEVâ€‹=ProfitValueâ€‹\nâ‡’ Think: For two firmsâ€¦\n\nâ€¦if the market values one firm higher [=EV is higher] than another firm,\nâ€¦even if their profit is relatively smaller [=relative EBITDA], it implies that:\nâ€¦the market thinks the firm has growth potential.\n\nThe EBITDA Multiple is a good measure of how good the operations are of a company becauseâ€¦\n\nEBITDA doesnâ€™t deduct financing costs.\nEBITDA can compare companies in similar industries about how good their operations are.\n"},"ECON-205-Intermediate-Microeconomics-II":{"title":"ECON 205 Intermediate Microeconomics II","links":["Monotonic-Transformation","Lagrangian-Optimization","Rationality-(Economics)","Utility-Function","Budget-Lines","Utility-Maximization","Utility-Maximization-with-Endowments","Uncompensated-Demand-curve","Indirect-Utility-Function","Expenditure-Minimization","Marginal-Willingness-to-Pay","Expenditure-Function","Map-of-Microeconomic-Optimization","Profit-Maximization","Input-Demand-and-Output-Supply","Profit-Function","Cost-Minimization","Monopoly","Microeconomic-Market-Equilibrium","Edgeworth-Box","Pareto-Efficiency","Compensating-and-Equivalent-Variation","Game-Theory","Dominant-Strategy-Equilibrium","Equilibria-in-Game-Theory","Oligopoly","Bertrand-Price-Competition","Cornout-Quantity-Competition"],"tags":["Courses"],"content":"Background Knowledge Â§\n\nMonotonic Transformation\nLagrangian Optimization\nRational Taste\n\nConsumer Choice Theory Â§\n\nUtility Function\nBudget Constraints\nUtility Maximization\n\nUtility Maximization with Endowments\nOrdinary Demand\nIndirect Utility Function\n\n\nExpenditure Minimization\n\nHicksian Demand Curve\nExpenditure Function\n\n\n&amp; See: Map of Microeconomic Optimization\n\nTheory of the Firm Â§\n\nProfit Maximization\n\nInput Demand and Output Supply\nProfit Function\n\n\nCost Minimization\n\nConstrained Constrainted Input Demand\n\n\nMonopoly\n\nEquilibrium Theory Â§\n\nMicroeconomic Market Equilibrium\nTrade between individuals\n\nEdgeworth Box\nPareto Efficiency\nCompensating and Equivalent Variation\n\n\n\nGame Theory Â§\n\nGame Theory\n\nDominant Strategy Equilibrium\nEquilibria in Game Theory\nSubgame Perfect Nash Equilibirum\nRepeated Game\n\n\nOligopoly Games\n\nBertrand Price Competition\nCornout Quantity Competition\n\n\n"},"Econ-201-Intermediate-Microeconomics-I":{"title":"Econ 201 Intermediate Microeconomics I","links":["Budget-Lines","Utility-Function","Lagrangian-Optimization","Income-Effect-(IE)","Substitution-Effect-(SE)","Types-of-Demand-Curves-(MicroEcon)","Production-Function","Profit-Maximization","Price-Controls","International-Trade","Game-Theory","Monopoly","Bertrand-Price-Competition","Monopolistic-Competition","Cartels-and-Collusion","Types-of-Goods-(Economics)"],"tags":["Courses"],"content":"Consumer Theory Â§\n\nBudget Lines\nIndifference Curve\nLagrangian Optimization\nIncome Effect (IE)\nSubstitution Effect (SE)\nTypes of Demand Curves (MicroEcon)\n\nTheory of the Firm Â§\n\nProduction Function\nProfit Maximization\n\nMarket Distortion Â§\n\nPrice Controls\nInternational Trade\n\nMarket Power Â§\n\nGame Theory\nMonopoly\nBertrand Price Competition\nMonopolistic Competition\nCartels and Collusion\nPublic Good\n"},"Econ-204-Econometrics":{"title":"Econ 204 Econometrics","links":["Econometrics","Bivariate-Ordinary-Least-Squares-Regression","Confidence-Intervals-and-Hypothesis-Testing-in-OLS-Linear-Regression","Multivariate-Ordinary-Least-Squares-Regression","Omitted-Variables","Post-Treatment-Variable","Nonlinear-Models","Dummy-Variables","Fixed-Effects-Model-for-Panel-Data","Difference-In-Difference","Two-Stage-Lease-Squares-Regression","Simultaneous-Equation-Model","Controlled-Experiments","Natural-Experiments","Regression-Discontinuity","tags/task","Homework-5"],"tags":["Courses","task"],"content":"\n\n                  \n                  Quote \n                  \n                \nCorrelation doesnâ€™t imply Causation\n\n\nEconometrics\nBivariate Ordinary Least Squares Regression\n\nConfidence Intervals and Hypothesis Testing in OLS Linear Regression\nProblem: Autocorrelation? â†’ Lagged Variables\nProblem: Heteroskedatisticy? â†’ robust standard errors\n\n\n\nDifferent Models Â§\n\nMultivariate Ordinary Least Squares Regression\n\nProblem: Omitted Variables â†’ Include the variables\nProblem: Post-Treatment Variable\n\nMediator Bias â†’ Your choice on what you want\nConfounder Bias â†’ Your choice on what you want\n\n\n\n\nNonlinear Models\n\nâ†’ Choose the best one\n\n\n\nTechniques Â§\n\nDummy Variables\n\nMultiplicative Dummies\nCategories\nDifference of Means test\n\n\nFixed Effects Model for Panel Data\n\nProblem: Endogeneity due to time-dependent or panel (=group)-dependent factors\nLSDV approach\nDe-meaned approach\nDifference In Difference\n\n\nTwo-Stage Lease Squares Regression and Instrumental Variables\n\nSimultaneous Equation Model\n\n\n\nDesigning and Analyzing Experiments Â§\n\nControlled Experiments\n\nNatural Experiments\n\n\nRegression Discontinuity\n\nEndogeneity fight Summary:\n\nSoak-up\n\nOther causality? â†’ Multivariate Ordinary Least Squares Regression\nMediator/Confounder? â†’ Post-Treatment Variable\nTime/Group-dependent? â†’ Fixed Effects Model for Panel Data\n\n\nIsolate/Create the exogenous variation\n\nIsolation? â†’ Two-Stage Lease Squares Regression and IV\nRandomization? â†’ Controlled Experiments\n\n\nRegression Discontinuity\n\nStudy Â§\n\nFormal Notes on chapters:\n\n #task 204 notes Ch.8 Panel Data, DiD\n #task 204 notes Ch.9 Instrumental Vars\n #task 204 notes Ch.10 Experiments\n #task 204 notes Ch.10 Discontinuity\n\n\nReading chapters\n\n #task 204 read Ch.10 Experiments\n #task 204 read Ch.11 Discontinuity\n\n\nAssignment &amp; examples dos\n\n #task 204 assign Ch.6\n #task 204 assign Ch.7\n #task 204 assign Ch.8\n #task 204 assign Ch.9\n #task 204 assign Ch.10\n #task 204 assign Ch.11\n\n\n #task mock exam 204\nQuestions\nSample test Q12. For Q11â€™s dataset, doesnâ€™t log(GHR) cause issues with\nOmitted vs Post-Treament: Q20:\n\neconometrics - Difference between the concept of omitted variable bias in econ and epidemiology/social sciences (Elwert and Winship) - Cross Validated\ncausality - Difference Omitted Variable Bias and Confounding? - Cross Validated\n\n\nSample test Q22. What does lagged mean?\nTips\nUnderstand the data first and what the model is trying to prove\nDonâ€™t be lazy. Write stuff down and calculate separately.\n\nHomework 5"},"Econ-210-Macroeconomics":{"title":"Econ 210 Macroeconomics","links":["Macroeconomics","Growth-Rate-Calculations","Gross-Domestic-Product","Agents-of-the-Macro-Economy","Macroeconomic-Market-Equilibrium","Laffer-Curve","Beveridge-Curve","Homogenous-Function"],"tags":["Courses"],"content":"\nMacroeconomics\nGrowth Rate Calculations\nGDP\nAgents of the Macro Economy\nMacroeconomic Market Equilibrium\nLaffer Curve\nBeveridge Curve\nHomogenous Degrees\n"},"Econ-361-Distributive-Justice":{"title":"Econ 361 Distributive Justice","links":["assets/361-Midterm---Tit-for-Tat,-Footbinding.pdf","assets/361-Final---Game-Theory,-Financial-Markets,-Distributive-Justice.pdf","Robert-Axelrod","Robert-Frank","Milton-Friedman","assets/Week-1---Nash-Equilibria.pdf","assets/Week-2---Axelrod.pdf","assets/Week-3---Robert-Frank.pdf","assets/Week-4---Mackie-and-Footbinding.pdf","assets/Week-5---Hayek-and-Price-Mechanism.pdf","assets/Week-6---Monopoly.pdf","Elinor-Ostrom","assets/Week-7---Hampton-and-Public-Goods.pdf","assets/Week-8---Ostrom-and-Resource-Regimes.pdf","Michael-Munger","Joseph-Stiglitz","Thomas-Picketty","assets/Week-9---Munger-and-Crony-Capitalism.pdf","assets/Week-10---Stiglitz-and-Inequality-in-the-U.S..pdf","assets/Week-11---Efficiency-vs.-Growth.pdf","Amartya-Sen","John-Stuart-Mill","John-Rawls","Robert-Nozick","assets/Week-12---J.S.-Mill-and-Utilitarianism.pdf","assets/Week-13---Rawls-and-Maximin-Principle.pdf"],"tags":["Courses"],"content":"\n\n                  \n                  Remember, there are still people starving as we speak. \n                  \n                \n\nSubmissions Â§\n\n361 Midterm - Tit-for-Tat, Footbinding.pdf\n361 Final - Game Theory, Financial Markets, Distributive Justice.pdf\n\nApplying Game Theory Â§\n\nRobert Axelrod - The Evolution of Cooperation\nRobert Frank - Passions within Reason\nJ.L. Mackie - Ending Foot Binding and Infibulation: A Conventional Account\nFriedrich Hayek - The Social Uses of Information\nMichael Rosenberg - Pure Theory of Labor Market Monopsony\nMilton Friedman - Externality\nWriting Assignments\n\nWeek 1 - Nash Equilibria.pdf\nWeek 2 - Axelrod.pdf\nWeek 3 - Robert Frank.pdf\nWeek 4 - Mackie and Footbinding.pdf\nWeek 5 - Hayek and Price Mechanism.pdf\nWeek 6 - Monopoly.pdf\n\n\n\nMarket Failures Â§\n\nJonathan Anomaly - Public Goods and Government Action\nJean Hampton - Free Rider Problems in the Production of Collective Goods\nElinor Ostrom - Collective Action and the Evolution of Social Norms\nRobert Frank - Darwinian Economy, Chapters 1-3\nWriting Assignments\n\nWeek 7 - Hampton and Public Goods.pdf\nWeek 8 - Ostrom and Resource Regimes.pdf\n\n\n\nMeasuring Amount of Market Failure Â§\n\nMichael Munger and Mario Villarreal-Diaz - The Road to Crony Capitalism, Independent Review\nJoseph Stiglitz - The Price of Inequality, Chapter 2: Rent Seeking and Chapter 3\nThomas Picketty\n\nRobert D. Kirkby - Summary of Picketty\nPicketty Explained Blog - Summary of Capital in the Twenty-First Century\n\n\nWriting Assignments\n\nWeek 9 - Munger and Crony Capitalism.pdf\nWeek 10 - Stiglitz and Inequality in the U.S..pdf\nWeek 11 - Efficiency vs. Growth.pdf\n\n\n\nSolutions to Market Failure Â§\n\nAmartya Sen - Equality of What?\nJohn Stuart Mill - Utilitarianism, Chapter 1, Chapter 2 (pp. 4-11), Chapters 3, 4\nJohn Rawls - A Theory of Justice\nRobert Nozick - Anarchy, State, and Utopia\nDerek Parfit - Equality and Priority\nWriting Assignment\n\nWeek 12 - J.S. Mill and Utilitarianism.pdf\nWeek 13 - Rawls and Maximin Principle.pdf\n\n\n"},"Econ-371-Finance":{"title":"Econ 371 Finance","links":["Present-Value-Calculations","Bonds-(Finance)","Equity","Comparable-Company-(Comps)-Analysis","Portfolio-Theory","CAPM-Model","Futures","Short-selling","Trade-Through","Interest-Rate","Derivatives-(Finance)","Contagion-(Finance)"],"tags":["Courses"],"content":"\nPresent Value Calculations\nBonds (Finance)\nEquity\nComparable Company (Comps) Analysis\nPortfolio Theory\nCAPM Model\nFutures\nGlossary\n\nShort-selling\nTrade-Through\nInterest Rate\nDerivatives (Finance)\nContagion (Finance)\n\n\n"},"Econometrics":{"title":"Econometrics","links":["Correlation"],"tags":["Economics"],"content":"\nEstablishing causality\n\ndoes â€œpolicy/behavior/program â†’ outcomeâ€?\nXâ†’Y?\n\n\nChallenges\n\nIs it random noise?\n\nRemoving outliers\n\n\nAre there exogenous factors?\n\n\n\nX is endogenous if X correlates with Ïµ (error)â€”non-causal, lurking variable\n\n\n\n\nX is exogenous if X doesnâ€™t correlation with Ïµâ€”likely causal\n\n\n\n\n\n\nRegression Analysis: Yiâ€‹=Î²0â€‹+Î²1â€‹Xiâ€‹+Ïµiâ€‹\n\nÎ²0â€‹: intercept. Less interesting\nÎ²1â€‹: slope. More Interesting\nX: independent variable\nY: dependeng variable\n\n\n! be carefulâ€¦\n\nCorrelation î€ = Causation\nA higher slope doesnâ€™t mean higher correlation; a higher Correlation coefficient (Ï=ÏƒXâ€‹ÏƒYâ€‹ÏƒXYâ€‹â€‹) does mean higher correlation.\nStatistical Significance î€ = Real-life Effects\n\n\n"},"Economic-Democracy":{"title":"Economic Democracy","links":["(Book)-The-Case-for-Economic-Democracy","(Economist)-Andrew-Cumbers"],"tags":["Economics","Philosophy/Political-Philosophy","index"],"content":"\n(Book) The Case for Economic Democracy\n(Economist) Andrew Cumbers\n(DevonThink) Economic Democracy and Labor Productivity\n"},"Economics-Course-Requirements-(4-or-3-left)":{"title":"Economics Course Requirements (4 or 3 left)","links":["ECON-205-Intermediate-Microeconomics-II"],"tags":["Courses"],"content":"B.S. in Economics, Finance Concentration\nFrequently Asked Questions: New Econometrics Sequence\nCourses\nMath Requirement :luc_check_circle: Â§\nCompletion of a higher-level math course (MATH 212 or higher) demonstrates proficiency in lower-level math courses; therefore, lower-level requirements may be waived for students who have successfully completed higher-level math courses.\n\nMATH 111LÂ Laboratory Calculus IÂ ORÂ MATH 105LÂ Laboratory Calculus and Functions IÂ ANDÂ MATH 106LÂ Laboratory Calculus Functions II\nMATH 122Â Introductory Calculus IIÂ ORÂ MATH 112LÂ Laboratory Calculus IIÂ ORÂ MATH 122LÂ Introductory Calculus II with Applications\nMATH 202Â Multivariable Calculus for Economics orÂ MATH 212Â Multivariable CalculusÂ ORÂ MATH 222Â Advanced Multivariable CalculusÂ ORÂ any higher-level math course with MATH 212 as prerequisite.\n\nCore Economics Courses :luc_check_circle: Â§\n\nECON 101D Economics Principles\n\nSKIPPED, Grades transferred from AP\n\n\nEconometrics (seeÂ FAQsÂ for more information about this new sequence)\n\nSKIPPED: ECON 104DÂ Statistical Foundations of Econometrics and Data Science\nECON 204DÂ Econometrics Data Science (must be taken before senior year)\nIll be taking STAT 230 â†’ STAT 432 â†’ Econ 204D\n\n\nMicroeconomics\n\nECON 201DÂ Intermediate Microeconomics I\n==ECON 205 Intermediate Microeconomics IID==Â Intermediate Microeconomics II [2]\n\n\nMacroeconomics\n\nECON 210DÂ Intermediate Macroeconomics\n\n\n\nElectives (2 or 3 left) Â§\nNo Concentration (1 left) Â§\n\nFive Economics General Electives at the 300or 400-level, of which one must be a 300level and one must be a 400-level\n\nECON 361 PPE Distributive Justice\nECON 372 Asset &amp; Risk\nECON 673 Mathematical Finance\nECON 565 Algorithmic Game Theory\nECON 386 PPE Capstone?\n(ECON 500-549 may only be counted toward the major with approval from the director of undergraduate studies))\n\n\n\nGeneral Restrictions Â§\n\nA maximum of two economics transfer credits will be accepted toward the major. This applied to courses taken in the United States and to study abroad courses. One exception if the London School of Economics full-year (fall and spring) program, from which a maximum of four courses may be counted toward the major.\n\nEffective for courses taken after the Spring 2018 semester, we will no longer accept transfer credits for the following courses: ECON 204, ECON 205, ECON 208, and ECON 210.Â Courses that are part of â€œDuke In â€¦â€ programs count as Duke courses and not transfer courses (please note that a few â€œDuke In â€¦â€ programs are hybrids in which some courses count as Duke courses but students may also take transfer courses at the foreign institution). Also, inter-institutional courses are not considered transfer courses, nor are pre-matriculation credits. If you have questions about whether a course taken away from Duke would be considered a transfer course, please consult the director of undergraduate studiesÂ or associate director of undergraduate studiesÂ before taking the course.\n\n\nDukeHub enforces prerequisites for many Economics courses.\n1Â Students with credit for both AP Macro and AP Micro (4 or higher) may receive credit for ECON 101. To receive credit for ECON 101 using an international standardized exam, please visit theÂ Trinity College policyÂ for qualifying scores.\n2Â Prerequisites are enforced for ECON 205D. They include ECON 201, andÂ eitherÂ MATH 202Â orÂ MATH 212Â orÂ MATH 222.\n3Â Students are limited to counting a maximum of TWO Fintech courses toward the finance concentration requirements.\n"},"Edgeworth-Box":{"title":"Edgeworth Box","links":["Pareto-Efficiency","Uncompensated-Demand-curve","Budget-Lines"],"tags":["Economics/Game-Theory"],"content":"\nContract Curve is the set of pareto efficient points in the edgeworth box.\n\nExample. The black curve in (b) is the contract curve. \nThe gradient of the two curves must be equal in every point of the contract curve.\nThe Core is the set of Pareto efficient allocations that make both parties better off than their endowments. (The highlighted section inside the green is the core.) \n\n\nEquilibrium is when the exchange rate of goods (i.e. the price ratio) is set in such a way that trade occurs and there is market clearance (i.e. Qdemandâ€‹=Qsupplyâ€‹).\n\nIt must be pareto efficient.\nExample of a Disequilibirum. Here. price is set to 1Â orange=1Â banana. Blue player will move E1â€‹â†’A, and red E2â€‹â†’B. But those two points do not meet.\nExample of Equilibirum. Here, price is set to 1.5Â orange=1Â banana. Blue moves Eâ†’C, and Pink moves Eâ†’C and therefore demand for bananas is equal to supply of bananas, and demand for oranges are equal to supply of oranges.\nSolving for the equilibirum:\n\nGet the Ordinary Demand for good x1â€‹ from both parties.\n\nin this case, the Budget Constraint is I=p1â€‹e1â€‹+p2â€‹e2â€‹\n\n\nSet the equilibirum condition Qdemandâ€‹=Qsupplyâ€‹\n\nx1Aâ€‹+x1Bâ€‹=e1Aâ€‹+e1Bâ€‹\nDemandÂ byÂ A+DemandÂ byÂ B=EndowmentÂ ofÂ A+EndowmentÂ ofÂ B\n\n\nSolving this for the price ratio p2â€‹p1â€‹â€‹ will yield the relative price (=price that will lead to a trade that results in an equilibirum).\n\n\n\n\n"},"Efficiency-(Statistics)":{"title":"Efficiency (Statistics)","links":["Cramer-Rao-Lower-Bound-(CRLB)"],"tags":["Math/Statistics"],"content":"Cramer-Rao Lower Bound (CRLB)"},"Efficient-Market-Hypothesis":{"title":"Efficient Market Hypothesis","links":[],"tags":["Economics/Finance"],"content":""},"Egotistic-Altruism":{"title":"Egotistic Altruism","links":["Be-Nice","Self-Before-Others"],"tags":["Economics/Game-Theory","Sociability"],"content":"\n\n                  \n                  Find a selfish reason to be mindful of others. \n                  \n                \n\n\nDonâ€™t trust yourself to be nice just out of your own benefit; it should also benefit you.\nPersonal Priority. You can only take care of others when you have taken care of yourself\n"},"Elasticity-of-Substitution":{"title":"Elasticity of Substitution","links":["Rationality-(Economics)","Marginal-Rate-of-Substitution-(MRS)","Utility-Function","Cobb-Douglas-Utility-(Two-Goods)"],"tags":["Economics/Micro-Economics"],"content":"\n\n                  \n                  tastes.)\n                  \n                \n\ndef. Elasticity of Substitution. The EoS of good x1â€‹ of x2â€‹ asks â€œhow much % x2â€‹ are you willing to give up to get one more % of x1â€‹â€œ?\nÏƒ2,1â€‹:=%Â changeÂ inÂ x2%Â changeÂ inÂ x1â€‹=âˆ£%Î”MRS1,2â€‹%Î”x1â€‹x2â€‹â€‹â€‹âˆ£â‰¡dlnâˆ£MRS1,2â€‹âˆ£dlnx1â€‹x2â€‹â€‹â€‹\nâ‡’ MRS is the Marginal Rate of Substitution (MRS) of good\nHigher elasticity of substitution (EoS) means the following things:\n\nUtility Function has less curvature\nx1â€‹ and x2â€‹ are better substitutes\n\nTaste and elasticity\n\nHomothetic tastes when MRS depends on x1â€‹x2â€‹â€‹ alone:\n\ni.e. MRS(tx1â€‹,tx2â€‹)=tkMRS(x1â€‹,x2â€‹)\n\n\n\nElasticity &amp; Indifference Curve Shapes Â§\n\nCobb-Douglas EOS Â§\n\nu(x1â€‹,x2â€‹)=x1Î±â€‹x21âˆ’Î±â€‹\nMRS=âˆ’1âˆ’Î±Î±â€‹â‹…x1â€‹x2â€‹â€‹\n\nâ‡’ Then we observe:\nâ€‹x1â€‹x2â€‹â€‹=MRS1,2â€‹Î±1âˆ’Î±â€‹âŸ¹dlnâˆ£MRSâˆ£dâ€‹lnx2â€‹x1â€‹â€‹=dlnâˆ£MRSâˆ£dâ€‹(lnMRS+ln1âˆ’Î±Î±â€‹)âŸ¹dlnâˆ£MRSâˆ£dlnx2â€‹x1â€‹â€‹â€‹=1Â =Ïƒ2,1â€‹â€‹â€‹\nâ‡’ We also can see that it is homogenous and thus homothetic:"},"Elinor-Ostrom":{"title":"Elinor Ostrom","links":[],"tags":["People"],"content":""},"Emergent-Phenomena":{"title":"Emergent Phenomena","links":[],"tags":["Philosophy"],"content":"\n\n                  \n                  E pluribus unum\n                  \n                \n"},"English-190FS-Renaissance-Literature":{"title":"English 190FS Renaissance Literature","links":["assets/190---Analysis-on-Doctor-Faustus.pdf"],"tags":["Courses"],"content":"Writing Assignments Â§\n\n190 - Analysis on Doctor Faustus.pdf\n\nBook Readings Â§\n\nShakespeare, The Merchant of Venice\nChristopher Marlowe, Doctor Faustus\nBen Jonson, The Alchemist\nMargaret Cavendish, The Blazing World\nGirolamo Cardano: The Book on Games of Chance\n\nAdditional Readings Â§\n\nColumbus, The Four Voyages\nJournals and Other Documents on the Life and Voyages of Christopher Columbus\nGeorge Sandy, Relation of a Journey (selections)\nGalileo Galilei, Dialogue Concerning the Two Chief World Systems (selections)\n"},"Entity-Relationship-Model":{"title":"Entity-Relationship Model","links":["Relational-Algebra"],"tags":["Computing/Data-Science"],"content":"\n\n                  \n                  Abstract \n                  \n                \nWeâ€™re trying to model real-world data subject to real-world constraints. The entity relationship model is a simple method to do so.\nDesign goals:\n\nRedundancy is bad\nAttributes cannot be lists!\nTrade-off between capturing more constrainsts vs. simplicity\n\nâ†’ Common Sense &gt; capturing all constraints\n\n\nDonâ€™t introduce nonexistent constraints\n\n\nComponents of an E/R Model\n\nEntityâ€”with attributes\n\nKey attributes are underlined\nâ‡’ This is NOT like database keys, in the case that weak entities require both its keys and its supporting entityâ€™s keys to identify it uniquely.\n\n\nRelationshipâ€”with attributes\n\nRelationship attributes are not the same as entity attributes: they cannot be duplicated.\ne.g. StopsAt cannot have multiple times for each Train-Station pair: \n\n\n\nComplex Relationships Â§\n(DevonThink) 3. E/R Design\nMultiplicity Â§\n\nMany-to-Many: Most types of relations \nMany-to-One\n\nhalf-circle arrow: exactly one \nNormal arrow: one or zero\n\n\nOne-to-One\n\nRoles in a Relationship Â§\n\nif youâ€™re taking two items from the same entity, the roles need to be clarified. \n\nN-ary Relationships Â§\n\none-to-one (=binary) relationships is not the norm.\nyou can break it up into many relationshipsâ€¦\n\nâ€¦but itâ€™s hard and may require new relations, entities, etc.\n\n\ne.g. a isMemberOf relationship can have multiple members, but only (zero or) one initiator for a groupâ€”member pair\n\n\nWeak Entity &amp; Supporting Relationships (=Heirarchical relationships) Â§\n\nmore data is needed to uniquely identify the thing\ne.g. a room number in a building needs the building identification to uniquely identify it\n\n\nISA Relationship (Subclassing) Â§\n\nliterally â€œA is-a Bâ€ relationship\nInherits the attributes (with the key), relationships\n\n\nTranslating into Relational Model Â§\n(DevonThink) 4. E/R Translation\n\nEntity Set â†’ Table. Train,LocalTrain, etc.\n\nAttribute â†’ Column of Table. number, engineer\nKey attribute â†’ Key number\n\n\nRelationship â†’ Table of keys (on both entities) and attributes if necessary.\nWeak Entity Set â†’ Table, but including all the keys up the hierarchy\n\nExpressTrainStopsAtStation includes keys of ExpressTrains\nYou need the keys of all supporting entities to uniquely identify it\n\n\nIsA Relationship â†’ Table, but we can choose how to translate it:\n\nEntity-in-all-superclass-and-specific-class\n\nScattered List\n\n\nEntity-only-in-specific-class\n\nScattered List\n\n\nAll-entities-in-one-table\n\nGoogle BigTableâ€™s approach\nNULL when a subclassâ€™s attribute doesnâ€™t apply\nResults in a sparse table (we have good ways to store this these days!)\n\n\n\n\n\n\n\n                  \n                  Full example\n                  \n                \n\n"},"Equilibria-in-Game-Theory":{"title":"Equilibria in Game Theory","links":["Strategy","Sperner's-Lemma","Brouwer's-Fixed-Point-Theorem","Linear-Programming","Integer-Linear-Programming","Signaling-Game"],"tags":["Economics/Game-Theory"],"content":"Intuition. Hierarchy of Games in game theory.\n\nPure Strategy Â§\ndef. Pure Strategy Nash Equilibrium is a set of strategies (one for each player) which is the best response strategy of each otherâ€™s move; i.e. you canâ€™t deviate without destabilizing the equilibrium.\nâˆ€iâˆˆPlayersâ€‹,Â siâ€‹=argminsâˆˆSiâ€‹â€‹c1â€‹(s,sâˆ’iâ€‹â€‹)\nwhere:\n\nsâˆ’iâ€‹: strategies of all other players (excluding i-th player)\ns: strategy for i-th player\nS: strategy set for i-th player\nciâ€‹(s): cost function for i-th player\n\nHow to Find PNE Â§\n\nIn Simultaenous Games: Use the Corner method\nIn Sequential Games:\n\nMake the Decision Tree into a Payoff Matrix, and use the Corner method\nJust test out every combination of Strategy\n\n\n\nalg. Corner Method to find NE. Finding the Nash Equilibrium in a payoff matrix.\n\nFor each player:\nFor each other playerâ€™s move; highlight the line of the best response\nâ†’ When both the left and top lines are highlighted that is NE.\n\nExample. Driving left or Right:\n\n\nSubgame Perfect Nash Equilibrium (for Pure Strategy) Â§\ndef. A Non-credible threat is when the follower in a sequential move game says: â€œIf I canâ€™t win, Iâ€™ll take you down no matter how much it costs to me.â€\n\nIn the above game, (R,R) is an example of a non-credible threat because when Player 1 chooses L, Player 2â€™s best response is Lâ€”but Player 2 threatens to go R. This is because they want the best possible outcome for them, R,(R,R)\n\ndef. Subgame Perfect Nash Equilibria (SPNE) are NE where the follower will only choose strategies that are best for them, and canâ€™t threaten the leader beforehand with non-credible threats.\nalg. Backwards Induction. To find the SPNE of a game, use Backwards Induction:\n\nDetermine the last playerâ€™s best strategy\nThe second-last player knows what the last player will do. Then determine what the second-last player will do.\nContinue solving until the first player.\n\n\nExample. Caterpillar game unraveling\nSPNE={(d,d),(d,d)}, payoff is (1,0) which is a lot worse off that global optimal.\n\nMixed Strategy Nash Equilibrium Â§\ndef. Mixed Strategy Nash Equilibrium\n\nEach player i chooses a distribution Ïƒiâ€‹ over strategy set Siâ€‹ â† Ïƒiâ€‹ is public knowledge\nAt runtime, each player chooses strategy siâ€‹âˆ¼Ïƒiâ€‹ independent of other players\n(s1â€‹,â€¦,snâ€‹) is a Mixed Nash Equilibrium if:\n\nâˆ€iâ€‹âˆ€siâ€‹âˆˆSiâ€‹,Â Â ExpectedÂ costÂ afterÂ switchingEsâˆ’iâ€‹âˆ¼Ïƒâˆ’iâ€‹â€‹[Ciâ€‹(siâ€²â€‹,sâˆ’iâ€‹â€‹)]â€‹â€‹â‰¥ExpectedÂ costÂ ofÂ potentialÂ equal.Â strat.Esâˆ’iâ€‹âˆ¼Ïƒâˆ’iâ€‹â€‹[Ciâ€‹(siâ€‹,sâˆ’iâ€‹â€‹)]â€‹â€‹\nthm. (Existence of MNE, John Nash) Any game with finite players and finite set of strategies for each player has an MNE.\nProof. The proof as three parts: the proof of Spernerâ€™s Lemma, using it to prove Brouwerâ€™s Fixed Point Theorem, and then reducing a mixed Nash Equillibrium to a fixed point in Brouwerâ€™s Fixed Point theorem. We will only reveal the last part in this proof.\nConsider the following:\n\nAgent i has the strategy set Siâ€‹. There are k agents. Their payoff is Ï€iâ€‹(Siâ€‹,Sâˆ’iâ€‹).\nÎ”iâ€‹:=(p1â€‹,p2â€‹,â€¦) is the mixed strategy set of agent i with each corresponding to the probability of each strategy in Siâ€‹.\n\nThis makes it a unit simplex in Râˆ£Siâ€‹âˆ£\n\n\nC:=Î”1â€‹Ã—â‹¯Ã—Î”kâ€‹ is all possible combinations of mixed strategy of all agents.\n\nC is a compact set, and we want to apply Brouwerâ€™s theorem on this space\nLet function fiâ€‹:Â combinationÂ ofÂ mixedÂ strat.Â Câ€‹â€‹â†¦Â iâ€™sÂ mixedÂ strat.Â Î”iâ€‹â€‹â€‹ be:\n\n\n\nfiâ€‹(xiâ€‹,xâˆ’iâ€‹â€‹):=Â maximize,Â returnÂ mixedÂ strategyÂ xâ€²Â argxâ€²âˆˆÎ”iâ€‹maxâ€‹â€‹â€‹Â ...thatÂ maximizesÂ expectedÂ payoffÂ E(Ï€iâ€‹(S))â€‹â€‹âˆ’Â regularizaerÂ (donâ€™tÂ moveÂ fast)Â âˆ£âˆ£xiâ€²â€‹âˆ’xiâ€‹âˆ£âˆ£22â€‹â€‹â€‹\nThen, let function f:Câ†¦C be defined f(x)=(f1â€‹(x1â€‹),f2â€‹(x2â€‹),â€¦,fkâ€‹(xkâ€‹)). Then f is continuous, thus there exists a point in which f(xâˆ—)=xâˆ—. This means at xâˆ— there is no more expected payoff maximization that can be made by any individual, i.e. MNE.\nâ– \nalg. Computation of MNE using Linear Programming.\n\nThe payoff matrix denotes what the column player (=minimizing player) gives to row player (=maximizing player)\n\n\nRow player thinks that column player will minimize exchange (stackleberg solution)\nColumn player thinks that row player will maximize exchange (stackleberg solution)\nStrategy tuple that satisfies both conditions is an MNE.\n\nCorrelated Nash Equilibrium (CNE) Â§\ndef. Correlated Nash Equilibrium\n\n3rd party computes joint distribution of all parties S1â€‹Ã—S2â€‹Ã—â‹¯Ã—Snâ€‹, to joint distribution Ïƒ â† this joint distribution is public knowledge.\nAt runtime, 3rd party draws strategy vector s=(s1â€‹,s2â€‹,â€¦,snâ€‹)âˆ¼Ïƒ\n3rd party tells player i to play siâ€‹\nPlayer i computes the posterior distribution of what other players will do: Ïƒâˆ’iâ€‹\n(s1â€‹,â€¦,snâ€‹) is a Correlated Nash Equilibrium iff:\n\nâˆ€iâ€‹âˆ€siâ€‹âˆˆSiâ€‹,Â Â ExpectedÂ costÂ afterÂ switchingEsâˆ’iâ€‹âˆ¼Ïƒâˆ’iâ€‹â€‹[Ciâ€‹(siâ€²â€‹,sâˆ’iâ€‹â€‹)]â€‹â€‹â‰¥ExpectedÂ costÂ ofÂ potentialÂ equal.Â strat.Esâˆ’iâ€‹âˆ¼Ïƒâˆ’iâ€‹â€‹[Ciâ€‹(siâ€‹,sâˆ’iâ€‹â€‹)]â€‹â€‹\nalg. CNE Computation Using Integer Linear Programming:\n\nExample of Correlated Nash Equilibirum: Traffic Lights game:\n\nImperfect Information Â§\nBaysian Nash Equilibrium Â§\nIn a\n\n\nmixed strategy (players each have probability of action)\n\n\none-shot game\ndef. Baysian Nash Equilibirum is a set of strategies that are mutual best responses given a certain probability of otherâ€™s actions\n\n\nFor a BNE to exist, each personâ€™s strategy must assign probabilities such that the opponent is neutral to each of their options. (if not, it means there is a dominant strategy for the opponent)\n\n\ndef. Perfect Baysian Equilibirum. In a mixed strategy, finitely repeated game, with each player having a belief a Perfect Baysian Equilibirum is one that\n\nthe playerâ€™s beliefs are consistent with strategy (rational)\nis a BNE for each subgame\nâ†’ Signaling Game is a good example\n"},"Equity":{"title":"Equity","links":["Dividend-Discount-Model","Comparable-Company-(Comps)-Analysis"],"tags":["Economics/Finance"],"content":"Terminology Â§\n\nEquity. Equity is a partial ownership of an asset (mostly companies)\n\nEquity in a mortgage\n\n\n\nEquity=NetÂ MarketÂ Valueâˆ’UnpaidÂ Balance\n- Equity in a company.\n\t- **Equity index**\n\t\t- $\\coloneqq$ a weighted average of equities\n\t\t- e.g. _S&amp;P 500, Dow Jones Ind. Avg., Nasdaq, Rusells 2000_ â† different indicies with different weights\n\t\t- ownership rights (like voting in decisions) are relinquished\n\t- [[Private Equity Firms]]\n\t- Earnings Season\n\t\t- Firms post earnings every quarter. Earnings $\\equiv$ Income $\\equiv$ Profit.\n- You buy an equity because you expect\n\t1. It pays regular dividends\n\t2. You expect its price to go up â† S&amp;P has always beaten any other asset class\n\n\nDividend Discount Model. Pricing an equity.\nMinority Interest (=non-controlling interest):= The interests of a non-controlling stockholder.\n\nThis interest is not interest rate. Itâ€™s about having a stake.\n\n\nFully Dilluted Shares:= total sum of outstanding shares.\nCommon Stock: may not pay dividend; but if it does, you expect it to grow\nPreferred Stock: No voting rights, but during bankruptcy you can liquidate first.\nComparable Company (Comps) Analysis. Which equity to buy?\nDividend Yield\n\nDividendÂ Yield=ShareÂ priceDividendÂ perÂ shareâ€‹"},"Estimator":{"title":"Estimator","links":["Bias-(Statistics)","Variance","Efficiency-(Statistics)","Consistency","Mean-Squared-Error","Likelihood-(Statistics)"],"tags":["Math/Statistics"],"content":"def. Statistic. let X1â€‹,â€¦,Xnâ€‹ observable random variables [= data of an experiment]. then statistic T is:\nT=Î´(X1â€‹,...,Xnâ€‹)\n\nÎ´:{X1â€‹,â€¦,Xn}â†’R i.e. is a real-valued function\nÎ´ cannot contain unknown variables\n\ndef. Estimator [= point estimate] is a statistic used to estimate the parameter of the model we think the data is showing. Note the following notation convention:\nÎ¸^=Î´(X1â€‹,...,Xnâ€‹)\n\nAssume X as an r.v. of an experiment, whose model includes parameter Î¸.\nTo estimate ground truth parameter Î¸, we can use an estimator r.v. Î¸^(X)\nA specific estimate for a particular observed value x1â€‹ is denoted Î¸^(x1â€‹)\nAn estimator has to be a function of known variables &amp; data only.\nVar(Î¸^)=E[(Î¸^âˆ’EÎ¸^)2], NOT E[(Î¸^âˆ’Î¸)2] â† This is MSE\n\nHow Good is Your Estimator? Â§\n\nAccuracy is higher. Increased as Bias (Statistics) is decreased\nPrecision is higher. Increased as Variance V(Î¸^) is decreased\nEfficiency (Statistics) is higher. If estimators Î¸^1â€‹,Î¸^2â€‹ have the same accuracy, but V(Î¸^1â€‹)&lt;V[Î¸^2â€‹] then the former is more efficient than the latter.\nConsistency.\nMean Squared Error is lower.\nLikelihood (Statistics) is higher.\n\nâ†’ In general, making sure to reduce bias of estimators is important. Note that:\n\nIf you can write down what the bias is mathematically [= characterize the bias], then you can make a new estimator that doesnâ€™t have the bias.\nBias usually decreases as the data points increase\n\n\n\n                  \n                  Example \n                  \n                \nlet X1â€‹,â€¦,Xnâ€‹âˆ¼iidN(Î¼,Ïƒ2) and\nlet estimator Î¸^:=âˆ‘inâ€‹aiâ€‹Xiâ€‹ where\n\na1â€‹,â€¦,anâ€‹ are weights that sum to 1. [= weighted average]\nÎ¸^ is estimating Î¼. Ïƒ is known.\n\n\n\n\nHow accurate is Î¸^? [=what is the bias?]\n\n\n\n&gt;&gt;E[Î¸^]&gt;&gt;&gt;&gt;B(Î¸^)â€‹=E[âˆ‘aiâ€‹Xiâ€‹]=âˆ‘E[aiâ€‹Xiâ€‹]=âˆ‘aiâ€‹E[Xiâ€‹]=Î¼=0&gt;â€‹&gt;&gt;&gt;\n\n\n\nHow precise is Î¸^? What are the best aiâ€‹,â€¦,anâ€‹?\n\n\n\n&gt;&gt;V(Î¸^)&gt;&gt;&gt;&gt;&gt;â€‹=V[âˆ‘aiâ€‹Xiâ€‹]=V[a1â€‹X1â€‹]+â‹¯V[anâ€‹Xnâ€‹]=a12â€‹V[X1â€‹]+â‹¯an2â€‹V[Xnâ€‹]=a12â€‹Ïƒ2+â‹¯an2â€‹Ïƒ2=Ïƒ2âˆ‘ai2â€‹&gt;&gt;â€‹&gt;&gt;&gt;\n\nâ†’ Thus V[Î¸^] is minimized when aiâ€‹=n1â€‹.\n"},"Euclid's-Algorithm-for-Greatest-Common-Denominator-(GCD)":{"title":"Euclid's Algorithm for Greatest Common Denominator (GCD)","links":[],"tags":["Computing/Algorithms","Math"],"content":"Algorithm Â§\nEuclidean algorithm - Wikiwand\n\nThe Euclidean algorithm is based on the principle that the greatest common divisor of two numbers does not change if the larger number is replaced by its difference with the smaller number.\nFor example, 21 is the GCD of 252 and 105 (as 252Â =Â 21Â Ã—Â 12 and 105Â =Â 21Â Ã—Â 5), and the same number 21 is also the GCD of 105 and 252Â âˆ’Â 105Â =Â 147. Since this replacement reduces the larger of the two numbers, repeating this process gives successively smaller pairs of numbers until the two numbers become equal. When that occurs, they are the GCD of the original two numbers.\n\ndef gcd(a, b):\n\twhile b != 0:\n\t\ta, b = b, a % b\n\t\t# guaranteed a &gt; b, \n\t\t# because remainder is smaller than divisor\n\t\t# needs to be one-line because the new a and b musn&#039;t\n\t\t# interfere for the old a and b\n\treturn a\n\nIn this implementation, the algorithm iteratively calculates the remainder when dividing the larger numberÂ aÂ by the smaller numberÂ b. It then updatesÂ aÂ to beÂ bÂ andÂ bÂ to be the remainder. This process continues untilÂ bÂ becomes zero, indicating thatÂ aÂ is the GCD of the original two numbers.\n\n\nThe implementation has a time complexity of O(log(min(a, b))) as it iteratively reduces the numbers by taking their remainders.\n\nTime Complexity Â§\nStack Overflow\n\nSo the number of iterations is linear in the number of input digits. For numbers that fit into cpu registers, itâ€™s reasonable to model the iterations as taking constant time and pretend that the total running time of the gcd is linear.\nOf course, if youâ€™re dealing with big integers, you must account for the fact that the modulus operations within each iteration donâ€™t have a constant cost. Roughly speaking, the total asymptotic runtime is going to be n^2 times a polylogarithmic factor. Something like n^2 lg(n) 2^O(log* n). The polylogarithmic factor can be avoided by instead using a binary gcd.\n"},"Everything-is-a-File":{"title":"Everything is a File","links":[],"tags":["Computing"],"content":"Everything is a File (Wikipedia)\n\nEverything is a file is an idea that Unix, and its derivatives, handle input/output to and from resources such as documents, hard-drives, modems, keyboards, printers and even some inter-process and network communications as simple streams of bytes exposed through the filesystem name space. [â€¦] The advantage of this approach is that the same set of tools, utilities and APIs can be used on a wide range of resources and a number of file types.\n"},"Evolutionary-Game-Theory":{"title":"Evolutionary Game Theory","links":["Social-Construct","Trust-Escrow-System","Prestige"],"tags":["Economics/Game-Theory","Social-Sciences"],"content":"Analysis of human behavior and Social Constructs using the tools of game theory.\n\nTrust Escrow System\nPrestige\n"},"Expected-Value":{"title":"Expected Value","links":[],"tags":["Math/Statistics"],"content":"Expected Value Â§\ndef. Expected Value. For random variable X with countably many outcomes, its expected value E(X) is defined as:\nE(X)E(X)â€‹:=âˆ€xâˆˆrange(X)âˆ‘â€‹xâ‹…P(X):=âˆ«âˆ’âˆâˆâ€‹xâ‹…fXâ€‹(x)dxâ€‹forÂ discreteforÂ continuousâ€‹â€‹\nProperties. The following identities hold for expected values, with constant k, random variables X,Y.\n\nE(k)=k\nE(X+Y)=E(X)+E(Y) Linearity\nE(kâ‹…X)=kâ‹…E(X)\nE(Xâ‹…Y)=âˆ‘âˆ€zâ€‹zâ‹…P(Xâ‹…Y=z)\n\nIf XâŠ¥Y then E(Xâ‹…Y)â‡’E(X)â‹…E(Y) (reverse does not hold)\n\n\nlet g be a function over range(X). Then, E(g(x))=âˆ‘âˆ€xâ€‹g(x)â‹…P(X=x) (Law of Unconscious Statistician)\n\n! E(g(x))î€ =g(E(x))\nE(Xk)=âˆ‘âˆ€xâ€‹xkâ‹…P(X=x)\n\n\n\nthm. Tail Sum Formula. when X is a non-negative discrete random variable:\nE(X)=i=0âˆ‘âˆâ€‹P(Xâ‰¥i)\nRemark. The Tail Sum formula is useful when the random variable is defined as the minimum or maximum of a certain set of events (e.g. minimum of multiple dice rolls, etc.)\n\n\n                  \n                  Expectation Manipulation from class:\n                  \n                \n\n\nConditional Expected Value Â§\nE(g(X,Y))=âˆ¬R2â€‹g(x,y)fX,Yâ€‹(x,y)dA\ndef. Conditional Expectation. let X,Y be jointly distributed. Then the conditional expected value is definedâ€¦\n\nâ€¦over an event: E(Xâˆ£A)=âˆ‘âˆ€Aâ€‹xâ‹…P(X=xâˆ£A)\nâ€¦over an event on a random variable E(Xâˆ£Y=y)=âˆ«âˆ’âˆâˆâ€‹xâ‹…fXâˆ£Y=yâ€‹(x)Â dx\nâ€¦over a random variable: E(Xâˆ£Y)=âˆ‘âˆ€xâˆ€yâ€‹xâ‹…P(X=xâˆ£Y=y)\n\n! While expectation conditioned on an event is a value, an expectation conditioned over a random variable is another random variable\nwith more rigour: E(Xâˆ£Y):=E(Xâˆ£Ïƒ(Y))\nIntuition. Think of it as â€œgiven all information by Y, whatâ€™s the new random variable?â€\n\n\n\nProperties.\n\nE(aX+bYâˆ£A)=aâ‹…E(Xâˆ£A)+bâ‹…E(Yâˆ£A) linearity\nE(X)=âˆ‘âˆ€iâ€‹E(Xâˆ£Aiâ€‹)â‹…P(Aiâ€‹) where A1â€‹,â€¦,Anâ€‹ is a partition of Î©.weighted summation\nIf X is F-measurable, E(Xâˆ£F)=X\nIf X is independent of H then E(Xâˆ£H)=E(X) Taking out independent factors. \nif X is F-measurable, E(XYâˆ£F)=XE(Yâˆ£F) Taking out whatâ€™s known\n\ne.g. E(Xt+0.2â€‹Xtâ€‹âˆ£F)=Xtâ€‹E(Xt+0.2â€‹)\n\n\nTower Property: if X is a random variable, and FâŠ‚G then: E(E(Xâˆ£G)âˆ£F)=E(Xâˆ£F)\n\n&amp; Think of it as â€œhigh-res cameraâ€ then â€œlow-res cameraâ€; the final picture is low-res.\n\n\n\nthm. Conditional Joint Expectation. X,Y and Râˆˆ[Range(X)Ã—Range(Y)]. Then:\nE(Xâˆ£x,yâˆˆR)whereÂ fX,Yâˆ£x,yâˆˆRâ€‹(x,y)â€‹=âˆ¬Râ€‹xâ‹…fX,Yâˆ£x,yâˆˆRâ€‹(x,y)Â dA=P(x,yâˆˆR)fX,Yâ€‹(x,y)â€‹â€‹â€‹\nthm. Calculating Expected Value from Conditional Expected Value. (Identity 2 above) let X,Y be jointly distributed. Then the expected value of X is calculated:\nE(X)E(X)â€‹=âˆ€yâˆ‘â€‹E(Xâˆ£Y=y)â‹…P(Y=y)=E(E(Xâˆ£Y))=âˆ«âˆ’âˆâˆâ€‹E(Xâˆ£Y=y)â‹…Â fYâ€‹(y)â‹…dy=E(E(Xâˆ£Y))â€‹â€‹\n\nUseful for computing E(X) when X depends on Y.\nWorks regardless of whether X,Y are random or discrete, and when mixed.\n"},"Expenditure-Function":{"title":"Expenditure Function","links":["Marginal-Willingness-to-Pay","Budget-Lines","Homogenous-Function","Shepard's-Lemma"],"tags":["Economics/Micro-Economics"],"content":"def. Expenditure Function. (â‰ˆIncome Function) Relates prices and a certain utility to the required income to achieve that level of utility.\nE:(p1â€‹,p2â€‹,uË‰)â†¦I\nDerivation. Substitute Hicksian Demand functions into the Budget Constraint.\nProperties.\n\nHD1 in prices (E(tp1,tp2â€‹,uË‰)=tE(p1â€‹,p2â€‹,uË‰))\nIncreasing in prices (âˆ‚p1â€‹âˆ‚Eâ€‹,âˆ‚p2â€‹âˆ‚Eâ€‹â‰¥0)\n\nequal when youâ€™re not buying that good.\nHigher prices require more income\n\n\nIncreasing in utility (âˆ‚uâˆ‚Eâ€‹&gt;0)\n\nMore utility requires more expenditure.\n\n\nUse Shepardâ€™s Lemma in order to get back to Hicksian Demand Curve\n"},"Expenditure-Minimization":{"title":"Expenditure Minimization","links":["Monotonic-Transformation","Utility-Maximization"],"tags":["Economics/Micro-Economics"],"content":"minÂ I=p1â€‹x1â€‹+p2â€‹x2â€‹Â suchÂ thatÂ uË‰=u(x1â€‹,x2â€‹)\n\nYou can do a Monotonic Transformation\nUse lagrangian\ncorner solutions, etc.\nSee Utility Maximization for the reverse casew\n"},"Exponential-Distribution":{"title":"Exponential Distribution","links":[],"tags":["Math/Common-Distributions"],"content":"def. Exponential Distribution. X has exponential distribution with intensity Î»:\nXâˆ¼Exp(Î»)fXâ€‹(x)={Î»eâˆ’Î»x0â€‹x&gt;0elseâ€‹FXâ€‹(t)=1âˆ’eâˆ’Î»tE(X)=Î»1â€‹Â Â Â Â Â Â Â Â Â Â Â SD(X)=Î»1â€‹â€‹\n\nThe exponential distribution is useful when modeling wait time X in a call center, with â€œbusinessâ€ of Î» (e.g. â€œon average Î» calls per hourâ€).\nBe careful that Î» is the number of events in timespan, not the average time it takes between events.\n"},"Exponential-Family":{"title":"Exponential Family","links":["Normal-Distribution","Exponential-Distribution","Chi-Squared","Bernouilli-Distribution","Poisson-Distribution","Binomial-Distribution","Multinomial-Distribution","Hypergeometric-Distribution"],"tags":["Math/Probability"],"content":"def. Expoential Family of Distributions is the distributions whose pdfs are in the following form:\nfXâ€‹(xâˆ£Î¸)=h(x)â‹…exp[Î·(Î¸)T(x)âˆ’A(Î·)]\nIncludes:\n\nNormal Distribution\nExponential Distribution\nChi-Squared\nBeta\nDiriochelt\nBernouilli Distribution\nPoisson Distribution\n\nAs well as:\n\nBinomial Distribution (with fixed number of trials)\nMultinomial Distribution (with fixed number of trials),\nNegative binomial (with fixed number of failures)\nGeometric (Not Hypergeometric!)\n"},"Exponential-Function":{"title":"Exponential Function","links":[],"tags":["Math"],"content":"By definitionâ€¦ (Taylor Approximation)\nex=xâ†’âˆlimâ€‹(1+x1â€‹)x=e\nOr by definition, the family of functions that satisfy:\nf(x+y)=f(x)â‹…f(y)\n(See Eulerâ€™s formula with introductory group theory - YouTube)\nAnother Definition:\nex=n=0âˆ‘âˆâ€‹n!xnâ€‹=1+x+2x2â€‹+â€¦"},"Extensible-Markup-Language":{"title":"Extensible Markup Language","links":["assets/Screenshot-2023-10-24-at-18.21.58.png","XPath-and-XQuery"],"tags":["Computing/Data-Science"],"content":"\nSemi-structured data (well-structured)\n\nDocument format (well-formed)\n\n\nSelf-describing\n\n{xml}&lt;book author=&quot;C. Darwin&quot;&gt;The Origin of Species&lt;/book&gt;\n\nTag: {xml}&lt;book&gt;,&lt;/book&gt;\nAttribute: {xml}author=&quot;C. Darwin&quot;\n\nID: id is a special attribute that is unique\n\n\nNamespace: definition of your schema\n\n&lt;myNS:book xmlns:myNS=&quot;http://.../mySchema&quot;&gt; \n\t&lt;myNS:title&gt;...&lt;/myCitationStyle:title&gt;\n\t&lt;myNS:author&gt;...&lt;/myCitationStyle:author&gt;...\n&lt;/book&gt;\n\nElements: The Origin of Species\n{xml}&lt;![CDATA[Tags: &lt;book&gt;,â€¦]]&gt; means character data (escape not required)\nTree Representation\nUse XPath and XQuery to query it\n"},"Fairness-(Economics)":{"title":"Fairness (Economics)","links":["Pareto-Efficiency","Utility-Function","Rationality-(Economics)","Integer-Allocation","John-Rawls","Ordinal-Allocation","Matching-Problems","Fractional-Allocation"],"tags":["Economics/Game-Theory","Economics/Micro-Economics"],"content":"Motivation. In Game Theory we attempt to formalize our intuitive notion of fairness into rigorous mathematical statements, in order to be able to prove if our allocations are fair or not. There are many different was of doing this, and we will define a few:\n\nScale Invariance (You canâ€™t compare utilities)\nEnvy-Free\nPareto Efficiency (see linked definition.)\nProportionality\nIn these definitions, we assume there are m divisible items, and n agents. We also assume that the Utility Function of the agents are\n\n\nContinuous\nStrictly increasing across a single item, for all items\nConcave (diminishing returns)\nIn other words, the agents have Rational Taste.\n\ndef. Scale Invariace. An Allocation is fair if it only depends on the ordinal preferences of the agents, not their cardinal value. i.e., if we scale any agentâ€™s utility Î¼iâ€‹ by Î±Î¼iâ€‹, the allocation would not change.\ndef. Envy-Free (EF). An allocation is envy free if they like their allocation rather than anybody elseâ€™s; âˆ€i,âˆ€j,xiâ€‹âª°iâ€‹xjâ€‹.\ndef. Proportionality (Prop). Allocation of n1â€‹ of each item to each agent shouldnâ€™t be a better solution than the current allocation for every agent. i.e.\nâˆ€i,Â xiâ€‹â€‹âª°iâ€‹Â ProportionalÂ allocationÂ (n1â€‹x1â€‹,n1â€‹x2â€‹,â€¦,n1â€‹xnâ€‹)â€‹â€‹\nOther Fairness Criteria Â§\n\nWhen EF cannot be achieved we may attempt approximate-envy freeness EF1\nMaximin Share is another benchmark based on Rawlsian maximin principle.\nIn Ordinal Allocation methods, in a probabilistic allocation setting, we may need to use baysian versions of the above criteria.\nIn Stable Matching Problems, stability is another fairness criteria.\n\nDirectory of Allocation Methods Â§\nCardinal Utility Functions Â§\n\nFractional Allocation\n\nFischer Market (=CEEI) â€“ SI, EF, Prop, PO\n\n\nInteger Allocation\n\nSerial Dictatorship (=Round Robin) â€“ EF1, but not anything else\nInteger Nash Welfare â€“ EF1, MMS-bounded\n\n\n\nOrdinal Utility Functions Â§\n\nProbabilistic Allocation\n\nRandom Dictatorship â€“ DSIC\nProportional Eating â€“ BEF, BPO\n\n\nStable Allocation (Kideney)\n\nTop Trading Cycles (TTC) â€“ DSIC, Stable\n\n\nStable Matching (Marriage)\n\nGale-Shapleyâ€”Proposer-optimal\n\n\nOnline\n\nDeterministic Ski Rental &lt;2 even in best\nRandomized Ski Rental &lt;eâˆ’1eâ€‹\nDeterministic Whole &lt;2\nFractional Greedy (&lt;2 in example bad case)\nFractional Water-filling (2ee+1â€‹ in example bad case)\n\n\n"},"Fast-Exponentiation":{"title":"Fast Exponentiation","links":[],"tags":["Computing/Algorithms"],"content":"Observation:\nxn={x(x2)(nâˆ’1)/2,(x2)n/2,â€‹\\mboxifn\\mboxisodd\\mboxifn\\mboxisevenâ€‹\nThus we can achieve O(logn) multiplications."},"Federal-Communication-Commission":{"title":"Federal Communication Commission","links":[],"tags":["Computing"],"content":"A U.S. Government agency that regulart"},"Federal-Funds-Rate":{"title":"Federal Funds Rate","links":["Interest-Rate","Federal-Reserve","Monetary-Policy"],"tags":["Economics/Finance"],"content":"The minimum Interest Rate declared by the Federal Reserve.\n\nThis is what we mean when we normally say â€The Fed is increasing instrest ratesâ€ as Monetary Policy\n"},"Federal-Reserve":{"title":"Federal Reserve","links":["Federal-Funds-Rate","inflation","Securities-and-Exchange-Commission","Too-Big-To-Fail","Monetary-Policy"],"tags":["Economics"],"content":"The United Statesâ€™ central bank independent of the government (or the Treasury) that has the following roles:\n\n\nSetting Interest Rates: The Federal Reserve has a significant influence over the interest rates in the U.S. economy. It can adjust the Federal Funds Rate to control inflation and stabilize the economy.\n\n\nManaging the Money Supply: The Fed controls the amount of money circulating in the economy through measures such as open market operations, reserve requirements for banks, and setting the discount rate [&gt;=Federal Funds Rate].\n\n\nRegulating Financial Markets: It supervises and regulates banks to ensure they are safe and sound. It also monitors their impact on the financial system. (This is separate from the SEC)\n\n\nActing as a Lender of Last Resort: In times of financial distress or crisis, the Federal Reserve provides funds to financially strained banks to prevent bankruptcy and protect the economy. (This causes problems of Too Big To Fail)\n\n\nMaintaining Financial Stability: The Fed works to maintain the stability of the financial system and contain systemic risk that may arise in financial markets.\n\n\nProviding Banking Services to Depository Institutions: These services include supplying the economy with fiat money (U.S. dollar), managing those finances, and processing payments.\n\n\nConducting National Monetary Policy: The Fed works towards achieving maximum employment, stable prices, and moderate long-term interest rates in the U.S. economy.\n\n\nPreventing Banking Panics: The Fed was initially created to prevent widespread panics in the banking sector. Today, it continues to act as a stabilizing force in the financial system.\n\n\nPromoting a Safe and Effective Payment System: The Federal reserve system also ensures the reliability of payment methods including checks, cash, and electronic transactions.\n\n\nKeep in mind that these roles and responsibilities may evolve over time, and additional duties may be undertaken depending on economic and financial conditions."},"Federal-Trade-Commission":{"title":"Federal Trade Commission","links":["Monopoly"],"tags":["Economics"],"content":"Consumer protection agency in the United States.\n\nMost famously, it protects against mergers &amp; acquisitions that lead to Monopoly\n"},"Fetishization":{"title":"Fetishization","links":[],"tags":["Philosophy/Marxism"],"content":"Fetishization in general refers to giving more meaning to something that does not inherently have meaning, or does not deserve that degree of meaning.\n\nFetishization of social cues: Finding meaning in social cues is a type of fetish. The actions, expressions or words have less meaning than what we feel they do.\n\nFetishization, Social Nature Â§\nWe see, then, that everything our analysis of the value of commodities previously told us is repeated by the linen itself, as soon as it enters into association with another commodity, the coat. Only it reveals its thoughts in a language with which it alone is familiar, the language of commodities.\nIt is thus that this value first shows itself as being, in reality, a congealed quantity of undifferentiated human labour."},"Finite-Automata":{"title":"Finite Automata","links":["Regular-Expressions"],"tags":["Computing/Formal-Languages"],"content":"Regular Expressions\nDefinitions Â§\ndef. Automata is an abstract model of a computer.\ndef. Regular Language is a language that can be expressed by a FSM\ndef. Trap state is a state in which any symbol input leads to the same state.\ndef. Closure of qiâ€‹ is simply the set of states reachable from qiâ€‹ with only Î».\nDeterministic Finite Automata (DFA) Â§\n[= Finite State Machine]\nDFA=(Q,Î£,Î´,q0â€‹,F)\n\nQ is the set of all states\nÎ£ is the set of all symbols\nÎ´:QÃ—Î£â†’Q is a function mapping from current state to the next state\n\nÎ´âˆ—(qiâ€‹,Î»)=qiâ€‹ [= empty strings lead to itself]\nÎ´âˆ—(q,wa)=Î´âˆ—(Î´(q,w),a) where a is a single symbol [= processes only one per tick]\n\n\nq0â€‹ is the start state (entry point)\nF is the set of final states\n\n\n\n                  \n                  a,b.\n                  \n                \n\ndef. Language. A string is accepted by a DFA when:\n\nAfter processing the string, the DFA is in a final state\nThe string is in the language\n\nThe set of all aceepted strings by a DFA is the language of the DFA:\nL(M)={wâˆˆÎ£âˆ—âˆ£Î´âˆ—(q0â€‹,w)âˆˆF}\ni.e. all the strings which, after processing it thru Î´âˆ—, it lands on a final state\nNon-deterministic Finite Automata (NFA) Â§\ndef. Non-deterministic Finite Automata can have multiple edges with the same labels; i.e.\nÎ´:QÃ—Î£âˆªÎ»â†’2Q\ni.e. from the current state, you can go to multiple states.\n\n\n                  \n                  Example Non-deterministic FSM \n                  \n                \n\n\ncorr. â€œthere exists a walk between qiâ€‹,qjâ€‹ whose labels concatenate to wâ€ is equivalent to:\nqjâ€‹âˆˆÎ´âˆ—(qiâ€‹,w)\nthm. All NFA can be convered into a DFA which:\nDFA={Â QÎ£Î´q0â€‹FDâ€‹}â€‹=2Q=QDâ€‹Ã—Î£=QDâ€‹={QâˆˆQDâ€‹âˆ£âˆƒqiâ€‹âˆˆQÂ whereÂ qiâ€‹âˆˆFNâ€‹}â€‹\nProving Regularity after Applying Properties Â§\ne.g. let L be a regular language. For all strings in L replace one a with b, and let this new language Lâ€². Is this a regular language?\npf. let Mbe a DFA for L.\n\nMake a copy M1â€‹,M2â€‹ and enclose it in a new machine, Mâ€²\nFor all a arcs in M1â€‹ write a b arc to the corresponding destination state in M2â€‹.\nThe start state for M1â€‹ is Mâ€² start state.\n\n\nNow, let\n\nw=uav, and wâ€²=ubv where w,u,vâˆˆÎ£âˆ—\nÎ´1âˆ—â€‹(q0â€‹,u)=qiâ€‹, Î´â€²(qiâ€‹,b)=qjâ€‹, Î´2âˆ—â€‹(qjâ€‹,v)âˆˆF as we outlined above\n\n\nIf wâˆˆL\nthen\n\nâ†’ proofs often involve duplicating the machine in some way.\nDFA Minimization Â§\nExample:\n\n\n"},"Fisher-Information":{"title":"Fisher Information","links":["Maximum-Likelihood-Estimator","Expected-Value","Likelihood-(Statistics)"],"tags":["Math/Statistics"],"content":"Fisher information helps us find better estimators.\n\nCramer-Rao Lower Bound shows what the best estimators can do with their precision\nReaching the CRLB means itâ€™s finite-sample efficient\nThe Maximum Likelihood Estimator is also a very good estimator.\n\ndef. Fisher Information is the amount of information we have about the unknown parameter. Itâ€™s the Expected Value of score.\n\nGiven fXâ€‹(x;Î¸), if X has a high peak we may assume that X carries a lot of information about Î¸.\nIf X is spread out a lot, we may assume that X carries little information. Thus:\n\nI(Î¸)â€‹:=Var[s]=E[s2]âˆ’E[s]2=E[s2]â€‹â€‹\n\n(2) â†’ (3) as we know that E[s2âˆ£Î¸gtâ€‹]=0\n\nthm. Addition of fisher information. if X1â€‹,â€¦,Xnâ€‹âˆ¼iidfXiâ€‹â€‹(x1â€‹,â€¦,xnâ€‹âˆ£Î¸), then:\nInâ€‹=nâ‹…I\nthm. Score and Fisher Information. if fXâ€‹(Î¸;x) is twice differentiable wrt Î¸, and under certain regularity conditions:\nI(Î¸)=âˆ’E[âˆ‚Î¸2âˆ‚2â€‹lnfXâ€‹(X;Î¸)]\n\nKnowing this we also know that E[sâ€™]=âˆ’E[s2].\n"},"Fixed-Effects-Model-for-Panel-Data":{"title":"Fixed Effects Model for Panel Data","links":["Dummy-Variables"],"tags":["Math/Statistics"],"content":"Panel data is a dataset that have multiple observation on a same timeframe. e.g.:\n\nGDP of OECD countries from 1900 to 2000\nAnnual crime rates of 20 U.S. Cities from 1980 to 2000\nPooled Model is when we mistakenly use all of the panel data to run the regression.\nExmaple. Robberies for large cities of California. Each city has its own reasons for having relatively larger or smaller robberies unrelated to policing. You can see that there are general clumps of datapoints corresponding to cities. \nInstead, we should separate the dataset w.r.t. cities and run regression on each of them separately: \n\nOne-way Fixed Effects Model Â§\nMotivation. In order to use a single regression run to capture the difference in cities, we introduce a fixed effect term (Î±iâ€‹), a addtitive term that is same for each city (i.e., all oakland datapoints have the same Î±iâ€‹, all SF datapoints have the same Î±iâ€‹, etc.). The model is this:\nYitâ€‹=Î²0â€‹+Î²1â€‹X1itâ€‹+Â fixedÂ effectÂ Î±iâ€‹â€‹â€‹+Â errorÂ Î½itâ€‹â€‹â€‹\n\ni indexes on each city\nt indexes on year (time)\nWe canâ€™t run regression on this directly because we donâ€™t know what we should set Î±iâ€‹ as. We instead use either Dummy Variables approach or a De-meaned apporach. Both result in the exact same regression result.\n\nLeast-Squares Dummy Variable Fixed Effects Model (LSDV) Â§\nYitâ€‹=Î²0â€‹+Î²1â€‹X1itâ€‹+Î²2â€‹D1iâ€‹+â‹¯+Î²Pâ€‹DPâˆ’1,iâ€‹+Î½itâ€‹\nWhere D1iâ€‹,â€¦,DPâˆ’1,iâ€‹ are the binary dummy variables. We run regression on this to get the regression table:\n\nDe-Meaned Fixed Effects Model Â§\nYitâ€‹âˆ’YË‰iâ€‹=Î²1â€‹(Xitâ€‹âˆ’XË‰iâ€‹)+Î½~itâ€‹\nBy subtracting the mean of each group from the datapoints, we â€œnormalizeâ€ the data so that theyâ€™re all comparable.\nDiscussion Â§\n\nFixed effects models cannot cause bias when used in non-panel data (i.e. all Î±iâ€‹=0)\nWhen Î±iâ€‹î€ =0, and we use a pooled model, it only causes bias when fixed effect is correlated with independent variable (=Î±iâ€‹ and X1iâ€‹) are correlated\n\nTwo-way Fixed effects model Â§\nMotivation. We may want to control for time period, e.g. for 2008 during the financial crisis, crimes in all cities probabily went up. The two-way model controls for time-based fixed effects too in our Califorinan crimes example, with the following model:\nYitâ€‹=Î²0â€‹+Î²1â€‹X1iâ€‹+Â cityÂ fixedÂ eff.Â Î±iâ€‹â€‹â€‹+Â timeÂ fixedÂ eff.Â Ï„tâ€‹â€‹â€‹+Î½itâ€‹\nWe can use double-LSDV, doubkle De-meaned, or LSDV-De-meaned approach. This is not discussed in the book.\nComparing the regression results for pooled, one-way, and two-way:\n"},"Focal-Point":{"title":"Focal Point","links":[],"tags":["Economics/Game-Theory"],"content":"When you ask two strangers to meet up at New York on Jan 1st., without giving them information, and without letting them coordinate, they will likely meet up in Times Square, at Midnight. This is a focal point.\nA Focal Point is a ê²°ì§‘ì  in a game with no coordination; a conspicuous point, either by nature or culture, that we can identify."},"Foreign-Direct-Investment":{"title":"Foreign Direct Investment","links":[],"tags":["Economics/Finance"],"content":"When companies directly invest into factories, workforce (=capital) in the country"},"Formal-Grammar":{"title":"Formal Grammar","links":["Greibach-Normal-Form","Chompsky-Normal-Form"],"tags":["Computing/Formal-Languages"],"content":"Grammar is formally defined as a tuple:\nG=(V,T,S,P)\n\nV are variable symbols to be used in the language (they canâ€™t be in a string, because theyâ€™re placeholders)\nT are terminal symbols to be used in the language.\nS is the start variable\nP is the production rules\n\n\n\n                  \n                  Notation for production rules: \n                  \n                \n\n\nwâ‡’z: w derives z\nwâˆ—â€‹z: w derives z in zero or more steps\nw+â€‹z: w derives z in one or more steps\n\nNormal Forms Â§\n\nGreibach Normal Form\nChompsky Normal Form\n"},"Formal-Languages":{"title":"Formal Languages","links":["Formal-Grammar"],"tags":["Computing/Formal-Languages"],"content":"Notations are borrowed from [[Set Theory]]\ndef. Î£ is the set of all symbols\ndef. A string is a finite set of symbols\ndef. A language is a set of strings\nString Manipulation Â§\n\nÎ» is the empty string\nconcat(w,v)=wâˆ˜v=wv\n\nâ€¦naturally, wn=wâ‹¯w\n\n\nreverse(w)=wR\nlen(w)=âˆ£wâˆ£\n\n\nWe can also define languages as containing strings. Some common ones:\n\nÎ£âˆ— â† set of strings, which are concatenated symbols 0 or more times\nÎ£+â† set of strings, which are concatenated symbols 1 or more times\n\n\n\n                  \n                  \\Sigma=\\{a,b\\}. Then:\n                  \n                \n\n\nÎ£âˆ—={Î»,a,b,aa,ab,ba,bb,...}\nÎ£+={a,b,aa,ab,ba,bb,...}\n\nYou can also use set operations on languages\n\nL1â€‹âˆ˜L2â€‹={xyâˆ£xâˆˆL1â€‹,yâˆˆL2â€‹}\n\nâ€¦naturally, L1â€‹âˆ˜L1â€‹=L12â€‹\n\n\nL1â€‹Ë‰â€‹=Î£âˆ—âˆ’L1â€‹\n\n\nA language given a grammar is defined as a set of terminal-only strings that are derivable from the starting strings. More formally:\nL(G)={wâˆˆTâˆ—âˆ£Sâˆ—â€‹w}"},"Forwards":{"title":"Forwards","links":["Derivatives-(Finance)","No-Arbitrage"],"tags":["Economics/Finance"],"content":"Forwards are a contract that promises to buy/sell an underlying asset at a certain strike price.\nExample. A farmer wants to sell their wheat, and a mill wants to buy some wheat. The current price of wheat is \\20$\n\nThe farmer is afraid of the price of wheat going down\nThe mill is afraid of the price of wheat going down\nTherefore, they draft up a contract: one year from now, they will transact the wheat at a price, \\22$ determined right now. One year from now, they will transact. This is a forward contract.\nUnderlying asset: wheat\nt: time of contract\nT: time of execution\nForward price (=Strike price): F_{T}(t)=K=\\22$\nSpot price: S(0)=\\20$\nContract size: how many units of wheat?\n! no money/assets changes hands now. Thus the value of a portfolio with a forwards contract is zero on the day they entered.\nNow, assume youâ€™re neither a farmer nor a mill, and you just want to bet on the price of wheat.\nShort position: think wheat price will increase. At execution, you will buy wheat from the spot market at price S(T) and give it to the counterparty at price K according to the futures contract\n\nPayoff: Kâˆ’S(T)\n\n\nLong position: think wheat price will decrease. At execution, you will get price the wheat for price K and then sell at the spot market for S(T)\n\nPayoff: S(T)âˆ’K\n\n\n\nthm. (The fair price of a forwards) Under assumption of No-Arbitrage, the fair strike price of a futures contract entered at time t and executed at future date T is:\nK=FTâ€‹(t)=S(t)e(râˆ’q)(Tâˆ’t)\n\nr is the risk-free rate\nq is the dividend rate. In many cases q=0. It only applies to underlying stocks.\nOne may prove this by contradiction, by assuming it doesnâ€™t hold, and constructing an arbitrage portfolio:\n\nthm. (Value of ongoing forward contract) For a futures contract entered at t=0, executed at T, the value of this contract at intermediate time t is:\nFTâ€‹(t)=(FTâ€‹(t)âˆ’FTâ€‹(0))eâˆ’r(Tâˆ’t)\nIntuition.\n\n! Value of a forward contract is not same as the fair price.\nFTâ€‹(t) is strike price of a hypothetical contract from t to T\nFTâ€‹(0) is strike price of a hypothetical contract from 0 to T\nThe difference of these two prices, discounted at risk-free rate.\n\nProof. Let portfolios:\n\nÎ Aâ€‹:\n\nlong forward, enter at t=0, execute t=T, with strike price FTâ€‹(0)\nShort forward, enter at t=t, execute t=T, with strike price FTâ€‹(t)\n\n\nÎ Bâ€‹: Deposit cash (FTâ€‹(t)âˆ’FTâ€‹(0))eâˆ’r(Tâˆ’t) at risk-free r\nThen at time T:\nÎ Aâ€‹(T)=Â longÂ forwardÂ S(T)âˆ’FTâ€‹(0)â€‹â€‹+Â shortÂ forwardÂ FTâ€‹(t)âˆ’S(T)â€‹â€‹=FTâ€‹(t)âˆ’FTâ€‹(0)\nÎ Bâ€‹(T)=FTâ€‹(t)âˆ’FTâ€‹(0)\nSince Î Aâ€‹(T)=Î Bâ€‹(T)âŸ¹Î Aâ€‹(t)=Î Bâ€‹(t) by Law of One Price. Then:\n\nÎ Aâ€‹(t)=Â valueÂ ofÂ longÂ forwardÂ positionÂ FTâ€‹(t)â€‹â€‹=FTâ€‹(t)âˆ’FTâ€‹(0)=Î Bâ€‹(t)\nâ– "},"Fractional-Allocation":{"title":"Fractional Allocation","links":["Fairness-(Economics)","Pareto-Efficiency","Convex-Programming","tags/task"],"tags":["Economics/Game-Theory","Economics/Micro-Economics","task"],"content":"Motivation. Given the Fairness (Economics) properties, we can start allocating things to people. Different allocation methods satisfy different fairness criteria. The most important allocation method is the CEEI Allocation, which is achieved by the Fischer market.\ndef. Fischer Market. The following describes a Fischer market. There are m items and n agents. There are qjâ€‹ units of item j.\n\nAll agents given \\1$\nSet prices at a certain point, pâ€‹ (ignore how we find this for now)\nAgents fine their demand set:\n\nxiâ€‹=Â UtilityÂ MaximizationÂ argmaxxiâ€‹â€‹Â Î¼iâ€‹(xiâ€‹â€‹)â€‹â€‹Â s.t.Â Â BudgetÂ ConstraintÂ pâ€‹â‹…xâ‰¤1â€‹â€‹\nTo clarify the notation:\n\nq1(i)â€‹ is the amount of item 1 allocated to agent j\nq1â€‹:=âˆ‘âˆ€iâ€‹q1(i)â€‹ which is the total amount of item allocated to\n\ndef. Competitive Equilibrium with Equal Incomes (CEEI). In a Fischer market, if we set the prices pâ€‹ just right, we will get a solution where: \n\nAll agents spend all their money âˆ€i,piâ€‹â€‹â‹…xiâ€‹â€‹=1\nAll items are fully allocated (=market clears).\n\n(q1(i)â€‹,Â eachÂ itemÂ quantityÂ toÂ iâ€¦.,qj(i)â€‹,â€¦â€‹â€‹,qm(i)â€‹)jâˆ‘â€‹qj(i)â€‹â€‹:=xiâ€‹â€‹=1â€‹thenequivalentlyâ€‹â€‹\n\nThe above two properties implies pâ€‹â‹…âˆ‘iâ€‹xiâ€‹â€‹=âˆ‘âˆ€jâ€‹âˆ‘âˆ€iâ€‹qj(i)â€‹=n\nThen, this allocation is a CEEI.\n\nthm. CEEI always exists.\n(We wonâ€™t prove.)\nthm. CEEI satisfies Scale Invariance, EF, Prop, and Pareto Efficiency. Let x1â€‹â€‹,â€¦xnâ€‹ be the CEEI allocation.\nProof of SI. In the Fischer market process agents will find their demand set. Demand set doesnâ€™t change depending on the scale of the utility; only the ordinal preferences.\nProof of EF. By contradiction. Assume i envies j s.t. xjâ€‹â€‹â‰»xiâ€‹â€‹. But everybody has the same 1thusicouldhavejustdemanded\\vec{x_{j}}instead.Thusthereisnoenvy.âˆ—ProofofPRâˆ—.SinceallmoneyisspentbyCEEIdefinition,\\sum_{j} p_{j}q_{j}=nwhereq_{j}istheamountofunitsofitemj.Thendividebothbyntoget\\sum_{j}p_{j} \\frac{q_{j}}{n}=1whichmeansthattheproportionalallocation\\left(\\frac{q_{1}}{n},\\dots \\frac{q_{m}}{n} \\right)isfeasible.ButallagentsdemandedsomeothersetS_{i}thusitâ€²satleastasgoodasproportionalallocationbundle.âˆ—ProofofParetoOptimality.âˆ—Bycontradiction.Assumethereisanalternativeallocation\\vec{y_{1}},\\dots,\\vec{y_{n}}suchthatitisaParetoimprovementsuchthatwinnerssetWdenotes&quot;winners&quot;agentswhoimproved:\\vec{y_{i}}\\succ_{\\forall i \\in W} \\vec{x_{i}}and&quot;indifferents&quot;setIdenotesagentswhohassameutility:\\forall i \\in I,~ \\mu_{i}(\\vec{y_{i}})=\\mu_{i}(\\vec{x_{i}}).Now,forthewinners,theydidnâ€²tdemandset\\vec{y_{i}}inCEEIallocation\\vec{x_{i}},sotheyclearlycouldnâ€²taffordit:\\vec{p} \\cdot \\vec{y_{j}}&gt;1.NowfortheIndifferents;if\\vec{p} \\cdot \\vec{y_{i}}&lt;1thentheycouldhaveinitiallybought\\vec{x_{i}}=\\vec{y_{i}}andafewmorestuffswithleftovermoney.Buttheydidnâ€²tdemandanythingotherthan\\vec{x_{i}},thus\\vec{p} \\cdot \\vec{y_{i}}\\geq 1$ by contradiction.\nCombining the inequality for winners and losers:\niâˆˆWâˆ‘â€‹pâ€‹â‹…yiâ€‹â€‹+iâˆˆIâˆ‘â€‹pâ€‹â‹…yiâ€‹â€‹âˆ€iâˆ‘â€‹pâ€‹â‹…yiâ€‹â€‹pâ€‹â‹…âˆ€iâˆ‘â€‹yiâ€‹â€‹âˆ€iâˆ‘â€‹yiâ€‹â€‹&gt;âˆ€iâˆ‘â€‹xiâ€‹â€‹â€‹&gt;n&gt;n&gt;Â b/cÂ CEEIÂ clearsÂ marketn=pâ€‹=(q1â€‹,â€¦,qmâ€‹)âˆ€iâˆ‘â€‹xiâ€‹â€‹â€‹â€‹â€‹â€‹â€‹â€‹\nBut we also know that CEEI allocation x1â€‹â€‹,â€¦,xnâ€‹â€‹ guarantees market clearing but y1â€‹â€‹,â€¦,ynâ€‹â€‹ does not, so:\nâˆ€iâˆ‘â€‹yiâ€‹â€‹â‰¤âˆ€iâˆ‘â€‹xiâ€‹â€‹\nAnd this is a contradiction. â– \nNow, for the mystical pâ€‹, we can find that by usingâ€¦\ndef. Eisenberg-Gale (EG) convex program is a Convex Programming for finding CEEI in additive utility. This maximizes:\nmaxâˆ€iâˆ‘â€‹lnÎ¼iâ€‹\nw.r.t. the following constraints:\n\nÎ¼iâ€‹=âˆ‘âˆ€jâ€‹Î¼i,jâ€‹â‹…xi,jâ€‹ â† utility is summation utility\nâˆ‘âˆ€iâ€‹xi,jâ€‹â‰¤1 â† nobody overspends\nxi,jâ€‹â‰¥0 â† no under-allocation\n\n\n Understand the KKT conditions and the derivation of the EG convex program#task\n\nthm. the EG Convex program finds the CEEI.\nProof. â– "},"Free-Cashflow":{"title":"Free Cashflow","links":["Income-Statement"],"tags":["Economics/Finance"],"content":"def. Cashflow Statement. A table showing the firmâ€™s cash in and out.\n\nD&amp;A addback: youâ€™ve already payed for the factory (un-smearing the cost)\nCapEx &amp; Salvage: money youâ€™re paying for the capital [=capital expenditure], and cash from selling the capital\nChange in Working Capital: Recieveables &amp; Payables\n\nNetÂ Income=Revenueâˆ’(COGS,Â SG&amp;A)â€‹EBITDAâ€‹âˆ’(D&amp;A+Interest)âˆ’Taxes\nFreeÂ CashÂ Flow=NetÂ Incomeâˆ’CapEx+D&amp;AÂ addbackÂ±NetÂ Recievables\ne.g. The process of valuing a firm using Free Cash Flows:\n\n\nCalculate Net Income (excl. interest, tax, etc.) from Income Statement\nCalculate Free Cashflow (w. CapEx &amp; Salvage)\nDiscount future cash flows to get Net Present Value = Firm Value\nDiscount parameter is usually obtained from investments with similar risk profiles, or the WACC formula.\n\n\n\n                  \n                  Internal Rate of Return (IRR). Itâ€™s another type of interest rate.\n                  \n                \n\n\nToo much cash isnâ€™t a good thing, because it means theyâ€™re not getting high return on capital.\n"},"Fund-(Finance)":{"title":"Fund (Finance)","links":[],"tags":["Economics/Finance"],"content":"Performance of Funds Â§\nTypes of funds that are actively managed [= âˆƒ fund manager] includes Hedge funds and Mutual funds. Comparison:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHedge FundsMutual FundsRegulations on what to investLinientStrictRegulation on who can joinStrict (only rich people)Linient (anybody)Risk ToleranceHighLowShort-selling?CanCannot (regulation)"},"Future-Value-Calculations":{"title":"Future Value Calculations","links":["Value-of-Money","Present-Value-Calculations","Interest-Rate","Banker's-Rule"],"tags":["Economics/Finance"],"content":"How to calculate the future value of some cash.\n\nA dollar now is worth more than a dollar tomorrow.\nCan be denoted in basis points as well.\nReverse of Present Value Calculations\n\nDefinitions Â§\n\nk: periods per year\nÏ„: duration (in years)\nn: number of compounding periods.\n\nn=Ï„â‹…k\n\n\nF0â€‹: Present value = Principal = Amount lent/borrowed at time t0â€‹\n\nFÏ„â€‹: Future Value = Amount at time t0â€‹+Ï„\n\n\nr: annual interest\nR: Interest Rate\n\nAlso:\n\nBankerâ€™s Rule is a common way to simplify math calculations.\nDiscountÂ Rate=1+Ï„â‹…r1â€‹.\n\ndef. Simple Interest\nâ‡’ Only principal is invested at the end of each year\nFÏ„â€‹=(1+Ï„â‹…r)F0â€‹\ndef. Compound Interest\nDivide into k periods per year, and compound for n periods:\nFnÂ periodsâ€‹=(1+krâ€‹)nF0â€‹\nDivide into k periods per year, and compound for Ï„ years (equivalent formula):\nFÏ„Â yearsâ€‹=(1+krâ€‹)Ï„kF0â€‹\nâ‡’ Conceptual Demonstration of Compounding Interest:\n\ndef. Continuous Compounding\nCompound for Ï„ years (equivalent formula):\nF(x)=eÏ„â‹…râ‹…F0â€‹\nâ‡’ You can get this formula from compound interest and setting kâ†’âˆ\ndef. Fractional Compounding\nFxâ€‹=(1+krâ€‹)xF0â€‹Â whereÂ xâˆˆR+\nâ‡’ You can do things like â€5.35Â months of daily compounding.â€\n\n\n                  \n                  Note \n                  \n                \nFor a fixed Ï„, Fkâ€‹(Ï„) is monotonic for k. â‡’ Proof in slides. (Using binomial expansion)\n"},"Futures":{"title":"Futures","links":["Forwards","tags/Short","tags/Long"],"tags":["Economics/Finance","Short","Long"],"content":"Futures contracts are same as Forwards but is exchange-traded. The pricing formula is exactly the same, but there is less counterparty risk because the exchange verifies the counterparty.\nA future is a contract that says â€œA will sell B a certain amount of resource R for $X at date N in the future.â€ This is because A wants to hedge against depreciation of R, and B appreciation of R.\n\n\nReduces risk for both parties\n\nFarmers have long position on wheat [=worry that wheat priceâ†‘]\nGeneral Mills have short position on wheat [=worry that wheat priceâ†“]\n\n\n#TotalÂ Sellers=#TotalÂ Buyers i.e.#Short =#Long positions (you canâ€™t subdivide a contract)\nUsed for liquid [=high trade volume] assets, usually highly demanded commondities like gold, oil.\nFutures Price Formula.\n\nFtâ€‹=Sâ‹…exp[(r+q)â‹…t]\n\n\nS is the spot [current] price of the commodity\n\n\nr is the riskless rate, continuous compounding at timespan (%)\n\n\nq is the carry rate, continuous compounding at timespan (%)\n\n\nt is the time to maturity (timespan)\n\n\nFutures Price &gt; Spot price (=Contango)\n\nâ€¦unless Backwardation: Futures Price &lt; Spot Price. â† This is abnormal.\n\n\n\nFutures Price converges to Spot price as it closes into maturity\n\n\n\n\n\n                  \n                  Futures Exchanges are large corporations themselves which manage these contracts. \n                  \n                \nâ€¦examples: Chicago Mechantile Exchange (CME), Tokyo Commodities Exchange (TOCOM), etc.\nâ€¦Transactors have escrow accounts to not incur fees and ensure safety of assets\nâ€¦Ensutre parties arenâ€™t bankrupt and can carry out the exchange\n\nRolling the Contract. You donâ€™t want to take delivery of the contract, but the contract is expiring soon. What you do? â‡’ You roll over the contract, i.e. sell your current contract and buy another one that matures later."},"GSF-386-Politics-of-Sexuality":{"title":"GSF 386 Politics of Sexuality","links":["GSF-Final-Planning","(Book)-The-Straight-State","(Book)-Not-Gay","(Book)-The-History-of-Sexuality","(Book)-Kids-on-the-Street","(Book)-The-Right-to-Sex","(Book)-Stagestruck","(Movie)-Stay-on-Board---The-Leo-Baker-Story-(2022)"],"tags":["Courses"],"content":"Submissions Â§\n\nEssay 1\nEssay 2\nEssay 3\nGSF Final Planning\n\nUnit 1: Theoretical Frameworks Â§\n\nDefinitions\n\n(DevonThink) Somerville, â€œQueerâ€  (p. 203-207)\n(DevonThink) Johnson, â€œQuareâ€ studies, or (almost) everything I know about queer studies I learned from my grandmother\n(DevonThink) Peiss, Charity Girls and City Pleasures\nListen: Baldwin reads Baldwin - Joey Part 1&amp;2 from Giovanniâ€™s Room Giovanniâ€™s Room â€œJoeyâ€ - Part 1 | Spotify\n\n\nLaw\n\n(Book) The Straight State\n\n\nInventions\n\nSelections from (Book) Not Gay\n(DevonThink) Ambrosino, The invention of â€˜heterosexualityâ€™\n(Book) The History of Sexuality (Volume 1: An Introduction: We â€œOther Victoriansâ€)\n\n\nQuare\n\nFebruary 9: Selections from Black Queer Studies: A Critical Anthology\n\n\n\nUnit 2: Politics and Poetics of Remembering Â§\n\nSpace\n\nAriana Vigil, â€œHeterosexualization and the State: The Poetry of Gloria AnzaldÃºaâ€\nAudrey Yue and Helen Hok-Sze Leung, â€œNotes towards the queer Asian City: Singapore and Hong Kongâ€\nRae Garringer, â€œWell, Weâ€™re Fabulous and Weâ€™re Appalachians, So Weâ€™re Fabulachiansâ€\nBecki L. Ross, â€œSex and (Evacuation from) the City: The Moral and Legal Regulation of Sex Workers in Vancouverâ€™s West End, 1975â€”1985â€ 2010\n\n\nMemory\n\nRachel Gelfand, â€œBetween Archivesâ€ Radical History Review\nHoracio N. Roque RamÃ­rez, â€œSharing Queer Authorities: Collaborating for Transgender Latina and Gay Latino Historical Meaningâ€\nElizabeth Lapovsky Kennedy, â€œTelling Tales: Oral History and the Construction of Pre-Stonewall Lesbian History\n\n\nKinship\n\n(Book) Kids on the Street\n\n\n\nUnit 3: Futures &amp; Pasts Â§\n\nPolitics &amp; Desire: (Book) The Right to Sex\nPerformance: (Book) Stagestruck\n(Movie) Stay on Board - The Leo Baker Story (2022)\nHistory\nProject Week!\n"},"GSF-Final-Planning":{"title":"GSF Final Planning","links":["(Movie)-Queer-Japan-(2019)","(Book)-æ­´å²ã®ä¸­ã®å¤šæ§˜ãªã€Œæ€§ã€","(Book)-ã€Œç”˜ãˆã€ã®æ§‹é€ ","(Article)-On-Liking-Women--Andrea-Long-Chu","(Book)-The-Straight-State","(Book)-The-Right-to-Sex","(Paper)-Notes-towards-the-queer-Asian-city---Singapore-and-Hong-Kong"],"tags":["Philosophy/Queer-Theory"],"content":"Sources Â§\n\n(Movie) Queer Japan (2019)\nâ€œAudrey Yue and Helen Hok-Sze Leung, â€œNotes towards the queer Asian City: Singapore and Hong Kongâ€\n(Book) æ­´å²ã®ä¸­ã®å¤šæ§˜ãªã€Œæ€§ã€\n\n(DevonThink) è»é‡ãƒ»ç¾ç©‚ã€ä¸‰æ©‹é †å­è‘—ã€æ­´å²ã®ä¸­ã®å¤šæ§˜ãªã€Œæ€§ã€ã€ã‚’èª­ã‚€\nä¸‰æ©‹é †å­ | ä¹™å¥³å¡¾ (interviews)\n\n\n(Book) ã€Œç”˜ãˆã€ã®æ§‹é€ \n\n(DevonThink) ã€Œç”˜ãˆã®æ§‹é€ ã€ã‚’èª­ã‚€- ã‚¹ãƒšã‚¯ãƒˆãƒ©ãƒ ã«é‡å­çš„\n\n\n(Article) On Liking Women  Andrea Long Chu\nCanaday, (Book) The Straight State\nSrinivasan (Book) The Right to Sex\nMinor: Jameson The political unconscious.pdf\n(DevonThink) Communist Manifesto\n\nStructure Â§\n\nConstruction of sexual spaces and identity in pre-modern history\n\npoint: Japan has spaces, US has identity\nU.S. construction through law\nJapan (edo period â† pre-modern precursor)\n\nconstruction of ç”·è‰²\nKabuki, etc.\n\n\nYue &amp; Leungâ€™s etymology suggest tradition vs society here, the western perspective. Mitsuhashi says itâ€™s imported.\n\n\nReification of desire into a clash of spaces/identity\n\nQueer Defined spaces in historic Japan\n\nIntroduce â€ ç”·è‰², definition\nåŒæ€§åŸç†â€“religious\nPaganist cultures readily accept (india), but europe doesnâ€™tã€Œç¥ã«è¿‘ã¤ã‚™ãè¡Œç‚ºã¦ã‚™ã‚ã‚‹å¥³è£…ãƒ»ç”·è£…ã¯å³ã—ãç¦ã—ã‚™ã‚‰ã‚Œã€(50)\næ­´å²ã®ä¸­ã«è¦‹ã‚‰ã‚Œã‚‹ã®ã¯ã€ŒåŒæ€§é–“æ€§æ„›ã€ã¦ã‚™ã¯ã‚ã£ã¦ã‚‚ã€ãã‚Œã¯äººã®æ€§çš„æŒ‡ å‘ã‚’ç•°æ€§æ„›ã‹åŒæ€§æ„›ã‹ã¨å›ºå®šçš„ãƒ»å¯¾ç«‹çš„ã«ã¨ã‚‰ãˆã‚‹æ¦‚å¿µã¦ã‚™ã‚ã‚‹ã€ŒåŒæ€§æ„›ã€ã¨ã¯ä¼¼ã¦éãªã‚‹ã‚‚ã®ã¦ã‚™ã‚ã‚‹ã¨ä¸»å¼µã™ã‚‹ã€‚\n\nInternesting point: Mitsuhashi, 4 categories of ç”·è‰²; first three shown in history, last only modern. But last is what western though considers â€œgayâ€\n\n\nFTM\nDeveloping: é™°é–“èŒ¶å±‹ - Wikipedia during edo period MJ\n\n\nOpposite of what a western historical record of queer of identity is: We the other victorians: brother and mental hospitals, taboo, nonexistence, silence.\n\nModern influenced: bring in Yue â€œconfucian norms not able to acceptâ€; they canâ€™t even justify it\n\nInstead, this is what it is\n\n\nSmoking gun, MJ: Christianity caused it\n\n\nBringing in western thought caused â€œGID illnessâ€ â€œlaw &amp; punishmentâ€\n\n\nModern Japan: Spaces and identity\n\nPoint: bringing in identity is inapplicable:\n\n^0212a3\n\nSumiko: GID? no, just lesbian\nGengoroh: sex, not love. (danshoku-style)\n\n\n\n\nPoint: Interaction between spaces and identity. Space has always been available in Japan, not as oppositions to the mainstream but part of it.\n\nSelf-identity is defined through spaces (US) vs. spaces define self-identity (japan\n\nSee goldfinger vs grammy tokyo conflict. Itâ€™s because youâ€™re living as a man youâ€™re not allowed, not because you are existentially a man.\n\n\nReason out more: Queer defined spaces in modern japanâ€”Conflict is between spaces in japan, and identity in the US.\n\nAdvertising of sexuality as â€œinherentâ€ in the US for acceptance vs. Separation of spaces in Japan for acceptance\n\n\n\n\n\n\nDesire as the fundamental element of japanese queer-ness (as opposed to what is correct/moral/ethical)\n\nBuddhism &amp; shinto doesnâ€™t anti-trans (ä¸‰æ©‹ï¼šã€Œæ—¥æœ¬ã¯ãƒˆãƒ©ãƒ³ã‚¹ã‚¸ã‚§ãƒ³ãƒ€ãƒ¼ã¨ã—ã¦å¤©å›½ã€)\n\n\n"},"Game-Theory":{"title":"Game Theory","links":["Rationality-(Economics)","Institutional-Design","Philosophy,-Political-Science,-Economics","Random-Variable","Equilibria-in-Game-Theory","Oligopoly","Cartels-and-Collusion","Bertrand-Price-Competition","Cornout-Quantity-Competition","Battle-of-the-Sexes","Prisoner's-Dillemma","Signaling-Game","Rock-Paper-Scissors","Traffic-Routing"],"tags":["Economics/Game-Theory","Economics/Micro-Economics"],"content":"A theory of interaction between rational agents.\n\nInstitutional Design is the field in public policy &amp; PPE that makes sure game theory &amp; agent incentives are taken into account\nItâ€™s part of economics because itâ€™s about rational agents interacting\n\nGame Â§\ndef. Game. Assuming n players:\n\nSiâ€‹: Strategy space of player i\ns=(s1â€‹,s2â€‹,â€¦,snâ€‹): which strategy combination happened.\nc1â€‹(s),c2â€‹(s),â€¦,cnâ€‹(s): associated cost of s happening for each player\n\nTypes of Games Â§\n\nTiming:\n\nStatic (=Simultaneous)\nDynamic (=Sequential Move)\n\n\nStrategy Formulation:\n\nPure Strategy: deterministic mapping from information set to action set \nMixed Strategy: probabilistic mapping that depends on a Random Variable\n\n\nInformation availability:\n\nComplete Information\nIncomplete Information\n\n\nRepetition:\n\nOne-off,\nFinite-Repetition,\nInfinite-Repetition\n\n\nPayoff structure:\n\nZero-sum: each strategy tuple sums to zero\nPositive/Negative Sum\n\n\n\nEquilibria Types Â§\nâ†’ See Equilibria in Game Theory\n\nStatic, Pure, One-offâ†’ Nash Equilibrium\nDynamic, Pure â†’ Subgame Perfect Nash Equilibirum\nStatic, Incomplete, (Pure or Mixed) â†’ Baysian Nash Equilbilibrium (BNE)\nDynamic, Incomplete, (Pure or Mixed) â†’ Subgame Perfect Baysian Nash Equilibirum (PBE)\n\nGames Modeled by Game Theory Â§\n\n\n                  \n                  (DevonThink) Game Theory List of Games for many types of simultaneous game&#039;s payoff matricies.\n                  \n                \n\n\nOligopoly Games\n\nCartels and Collusion\nBertrand Price Competition\nCornout Quantity Competition\n\n\nBattle of the Sexes\nPrisonerâ€™s Dillemma\n\nPublic Good Game\n\n\nSignaling Game\nStag Hunt\nAssurance Game\nChicken Game\nRock Paper Scissors\nTraffic Lights\nTraffic Routing\n\nNotation Â§\n\nStrategy Tuple of player A is denoted SA=(S1Aâ€‹,S2Aâ€‹)\nPayoff to player A given strategy SA by A, SB by player B, etc.\nâ‡’ is denoted Ï€A(SA,SBâ€¦)\n\nAlternatively, Cost is given as: CAâ€‹(SA,â€¦)\n\n\nNash Equilibria are Tuples: NE=(S1Aâ€‹,S2Bâ€‹)\n\nIn a simultaneous game, all playerâ€™s strategy should be specified\nIn a sequential game, the second player (=follower)â€™s strategy should include the response for all of the first player (=leader)â€™s moves.\n\nNotation: SPE=(S1Aâ€‹;S1Bâ€‹,S2Bâ€‹)\n\n\n\n\n\nBranches of Game Theory Â§\n\nExperimental game theory\nEvolutionary game theoryâ€”using game theory to explain strategies that affect natural selection\nApplied game theory\n"},"Gamma-Distribution":{"title":"Gamma Distribution","links":["Central-Limit-Theorem"],"tags":["Math/Common-Distributions"],"content":"def. Gamma Distribution. In a Poisson Point Process with intensity Î», let Wiâ€‹ be the â€œwait timesâ€ between the iâˆ’1 -th and i-th event. let X be the total â€œwait timeâ€ for r events; i.e. X=W1â€‹+â‹¯+Wrâ€‹. Then X is distribued over Gamma:\nXâˆ¼Î“(r,Î»)fXâ€‹(x)={Î»eâˆ’Î»x(râˆ’1)!(Î»x)râˆ’1â€‹1â€‹x&gt;0elseâ€‹FXâ€‹(t)=1âˆ’k=0âˆ‘râˆ’1â€‹eâˆ’Î»tk!(Î»t)kâ€‹E(X)=Î»râ€‹Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â SD(X)=Î»râ€‹â€‹â€‹\n\n\n                  \n                  Tip \n                  \n                \n\nGamma Distribution also follows the Central Limit Theorem. Thus limrâ†’âˆâ€‹Xâˆ¼Normal"},"Gaussian-Splatting":{"title":"Gaussian Splatting","links":["NERF"],"tags":["Computing/Graphics"],"content":"Intuitive Understanding:\n\nhttps://www.youtube.com/watch?v=VkIJbpdTujE\n\n\nImprovement over NERFs (pure neural network)\n\n3-D Gaussians (3d bell curve) is fulled\n\nStart with simple gaussian, use gradient descent to fit the scene better\nColor harmonics, blending to achieve realism\n\n\n\nRasterization is so much faster because traditional triangle rendering has so much more triangles, but GS uses much less gaussians\n\n"},"Gender-is-a-performance":{"title":"Gender is a performance","links":["Pride"],"tags":["Philosophy/Queer-Theory"],"content":"Pride"},"Generalized-Likelihood-Ratio-Test":{"title":"Generalized Likelihood Ratio Test","links":[],"tags":["Math/Statistics"],"content":"thm. Generalized Likelihood Ratio Testing (GLT). Comparing Hypotheses:\n\n\nH0â€‹âˆˆÎ˜0â€‹\n\n\nH1â€‹âˆˆÎ˜1â€‹\nThe Generalized Likelhood Ratio is:\n\n\nÎ›~=supÎ¸âˆˆÎ˜0â€‹â€‹L(Î¸)supÎ¸âˆˆÎ˜0â€‹âˆªÎ˜1â€‹â€‹L(Î¸)â€‹=usuallyL(Î¸^MLEâ€‹)L(Î¸0â€‹)â€‹\nThe Generalized Likelihood Ratio Test (GLT) is:\nÎ´:{H0â€‹H1â€‹â€‹elseÂ ifÂ Î›~&gt;câ€‹\n\n\n                  \n                  \\tilde \\Lambda is often very hard to manipulate. Use Wilkâ€™s phenomenon in order to approximate the cutoff regions.\n                  \n                \n\n\n\nthm. Wilkâ€™s Phenomenon. For Hypotheses\n\n\nH0â€‹âˆˆÎ˜0â€‹ â† r0â€‹ dimentions\n\n\nH1â€‹âˆˆÎ˜1â€‹ â† r1â€‹ dimensions\ni.e. H0â€‹âŠ‚H1â€‹ then:\n\n\n\n\n2lnÎ›dâŸ¶nâ†’âˆâ€‹â€‹Ï‡r1â€‹âˆ’r0â€‹2â€‹"},"Gini-Coefficient":{"title":"Gini Coefficient","links":[],"tags":["Economics/Macro-Economics","index"],"content":"measures inequality."},"Girlhood-&-Womanhood":{"title":"Girlhood & Womanhood","links":[],"tags":["Philosophy/Queer-Theory","Sociability"],"content":"Girls are more cliquey in America."},"Git-for-Every-Minimal-Incremental-Feature":{"title":"Git for Every Minimal Incremental Feature","links":["Atomic"],"tags":["Computing"],"content":"Atomic git commits. Commit every time you implement the smallest chunked chage. You should have many commits in a single day."},"Global-Industry-Classification-Standard":{"title":"Global Industry Classification Standard","links":["Commodities","Real-Estate"],"tags":["Economics"],"content":"classified industries into:\n\nEnergy\nMaterials\nIndustrials\nConsumer Discresionary\nConsumer Staples\nHealthcare\nFinancials\nInformation Technology\nCommunication Services\nUtilities\nReal Estate\n"},"Graph":{"title":"Graph","links":["Tree","Directed-Graph","Directed-Acyclical-Graph","assets/Screenshot-2023-10-25-at-21.15.21.png","assets/Screenshot-2023-10-25-at-21.14.48.png"],"tags":["Math","Computing"],"content":"def. Graph. A Graph is defined as:\n\nOrdered pair (V,E) where\n\nV is the set of all vertices\nE={x,yâˆ£x,yâˆˆVÂ andÂ xî€ =y}\n\n\n\nTypes of Graphs Â§\n\nVariations on:\n\nDirected or Undirected\nConnected or Not Connected\nCyclical or Acyclical\n\n\nCommon types:\n\nTree is a connected undirected acyclical graph\n\nForest is a set of trees\n\n\nDirected Graph\n\nDirected Acyclical Graph\n\n\n\n\n\nProperties of Graphs Â§\n\nDegree of a vertex vâˆˆV: number of edges that connect to v\nLoop: an edge that connects a vertex to itself\nCycle: a path that starts and ends with the same vertex\n\nRepresentation of Graphs in Memory Â§\n\nAdjacency Matrix\n\n2D table of all nodes: Store a 1 if the edge between two nodes exists, 0 otherwise. Example\n\n\nAdjacency List\n\nArray of all vertices, which are also linked list that list all reachable neighbors. Example\n\n\n\n\nComplexities for the two types of representations: \n\nPaths Â§\n\nv1â€‹â†’v2â€‹â†’â‹¯â†’vkâ€‹\nA Simple Path is one that does not repeat verticies\n\nSpecial Variants Â§\n\nA Metric weighted graph is where the edge weights satisfy the triangle inequality; i.e. the vertices lie on a surface, and the edges are Euler distances of the verteces\n"},"Greedy-Algorithm":{"title":"Greedy Algorithm","links":["Proof-by-contradiction","Interval-Scheduling","Proof-by-Contradiction","Scheduling-Problem","Minimal-Spanning-Tree-Problem"],"tags":["Computing/Algorithms"],"content":"\n\n                  \n                  Be Skeptical of Greedy Algorithms \n                  \n                \n\n\n\nOften for optimization problems (minimize/maximize)\nHard to argue for correctness\n\nUse Proof by contradiction, or the exchange argument\n\n\nWorks well for approximating optimal solutions\n\nWhen the correct algorithm is intractable (O(2n)), then often the greedy solution that is O(nk) is useful (=tractable)\n\n\nGradient descent is a greedy optimization algorithm.\n\nLinear optimization algorithms are â€œanalyticalâ€ and correct, but take lots of time.\nGradient descent algorithms (all of ML) is greedy, but not the global optimum solution. Theyâ€™re â€œgood enoughâ€ and â€œtractableâ€\n\n\n\nProof of Correctness Â§\n\nFeasibility: there is an algorithm that gives a solution that obeys the constraints of the problem\nOptimality: the algorithmâ€™s solution is the best possible. Use either:\n\nProof by Contradiction\n\nLet solution by greedy algorithm solution A.\nAssume there is a more optimal solution Oâˆ—\nThen derive a contradiction\n\n\nExchange Argument\n\nLet solution by greedy algorithm solution A\nAssume there is a optimal solution Oâˆ—\nBy exchanging individual elements which donâ€™t reduce optimality, slowly show A is at least as good as Oâˆ—\n\n\nStaying Ahead\n\nAt every stage of the greedy algorithm, show that it is at least as good as the optimal solution\n\n\n\n\n\nExamples\n\nScheduling Problem\nMinimal Spanning Tree Problem\n"},"Greeks-(Option)":{"title":"Greeks (Option)","links":["Black-Scholes-European-Option-Pricing-Formula","Normal-Distribution"],"tags":["Economics/Finance"],"content":"\nNotation is equivalent to the BSM formula.\nDerivative of CDF of Normal Distribution\n\n\nDelta Â§\nÎ”C,Sâ€‹Î”C,Kâ€‹â€‹:=âˆ‚Sâˆ‚Câ€‹:=âˆ‚xâˆ‚Câ€‹âˆ£x=Stâ€‹â€‹:=âˆ‚Kâˆ‚Câ€‹â€‹=eâˆ’q(Tâˆ’t)N(d1â€‹)=eâˆ’r(Tâˆ’t)N(d2â€‹)â€‹â€‹\nTable of Deltas for Call/Put options as execution time approaches.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntâ†’T or Ï„â†’0â€‹At the Money CallStâ€‹âˆ’K=0In the Money CallStâ€‹âˆ’K&gt;0Out of the Money CallStâ€‹âˆ’K&lt;0d1â€‹0âˆâˆ’âˆN(d1â€‹)21â€‹10Î”Câ€‹21â€‹10Î”Pâ€‹âˆ’21â€‹0âˆ’1For putsAt the money PutKâˆ’Stâ€‹=0Out of the Money PutKâˆ’Stâ€‹&lt;0In the Money PutKâˆ’Stâ€‹&gt;0\nGamma Â§\nÎ“Câ€‹:=âˆ‚S2âˆ‚2Vâ€‹=Î“Pâ€‹=Stâ€‹ÏƒÏ„â€‹eâˆ’qÏ„Nâ€²(d+â€‹)â€‹\nTheta Â§\nÎ˜Câ€‹:=âˆ‚Ï„âˆ‚Vâ€‹Î˜Pâ€‹:=âˆ‚Ï„âˆ‚Vâ€‹â€‹=âˆ’Stâ€‹eâˆ’qÏ„ÏƒNâ€²(d+â€‹)=âˆ’Stâ€‹eâˆ’qÏ„ÏƒNâ€²(d+â€‹)â€‹+qStâ€‹eâˆ’qÏ„N(d+â€‹)âˆ’qStâ€‹eâˆ’qÏ„N(âˆ’d+â€‹)â€‹âˆ’rKeâˆ’rÏ„N(dâˆ’â€‹)+rKeâˆ’rÏ„N(âˆ’dâˆ’â€‹)â€‹â€‹"},"Greibach-Normal-Form":{"title":"Greibach Normal Form","links":[],"tags":["Computing/Formal-Languages"],"content":""},"Gross-Domestic-Product":{"title":"Gross Domestic Product","links":[],"tags":["Economics/Macro-Economics","index"],"content":"GDP can be calculated by the following three methods:\nGDP Â§\nDefined equivalently in 3 ways:\nGDP=Yâ€‹=f(l,k)=Ilâ€‹+Ikâ€‹+Ï€+tax=C+I+Gdeficitâ€‹+NEâ€‹â€‹\n\n(1) uses the production function f(l,k) against the whole economy\n(2) uses the Income method\n(3) uses the Output method. Generally, C&gt;G&gt;I&gt;NE.\n\nConsumption is stable in recessions because you need to eat; Investment suffers\nGovernment spending composes around 1/3 in US, 1/2 is EU\nNote that NEâˆ’Exportâˆ’Imports and thus Net Exports can be negative.\n\n\n\nğŸ“ Observee (2) and (3) are same because the macroeconomic circular flow is a closed loop.\n\n\nHistorically, the LR trend of GDP has been growing exponentially since the industrial revolutionâ€¦\n\nâ€¦GDP per capita [â†a better measure of well-being] is growing tooâ€¦\nâ€¦Consumption per capita [â†an even better measure of well-being] is growing too!\nThis growth seems to be coming from growth in labor income, while capital income is stagnant.\n\n\nShort-run fluctuations in GDP are due to the business cycle.\nSome economic activity is not in GDP:\n\nInformal market (big in some countries; e.g. 1/3 in Brazil)\nHome production; i.e. homemaking\n\n\n\nCalculation Methods Â§\n\n\nOutput [= production] method\nYâ€‹=VA1â€‹+VA2â€‹+â‹¯=(P1â€‹)+(P2â€‹âˆ’P1)+â‹¯â€‹\n\n\nExpenditure method:\nY=C+I+G+NX\nâ†’ C is only for final sales, not for intermediate goods. Final sales are always to the household.\n\n\nIncome method\nY=IKâ€‹+INâ€‹+Ï€+t\nâ†’ Note that firms pass on their taxes to the consumer (HH), or corporate taxes are paid by entrepreneurs who are at the end of the day HHs.\n\n\nGNI [= GNP] Â§\n\nGNI method\nYD=IKDâ€‹+INDâ€‹+Ï€+t\nâ€¦t if both incomes are pre-tax incomes\nGNP method\nYD=C+I+G+NX+NI\nâ€¦where NI is the net domestic income (inflow - outflow)\n\nDeflator &amp; CPI Â§\n\n\nDeflator is the reduction of nominal GDP in years after the base year due to inflation.\n\n\nDeflator=YRealYNominalâ€‹â‹…100\nâ€¦thus the real gdp for year i is calculated YiRâ€‹=Deflatoriâ€‹YiNâ€‹â€‹â‹…100\n\nDeflator is 100 in the base year\nDeflator âˆ inflation rate\n\n\n\nCPI is another index to reduce the nominal GDP. Assume the current year is i, base year b\n\n\nCPIcurrentâ€‹=âˆ‘pbaseqbaseâˆ‘pcurrentqbaseâ€‹â‹…100=YofÂ baseinÂ currentÂ dollarsâ€‹YofÂ baseinÂ currentÂ dollarsâ€‹â€‹â‹…100â€‹\nâ€¦thus the real gdp for year i is calculated YiRealâ€‹=CPIiâ€‹YiNominalâ€‹â€‹â‹…100"},"Ground-Truth":{"title":"Ground Truth","links":[],"tags":["Math/Statistics"],"content":"the actual true value, or the current idealized value of a r.v."},"Growth-Rate-Calculations":{"title":"Growth Rate Calculations","links":["Malthusian-Growth","Gross-Domestic-Product","Industrial-Revolution"],"tags":["Economics/Macro-Economics"],"content":"\nGrowth of GDP is exponential since the Industrial Revolution\nGrowth Rate is always quoted as the exponential growth rate eg\nGrowth rate itself is mostly constant\n\nYtâ€‹=Ytâˆ’1â€‹â‹…egegâ‰ˆYtâˆ’1â€‹Ytâ€‹â€‹â‰ˆYtâˆ’nâˆ’1â€‹Ytâˆ’nâ€‹â€‹\n\nPredicting growth into the future: Ytâˆ’nâ€‹â‹…enâ‹…g=Ytâ€‹\nAdding growth rates: gxâ€‹=gyâ€‹+gzâ€‹\ne.g. Ynominal=PriceÂ Levelâ‹…Yreal\nâ‡’ gYnominal=gpriceÂ level+gYreal\nDividing growth rates: gaâ€‹=gbâ€‹âˆ’gcâ€‹\ne.g. GDPÂ perÂ Capita=populationYâ€‹\nâ‡’ gGDPÂ perÂ Cap.=gYâˆ’gpopulation\nfunction of growth rate:\nlet A=f(B) then gaâ€‹=âˆ‚Bâˆ‚Aâ€‹â‹…f(B)Bâ€‹â‹…gbâ€‹\ne.g.2. Y=KÎ±N1âˆ’Î± â‡’ elasticity gY=Î±gÎ±â€‹+(1âˆ’Î±)gNâ€‹\n"},"Hacking-Flash-Apps":{"title":"Hacking Flash Apps","links":[],"tags":["Computing"],"content":"https://github.com/jindrapetrik/jpexs-decompiler is a flash decompiler and ide. Edit flash source &amp; view assets, etc.\nhttps://github.com/ruffle-rs/ruffle is a emulator for flash written in rust. It doesnâ€™t support all of the API yet. If you look at the FAQ thereâ€™s a link to a webarchiveâ€™s archive of adobeâ€™s flash debugger tools. Itâ€™s in google drive.\nSwiftchan is an archive of .swf files (mainly flash games)."},"Hash-Table":{"title":"Hash Table","links":[],"tags":["Computing/Data-Structures"],"content":"Hash table - Wikiwand\n\n\n                  \n                  Tip \n                  \n                \nThe nice thing about hash tables is that most algorithms are O(1) unless hash collisions occur.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAlgorithmAverageWorst caseSpaceÎ˜(n)O(n)SearchÎ˜(1)O(n)InsertÎ˜(1)O(n)DeleteÎ˜(1)O(n)"},"Hashing-Algorithms":{"title":"Hashing Algorithms","links":[],"tags":["Computing/Algorithms"],"content":"def. Hash Function. A function that maps data to a hash table.\n\nData is denoted SâŠ‚U (=Universe)\n\nUniverse can be continuous or discrete\n\n\nHash table T has m slots, thus T=[m]\n\n[m]:={0,â€¦,mâˆ’1}, [m]+:={1,â€¦,mâˆ’1}\nAccess time is O(1)\n\n\nh(x) is the hash function that takes in data point x\n\nUniform Hash Function Â§\ndef. Uniformity. A hash function is uniform iff:\nâˆ€iâˆˆ[m],Â P[h(x)=i]=m1â€‹\ne.g. Modular Hash Function.\nh(x)=xÂ modÂ m\n\nIf x is random, P[h(x)=i]=m1â€‹\n\nUniversal Hash Function Â§\nalg. Universal Hashing. A hash function is universal iff:\nâˆ€xî€ =yÂ P[h(x)=h(y)]â‰¤m1â€‹\n\nInitialization: Choose a random h from family H\nUse that h(x) for all future hashing needs for that dataset\nâ‡’ probability of collision is m1â€‹\n\ne.g. Universal Modular Hash Function.\ndef. Linear Congruence Hashing (integer key)\n\nChoose a very large prime number p (bigger than the number of things you need to hash=âˆ£Uâˆ£)\nConstruct a hash table of size m\nConstruct a family of hash functions H={ha,bâ€‹(x)=(ax+bÂ modÂ m)Â modÂ m}âˆ£a,b&lt;p\nâ‡’ H is a universal family\n\ndef. Multiply-Shift Binary Hashing (integer key) (SotA)\n\nCollision Â§\ndef. Collision Probability.\nAlternative Techniques Â§\nDouble Hashing Â§\n\n\nConstruction: Sâ†’hTâ†’hiâ€‹Tiâ€‹\nTiâ€‹: the secondary hash table\nSiâ€‹: set that denotes all the elements hashed to Tiâ€‹. Depends on what S, the data, actually is\n\nE[Siâ€‹]â‰ˆmnâ€‹\nFor some slack, we usually make the secondary hash table âˆ£Tiâ€‹âˆ£=O(âˆ£Siâ€‹âˆ£2)\n\n\n\nBloom Filters Â§\n\nFrom a family of hash functions H choose k different functions h1â€‹â€¦hkâ€‹\nInitialize boolean array T which has size m\n\n\nInsert(x)\n\ncalculate h1â€‹(x),â€¦hkâ€‹(x) and store them into T[h1â€‹(x)]â€¦T[hkâ€‹(x)].\nIf thereâ€™s alreay a 1 in the table, keep it that way\n\n\nSearch(x)\n\ncalculate h1â€‹(x),â€¦hkâ€‹(x)\nIf all of T[h1â€‹(x)]â€¦T[hkâ€‹(x)] returns 1, itâ€™s highly likely that it is present.\n\n\n(false positive rate=) Probability that search(x) returns True, even if xâˆˆ/S: â‰ˆ(1âˆ’eâˆ’kn/m)kâ€¦â€¦(1)\n\n\n\n\n(1)â€¦â€¦n is not really known. m is limited by memory. So choose k as big as possible\n\nk=ln2â‹…nmâ€‹ is good â‡’ false positive search(x) is â‰ˆ0â€‹.\n\n\nProbability that bit B[j]=0 is (1âˆ’m1â€‹)kâˆ£Sâˆ£\n"},"Hedonism":{"title":"Hedonism","links":["Drugs-Catalogue","Desire","Functional-Daily-Life"],"tags":["Philosophy"],"content":"\nDrugs Catalogue\nDesire\n\nHedonism is not bad if you can live a normal life.\n\n\n                  \n                  If it&#039;s not life-ruining drugsâ€¦ \n                  \n                \n"},"Hedonistic-Utilitarianism":{"title":"Hedonistic Utilitarianism","links":[],"tags":["Philosophy/Ethics"],"content":"Morality is Simply a Discussion of Suffering Â§\nAll of ethics and morality is a discussion of pain and suffering, and who has it."},"Heteronormativity":{"title":"Heteronormativity","links":[],"tags":["Philosophy/Queer-Theory"],"content":""},"Historical-Materialism":{"title":"Historical Materialism","links":["Proletatriat-(Marxism)"],"tags":["Philosophy/Marxism"],"content":"Productive Forces, RoP, Historical Progression Â§\n\n[Capitalism] has pitilessly torn asunder the motley feudal ties that bound man to his â€œnatural superiorsâ€, and has left remaining no other nexus between man and man than naked selfinterest, than callous â€œcash paymentâ€. [â€¦] It has resolved personal worth into exchange value, and in place of the numberless indefeasible chartered freedoms, has set up that single, unconscionable freedomâ€”Free Trade.\n\n\nIt has converted the physician, the lawyer, the priest, the poet, the man of science, into its paid wage labourers.\n\n\nProductive forces are the steady march of technology which drive economic growth through â€œgood ideasâ€ and efficiency.\nRelations of production are the social institutions that facilitate (or hinder) productionâ€”the context within which production occurs\nâ†’ Think: patent systems (transforming ideas into property), protection of proptery, chattle slavery\n\n\nDirection of History Â§\n\nOur epoch, the epoch of the bourgeoisie, possesses, however, this distinct feature: it has simplified class antagonisms. Society as a whole is more and more splitting up into two great hostile camps, into two great classes directly facing each otherâ€”Bourgeoisie and Proletatriat (Marxism).\n\nFeudalistic society i.e. guilds + birth-determined rank â†’ Capitalist Society i.e. private property, wage-labor\nâ†’ Productive forces has outgrown capitalismâ€”â€specture haunting Europeâ€\nâ‡’ Constant change in ideas, innovation, striving for growth, and societal thought, idealology changed to serve its mode of production\n\nAll fixed, fast-frozen relations, with their train of ancient and venerable prejudices and opinions, are swept away, all newformed ones become antiquated before they can ossify. All that is solid melts into air, all that is holy is profaned, and man is at last compelled to face with sober senses his real conditions of life, and his relations with his kind.\n\nâ‡’ BZ RoP destroys national boundaries, cosmopolitan nature of production as it brings together global supply of goods into global consumer demand (ultimately, the â€œepidemic of overproductionâ€)\n\nThe bourgeoisie has through its exploitation of the world market given a cosmopolitan character to production and consumption in every country.\n\n\nIt compels all nations, on pain of extinction, to adopt the bourgeois mode of production; it compels them to introduce what it calls civilisation into their midst, i.e., to become bourgeois themselves. In one word, it creates a world after its own image.\n\nâ‡’ Ultimately consuming the whole world economy into its RoP\n\nCommunism is the necessary form and the dynamic principle of the immediate future, but communism is not as such the goal of human developÂ­ meant - the form of human society.9\n\nand communism is thus inevitable:\n\nenough. In order to supersede private property as it actually exists, real communist activity is necessary. History will give rise to such activity, and the movement which we already know in thought to be a self-superseding moveÂ­ meant will in reality undergo a very difficult and protracted process.\n\nbecause the brotherhood of man is real\n\nThe brotherhood of man is not a hollow phrase, it is a reality, and the nobility of man shines forth upon us from their work-worn figures.\n\n\n\n[â€¦] in one word, the feudal relations of property became no longer compatible with the already developed productive forces; they became so many fetters. They had to be burst asunder; they were burst asunder.\n\n\na society that has conjured up such gigantic means of production and of exchange, is like the sorcerer who is no longer able to control the powers of the nether world whom he has called up by his spells.\n\nâ‡’ When PF outgrows RoP, naturally PF wins; i.e. communism is inevitable. Feudalism to Capitalism, Capitalism to Communism\nCurrently we observe this as the epidemic of overproduction:\n\n[â€¦] the epidemic of over-production. Society suddenly finds itself put back into a state of momentary barbarism [â€¦] And how does the bourgeoisie get over these crises? On the one hand by enforced destruction of a mass of productive forces; on the other, by the conquest of new markets, and by the more thorough exploitation of the old ones.\n"},"Homogenous-Function":{"title":"Homogenous Function","links":["Monotonic-Transformation"],"tags":["Economics","Math"],"content":"def. Homogenous production function\nf(xz,xK,xN)=xÎ»f(z,K,N)\n\n\nz: Productivity\n\n\nK: Capital\n\n\nN: Labor\ni.e. if the inputs are multiplied by x, the output is multiplied by xÎ».\nâ‡’ We say: â€f is a homogenous function of degree Î»â€\n\n\nThis implies we have increasing returns to scale\n\n\nMonotonic Transformation of a homogenous function is also homogenous.\n\n"},"Hotelling's-Lemma":{"title":"Hotelling's Lemma","links":[],"tags":["Economics/Micro-Economics"],"content":"âˆ‚pâˆ‚Ï€(w,r,p)â€‹âˆ‚wâˆ‚Ï€(w,r,p)â€‹âˆ‚râˆ‚Ï€(w,r,p)â€‹â€‹=x(w,r,p)=âˆ’l(w,r,p)=âˆ’k(w,r,p)â€‹outputÂ supplylaborÂ demandcapitalÂ demandâ€‹â€‹"},"Huffman-Text-Compression-Algorithm":{"title":"Huffman Text Compression Algorithm","links":[],"tags":["Computing/Algorithms"],"content":"The Huffman algorithm is the most efficient single-text compression for text.\nHow Computers Compress Text: Huffman Coding and Huffman Trees - YouTube\n\nProven to be most efficient for single-character compression\nUses a complete binary tree to store data\nIs a optimization problem.\n\nExample of Huffman Tree.\n\nNumber indicates summed frequency\n0: left, 1: right\n\n0010 encodes n\n111 encodes (blank)\n\n\nâ‡’ The more frequent the letter, the shorter the encoding is\nNo encoding is a prefix of any other tree (each letter is encoded by different number of bits)\n\n"},"Human-Development-Index":{"title":"Human Development Index","links":["United-Nations"],"tags":["Economics","index"],"content":"Published by the United Nations"},"Humanism":{"title":"Humanism","links":[],"tags":["Philosophy"],"content":"\nHumanism is a philosophical stance that emphasizes the individual and social potential, and agency of human beings, whom it considers the starting point for serious moral and philosophical inquiry.\nThe meaning of the term â€œhumanismâ€ has changed according to successive intellectual movements that have identified with it. During the Italian Renaissance, ancient works inspired Italian scholars, giving rise to the Renaissance humanism movement. During the Age of Enlightenment, humanistic values were re-enforced by advances in science and technology, giving confidence to humans in their exploration of the world. By the early 20th century, organizations dedicated to humanism flourished in Europe and the United States, and have since expanded worldwide. In the early 21st century, the term generally denotes a focus on human well-being and advocates for human freedom, autonomy, and progress. It views humanity as responsible for the promotion and development of individuals, espouses the equal and inherent dignity of all human beings, and emphasizes a concern for humans in relation to the world.\nStarting in the 20th century, humanist movements are typically non-religious and aligned with secularism. Most frequently, humanism refers to a non-theistic view centered on human agency, and a reliance on science and reason rather than revelation from a supernatural source to understand the world. Humanists tend to advocate for human rights, free speech, progressive policies, and democracy. People with a humanist worldview maintain religion is not a precondition of morality, and object to excessive religious entanglement with education and the state.\nContemporary humanist organizations work under the umbrella of Humanists International. Well-known humanist associations are Humanists UK and the American Humanist Association.\nWikipedia\n\nThe principle of inherent life value\nì§ì—…ì— ê·€ì²œì€ ì—†ë‹¤"},"Hypergeometric-Distribution":{"title":"Hypergeometric Distribution","links":[],"tags":["Math/Common-Distributions"],"content":"def. Hypergeometric Distribution. Describes probabilities with successive draws without replacement. In a population of N with K members containing the feature, among n trials the probability of drawing k with the feature is:\nXP(X=k)â€‹âˆ¼Hypergeometric[N,K,n]=(knâ€‹)Nnâ€‹Kkâ€‹(Nâˆ’K)nâˆ’kâ€‹â€‹=(nNâ€‹)(kKâ€‹)(nâˆ’kNâˆ’Kâ€‹)â€‹â€‹\ndef. Geometric Distribution. let X s.t. Range(X)=N, where X is the number of trials until the first success, and success probability is p. X is Geometrically p-Distributed:\nXâˆ¼Geom(p)P(X=k)=p(1âˆ’p)kâˆ’1\n\nwhere X is the number of total trials and p is the probability of an eventâ€”normally, geometric distributions are used to model the number of successful events before a failure.\ne.g. the number of basketball free throws until a failure\nE(X)=p1â€‹\nSD(X)=p1âˆ’pâ€‹â€‹\n\n\n\n                  \n                  Info \n                  \n                \n\nY=Xâˆ’1 is also a geometric distribution; the number of failures before a success.\n\n\n&gt;Yâˆ¼Geom(p)&gt;P(Y=k)=p(1âˆ’p)k&gt;\ndef. Negative Binomial Distribution. let X describe the number of successes with probability p before r failures. X is a Negative Binomal Distribution where:\nXâˆ¼NegBinom(r,p)P(X=k)=(kk+râˆ’1â€‹)(1âˆ’p)rpk\n\nE(X)=1âˆ’pprâ€‹\nSD(X)=1âˆ’pprâ€‹â€‹\n"},"Hypothesis-Testing":{"title":"Hypothesis Testing","links":["Estimator","Likelihood-Ratio-Test","Generalized-Likelihood-Ratio-Test","Student's-t-test","Wilcoxon-Signed-Rank-Test","Wilcoxon-Rank-Sum-Test","Permutation-Test"],"tags":["Math/Statistics"],"content":"def. A Hypothesis test is a criteria to determine between two statements about an unknown parameter of a distribution:\nÎ´:{H0â€‹H1â€‹â€‹ifÂ criteriaifÂ alternativeâ€‹\nwhere:\n\nH0â€‹ is the Null hypothesis\nH1â€‹ is the Alternative hypothesis\n\ndef. Type I and II Errors, as well as size and power are defined as follows:\n\nType I Error is the probability of a false positive:\nP(AssumeÂ H1â€‹Â âˆ£Â H0â€‹Â isÂ true) â†’ the Size of the test = Level of the test\nType II Error is the probability of a false negative:\nP(AssumeÂ H0â€‹Â âˆ£Â H1â€‹Â isÂ true) â†’ the Power of the test\n\nâ‡’ Constructing a Î³=1âˆ’Î± -level test is to construct one that has a true negative rate of Î³ [= a false positive rate of Î±]\nP-Values Â§\ndef. let X1â€‹,â€¦,Xnâ€‹âˆ¼iidF(). then the p-value is the minimum Î± [= false positive rate = size] at which you would adopt H1â€‹.\n\nCommon Hypothesis Tests Â§\n\nLikelihood Ratio Test\nGeneralized Likelihood Ratio Test\n\nMultiple Hypothesis Testing Â§\nMotivation. Assume 20 sets of sample data. Then the false positive rate of one sample:\nP(atÂ leastÂ oneÂ significantÂ resultÂ âˆ£Â allÂ isÂ null)=1âˆ’P(allÂ isÂ nullÂ âˆ£Â allÂ isÂ null)=1âˆ’(1âˆ’0.05)20â‰ˆ0.64\nWhat Is the Bonferroni Correction?\nA good explaination of the bonferroni correction.\nâ‡’ This is too high to be acceptable. This is p-hacking. Thus:\ndef. Bonferroni Correction. In m-tests on a single dataset X1â€‹,â€¦,Xnâ€‹, level must be changed to mÎ±â€‹ in order to make a reasonable test.\nMore Types of Tests Â§\n\nStudentâ€™s t-test\nWilcoxon Signed Rank Test\nWilcoxon Rank Sum Test\nPermutation Test\n"},"Income-Effect-(IE)":{"title":"Income Effect (IE)","links":[],"tags":["Economics/Micro-Economics"],"content":"Assume you consume only pasta and steak. As exogenous income rises, you consume more steak, and less pasta. In this case, steak is a normal good, while pasta is an inferior good.\ndef. The Income effect is a change in consumption only due to income\nAbsolute changes in consumption define normal/quasi-linear/inferior goods\n\n\n                  \n                  â†‘ â€” Normal Good\n                  \n                \nIncomeâ†‘â€¦consumption same â€” Quasi-linear Good\nIncomeâ†‘â€¦consumptionâ†“ â€” Inferior Good\n\n\nOn the other hand, relative changes in consumption define luxury/homothetic/necessary goods.\n+% Income &gt; +% consumption â€” **Luxury Good\n+%** Income = +% consumption â€” **Homothetic Good\n+%** Income &lt; +% consumption â€” **Necessary Good**\n\n\nIncome Elasticity of Demand Â§\n"},"Income-Statement":{"title":"Income Statement","links":[],"tags":["Economics/Finance"],"content":"Example Income Statement:\n\na Income Statement is a table showing the firmâ€™s income [â‰ˆ profit]\n\nCoGS: variable cost\nSG&amp;A: admin cost\nEBITDA = Profits before financial costs\nDepreciation &amp; Amortization: Capital depreciation\nEBIT = Profits after capital depreciation\n"},"Independence-(Math)":{"title":"Independence (Math)","links":["Stat-230"],"tags":["Math/Probability"],"content":"Independence of Events Â§\nthm. For partition B1â€‹,â€¦,Bnâ€‹ of Î©, for all AâŠ†Î©:\nP(A)=P(AB1â€‹)+P(AB2â€‹)+â‹¯+P(ABnâ€‹)=P(Aâˆ£B1â€‹)â‹…P(B1â€‹)+â‹¯+P(Aâˆ£Bnâ€‹)â‹…P(Bnâ€‹)\n\ni.e. P(A) is the weighted average of conditional probabilities P(Aâˆ£Biâ€‹) with weights P(Biâ€‹).\n\ndef. Independence of Two Events. Two events A, B are independent if\nP(Aâˆ£B)=P(Aâˆ£BC)â‡”P(Aâˆ£B)=P(A)\nthm. Necessary and sufficient for independence of two events:\nA,BÂ areÂ independentâ‡”P(AB)=P(A)â‹…P(B)â‡”P(AB)=P(B)â‹…P(Aâˆ£B)\n\n\n                  \n                  Warning \n                  \n                \n\nEvents are independent not when they are related, but instead whether one event influences the probabilities of another.\ndef. Independence of Three Events. Three events A, B, C are independent if both:\n\nThey are pairwise independent\nP(ABC)=P(A)â‹…P(B)â‹…P(C)\n\nthm. Necessary and sufficient for independence of two events; if both:\n\nP(AB)=P(A)â‹…P(B)\nP(Câˆ£AB)=P(Câˆ£ACB)=P(Câˆ£ABC)=P(Câˆ£ACBC) â† all of them have to be equal.\n\nthm. Multiplication Rule for Three Independent Events.\nP(ABC)=P(A)â‹…P(B)â‹…P(C)\nIndependence of Random Variable Â§\ndef. Independence. Two Stat 230s X,Y are independent IFF for all pairs of (x,y)\nâˆ€x,yâ€‹P(X=x,Y=y)=P(X=x)â‹…P(Y=y)â‡•âˆ€x,yâ€‹P(X=xâˆ£Y=y)=P(X=x)\n\ni.e. the same as it is for events.\n\ndef. For n random variables X1â€‹,â€¦,Xnâ€‹ are mutually Independent IFF for all (k1â€‹,â€¦,knâ€‹):\nâˆ€x,yâ€‹P(X1â€‹=k1â€‹,...Xnâ€‹=knâ€‹)=P(X1â€‹=k1â€‹)â‹…â‹¯â‹…P(Xnâ€‹=knâ€‹)"},"Indirect-Utility-Function":{"title":"Indirect Utility Function","links":["utility","Lagrangian-Optimization","Uncompensated-Demand-curve","Homogenous-Function","Roy's-Identity"],"tags":["Economics/Micro-Economics"],"content":"The indirect utility function relates (Prices,Â Income) directly to utility, assuming the person is utility-maximizing\nUtilityÂ Function:Â IndirectÂ UtilityÂ Function:Â â€‹u:(x1â€‹,x2â€‹)â†¦utilityv:(p1â€‹,p2â€‹,I)â†¦utilityâ€‹â€‹\nDerivation Process:\n\nUse Lagrangian Optimization to derive Demand Functions x1â€‹(p1â€‹,p2â€‹,I),Â x1â€‹(p1â€‹,p2â€‹,I)\nSubstitute these demand functions into the original utility function u(x1â€‹,x2â€‹) to get the indirect utility function.\n\nProperties\n\nHD0 in (Prices,Income) â†’ Check after derivation!\n\nIn other words, inflation in prices and income doesnâ€™t change utility\n\n\nDecreasing in prices (âˆ‚p1â€‹âˆ‚vâ€‹,âˆ‚p2â€‹âˆ‚vâ€‹&lt;0), Increasing in income (âˆ‚Iâˆ‚vâ€‹&gt;0)\n\nâ†’ Check after derivation!\n\n\nUse Royâ€™s Identity to get back to the Marshallian Demand.\n"},"Inflation-vs.-Recession":{"title":"Inflation vs. Recession","links":["Inflation"],"tags":["Economics/Macro-Economics"],"content":"Paul A. Volcker was the fed chair who brought down high Inflation at the cost of a recession in the 1980â€™s.\nâ‡’ Generally, central banks will try to bring down inflation first, at the cost of a recession."},"Inflation":{"title":"Inflation","links":[],"tags":["Economics/Macro-Economics","index"],"content":"Inflation:= change in the price of the basket of goods [= a representative sample of GDP]\nI.R.=Ptâˆ’1â€‹Ptâ€‹âˆ’Ptâˆ’1â€‹â€‹\n\n\nInterest rate âˆ inflation rate [â† explained later]\n\n\nHistorically, price of capital equipment (relative to consumption goods) have gone down\nâ€¦but the price of housing have gone up\nâ†’ thus must know inflation of what?\n\nTotal Inflation: CPI measured using the representative basket of goods\nCore Inflation: represents the long run trend in the price level.\n\nIn measuring long runÂ inflation, transitory price changes should be excluded.\nâ‡’ Exclude items frequently subject to volatile prices, like food and energy\ni.e. the change in Core CPI\n\n\n\n\n\nInflation data is often shown as Year-over-Year (YoY) which means you canâ€™t compound\n\n"},"Initial-Public-Offering":{"title":"Initial Public Offering","links":[],"tags":["Economics/Finance"],"content":""},"Inner-Product":{"title":"Inner Product","links":[],"tags":["Math/Linear-Algebra"],"content":"\nReal and Complex numbers R,C: Arithmetic Muliplication\nReal space Rn: Dot Product\nâ†’ You generalize up to Hilbert Spaces\n\nNOT a\n\nMatrix Product\n"},"Input-Demand-and-Output-Supply":{"title":"Input Demand and Output Supply","links":["Uncompensated-Demand-curve","Profit-Function","Utility-Maximization","Cost-Minimization","Input-Demand-and-Output-Supply","Profit-Maximization-for-Perfect-Competition","Production-Function","production-function"],"tags":["Economics/Micro-Economics"],"content":"Long Run Input Demand Â§\ndef. Ordinary Input Demand. Ordinary Demand for Inputs (=labor l, capital k)\n\nTo derive: Profit Function\nProperties:\n\nHD0 in (w,r,p)\nDecreasing in own-price â†regardless of anything! (Unlike Utility Maximization)\n\n\n\ndef. Conditional Input Demand. Demand of input (=labor l, capital k) in order to produce a certain level out output xË‰\n\nHOWTO get: Cost Minimization\nProperties\n\nHD0 in input prices w,r\nDecreasing in own-price\n\n\n\nShort Run Input Demand Â§\nShort run (own-price) labor demand: lkË‰â€‹(w,pâˆ£kË‰)\n\nkË‰ is a parameter. Set it as the long-run input demand k(w,r,p).\nIn the short run, a change in w or p will only operate within lkË‰â€‹ with no change in kË‰ possible.\nIn the long run, we simply calculate the long-run input demand l(w,r,p).\nRelationship between long-run input demand, visually: \n\nLong Run Output Supply Â§\ndef. Ordinary Supply. Relates the prices of inputs and output with the quantity of output produced\nx:(w,r,p)â†¦x\nProperties\n\nHD0 in prices w,r,p\nincreasing in output price x\ndecreasing in input price w,r,\n\n(HowTo) Derive Supply Function Â§\nMethod 1:\n\nGet Input Demand and Output Supply from Profit Maximization\nSubstitute into the Production Function x=f(l(w,r,p),k(w,r,p))\nSimplify to get x(w,r,p).\nMethod 2:\nGet cost function from Cost Minimization\n\nShort Run Output Supply Â§\nShort run (own-price) output supply: xkË‰â€‹(w,pâˆ£kË‰)\n\nkË‰ is a parameter. Set it to the long-run input demand k(w,r,p)\nUse the production function x=f(l,k) but with kË‰ fixed.\nIn the short run, a change in w or p will only operate within xkË‰â€‹ with no change in kË‰ possible.\nIn the long run, we simply calculate the long-run output demand l(w,r,p).\n\n"},"Institutional-Design":{"title":"Institutional Design","links":["horizontal-organization","Centralized-Power","Microphysics-of-Power","Utility","Game-Theory"],"tags":["Economics/Game-Theory","Philosophy/Political-Philosophy"],"content":"\nHorizontal vs Vertical organization structure\nCentralized vs Decentralized (Microphysics of-) Microphysics of Power\nIncentives &amp; Payoff structures in Game Theory\n"},"Instruction-Set":{"title":"Instruction Set","links":[],"tags":["Computing/Computer-Architecture"],"content":"Instruction Set: a set of instructionsâ€”the â€œvocabularyâ€â€”that a process of certain architecture understands (x86, MIPS, etc.)\nTypes of Instruction Set: ARMv7, ARMv8 (64-bit), MIPS, x86 (32, 64-bit). The concept of the instruction set supports the stored-program concept (idea that instructions and data are both stored in main memory, with a memory heirarchy.)"},"Instructions-(Computer-Science)":{"title":"Instructions (Computer Science)","links":["Instruction-Set","Branching-(Computer-Science)"],"tags":["Computing/Computer-Architecture"],"content":"2.1. Introduction Â§\nInstruction Set language of the hardware. Vocabulary understood by a given architecture.\n2.2. Operations of the Computer Hardware Â§\n\nRegister: Places to store variables\n\nAn instruction in MIPS looks like this:\nadd $s1, $s2, $s3 which means\ns1 â† s2 + s3\nNotice that one instruction has three operands. In MIPS, there are 32 registers and 230memory addresses which can be used as operands.\n\nSimplicity favors regularity. Itâ€™s easier to design hardware for a fixed number of operands and registers.\n\n2.3. Oper_and_s Of the Computer Hardware Â§\n\nWord: size of a register (32-bits in a 32-bit architecture)\ni.e. 1 word = 4 bytes = 32 bits &gt; Smaller is Faster. Having only 32 registers is simple; having 3 operands is simple. More registers will lead to slower clock cycles. &gt;\nAlignment Restriction: data in memory must be aligned to multiples of 4.\ni.e. since each memory address refers to one byte, valid memory addresses are 0x04, 0x08, â€¦ (each are 1 word in size).\nEndian-ness: big endian refers the leftmost 0x04 referring to 0x04~0x07 and so on. little endian refers to the rightmost 0x04 referring to 0x01~0x04 and so on. Picture: bigâ–¶ï¸little\n\nData Transfer Instruction: instruction to move data between RAM and registers. Supply the memory address stored in a register\n// Load Word Example\nlw $t1, 8($s1)\n// access *address* stored in $s1 in RAM\n// move down 8 bytes (offset)\n// and store that in register $t1\n \n// Store Word Example\nsw $t1, 8($s1)\n// the same thing, but storing $t1 into memory addr $s1 offset by *2 words*\nNote that the offset is in bytes, not words. â†’ Thus to access arr[1] you should offset 4($s1). Offset addressing is natural for arrays and structs (from C).\nImmediate Operations: instructions to add a constant to a register value. Immediate operations are very fast, since they donâ€™t need to load data from memory.\naddi $s1, $s2, 4 // &quot;add immediate&quot;\n// store in s1 the sum of value in s2 and 4\n// s1 = s2 + 4;\n2.4. Signed and Unsigned Numbers Â§\n0000 0000 0000 0000 0000 0000 0000 0000 // 32 bit number = 1 word\n// most significant bit            // least significant bit\nTwoâ€™s Compliment Representation: think of it like this:\nâˆ’231âˆ’1â‹…â‹…â‹…âˆ’1,0,1â‹…â‹…â‹…231\n1000 0000 ... 0000 = -2^31 - 1\n...\n1111 1111 ... 1111 = -1\n// this is where it resets...\n0000 0000 ... 0000 = 0\n0000 0000 ... 0001 = 1\n...\n0111 1111 ... 1111 = 2^31\n// and overflow back to 1000 0000 ... 0000 = -2^31 - 1\nThis representation is the default since 1965.\nAdvantages of Twoâ€™s Compliment Representation:\n\nBinary to Decimal: most significant bit is -2^32 and the rest is normal binary\nNegation: invert bits and add oneâ€”this works both ways!\nSign Extension(=Precision Extension) (16â†’32 bits, etc.): extend the sign bit leftward (most significant bit)\ni.e. positive number: extend the zeros; negative number: extend the one.\n\n2.5. Representing Instructions in the Computer Â§\nRegister Representation:\n#8  ~ #15: $t0 ~ $t7\n#16 ~ #23: $s0 ~ $s7\nInstruction in Machine Code: instructions can be R-type or I-type. Each have different sized-fields (but is 32 bits in total).\n// R type instruction example\nadd $t1, $s1, $s2\n// divided into fields:\nop   | rs  | rt  | rd  |shamt| funct | // field names\n0    | 17  | 18  | 8   |  0  | 32    | // machine code in decimal\n6b   | 5b  |  5b |  5b |  5b | 6b    | // bit size of each field\nEach part of the instruction is called a field. List of Field Names:\n\nop: opcode, the operation\nrs: register source\nrt: register source 2\nrd: register destination (result of the operation)\nshamt: shift amount\nfunct: function code, select a specific variant of the opcode.\n\nLine label. loop in the following instruction is a line label. Itâ€™s just there for humans; like comments in code.\nloop: lw [...]\n\t\t\tadd [...]\n\t\t\tj loop\n\n2.6. Logical Operations Â§\n| Operation | command | example | explaination | comments |\n| ----------- | --------- | ----------------- | ------------------------------ | ----------------------------------------------------------------------------------------- | ------------------------------------------------ |\n| Shift Left | sll | sll t2,s0, 4 | s0to left 4 bits, store in t2 | equivalent to multiply by 2^n |\n| Shift Right | srl | srl t2,s0, 4 | s0to right 4 bits, store in t2 | equivalent to divide by 2^n |\n| AND | and, andi | and t0,t1, $t2 | t0 = t1 &amp; t2 | andi has a constant in place of a second register. |\n| OR | or, ori | or t0,t1, $t2 | t0 = t1 | t2 | orihas a constant in place of a second register. |\n| NOT | nor | nor t0,t1, $t2 | | NOR(A, B) = NOT (A OR B) thus if one operator is 0, then it becomes a simple NOT command. |\n2.7. Instructions for Making Decisions Â§\n\nBasic block: a block of assembly code without branches\n\nTwo types of jump operations: conditional branches and unconditional jump.\nConditional Branches:\nbeq $t0, $t1, L1 // branch if equal\n// if t0 == t1, goto label L1\nbne $t0, $t1, L1 // branch not equal\n// if t0 != t1, goto label L1\nUnconditional Jump:\nj Exit // go to label Exit\nLess Than (branch on less than is not included since it takes clock cycles)\n/* SIGNED */\nslt $t0, $s1, $s2 // set on less than\n// if s1 &lt; s2, t0 = 1 ; else t0 = 0\nslti $t0, $s1, 10 // set on less than immediate\n// second argument is a constant\n \n/* UNSIGNED */\nsltu $t0, $s1, $s2 // slt, but compare as if two integers are unsigned\nsltiu $t0, $s1, $s2 // slti, but compare as if two integers are unsigned\n\n\n                  \n                  Treating signed numbers as unsigned is useful in checking 0 \\leq x \\lt y. &gt; sltui $t0, $s1, 10 â† if s1 is negative, treating it as an unsigned number the 2^{31}th place has a 1 which makes it a *very big signed numberâ€”*and thus t0 is set to 0. If s1is positive then its value is same signed or unsigned; thus s1 &lt; 10 is evaluated normally.\n                  \n                \n\n2.8. Supporing Procedures in Computer Hardware Â§\nProcedure: =function call in assembly.\n\nLeaf Procedure. A procedure that doesnâ€™t call any other procedures. (think: the end of a branch)\n\nTo execute a procedure you need to:\n\nPut parameters in a place expected by the procedure\nTransfer control to the procedure\nPerform task\nPut result value in expected place (by the caller)\nreturn control to caller\n\nRegisters (usually) used for procedure calling:\n\na0 ~ a3: pass arguments\nv0 ~ v1: return values\nra: return address (return here after procedure is done)\nProgram Counter (PC): holds the memory address of the instruction currently executing\n\nInstruction specialized for procedure calling:\njal Procedure // jump and link\n// an unconditional jump + saves current calling address to $ra\n// used when transferring control to the procedure\njr $ra // jump register\n// an unconditional jump but instead of a Label, jump to the address in register $ra\n// used when returing control to the caller from a procedure\n\nSpilling Registers into the Stack\n\nStack. When a0 ~ a3 isnâ€™t enough for a procedure, s0 ~ s7 should be saved into a memory portion call thed stack. (t0 ~ t9 is not saved)\n\n$sp points to the end of the stack (where spilled data should be stored next)\nplacing and removing data is called push / pop\nBy convention stack grows from higher memory address to lower memory address, e.g. from 0x08 to 0x04, and by one word each.\n\n\nProcedure Frame (=Activation Record). Space on stack reserved for storing the procedureâ€™s local varaibles and arrays that donâ€™t fit into registers. The frame is located below the saved registers at the little end of the stack.\n\n$fp (frame pointer) points to the little end of the procedure frame. This is useful because stack pointer can change during a procedure.\n\n\n\nCalling a leaf procedure:\n\n\nadjust stack pointer by number of registers that requires saving:\naddi $sp, $sp, -12 // stack grows down\nsw $s1, 8($sp) // push first variable\nsw $s2, 4($sp)\nsw $s3, 0($sp)\n\n\nexecute procedure body\n\n\nsave return value to registers v0 ~ v1\n\n\nrestore register values to registers\nlw $s3, 0($sp) // pop last variable\nlw $s2, 4($sp)\nlw $s1, 8($sp)\naddi $sp, $sp, 12 // stack deletes up\n\n\nData preserved/not preserved across procedure calls:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPreservedNot Preserveds0 ~ s7t0 ~ t9sp stack pointera0 ~ a3 argument registerra return addressv0 ~ v1 return value registerstack above stack pointer (bigger end)stack below stack pointer (littler end)\n(Not storing the temporary registers t0~t9 reduces memory store/load.)\n\nAllocating Data on the Heap\nStructure of the executable, from big end to little end:\n\nThe Stack grows down (higher address â†’ lower address). sp â†’ 7fff fffc\nThe Heap grows up (lower addr â†’ higher addr).\nText Segment (instructions)\nReserved\n\n2.9. Communicating with People Â§\nASCII Table on p.106. Notice that:\n\none ascii charater is 1 byte (=8 bits)\n0b0 is NULL\nupper and lower letters differ by 32=25\n\nTo store strings, either:\n\nfirst position in string stores length\naccompanying variable holds string length or\nthe last position marks the end of the string\n\nSinced people use ASCII a lot, and ASCII is 1 byte, there are data transfer instructions for bytes:\nlb $t0, 0($sp) // load byte (and sign extend)\nsb $t0, 4($sp) // store byte and sign extend\nlbu $t0, 0($sp) // load byte unsigned\nsbu $t0, 4($sp) // store byte unsigned\n\nUnicode is used by Java and other modern languages. Notice that:\n\nUTF-16 is default, using 16-bits\nUTF-8 is ASCII-compatible, and is variable-length\nUTF-32 uses 32 bits\n\nMIPS also accomodates UTF-16 by providing data transfer instructions for half-words (16-bits):\nlh $t0, 0($sp) // load halfword and sign extend\nsh $t0, 4($sp) // store halfword and sign extend\nlhu $t0, 0($sp) // load halfword unsigned\nshu $t0, 4($sp) // store halfword unsigned\n2.10. MIPS Addressing for 32-bit Immediates and Addresses Â§\nWhen you need to load a 32-bit constant into register, you need two instructions (a new one, lui):\n/* loading 0000 0000 0011 1101 0000 1001 0000 0000 */\nlui $s0, 61 // load upper immediate;\n// 61   = 0000 0000 0011 1101 (upper half of constant)\nori $s0, $s0, 2304 // logical OR immediate;\n// 2304 = 0000 1001 0000 0000 (lower half of constant)\n// s0 has the full value.\nAddressing in Jumps and Branches\njump instruction:\nj 10000\n|  2  |             10000                 |\n|  6b |              26b                  |   // can use 26 bits for addressing\n \nbranch instruction:\nbne $s0, $s1, Exit\n|  5   |  16   |  17   |        Exit      |\n| 6b   |  5b   |  5b   |        16b       |   // can only use 16 bits for addressing"},"Integer-Allocation":{"title":"Integer Allocation","links":["Fractional-Allocation","Fairness-(Economics)","Utility-Function"],"tags":["Economics/Game-Theory","Economics/Micro-Economics"],"content":"Motivation. As opposed to Fractional Allocation where an item can be infinitely divided (and thus much fairness criteria are satisfied), in a situation where you cannot divide the items it is much harder to find a â€œfairâ€ allocation. We will try nevertheless; here are a few attempts:\n\nConverting fraction allocation to integer allocation\nSerial Dictatorship\nNash Welfare Objective\n\n\n\n                  \n                  \\mu_{i} is an additive utility function.\n                  \n                \n\nFractional to Integer Â§\nFirst use fractional, then convert to integer allocation.\nSerial Dictatorship Â§\ndef. Serial Dictatorship. (Round Robin). The following process of allocation is a SD allocation:\n\nRound i: Each agent picks favorite item\nRepeat until all items allocated\nProperties.\n\n\nSD is EF1 (defined and proved below)\nSD is not PO\nComparable to MMS (bounded; see below)\ndef. Envy-Free without one item (EF1). An allocation is envy-free without one item if:\n\nâˆ€i,jÂ âˆƒitemÂ gÂ s.t.Â Â iâ€™sÂ alloc.Î¼iâ€‹(Siâ€‹)â€‹â€‹â‰¥Î¼iâ€‹(Â someÂ otherâ€™sÂ allocÂ withoutÂ gÂ Sjâ€‹âˆ’{g}â€‹â€‹)\nIntuition. If i envies jâ€™s basket Sjâ€‹ (=traditional Envy) then take out one item g, and then i no longer envies Sjâ€‹âˆ’{g}. \nthm. SD is EF1.\nProof. For all agent i, letâ€™s say i envies j.\n\nDue to SD game order, iâ€™s pick in the k-th round will always be preferred to jâ€™s pick in the k+1-st round. Therefore, i will: iâ€™sÂ picksÂ fromÂ roundÂ 1Â toÂ finishâ‰»iâ€‹jâ€™sÂ picksÂ fromÂ roundÂ 2Â toÂ finish\nThe issue arises because j may pick before i in round 1. If we simply remove that item, i will not envy j anymore.\nTherefore, in any pair of agents i envying j, removing one item that was picked by j before i in the first round is enough to make i no longer envy j. â– \nExample.\n\n\n\n2 may envy 1 because 2 prefers a to d, its first pick.\nBut 2 does not envy any other of 1â€™s pick, because it picked it.\nRemoving a from 1â€™s set makes 2 no longer envy 1.\n\nComparison to MMS Â§\ndef. Maximin Share (MMS). Imagine first an allocation process where \n\ni splits the items first\nAll other agents chooses which item to have\ni gets the remaining item.\nIn this case, it is in iâ€™s best interest to maximize the minimum utility bundle (for itself)â€˜s utility. Thus we have the definition of MMS as the utility of this maximin bundle:\n\nÎ¼iâ€‹(MMSiâ€‹):=Â maximizeÂ the...Â maxSâ€‹â€‹â€‹Â minimumÂ utilityÂ bundleÂ min{Î¼iâ€‹(Siâ€‹)}â€‹â€‹\nExample. The blue groups are what each agent splits the items into to maximize their minimum utility. The red circles are an example allocation that give more utility than MMS for every agent. \nlem. (MMS utility worse than proportional utility). If we allow a fractional allocation on items T, a proportional allocation will give utility nÎ¼iâ€‹(T)â€‹ for agent i. On the other hand, if you use (integer) MMS allocation:\nÎ¼iâ€‹(MMSiâ€‹)â€‹=allocationÂ Smaxâ€‹Â Siâ€‹âˆˆSminâ€‹Î¼iâ€‹(Siâ€‹)â‰¤Smaxâ€‹Â avg.Â utilityÂ ofÂ eachÂ goodÂ nâˆ‘Siâ€‹âˆˆSâ€‹Î¼iâ€‹(Siâ€‹)â€‹â€‹â€‹=Smaxâ€‹nÎ¼iâ€‹(T)â€‹=nÎ¼iâ€‹(T)â€‹â€‹min.Â &lt;Â avg.maxÂ doesnâ€™tÂ applyâ€‹â€‹\nTherefore we Î¼iâ€‹(MMSiâ€‹)â‰¤nÎ¼iâ€‹(T)â€‹ â– \nthm. (Serial Dictatorship vs. Proportional vs. MMS) Let Siâ€‹ be a serial dictatorship allocation. For agent i, let Î¼imaxâ€‹ be a single item that i values the most. Then:\nÂ SDÂ Î¼iâ€‹(Siâ€‹)â€‹â€‹+Î¼imaxâ€‹â‰¥Â propÂ nÎ¼iâ€‹(T)â€‹â€‹â€‹â‰¥Î¼iâ€‹(MMSiâ€‹)\nProof. Model the round robin with n agents and items from set T, s.t. we call round 1 starting with agent i. All items allocated before i in round 1, let T0â€‹. These are ignored for now.\n\nLet the items allocated to agents in round k be Tkâ€‹. Let Î¼i(k)â€‹ be the utility to agent i by the single item allocated to i on round k. For agent i in every round:\nÎ¼i(k)â€‹âˆ€kâ€‹âˆ‘â€‹Î¼k(k)â€‹â€‹â‰¥tâˆˆTkâ€‹maxâ€‹Î¼iâ€‹(t)â‰¥nÎ¼iâ€‹(Tkâ€‹)â€‹â‰¥âˆ€kâˆ‘â€‹nÎ¼iâ€‹(Tkâ€‹)â€‹â€‹maxâ‰¥avg.â€‹â€‹\nNow, consider the ignored items T0â€‹. We can easily establish that:\nÎ¼iâ€‹(T0â€‹)â€‹=âˆ£T0â€‹âˆ£Â avg.Â âˆ£T0â€‹âˆ£Î¼iâ€‹(T0â€‹)â€‹â€‹â€‹â‰¤âˆ£T0â€‹âˆ£tâˆˆT0â€‹maxâ€‹Î¼iâ€‹(t)â‰¤nâ‹…tâˆˆT0â€‹maxâ€‹Î¼iâ€‹(t)â‰¤nâ‹…tâˆˆTmaxâ€‹Î¼iâ€‹(t)â€‹avg.â‰¤maxâ€‹â€‹\nContinuing on from above:\nâˆ€kâ€‹âˆ‘â€‹Î¼k(k)â€‹Î¼kâ€‹(Â SDÂ allocÂ Siâ€‹â€‹â€‹)â€‹â‰¥nâˆ‘âˆ€kâ€‹Î¼iâ€‹(Tkâ€‹)â€‹â‰¥nÎ¼iâ€‹(Tâˆ–T0â€‹)â€‹=nÎ¼iâ€‹(T)âˆ’Î¼iâ€‹(T0â€‹)â€‹â‰¥nÎ¼(T)âˆ’nmaxtâˆˆTâ€‹Î¼iâ€‹(t)â€‹=nÎ¼iâ€‹(T)â€‹âˆ’tâˆˆTmaxâ€‹Î¼iâ€‹(t)â€‹â€‹\nThus we have the final inequality w.r.t proportional allocation and thus MMS (due to theorem before).\nÎ¼iâ€‹(Siâ€‹)+tâˆˆTmaxâ€‹Î¼iâ€‹(t)â‰¥nÎ¼iâ€‹(T)â€‹â‰¥Î¼iâ€‹(MMSiâ€‹)\nâ– \nthm. (Alternative SD vs MMS) Serial Dictatorship allocation Siâ€‹ satisfies for each agent that:\nÎ¼iâ€‹(Siâ€‹)â‰¥21â€‹MMSiâ€‹\nProof.\nâ– \nInteger Nash Welfare Â§\ndef. Integer Nash Welfare. For integer allocation x, Nash welfare is:\nNashÂ Welfare:=Â productÂ ofÂ everybodyÂ iâˆâ€‹â€‹â€‹Â SumÂ aÂ personâ€™sÂ utilityÂ jâˆ‘â€‹Î¼ijâ€‹xijâ€‹â€‹â€‹\n\nNP hard to compute\nâ€¦but satisfies EF1\n\nthm. (Integer Nash Welfare objective satisfies EF1).\nProof. Suppose in the allocation S, i envies j even remove one item. Now, choose gâˆ— as the most bang-for-buck item to move from Sjâ€‹ to Siâ€‹:\ngâˆ—:=argmingâˆˆSjâ€‹â€‹Î¼iâ€‹(g)Î¼jâ€‹(g)â€‹\nAnd we also note the inequality (1):\nÎ¼iâ€‹(gâˆ—)Î¼jâ€‹(gâˆ—)â€‹â‰¤Î¼iâ€‹(Sjâ€‹)Î¼jâ€‹(Sjâ€‹)â€‹\nNow per our assumption, i still envies Sjâ€‹âˆ–{gâˆ—}:\nÎ¼iâ€‹(Siâ€‹)Î¼iâ€‹(Siâ€‹)+Î¼iâ€‹(gâˆ—)Î¼iâ€‹(gâˆ—)Î¼jâ€‹(gâˆ—)â€‹(Î¼iâ€‹(Siâ€‹)+Î¼iâ€‹(gâˆ—))Î¼iâ€‹(gâˆ—)Î¼jâ€‹(gâˆ—)â€‹Î¼iâ€‹(Sjâ€‹)â€‹&lt;Î¼iâ€‹(Sjâ€‹)âˆ’Î¼iâ€‹(gâˆ—)&lt;Î¼iâ€‹(Sjâ€‹)&lt;Â byÂ inequalityÂ (1)Â Î¼iâ€‹(gâˆ—)Î¼jâ€‹(gâˆ—)â€‹Î¼iâ€‹(Sjâ€‹)â‰¤Î¼iâ€‹(Sjâ€‹)Î¼jâ€‹(Sjâ€‹)â€‹Î¼iâ€‹(Sjâ€‹)â€‹â€‹=Î¼jâ€‹(Sjâ€‹)â‰¤Î¼iâ€‹(Sjâ€‹)â€‹multiplyÂ byÂ Î¼iâ€‹(gâˆ—)Î¼jâ€‹(gâˆ—)â€‹inequalityÂ (2)â€‹â€‹\nNow, on the other hand, since Siâ€‹,Sjâ€‹,â€¦ are NW allocations, it is the maximum product:\nÎ¼iâ€‹(Siâ€‹)Î¼jâ€‹(Sjâ€‹)Î¼jâ€‹(gâˆ—)(Î¼iâ€‹(Siâ€‹+Î¼iâ€‹(gâˆ—)))Î¼iâ€‹(gâˆ—)Î¼jâ€‹(gâˆ—)â€‹(â‰¤Î¼iâ€‹(Sjâ€‹)sinceÂ IÂ Î¼iâ€‹(Siâ€‹)+Î¼iâ€‹(gâˆ—)â€‹â€‹)â€‹â‰¥Â giveÂ toÂ iÂ (Î¼iâ€‹(Siâ€‹)+Î¼iâ€‹(gâˆ—))â€‹â€‹Â removeÂ fromÂ jÂ (Î¼jâ€‹(Sjâ€‹)âˆ’Î¼jâ€‹(gâˆ—))â€‹â€‹â‰¥Î¼jâ€‹(Sjâ€‹)Î¼iâ€‹(gâˆ—)â‰¥Î¼jâ€‹(Sjâ€‹)â€‹expandÂ andÂ simplifyâ€‹â€‹\nâ– "},"Integer-Multiplication":{"title":"Integer Multiplication","links":[],"tags":["Computing/Algorithms"],"content":"alg. Long Multiplication. (grade school) algorithm\n\nComplexity: Time O(n2).\n\nalg. Karatsuba Multiplication. Recursive algorithm to compute\n\nIdea: To get xÃ—yâ€¦\n\nLet a,b,c,d be digits of x=abË‰,y=cdË‰, and observe:\n\nx=10n/2a+b\ny=10n/2c+d\n\n\nxÃ—y=10nac+10n/2(ad+bc)+bd\n\nRecurse Compute aÃ—c â€¦(1)\nRecurse Compute bÃ—d â€¦(2)\nTo compute the middle term, instead of computing aÃ—d,bÃ—c we do:\n\nRecursively compute (a+b)(c+d)=ac+ad+bc+bd â€¦(3)\n(3) subtract (1) and (2) to get middle term ad+bc\n\n\n\n\n\n\nSee Karatsuba Multiplication in 13 min - YouTube\n\n\nComplexity\n\nTime: O(nlog2â€‹3â‰ˆn1.58)\nSpan: Tâˆâ€‹(n)=O(n) (by parallelzing all 3 recursive calls)\n\n\n\nalg. Lattice Multiplication. Developed for longer integer hand-calculation."},"Integration-Rules":{"title":"Integration Rules","links":[],"tags":["Math/Calculus"],"content":""},"Interest-Rate":{"title":"Interest Rate","links":["Present-Value-Calculations","Federal-Funds-Rate"],"tags":["Economics/Finance"],"content":"Rates in General Â§\ndef. Rate is a simple abstraction of interest rate so that we can calculate things easily.\nRâ€‹=F(0)F(Ï„)âˆ’F(0)â€‹=Ï„â‹…r=(1+krâ€‹)Ï„kâˆ’1â€‹Â (Definition)Â (...forÂ simpleÂ interest)Â (...forÂ compoundÂ interest)â€‹â€‹\ne.g. when banks say they have an APR (Annual Percentage Rate) of 10.99%, their actual rate [=Annual Percentage Yield] is:\nR=(1+36510.99%â€‹)365âˆ’1â‰ˆ11.61%\ndef. Required Rate of Return (RRR) (=Discount Rate).\n\nRRR of asset: Minimum amount of profit that the investor will accept\nRRR in general: Average rate of similar-risk investments in the market\n\ndef. Internal Rate of Return (IRR).\n\nAnnual rate of growth of an investment.\nSolution of the equation NPV(rIRRâ€‹)=set0\n\nSee NPV calculations\n\n\n\nInterest Rate Â§\nEquivalently:\n\nDiscount rate\nPrice of Money\n\nTypes of interest rates:\n\nYield: interest rate on bonds\nMortgage Prime rates\nLIBOR (inter-bank interest rates)\nFederal Funds Rate\n"},"International-Baccalaureate-(IB)":{"title":"International Baccalaureate (IB)","links":["assets/IB-Econ-HL---(Macroeconomic-Investigation)-Japan-vs-US.pdf","assets/IB-Econ-HL---(IA)-Analysis-on-Solar-Tariffs.pdf","assets/IB-Econ-HL---(IA)-Analysis-on-BoE-Monetary-Policy.pdf","assets/IB-Econ-HL---(IA)-Chinese-Currency-Devaluation.pdf","assets/IB-Econ-HL---Elasticities-and-Taxes.pdf","assets/IB-Econ-HL---Basic-Concepts.pdf","assets/IB-Econ-HL---Theory-of-the-Firm.pdf","assets/IB-Econ-HL---Market-Failure.pdf","assets/IB-Physics-HL---(Internal-Assessment-Report)-Lagrangian-of-Atwood-Machine.pdf","assets/IB-Physics-HL---(Lab-Report)-Specific-Heat-Capacity.pdf","assets/IB-Physics-HL---(Lab-Report)-Circular-Motion.pdf","assets/IB-Physics-HL---(Lab-Report)-Internal-Resistance.pdf","assets/IB-Physics-HL---(Lab-Report)-Free-Fall.pdf","assets/IB-Physics-HL---(Lab-Report)-Lorentz-Force.pdf","assets/IB-Literature---(IA)-The-Assult.pdf","assets/IB-Literature---(Comparative)-Equus-vs.-Streetcar-Named-Desire.pdf","assets/IB-Literature---(Presentation)-1984.pdf","assets/IB-Literature---(Commentary)-Acceptance-Speech.pdf","assets/IB-Literature---(Commentary)-Blaze.pdf","assets/IB-Literature---(Commentary)-My-Rival's-House.pdf","assets/IB-Literature---(Commentary)-Elephant-Riding.pdf","assets/IB-Literature---(Commentary)-Nighttime-Fires.pdf","assets/IB-Literature---(Commentary)-A-Fraction-of-the-Whole.pdf","assets/IB-Literature---(Commentary)-A-Sense-of-an-Ending.pdf","assets/IB-Literature---(Commentary)-The-Thing-Around-Your-Neck.pdf","assets/IB-Japanese-A---(Creative-Writing)-ã€Œç¾…ç”Ÿé–€ã€.pdf","assets/IB-Japanese-A---Written-Task-1-ã€Œæ—¥æœ¬èªã¨ç¤¾ä¼šæ§‹é€ ã€.pdf","assets/IB-Japanese-A---Written-Task-2-ã€Œæ–‡å­¦æ‰¹åˆ¤ã€.pdf","assets/IB-Japanese-A---Written-Task-3-ã€Œãƒã‚¹ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã€.pdf","assets/IB-Japanese-A---Written-Task-4-ã€Œæ–‡å­¦æ‰¹è©•ã€.pdf","assets/IB-Japanese-A---(Presentation)-ç”˜ãˆã®æ§‹é€ ãƒ»ç¬¬äºŒç« ã®äºŒ.pdf","assets/IB-Japanese-A---(Presentation)-æ—¥æœ¬èªã¨ã‚¢ãƒ‹ãƒ¡ã€Œã†ã•ããƒ‰ãƒ­ãƒƒãƒ—ã€.pdf","assets/IB-Japanese-A---(Presentation)-Apple-åºƒå‘Šæ‰¹è©•.pdf","assets/IB-Japanese-A---(Commentary)-ã€Œæ—¥æœ¬èªã€.pdf","assets/IB-Japanese-A---(Commentary)-ã€Œã“ã“ã‚ã€.pdf","assets/IB-Japanese-A---(Commentary)-ã€Œé‡å‘‚æ¾äººå½¢ã€.pdf","assets/IB-Japanese-A---(Commentary)-ã€Œç¾…ç”Ÿé–€ã€.pdf","assets/IB-Extended-Essay---Evaluation-of-Optimization-Algorithms-for-Machine-Learning.pdf","assets/IB-ToK-Essay---Epistemiology.pdf","assets/IB-ToK-Presentation---Consciousness.pdf"],"tags":["Courses"],"content":"Economics HL Â§\n\nIB Econ HL - (Macroeconomic Investigation) Japan vs US.pdf\nInternal Assessments\n\nIB Econ HL - (IA) Analysis on Solar Tariffs.pdf\nIB Econ HL - (IA) Analysis on BoE Monetary Policy.pdf\nIB Econ HL - (IA) Chinese Currency Devaluation.pdf\n\n\nAnalysis Essays\n\nIB Econ HL - Elasticities and Taxes.pdf\nIB Econ HL - Basic Concepts.pdf\nIB Econ HL - Theory of the Firm.pdf\nIB Econ HL - Market Failure.pdf\n\n\n\nPhysics HL Â§\n\nIB Physics HL - (Internal Assessment Report) Lagrangian of Atwood Machine.pdf\nLab Reports\n\nIB Physics HL - (Lab Report) Specific Heat Capacity.pdf\nIB Physics HL - (Lab Report) Circular Motion.pdf\nIB Physics HL - (Lab Report) Internal Resistance.pdf\nIB Physics HL - (Lab Report) Free Fall.pdf\nIB Physics HL - (Lab Report) Lorentz Force.pdf\n\n\n\nLiterature SL Â§\n\nIB Literature - (IA) The Assult.pdf\nIB Literature - (Comparative) Equus vs. Streetcar Named Desire.pdf\nIB Literature - (Presentation) 1984.pdf\nPoetry Commentary\n\nIB Literature - (Commentary) Acceptance Speech.pdf\nIB Literature - (Commentary) Blaze.pdf\nIB Literature - (Commentary) My Rivalâ€™s House.pdf\nIB Literature - (Commentary) Elephant Riding.pdf\nIB Literature - (Commentary) Nighttime Fires.pdf\n\n\nProse Commentary\n\nIB Literature - (Commentary) A Fraction of the Whole.pdf\nIB Literature - (Commentary) A Sense of an Ending.pdf\nIB Literature - (Commentary) The Thing Around Your Neck.pdf\n\n\n\nJapanese A SL Â§\n\nIB Japanese A - (Creative Writing) ã€Œç¾…ç”Ÿé–€ã€.pdf\nWritten Tasks\n\nIB Japanese A - Written Task 1 ã€Œæ—¥æœ¬èªã¨ç¤¾ä¼šæ§‹é€ ã€.pdf\nIB Japanese A - Written Task 2 ã€Œæ–‡å­¦æ‰¹åˆ¤ã€.pdf\nIB Japanese A - Written Task 3 ã€Œãƒã‚¹ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã€.pdf\nIB Japanese A - Written Task 4 ã€Œæ–‡å­¦æ‰¹è©•ã€.pdf\n\n\nPresentations\n\nIB Japanese A - (Presentation)ã€€ç”˜ãˆã®æ§‹é€ ãƒ»ç¬¬äºŒç« ã®äºŒ.pdf\nIB Japanese A - (Presentation) æ—¥æœ¬èªã¨ã‚¢ãƒ‹ãƒ¡ã€Œã†ã•ããƒ‰ãƒ­ãƒƒãƒ—ã€.pdf\nIB Japanese A - (Presentation) Apple åºƒå‘Šæ‰¹è©•.pdf\n\n\nCommentary\n\nIB Japanese A - (Commentary) ã€Œæ—¥æœ¬èªã€.pdf\nIB Japanese A - (Commentary) ã€Œã“ã“ã‚ã€.pdf\nIB Japanese A - (Commentary) ã€Œé‡å‘‚æ¾äººå½¢ã€.pdf\nIB Japanese A - (Commentary)ã€€ã€Œç¾…ç”Ÿé–€ã€.pdf\n\n\n\nCore Â§\nExtended Essay Â§\nIB Extended Essay - Evaluation of Optimization Algorithms for Machine Learning.pdf\nTheory of Knowledge Â§\n\nIB ToK Essay - Epistemiology.pdf\nIB ToK Presentation - Consciousness.pdf\n"},"International-Trade":{"title":"International Trade","links":["Balance-of-Payments"],"tags":["Economics/Macro-Economics"],"content":"Balance of Payments"},"Jean-Baudrillard":{"title":"Jean Baudrillard","links":["Postmodernism","Living-in-Hyper-Reality"],"tags":["People","Philosophy"],"content":"The postmodern condition (Postmodernism)\ndef. Simulation\n\nbtw. illusion problem!= simulation problem\nThere is no way out of the simulation\npostmodern age: no longer a distinction between illusion and reality â‡’ this situation is a simulation\nâ€œstranded in a world without referentsâ€\nThe desert of the real (everything scary about postmodernism!)\nâ€œtribute to individuals which is property and function of the simulationâ€\nâ€œthe analyst of simulation, therefore, is subject to the very rule he or she analyzesâ€\nSimulation attempts to\n\nhypermarket\ndef. Referent\n\na signpost into reality\n\ndef. Simulacra\ndef. Hyperreality. See Living in Hyper-Reality"},"John-Rawls":{"title":"John Rawls","links":[],"tags":["People","Economics/Game-Theory"],"content":"\nJustice as Fairness\nMaximin Principle\nBasic Rights\n"},"John-Stewart-Mill":{"title":"John Stewart Mill","links":["Utilitarianism"],"tags":["People"],"content":"Utilitarianism"},"John-Stuart-Mill":{"title":"John Stuart Mill","links":[],"tags":["Economics","Philosophy","People"],"content":""},"Joint-Distributions":{"title":"Joint Distributions","links":["Marginal-Distribution","Expected-Value"],"tags":["Math/Probability"],"content":"Discrete Joint Distribution Â§\ndef. Joint Distributions of two discrete random variables X,Y encode the probabilities for every pair of (x,y) for (X,Y). Following is an example of a joint distribution where X is the result of rolling a first dice and Y the result of a second roll.\n\nREMARK. Joint Distributions are distributions too, which means it has to follow all the rules of distributions (e.g. âˆ‘=1)\nContinuous Joint Distribution Â§\ndef. Joint Probability Density. Let X,Y be two independent continous random variables. Then the joint probability density function is defined as the derivative of the cumulative density function:\nfX,Yâ€‹(x,y):=âˆ‚xâˆ‚yâˆ‚2FX,Yâ€‹(x,y)â€‹\nfX,Yâ€‹(x,y)Î”xÎ”y=P((x,y)âˆˆR)âˆ´fX,Yâ€‹(x,y)=Î”x,Î”yâ†’0limâ€‹Î”xÎ”yP(x,y)âˆˆRâ€‹\nAnd thus the following holds:\n\nP((x,y)âˆˆR)=âˆ¬Râ€‹f(x,y)Â dA where R is an event\nâˆ¬R2â€‹fdA=1\nXâŠ¥Yâ‡”fX,Yâ€‹=fXâ€‹â‹…fYâ€‹\n\n\nThe blue volume in the picture is the probability of the event X and Y are in R.\n\nSee Joint Marginal Distribution\nSee Joint Expected Value\n\nFull Visual Example Â§\n\n\nBlue is the probability density function, fX,Yâ€‹(x,y)={Ï€1â€‹0â€‹(xâˆ’1)2+yâ‰¤1elseâ€‹\nRed is the marginal probability density of Y,\n\nfâˆ—Y(y)={âˆ«âˆ—x=1âˆ’1âˆ’y2â€‹1+1+y2â€‹f_X,Y(x,y)dx0â€‹yâˆˆ[âˆ’1,1]elseâ€‹\nMinimum and Maximum Joint Dist Â§\nthm. Let X1â€‹,â€¦Xnâ€‹ be i.i.d.; let P=min(X1â€‹,â€¦,Xnâ€‹),Q=max(X1â€‹,â€¦,Xnâ€‹). Then:\nfP,Qâ€‹(p,q)={n(nâˆ’1)â‹…fXiâ€‹â€‹(p)â‹…fXiâ€‹â€‹(q)â‹…[âˆ«pqâ€‹fXiâ€‹â€‹(x)dx]nâˆ’20â€‹y&lt;zelseâ€‹\n\nExamples of Joint Distributions Â§\n\n\n                  \n                  Tip \n                  \n                \n\nRecall that joint distributions are also distributions [=encapsulate fully the information of an experiement].\nUniform Joint Â§\nthm. If X,Y are both uniformly distributed over [x1â€‹,x2â€‹],[y1â€‹,y2â€‹]â‰¡Î©, thenâ€¦\n\nheight of the distribution is âˆ£Î©âˆ£1â€‹ (where âˆ£Î©âˆ£ denotes the area of the outcome space.)\nP((x,y)âˆˆR)=âˆ£Î©âˆ£âˆ£Râˆ£â€‹\n\n\nNormal Joint (Linear Combination) Â§\nthm. Linear Combination of Normal Distributions. If X1â€‹âˆ¼N(Î¼1â€‹,Ïƒ1â€‹) and X2â€‹âˆ¼N(Î¼2â€‹,Ïƒ2â€‹) then:\nâˆ€a,bâˆˆR,aX1â€‹+bX2â€‹âˆ¼N(aÎ¼1â€‹+bÎ¼2â€‹,a2Ïƒ12â€‹+b2Ïƒ22â€‹)\nNormal Joint (Product) Â§\nthm. if Xâˆ¼N(Î¼1â€‹,Ïƒ2) and Yâˆ¼N(Î¼2â€‹,Ïƒ2) (i.e. std. dev. is the same) then\n\nfX,Yâ€‹=fXâ€‹â‹…fYâ€‹\nVolume of sector Î¸ from (Î¼1â€‹,Î¼2â€‹) is 2Ï€Î¸â€‹\n\n\nRayleigh Distribution Â§\n[=Squared &amp; Rooted Joint Normal]\ndef. Rayleigh Distribution. let X,Yâˆ¼Normal(0,Ïƒ) and W=X2+Y2â€‹, then:\nWfRâ€‹(r)FRâ€‹(r)E(X)=Ïƒ2Ï€â€‹â€‹Â Â Â â€‹âˆ¼Rayleigh(Ïƒ)Râˆ¼RL(Ïƒ)=Ïƒ2râ€‹e2â‹…Ïƒ2âˆ’r2â€‹Â forÂ r&gt;0=1âˆ’e2â‹…Ïƒ2âˆ’r2â€‹Â forÂ r&gt;0Â Â Â Â Â Â SD(X)=Ïƒ24âˆ’Ï€â€‹â€‹â€‹\n\nWhere Ïƒ is the â€œscaling factorâ€ (standard dev. must be same for X,Y)\nIf Ïƒ=1 then W is a Standard Rayleigh distribution:\n\nthm. Standardizing Rayleigh Distributions. If Wâˆ¼RL(Ïƒ):\nÏƒWâ€‹âˆ¼RL(1)"},"Joseph-Stiglitz":{"title":"Joseph Stiglitz","links":[],"tags":["Economics/Game-Theory","Economics/Finance","People"],"content":"Occupy Wall Street Movement"},"K-Clustering-Problem":{"title":"K-Clustering Problem","links":[],"tags":["Computing/Algorithms"],"content":"Notation Â§\n\np: a point\nÏ•:pâ†’c: which center is assigned to point p\nc1â€‹â€¦ckâ€‹: centers\n\nk: number of centers we want\n\n\n\nK-Max Â§\nQ. K-Max. K-Clustering with cost as maximum distance from center\nalg. K-Max approximation.\n\nChoose any point as one center\nChoose the point most distant from any chosen center points\nRepeat until you have any many centers as you wish\n\n\nTight 2-approximation\n\nUse triangle inequality\n\n\n\nK-Means Â§\nQ. K-Means. K-Clustering with cost total squared distance (equiv. to cost mean squared distance):\nC=âˆ‘âˆ£âˆ£pâˆ’Ï•(p)âˆ£âˆ£2\nalg. Lloydâ€™s Approximation Algorithm. (=K-Means Approximation)\n\nInitialize k centers arbitrarily\nDivide into clusters\nRecompute new centers as the mean point of each cluster\nRepeat as many times as you want\nAnalysis\n\n\nGuaranteed that every iteration will only decrease cost (=will converge)\nConverged centers are not guaranteed to be global optimum\n\nalg. K-Means++ Approximation Algorithm.\n\nInitialize k centers byâ€¦\n\nChoose any first center c1â€‹\nChoose randomly another point as the next center, but the probabiliy of choosing point p is proportional to distance between ciâ€‹ and p\nRepeat until we have all centers c1â€‹â€¦ckâ€‹\n\n\nRun Llyodâ€™s algorithm\nRe-initialize, re-run Llyod for T trials\nAnalysis\n\n\nE(ALG[T=1])=O(5lnk+10)OPT\nALG[T=O(logÏµ1â€‹)]=O(lnk)OPT with probability 1âˆ’Ïµ\n\ni.e. after T=O(logÏµ1â€‹) trialsâ€¦\nthe best trial run will very likely have cost O(lnk)OPT\n\n\n"},"Karl-Marx":{"title":"Karl Marx","links":[],"tags":["People","Philosophy/Political-Philosophy","Philosophy","Economics"],"content":""},"Knapsack-Problem":{"title":"Knapsack Problem","links":["utility","Subset-Sum"],"tags":["Computing/Algorithms"],"content":"def. Knapsack Problem. You have items 0â€¦nâˆ’1 with costs c[0â€¦nâˆ’1] and utility v[0â€¦nâˆ’1] with a budget B. What is the maximum utility you can achieve? Course Description\nIdea: Simple iteration DP\n\nthm. Knapsack is NP-complete\n\nIdea: Reduce from Partition Problem.\n"},"Knuthâ€“Morrisâ€“Pratt-Substring-Matching":{"title":"Knuthâ€“Morrisâ€“Pratt Substring Matching","links":[],"tags":["Computing/Algorithms"],"content":"You can match text of length m with pattern of length n in O(m+n). (Brute force matching takes O(mn)).\n\nLeetcode Problem: Leetcode 28. Find the Index of the First Occurrence in a String\nExplanation Video: Knuthâ€“Morrisâ€“Pratt(KMP) Pattern Matching\n\nGiven two strings needle and haystack, return the index of the first occurrence of needle in haystack, or -1 if needle is not part of haystack.\n1. Build Prefix-suffix Table Â§\ne.g.1:\npattern: A B A B C  \ntable:   0 0 1 2 0\nmeaning: e.g.  |--there is a prefix of length 2\n\ne.g.2:\nindex:   0 1 2 3 4 5 6 7 8 \npattern: a a b a a b a a a\ntable:   0 1 0 1 2 3 4 5 2\nmeaning e.g.         |--there is a prefix of length 4\n\n2. Compare Text with Pattern Â§\ntext:    a b x a b c a b c a b y\n---------------**********^---------\n\t\t\t\t\t\t |- y != c, search from index 2 \npattern: a b c a b y\nindex    0 1 2 3 4 5\ntable:   0 0 0 1 2 0\n\nTime to build table: O(n)\nTime to search text: O(m)\nTotal Time: O(m+n)"},"LRU-algorithm":{"title":"LRU algorithm","links":["Cache"],"tags":["Logistics","Computing/Algorithms"],"content":"Least Recently Used (LRU) is a cache replacement algorithm\n\nIn computing, cache replacement policies (also frequently called cache replacement algorithms or cache algorithms) are optimizing instructions, or algorithms, that a computer program or a hardware-maintained structure can utilize in order to manage a cache of information stored on the computer. Caching improves performance by keeping recent or often-used data items in memory locations that are faster or computationally cheaper to access than normal memory stores. When the cache is full, the algorithm must choose which items to discard to make room for the new ones.\nWikipedia\n\n(DevonThink) How Should You Organize Your Closet? Exactly Like a Computer Organizes Its Memory | WIRED"},"Laffer-Curve":{"title":"Laffer Curve","links":[],"tags":["Economics/Macro-Economics"],"content":"\nGovernment Revenue:\nG=wNSt=w(hâˆ’l)t\nObserve:\nâˆ‚tâˆ‚Gâ€‹=w(hâˆ’l)âˆ’twâˆ‚tâˆ‚lâ€‹\n\nIn economics, the Laffer Curve illustrates a theoretical relationship between rates of taxation and the resulting levels of the governmentâ€™s tax revenue. The\nThe shape of the curve is a function of taxable income elasticityâ€”i.e., taxable income changes in response to changes in the rate of taxation. As popularized by supply-side economist Arthur Laffer, the curve is typically represented as a graph that starts at 0% tax with zero revenue, rises to a maximum rate of revenue at an intermediate rate of taxation, and then falls again to zero revenue at a 100% tax rate. However, the shape of the curve is uncertain and disputed among economists.One implication of the Laffer curve is that increasing tax rates beyond a certain point is counter-productive for raising further tax revenue. Particularly in the United States, conservatives have used the Laffer curve to argue that lower taxes may increase tax revenue. However, the hypothetical maximum revenue point of the Laffer curve for any given market cannot be observed directly and can only be estimatedâ€”such estimates are often controversial. According to The New Palgrave Dictionary of Economics, estimates of revenue-maximizing income tax rates have varied widely, with a mid-range of around 70%.The Laffer curve was popularized in the United States with policymakers following an afternoon meeting with Ford Administration officials Dick Cheney and Donald Rumsfeld in 1974, in which Arthur Laffer reportedly sketched the curve on a napkin to illustrate his argument. The term â€œLaffer curveâ€ was coined by Jude Wanniski, who was also present at the meeting. The basic concept was not new; Laffer himself notes antecedents in the writings of the 14th-century social philosopher Ibn Khaldun and others.\nWikipedia\n"},"Lagrangian-Optimization":{"title":"Lagrangian Optimization","links":["Budget-Lines","Monotonic-Transformation","Utility-Function","Utility-Maximization"],"tags":["Economics/Micro-Economics","Math/Calculus"],"content":"Alg. Lagrangian Optimization.\nLet:\n\nf(x) the target function to optimize\ng(x)=c is the constraint function\nÎ» is the Lagrange multiplier.\n\n\n(when optimizing for budget constraint) Do a Monotonic Transformation on the Utility Function to make the function easier to manipulate\nThe Lagrangian function is constructed to find the maximum or minimum of a target function subject to constraints:\n\nThe Lagrangian: L(x,Î»)=f(x)âˆ’Î»(g(x)âˆ’c)\nÎ» is an unknown constant\n\n\nThe first-order necessary conditions (also known as KKT conditions) are found by taking the derivative of the Lagrangian with respect to all variables and the Lagrange multipliers, and setting them equal to zero:\n\nFor all i, âˆ‚xiâ€‹âˆ‚Lâ€‹=0\nâˆ‚Î»âˆ‚Lâ€‹=0\n\n\nFeasibility condition:\n\nIs it in the feasible region: g(x)=c?\n\n\nSolve for x,Î» â† this is the optimal point\n\n\n\n                  \n                  Example \n                  \n                \nWorked Example\n![[Pasted image 20230905153050.png|Worked Example|625]]\nUtility Maximization\n"},"Late-stage-Capitalism":{"title":"Late-stage Capitalism","links":[],"tags":["Economics"],"content":""},"Leverage":{"title":"Leverage","links":[],"tags":["Economics/Finance"],"content":""},"Lifetime-(Programming-Language)":{"title":"Lifetime (Programming Language)","links":[],"tags":["Computing"],"content":"Rust has generic lifetime annotations.\nValidating References with Lifetimes - The Rust Programming Language\nfn main() {\n    let r;                // ---------+-- &#039;a\n                          //          |\n    {                     //          |\n        let x = 5;        // -+-- &#039;b  |\n        r = &amp;x;           //  |       |\n    }                     // -+       |\n                          //          |\n    println!(&quot;r: {}&quot;, r); //          |\n}                         // ---------+\nâ€¦this returns a compiler error, because variable x does not live long enough, even though r is a valid value."},"Likelihood-(Statistics)":{"title":"Likelihood (Statistics)","links":["Estimator"],"tags":["Math/Statistics"],"content":"Likelihood:\n\ninstead of asking â€œgiven parameter Î¸ what is the probability of r.v. X=xâ€â€¦\nâ€¦ask: â€œgiven data about X, what is the likelihood of parameter Î¸ being within an interval?â€\n\nThis is the best way to evaluate an estimator.\nLikelihood Function Â§\ndef. The likelihood function for X1â€‹,â€¦,Xnâ€‹âˆ¼iidfXiâ€‹â€‹(x1â€‹,â€¦,xnâ€‹âˆ£Î¸) is the likelihood that given the data, the liklihood of parameter to be that value:\nL(Î¸)=fXâ€‹(Î¸;x)Lnâ€‹(Î¸)=fnâ€‹(Î¸;x1â€‹,...,xnâ€‹)=iidi=1âˆnâ€‹fXkâ€‹univarâ€‹(Î¸;xkâ€‹)\nwhere for the liklihood function, the variable is Î¸ and the parameters are x1â€‹,â€¦,xnâ€‹.\n\nThe domain of the likelihood function is the parameter space.\n\n\n\n                  \n                  Info \n                  \n                \n\nAlternatively, understanding L to be the (mythical) value of the pdf is another way to think of it.\ní™•ë¥ (Probability) vs ê°€ëŠ¥ë„(Likelihood)\ndef. the Log liklihood is simply the natural log of the likelihood function. It exists because itâ€™s just easy to manipulate.\nl(Î¸)=log[L(Î¸)]=log[fXiâ€‹â€‹(Î¸;x)]lnâ€‹(Î¸)=log[Lnâ€‹(Î¸)]=log[i=1âˆnâ€‹fXkâ€‹univarâ€‹(Î¸;xkâ€‹)]\nScore Â§\ndef. the Score is the derivative of the log likelihood. It measures how close the estimator Î¸^ is to the actual value of Î¸.\ns(Î¸)=âˆ‚Î¸âˆ‚logL(Î¸)â€‹\n\nScore is best when 0, and the absolute value measures how far away Î¸^ is from actual Î¸. Signed for direction.\nE[sâˆ£Î¸gtâ€‹]=0 â† under regularity conditions. Obviously, if we know real Î¸, then the score is perfect.\n"},"Likelihood-Ratio-Test":{"title":"Likelihood Ratio Test","links":["Likelihood-(Statistics)"],"tags":["Math/Statistics"],"content":"def. let X1â€‹,â€¦,Xnâ€‹âˆ¼f(;Î¸). To compare hypotheses:\n\n\nH0â€‹:Î¸=Î¸0â€‹\n\n\nH1â€‹:Î¸=Î¸1â€‹\nWe define the Likelihood (Statistics) Ratio Î› as:\n\n\nÎ›(X1â€‹,...,Xnâ€‹)=L(Î¸0â€‹;X1â€‹,...,Xnâ€‹)L(Î¸1â€‹;X1â€‹,...,Xnâ€‹)â€‹\nThen devise the Likelihood Ratio Test (LRT) for cutoff c:\nÎ´:{H0â€‹H1â€‹â€‹elseÂ ifÂ Î›&gt;câ€‹\nThe Significance of the LRT is in that it is the most powerful test:\nthm. Neymannâ€”Pearson Lemma. Given level Î± [=false positive rate = type I error rate], then the LRT is the Uniformly Most Powerful (UMP) test.\nThere is also another significant result for certain likelihood ratio. But first define:\ndef. Monotone Likelihood Ratio (MLR) is when the likelihood ratio Î› is never decreasing for some variable x.\nThen we can determine the UMP of such Î›:\nthm. Karlinâ€”Rubin Theorem. In a distribution with Î› that is MLR for region T(x) [statistic] for a sampling X1â€‹,â€¦,Xnâ€‹ in this distribution the UMP is:\nÎ´:{H0â€‹H1â€‹â€‹elseÂ ifÂ T&gt;câ€‹"},"Limit-Laws":{"title":"Limit Laws","links":[],"tags":["Math/Calculus"],"content":"Lâ€™HÃ´pitalâ€™s Rule Â§\nxâ†’climâ€‹g(x)f(x)â€‹=xâ†’climâ€‹gâ€²(x)fâ€²(x)â€‹\nInapplicable Scenarios\nSure, here are the limit laws in markdown table format:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLawsDescriptionConstant Lawlimxâ†’aâ€‹c=cIdentity Lawlimxâ†’aâ€‹x=aSum/Difference Lawlimxâ†’aâ€‹[f(x)Â±g(x)]=limxâ†’aâ€‹f(x)Â±limxâ†’aâ€‹g(x)Product Lawlimxâ†’aâ€‹[f(x)â‹…g(x)]=limxâ†’aâ€‹f(x)â‹…limxâ†’aâ€‹g(x)Quotient Lawlimxâ†’aâ€‹g(x)f(x)â€‹=limxâ†’aâ€‹g(x)limxâ†’aâ€‹f(x)â€‹ (if limxâ†’aâ€‹g(x)î€ =0)Exponentiation Lawlimxâ†’aâ€‹[f(x)]n=[limxâ†’aâ€‹f(x)]nComposition Lawlimxâ†’aâ€‹[f(g(x))]=f(limxâ†’aâ€‹g(x))Squeeze TheoremIf f(x)â‰¤g(x)â‰¤h(x) for all x in some interval containing a, and limxâ†’aâ€‹f(x)=L=limxâ†’aâ€‹h(x), then limxâ†’aâ€‹g(x)=L.Intermediate Value TheoremIf f(x) is a continuous function on the closed interval [a,b] and C is any number between f(a) and f(b), then there exists at least one number c in the interval (a,b) such that f(c)=C."},"Limits-of-Math-and-Computing":{"title":"Limits of Math and Computing","links":["Algorithm","Turing-Machine","(Book)-Godel-Escher-Bach"],"tags":["Philosophy/Analytic","Math","Computing/Formal-Languages"],"content":"\n\n                  \n                  Church-Turing Thesis \n                  \n                \nA function can be calculated by an Effective Method if and only if it is computable by a Turing Machine.\n\ni.e.\n\nAlgorithms and Turing Machines are the same thing.\nTuring Machines are the most power type of possible automation.\n\n\n\n                  \n                  Warning \n                  \n                \nIt cannot be proven until we know exactly what an â€Effective Methodâ€ is. Can humans be described by an effective method? Nobody knows.\n\nSee (Book) Godel Escher Bach for a deep dive."},"Linear-Algebra":{"title":"Linear Algebra","links":["main-diagonal","Matrix-Chain-Multiplication"],"tags":["Math/Linear-Algebra"],"content":"Vector Algebra\n\naTa=âˆ£aâˆ£2 is a scalar. aaT is an nÃ—n matrix.\nâˆ£aâˆ£=a12â€‹+â‹¯+an2â€‹â€‹\n\nMatrix can be\n\n\nSymmetric\n\nPositive-definite\nPositive-semi-definitie\nNegative-definite\nNegative-semi-definite\n\n\n\nDiagonal: entries outside the main diagonal are all zero\n\nDiagonalizable: A is diagonalizable iff exists invertible matrix P where PAPâˆ’1 is a diagonal matrix\n\nInverse of a diagonalizable matrix is also diagonalizable\nOrthogonally diagonalizable: A is orthogonally diagonizable iff exists orthogonal matrix P where PAPT=PAPâˆ’1=I\n\n\n\n\n\nInvertible vs Singular\n\nInvertible: There exists an inverse = determinant is non-zero âˆ£Aâˆ£î€ =0\n\nThe inverse of a symmetric matrix is also symmetric\n\n\nSingular: There does not exist an inverse\nAAâˆ’1=I\n\n\n\nOrthogonal:A is orthogonal iff Aâˆ’1=AT\n\n\nRank:= dimension of the vector space generated by its columns\n\n\nIdentity Matrix I\n\n\nDeterminant: scalar value that determines if the matrix has a determinant\n\n\nMatrix Algebra Identities\n\nNon-commutative\n\nCommutative only with scalars\n\n\nDistributive (w.r.t. matrix addition)\nAssociative\n\nComputational complexity depends on which you multipliy first: Matrix Chain Multiplication\n\n\nTranspose-distribution (AbC)T=CTbAT\nInverse-distribution (AB)âˆ’1=Bâˆ’1Aâˆ’1\nTranspose-Inverse (AT)âˆ’1=(Aâˆ’1)T\n"},"Linear-Programming":{"title":"Linear Programming","links":[],"tags":["Computing/Algorithms"],"content":"Linear Programing Â§\nInteger Linear Programming Â§\nLinear programming but only for integer solutions. Example of a {0,1} ILP problem.\n\n\n{0,1} ILP is NP-complete\nGeneral ILP is also NP-complete\n"},"List-of-Elasticities-and-Rates-of-Substitution":{"title":"List of Elasticities and Rates of Substitution","links":["Price-Elasticity-of-Demand","Elasticity-of-Substitution","Technical-Rate-of-Substitution"],"tags":["Economics"],"content":"\nElasticity of Demand\nElasticity of Substitution\nTechnical Rate of Substitution\n"},"Living-With-the-Internet":{"title":"Living With the Internet","links":["Personal-Computing","Attention-is-Currency","Highly-Sensitive-Person-(HSP)","Stream-of-Content","CGP-Grey","Negative-Emotions-are-Not-Helpful","Nudging"],"tags":["Computing/Internet"],"content":"\n\n                  \n                  Abstract \n                  \n                \n\nThe internet is a world you can access with the terminal of your personal computer.\nThe internet was, is, and always will be uncharted territory.\n\n\nPrinciples Â§\n\n\n                  \n                  Digital Minimalism \n                  \n                \n\n\nCritical Information Consumption\n\nTo navigate the dangers of the web, you need critical thinking â€“ but also critical ignoring\n\n\nAttention is Currency\n\nModern society, wrote Simon, faces a challenge: to learn to â€œallocate attention efficiently among the overabundance of sources that might consume it.â€\n\nAttention is the currency of the modern internet businesses.\nCorporate internet tries to entice you with your attention. (there is a distinction between corporate internet and grassroots internet.)\n\n\nBeware Overstimulation. Give attention to what matters only.\n\nUse the Stream of Contentâ€”pick out only what you find nutritious, and ignore the rest.\n\n\nCGP Grey: Thinking about Attention by CGP Grey\n\n\nRefraining from Outrage\n\nCGP Grey: Though Germs by CGP Grey\nNegative Emotions are Not Helpful.\n\n\nSolution: Nudging\n\nBuild in friction to reduce the chances of you giving into attention-sucking content or outrage content\n\n\n"},"Living-in-Hyper-Reality":{"title":"Living in Hyper-Reality","links":["Jean-Baudrillard","Emergent-Phenomena","Hyper-Reality","Normative-Scripts","Ask-vs.-Guess-Culture","Social-Media","Living-With-the-Internet","Personal-Computing","Tools-and-Structures-Define-Your-Capacity","Pride","Gender-is-a-performance"],"tags":["Philosophy/Epistemology"],"content":"We no longer live in a world that is understandable through the natural way of things. (Jean Baudrillard)\n\nThe Emergent Phenomena our societies have constructed, from Gender Roles to Ask vs. Guess Culture, Social Media is far removed from our nature as human beings or our nature of what it means to be a social creature.\nâ‡’ Itâ€™s past the tipping point of being connected to the â€œrealâ€, thus Baudrillardâ€™s Hyperreality\nThe naturalism argument no longer holds\nâ€œItâ€™s the way itâ€™s always beenâ€ no longer holds ground\n\nInstead of invoking hyperreality as something to be afraid of, embrace it.\n\nLiving With the Internet\nPersonal Computing\nTools and Structures Define Your Capacity\nPride, and Gender is a performance\n"},"Living-in-HyperReality":{"title":"Living in HyperReality","links":["Jean-Baudrillard","Emergent-Phenomena","Constructed-World","Society's-Scripts","Ask-vs.-Guess-Culture","Social-Media","Living-With-the-Internet","The-Personal-Computer","Tools-and-Structures-Define-Your-Capacity","Pride","Gender-is-a-performance"],"tags":["Philosophy/Epistemology"],"content":"We no longer live in a world that is understandable through the natural way of things. (Jean Baudrillard)\n\nThe Emergent Phenomena our societies have constructed, from Gender Roles to Ask vs. Guess Culture, Social Media is far removed from our nature as human beings or our nature of what it means to be a social creature.\nâ‡’ Itâ€™s past the tipping point of being connected to the â€œrealâ€, thus Baudrillardâ€™s Hyperreality\nThe naturalism argument no longer holds\nâ€œItâ€™s the way itâ€™s always beenâ€ no longer holds ground\n\nInstead of invoking hyperreality as something to be afraid of, embrace it.\n\nLiving With the Internet\nThe Personal Computer\nTools and Structures Define Your Capacity\nPride, and Gender is a performance\n"},"Log-Rules-and-Exponent-Rules":{"title":"Log Rules and Exponent Rules","links":[],"tags":["Math"],"content":"\nProduct Rule:\n\nlogbâ€‹(xy)=logbâ€‹x+logbâ€‹y\n\n\nQuotient Rule:\n\nlogbâ€‹(x/y)=logbâ€‹xâˆ’logbâ€‹y\n\n\nPower Rule:\n\nlogbâ€‹xn=nâ‹…logbâ€‹x\n\n\nChange of Base Rule:\n\nlogbâ€‹a=logcâ€‹blogcâ€‹aâ€‹\n\n\nIdentity Rule:\n\nlogbâ€‹b=1 and logbâ€‹1=0\n\n\n"},"Log-Rules":{"title":"Log Rules","links":[],"tags":["Math"],"content":"\nProduct Rule:\n\nlogbâ€‹(xy)=logbâ€‹x+logbâ€‹y\n\n\nQuotient Rule:\n\nlogbâ€‹(x/y)=logbâ€‹xâˆ’logbâ€‹y\n\n\nPower Rule:\n\nlogbâ€‹xn=nâ‹…logbâ€‹x\n\n\nChange of Base Rule:\n\nlogbâ€‹a=logcâ€‹blogcâ€‹aâ€‹\n\n\nIdentity Rule:\n\nlogbâ€‹b=1 and logbâ€‹1=0\n\n\n"},"Lognormal-Distribution":{"title":"Lognormal Distribution","links":["Normal-Distribution"],"tags":["Math/Common-Distributions"],"content":"def. Lognormal Distribution. A random variable X is a lognormal random variable iff\n\nX=ln(N(Î¼,Ïƒ2)) i.e. log of the Normal Distribution random variable\nPDF:\n\nfXâ€‹(x)=xÏƒ2Ï€â€‹1â€‹exp[âˆ’2Ïƒ2(lnxâˆ’Î¼)2â€‹]\n\nE(X)=eÎ¼+2Ïƒ2â€‹\nVar(X)=(eÏƒ2âˆ’1)e2Î¼+Ïƒ2\nCDF:\n\nFXâ€‹(x)=Î¦(Ïƒlnxâˆ’Î¼â€‹)\n- Where $\\Phi$ is the Standard [[Normal Distribution]] CDF.\n"},"Longest-Common-Sequence":{"title":"Longest Common Sequence","links":[],"tags":["Computing/Algorithms"],"content":""},"Longest-Palindrome-Algorithm":{"title":"Longest Palindrome Algorithm","links":[],"tags":["Computing/Algorithms"],"content":""},"Longest-Palindromic-Substring":{"title":"Longest Palindromic Substring","links":[],"tags":["Computing/Algorithms"],"content":"def. Longest Palindromic Substring.\ndef. Smallest Palindromic Decomposition. Homework Link"},"Machine-Learning":{"title":"Machine Learning","links":[],"tags":["Computing"],"content":"Machine Learning Â§\nOverview Â§\nTopics in:\nNN, CNN, RNN, LSTM, Reinforcement, GAN\nTools and libraries:\npyplotlib, scipy, numpy, tensorflow\nAsk HN: Full-on machine learning for 2020, what are the best resources? | Hacker News\nSince the â€œHow Do I Learn AI/MLâ€ question pops up on Hacker News once a month (mâ€¦ | Hacker News\n\n\n                  \n                  Honestly, skip all of the courses. Pick a problem to solve, start googling for common models that are used to solve the problem, then go on github, find code that solves that problem or a similar one. Download the code and start working with it, change it, experiment. All of the theory and such is mostly worthless, its too much to learn from scratch and you will probably use very little of it. There is so much ml code on github to learn from, its really the best way. When you encounter a concept you need to understand, google the concept and learn the background info. This will give you a highly applied and intuitive understanding of solving ml problems, but you will have large gaps. Which is fine, unless you are going in for job interviews. \n                  \n                \n\nReferences Â§\nPapers with Code - The latest in Machine Learning\nTowards Data Science\nMachine Learning Glossary | Google Developers\nLinks &amp; Tutorials Â§\nForwardpropagation - ML Glossary documentation\nhttps://www.youtube.com/watch?v=NfnWJUyUJYU&amp;list=PLkt2uSq6rBVctENoVBg1TpCC7OQi31AlC\nCS231n Convolutional Neural Networks for Visual Recognition\nMathematics for Machine Learning\nMathematics for Machine Learning\nStanford CS321n\nCS231n Convolutional Neural Networks for Visual Recognition\nGenerative Adversarial Networks Â§\nUnderstanding Generative Adversarial Networks (GANs)"},"Macroeconomic-Market-Equilibrium":{"title":"Macroeconomic Market Equilibrium","links":[],"tags":["Economics/Macro-Economics"],"content":"General Equilibrium Â§\n\nMarket Equilibrium is a point that is both optimal and feasible:\n\nOptimality: HHs, firms, govnâ€™t are maximally happy; Ï€, u maximized, government plan is in place\nFeasibility: Budget/Resource Constraints are in action\n\nFeasibility Â§\n\nLabor Market: NS=ND\nGoods Market: YS=C+G â†â€œResource Constraintâ€\nHH income: C+T=wN+Ï€ â†â€Consumer Budget Constraintâ€\nGovernment G=T â†â€Government Budget Constraintâ€\n\nâ‡’ If the two of three budget constraints are satisfied, the other one is automatically satisfied\n\nDeriving the Equilibrium Â§\n1. Production Possibility Frontier Â§\n\n\nPPF indicates current level of technology, levels of govnâ€™t spending\nGradient of the PPF is the Marginal Rate of Transformation (MRT) of the economy; i.e. opportunity cost of transforming between consumption and leisure. This is equivalent to wage.\nGovernment speding is indicated by a downward shift of the PPF\n\n2. Household Optimization Â§\n\n\nConsider: even if households do not work, they will get Ï€+NetÂ Transfers amount of income\n\n1+2: Market Equilibrium Â§\n\nAt Point Aâˆ—(Câˆ—,Lâˆ—):\n\nFirms produce maximally, HHs maximize utility\nIs feasible [=inside PPF, inside HH budget constraint]\nMRS=MRT=âˆ’w\n\n\n\n                  \n                  Examples of Disequilibrium \n                  \n                \nâ†’ The left case: MRS=MRT but is infeasible âˆµ household indifference curve is outside\nâ†’ The right case: feasible, but household utility is not maximized\n\n\nChanges in Equilibrium Â§\n\nChanges in Government Spending [= G], normally due to war, or infrastructure projects\n\n\n\n\n                  \n                  Government can crowd out private consumption, because it reduces HH income (income effect): \n                  \n                \n\nTaxesâ†‘ â‡’ HH income â†“ â‡’ YDâ†“ â‡’ NSâ†“ â‡’ Y likely increases âˆµ Yâ†‘=Câ†“+Gâ‡‘"},"Macroeconomic-Variable-Relationships":{"title":"Macroeconomic Variable Relationships","links":["Philips-Curve","Beveridge-Curve","Laffer-Curve"],"tags":["Economics/Macro-Economics"],"content":"\nPhilips Curve: Unemployment vs Interest Rate\nBeveridge Curve: Unemployment vs Job Vacancies\nLaffer Curve: Government Revenue vs Tax Rate\n"},"Macroeconomics":{"title":"Macroeconomics","links":["Unemployment","Inflation","Circular-Flow-of-Income","Taxation"],"tags":["Economics/Macro-Economics"],"content":"Macroeconomics studies Aggregate Pheonomena of: GDP / Employment / Investment / Inflation &amp; Money / LR growth / Investment, Govnâ€™t Expenditure, Exports.\n\nBegan formally from the 20th century after the Great Depression; before that it ways just microeconomics. (Keynes &amp; Hayaek)\nStatic vs Dynamic\n\nStatic: comparing at the same point in time\nDynamic: comparing at different points in time\ne.g. Comparative statics, like an exogenous increase in demand causing QSâ€‹ to increase\n\n\nEconomic Time in macro covers usually the following timeframes:\n\nShort Run (SR): several years\nMedium Run (MR): 1~2 years\nLong Run (LR): Decades\n\n\nReal vs Nominal Variables.\n\nReal: real things as units (cars, hours, gallons), or base-year currency\nNominal: values in currency at a certain year\n\n\n\nUnemployment\nInflation\nCircular Flow of Income\nTaxation"},"Majority-Voting-Algorithm":{"title":"Majority Voting Algorithm","links":["CS330-HW03"],"tags":["Computing/Algorithms"],"content":"From CS330 HW03\nProblem. Call an array good if more than half of its elements are the same. The domain from which the elements are taken is not necessarily ordered like integers so one cannot make comparisons like â€œIs A[i] &gt; A[j]?â€ or sort the array, but one can check whether two elements are the same in O(1) time.\nIdea: a majority element must be majority in either of the two halves of an array.\nAlgorithm:\n# array to check\nA[1..n]\n \nfunction Count(l, r, elem)\n\t# base case\n\tif l = r\n\t\treturn 1\n \n\t# divide array into two, and count there\n\tm = ceiling((l+r)*0.5)\n\tl_count = PCount(l, m, elem)\n\tr_count = PCount(m+1, r, elem)\n \n\t# return the sum of left and right counts\n\treturn l_count + r_count\n \nfunction MajorityElem(l,r)\n\t# base case\n\tif l = r\n\t\treturn A[l] \n \n\t# check left, right half majority\n\tm = ceiling((l+r)*0.5)\n\tleft_majority = MajorityElem(l, m)\n\tright_majority = MajorityElem(m+1, r)\n \n\t## check consensus\n \n\t# check no consensus first; if one is null return the non-null\n\tif left_majority == NULL and right_majority != NULL:\n\t\treturn right_majority\n\tif left_majority != NULL and right_majority == NULL:\n\t\treturn left_majority\n \n\t# there cannot be a both no consensus case\n \n\t# consensus agrees\n\tif left_majority == right_majority:\n\t\treturn left_majority\n\t\n\t# consensus disagrees\n\telse if left_majority != right_majority:\n \n\t\t# count the majority\n\t\tleft_count = Count(l, r, left_majority)\n\t\tright_count = Count(l, r, right_majority)\n\t\t\n\t\t# if tied, no consensus\n\t\tif left_count == right_count\n\t\t\treturn NULL\n\t\t\n\t\t# winner exists, return the winner\n\t\treturn left_count &gt; right_count ? left_majority : right_majority\n\t\t\n\nCount function: T(n)â‰¤2T(2nâ€‹)+O(1)=O(n)\nMajorityElement function: T(n)â‰¤2T(2nâ€‹)+2â‹…O(n)\n\nFirst term: recursive calls\nSecond term: calls Count\nSolution: T(n)=O(nlogn) (same recurrence relation as mergesort)\n\n\nCorrectness (Brief argument):\n\nBase case: in n=1 the element is majority element\nIH: Assume MajorityElement(k/2) is correct.\nIS:\n\nIf one of them has no majority but the other ones does, the one with majority must be the true majority because of an element exists in more than half of the total array it must be that in one of the halves it will be the majority.\nIf both halves have a majority, then the one that has more counts in the total array wins\nThere cannot be a both halves no-majority case as explained in (1)\n\n\n\n\n"},"Malthusian-Growth":{"title":"Malthusian Growth","links":[],"tags":["Economics/Macro-Economics"],"content":""},"Map-of-Microeconomic-Optimization":{"title":"Map of Microeconomic Optimization","links":["Utility-Maximization","Uncompensated-Demand-curve","Indirect-Utility-Function","Roy's-Identity","Expenditure-Minimization","Marginal-Willingness-to-Pay","Expenditure-Function","Shepard's-Lemma","Profit-Maximization","Input-Demand-and-Output-Supply","HowTo---Profit-Maximization-for-Perfect-Competition-for-Perfect-Competition","Hotelling's-Lemma","Cost-Minimization","Cost-Function"],"tags":["Economics/Micro-Economics"],"content":"Utility Maximization (Household) Â§\n\n\nUtility Maximization\n\nUncompensated Demand Function (p1â€‹,p2â€‹,I)â†¦x1â€‹\nIndirect Utility Function (p1â€‹,p2â€‹,I)â†¦u\nRoyâ€™s Identity\n\n\nExpenditure Minimization\n\nCompensated Demand Function (p1â€‹,p2â€‹,u)â†¦x1â€‹\nExpenditure Function (p1â€‹,p2â€‹,u)â†¦I\nShepardâ€™s Lemma\n\n\nInvert between Indirect Utility Function and Expenditure Function by solving for I or u depending on what you want.\n\nProfit Maximization (Firm) Â§\n\n\nProfit Maximization maxl,kâ€‹Â Ï€=pxâˆ’wlâˆ’rkÂ Â suchÂ thatÂ x=f(l,k)\n\nOrdinary Input Demand and Output Supply (w,r,p)â†¦l,k\nOutput Input Demand and Output Supply (w,r,p)â†¦x\nProfit Function (w,r,p)â†¦Ï€\n\nHotellingâ€™s Lemma back to input demand\n\n\n\n\nCost Minimization minl,kâ€‹Â c=wl+rkÂ suchÂ thatÂ x=f(l,k)\n\nConditional Input Demand and Output Supply (w,r,xË‰)â†¦l,k\nConditional Cost Function (w,r,xË‰)â†¦C\n\nShepardâ€™s Lemma back to conditional input demand\n\n\n\n\nmaxxâ€‹pxâˆ’C(w,r,xË‰) for cost function to output supply\nsubstitute Input Demand and Output Supply into Conditional Input Demand to get Ordinary Input Demand and Output Supply\n"},"Marginal-Distribution":{"title":"Marginal Distribution","links":["Joint-Distributions"],"tags":["Math/Probability"],"content":"Discrete Marginal Distribution Â§\ndef. Marginal Distributions are used when you only have the joint distribution available, and you want to get the distribution of one of the variables. Theyâ€™re called that because you can write them in the margins.\n\nJoint Marginal Distribution Â§\ndef. Marginal Distribution of Continuous Joint Distributions. Let X,Y and given fX,Yâ€‹. Then PDF of X is:\nfXâ€‹(xË‰)=âˆ«y=âˆ’âˆâˆâ€‹fX,Yâ€‹(xË‰,y)dy\nâ€¦and vice versa for fYâ€‹.\n\nThe red area is the marginal probability density at x."},"Marginal-Rate-of-Substitution-(MRS)":{"title":"Marginal Rate of Substitution (MRS)","links":["Utility-Function","Rationality-(Economics)"],"tags":["Economics/Micro-Economics"],"content":"def. Marginal Rate of Substitution. MRS1,2â€‹ asks â€œHow much of x2â€‹ can you give me for one unit of x1â€‹?â€\n\nMRS1,2â€‹ means MRS of good x1â€‹ for good x2â€‹, i.e. â€œone unit of x1â€‹ for how many units of x2â€‹?&quot;&quot;\n\nMRS1,2â€‹:=âˆ’dx1â€‹dx2â€‹â€‹=âˆ’âˆ‚x2â€‹âˆ‚uâ€‹âˆ‚x1â€‹âˆ‚uâ€‹â€‹\n\n\n                  \n                  x_{1},x_{2} changes spots in the nominator/denominator in the final formula.\n                  \n                \n\n\n\nThe tangent of Utility Function at a certain point is the MRS at that specific point (more accurately, its absolute value of the tangent)\nConvexity Assumption causes MRS to decrease (=Diminishing MRS) rightward (the more of good x1â€‹ we consume, the more we would like x2).\nWhen two people have different MRS, then they can trade for both of their utility.\n\ne.g. MRSAâ€‹=âˆ’3, MRSBâ€‹=âˆ’21â€‹\nâ‡’ they can trade at any rate where MRSAâ€‹&lt;rate&lt;MRSBâ€‹ to both of their benefit.\n\n\n\nDeriving the MRS Formula Â§\nWeâ€™re looking for a place on the scalar field provided by u(x1â€‹,x2â€‹) where the gradient is zero.\nâ‡’ Thus we need to find a point where the following is true:\nâˆ‡u(x1â€‹,x2â€‹)=Î´x1â€‹Î´uâ€‹dx1â€‹+Î´x2â€‹Î´uâ€‹dx2â€‹=0\nBy the definition of MRS itâ€™s the gradient of a indifference curve, i.e. the gradient of a level curve in the field:\nMRS=âˆ’dx1â€‹dx2â€‹â€‹=âˆ’âˆ‚u/âˆ‚x2â€‹âˆ‚u/âˆ‚x1â€‹â€‹\nChanges in MRS Â§\n\nMRS can change due to exogenous factors; in this case the whole indifference curve will change accordingly too.\ne.g. After 9.11., air travel is perceived by consumers to be less safe.\n\n\n\nObserve that air travel becoming less safe, causes the MRS to decrease, as one is willing to trade less money for flying by air.\nYou can think of this from a different perspective by instead of thinking of air safety as an exogenous factor, actually quantifying air safety as a measure as well, and graphing it together.\nGraphing air safety as the third axis shows that we can in fact visualize the decrease in MRS of air miles and $â€˜s of other consumption.\n\n"},"Marginal-Willingness-to-Pay":{"title":"Marginal Willingness to Pay","links":["CGP-grey","Consumer-Surplus","Expenditure-Minimization","Utility-Function","HD"],"tags":["Economics/Micro-Economics"],"content":"\n\n                  \n                  Abstract \n                  \n                \nBasically, â€œIn a vacuum, how much do you want it?â€\n\nThink CGP greyâ€™s â€œIâ€™d pay anything for Apple to make X.â€\nUsed to calculate Consumer Surplus\nDoesnâ€™t really show up in actual reality. A theoretical construct to help calculate some things\n\n\nMarginal Willingness to Pay (MWTP) Curve is derived from a single Indifference curveâ€™s MRS along different consumption quantitiesâ€”when the y-axis is measured in $ of other goods.\nDerivation. Expenditure Minimization of the Utility Function\nProperties.\n\nDecreasing in own price\nHD0 in prices (h1â€‹(tp1â€‹,tp2â€‹,uË‰)=h1â€‹(p1â€‹,p2â€‹,uË‰))\n\nIn other words, if the ratio of prices are the same, your behavior wonâ€™t change (but you may need more income).\n\n\n\nâ‡’ The area under the MWTP curve is closely related to Consumer Surplus.\nâ†’ Think of it as the amount a consumer is willing to pay per unit of goodâ€”when they want it more, theyâ€™ll obviously willing to pay less for even more of it, so the MWTP slopes down.\n\nThis is sometimes called the Compensated Demand Curve, since you can think of it in terms of:\n\nA change in price (blue to red)\nCompensating your budget by a certain amount so youâ€™re not worse off than before (red to green)\nGraphing the optimal points along quantity consumed and price\n\nMWTP curves can be same or different to own-price demand curves (OPDC). This is because\n\n\nMWTP accounts only for the substitution effect, while OPDC accounts for both the substitution effect and the income effect\nMWTP is along one indifference curveâ€”a fixed utilityâ€”, while OPDC doesnâ€™t care about utility.\n\n"},"Market-Beta":{"title":"Market Beta","links":["CAPM-Model"],"tags":["Economics/Finance"],"content":"Market Beta (Î²)\n\nConsider:\n\nSecurity i with (Ri,â€‹,Ïƒiâ€‹,Î¼iâ€‹)\nMarket (RMâ€‹,ÏƒMâ€‹,Î¼Mâ€‹)\n&amp;  Market Beta measures the degree to which the security price correlates with the market price\n\nMarket beta is a coefficient of regression, derived from past data\n\n\nMarketâ€™s beta is 1.\n\n\nDefinition: Î²iâ€‹:=ÏƒM2â€‹Cov(Riâ€‹,RMâ€‹)â€‹=Ïi,Mâ€‹â‹…ÏƒMâ€‹Ïƒiâ€‹â€‹\nÎ²iâ€‹=Î¼Mâ€‹âˆ’Î¼fâ€‹Î¼iâ€‹âˆ’Î¼fâ€‹â€‹ or equivalently Î¼iâ€‹âˆ’Î¼fâ€‹=Î²(Î¼Mâ€‹âˆ’Î¼fâ€‹) â† â€CAPM Modelâ€\n\nUnder assumptions V is positive definite, Î¼â€‹,e are linearly independent and 0â‰¤Î¼fâ€‹&lt;max(Î¼â€‹)\nÎ²&lt;0: security return is opposite of market\nÎ²=0: security is uncorrelated to market\n0&lt;Î²&lt;1: security return moves same as market, but fluctuates less (defensive)\n1&lt;Î²: security return moves same as market, but fluctuates more (aggressive)\n\n\n\n\n\n                  \n                  Security Market Line \n                  \n                \nPlotting Î¼iâ€‹âˆ’Î¼fâ€‹=Î²(Î¼Mâ€‹âˆ’Î¼fâ€‹) with return vs market beta:\n\n"},"Market-Power":{"title":"Market Power","links":["Monopolistic-Competition"],"tags":["Economics/Micro-Economics"],"content":"Monopolistic Competition"},"Markov-Inequality":{"title":"Markov Inequality","links":[],"tags":["Math/Statistics"],"content":"thm. Markov Inequality. For a non-negative random variable X, the following hols for all positive constant a:\nP(Xâ‰¥a)â‰¤aE(X)â€‹"},"Martha-Nussbaum":{"title":"Martha Nussbaum","links":["cosmopolitan"],"tags":["People"],"content":"\nAuthor of Cultivating Humanity, book about what a cosmopolitan university education system would look like\nAuthor of article (DevonThink) Patriotism and Cosmopolitanism - Boston Review\n"},"Matching-Problems":{"title":"Matching Problems","links":["Property-Exchange","Stable-Marriage-Problem","Maximum-Flow-Problem"],"tags":["Computing/Algorithms"],"content":"\nUnpartitioned Matching: Priority Matching Algorithm\nPartitioned Matching:\n\nGale-Shapely Algorithim\nApplication of Ford-Fulkerson Maximum Flow Algorithm \n\n\n"},"Math-581-Mathematical-Finance":{"title":"Math 581 Mathematical Finance","links":["Value-of-Money","Present-Value-Calculations","Future-Value-Calculations","Interest-Rate","Banker's-Rule","Annuity","Perpetuity","Bond-Price","Portfolio-Theory","Dividend-Discount-Model","CAPM-Model","Market-Beta","Measuring-Security-Performance","Binomial-Security-Pricing-Model","Stochastic-Process","Stochastic-Calculus","Options-(Finance)","No-Arbitrage","Black-Scholes-Merton-Derivative-Pricing-Formula","581-Exam-Topics"],"tags":["Courses"],"content":"\nTime Value of Money\n\nPresent Value Calculations\nFuture Value Calculations\nInterest Rate\nBankerâ€™s Rule\n\n\nAmortizing Securities\n\nAnnuity\nPerpetuity\nBond Price\n\n\nPortfolio Theory\n\nDividend Discount Model\nCAPM Model\n\nMarket Beta\n\n\nMeasuring Security Performance\n\n\nBinomial Security Pricing Model\n\nLog Normal Model of Security Pricing\n\n\nStochastic Process &amp; Stochastic Calculus\nOptions (Finance)\n\nNo-Arbitrage\nBlack-Scholes-Merton Derivative Pricing Formula\n\n\n581 Exam Topics\n"},"Math-582-Financial-Derivatives":{"title":"Math 582 Financial Derivatives","links":["Probability","Expected-Value","Binomial-Security-Pricing-Model","Stochastic-Process","Stochastic-Calculus","Quadratic-Variation","No-Arbitrage","Forwards","Futures","Options-(Finance)","Black-Scholes-European-Option-Pricing-Formula","Risk-Neutral-Assumption","Risk-Neutral-Derivation-of-BSM","Binomial-Option-Pricing-Model","Greeks-(Option)","Delta-and-Gamma-Hedging","Warrants-(Finance)","Merton-Jump-Diffusion-Model","tags/task"],"tags":["Courses","task"],"content":"\n\n                  \n                  For Stochastic Calculus \n                  \n                \nYoung man, in mathematics you donâ€™t understand things. You just get used to them.â€\n\n\n\nProbability\n\nConditional Expected Value\n\n\n\nBinomial Security Pricing Model\n\n\nStochastic Process\n\nStochastic Calculus\nQuadratic Variation\n\n\n\nNo-Arbitrage (=Law of One Price)\n\n\nForwards\n\nFutures\n\n\n\nOptions (Finance)\n\nBlack Scholes European Option Pricing Formula\n\nRisk-Neutral Assumption and Risk-Neutral Derivation of BSM\nBinomial Option Pricing Model derivation of BSM\n\n\nGreeks (Option)\nDelta and Gamma Hedging\nWarrants (Finance)\nMerton Jump Diffusion Model\n\n\n\nPayoff: the gross outcome of an investment or trade. The amount you earned from that trade, regardless of commissions, extraneous costs, etc.\n\n\nProfits: the gross outcome of an investment or trade, including commissions, extraneous cost\n\nâ†’ the distinction happens in Options (Finance). Payoffs donâ€™t consider the option premium, while the profits do.\n\n\n\nReturn: short for â€œrate of returnâ€. The percentage of profit (not payoff!) per original investment. Quoted in percentage (%) or log-returns.\n\n\n #task 582: Why expectation is zero? here\n\n\n TW2 Q1(g) &amp; Q2(a)#task\n\n\n TW3 Q4 &amp; Q5 &amp; Q6#task\n\n\n TW: Solving the BSM PDE (second derivatives)#task\n\n\n TW8#task\n\n\n #task understand Warrants (Finance)\n\n\n #task Understand gamma hedging\n\n\n #task understand Risk-Neutral Derivation of BSM\n\n\n #task Understand Merton Jump Diffusion Model\n\n\n #task Understanding Quadratic Variation\n\n"},"Mathematical-Induction":{"title":"Mathematical Induction","links":[],"tags":["Math"],"content":"Weak Induction [=Normal Induction] Â§\n\nBase case\n\nP(1)Â isÂ trueÂ \n\nInductive Hypothesis (IH)\n\nAssumeÂ P(k)Â isÂ true\n\nInductive Step\n\nP(k)Â isÂ trueÂ â‡’P(k+1)Â isÂ true\nStrong Induction Â§\n\nBase cases\n\nP(1)â€¦P(n)Â isÂ true\n\nInductive Hypothesis (IH)\n\nAssumeÂ P(k)Â isÂ true\n\nInductive Step\n\nP(k)Â isÂ trueÂ â‡’P(k+1)Â isÂ true"},"Mathematical-Optimization":{"title":"Mathematical Optimization","links":["Lagrangian-Optimization","Linear-Programming","Convex-Programming","tags/task"],"tags":["Math/Calculus","task"],"content":"\nLagrangian Optimization\nLinear Programming\nConvex Programming\n\nKKT conditions\n\n\n #task understand kkt conditions\n"},"Mathematical-Proof":{"title":"Mathematical Proof","links":["Mathematical-Induction","Proof-by-contradiction"],"tags":["Math"],"content":"Types of proofs:\n\nMathematical Induction\nProof by contradiction\nContrapositive Proof: prove pâŸ¹q by proving Â¬qâŸ¹Â¬p\n"},"Matrix-Chain-Multiplication":{"title":"Matrix Chain Multiplication","links":["Dynamic-Programming"],"tags":["Computing/Algorithms"],"content":"Matrix Chain Multiplication. Given matricies A0â€‹,â€¦,Anâˆ’1â€‹ with dimensions (m0â€‹Ã—m1â€‹),(m1â€‹Ã—m2â€‹),â€¦,(mnâˆ’1â€‹Ã—mnâ€‹), which order should we multiply the matricies in order to minimize the number of scalar multiplications? Description from course\nIdea:\n\nSearch every subproblem but with Dynamic Programming.\nfor every chain of matricies, get the split with minimum multiplication required.\nIterate for increasing gap (=chain length)\n\n\n"},"Matrix-Multiplication":{"title":"Matrix Multiplication","links":["Parallel-Algorithms","Inner-Product","tags/processors"],"tags":["Computing/Algorithms","processors"],"content":"Traditional (Textbook) algorithm is O(n3)\nWe have gotten it down to â‰ˆO(n2.37)\nalg. PInnerProduct. Use PSum from Parallel Algorithmss. Calculates Inner Product of two vectors\n\nSpan Tâˆâ€‹(n)=O(logn)\n#processors p=O(lognnâ€‹)\nWork: Wâˆâ€‹(n)=O(n)\n\nalg. Matrix Multiplication.\n\nT(n)=O(n3)\n\ndef MatMult(A, B)\n\tfor i=1 to n\n\t\tfor j=1 to n\n \n\t\t\t# calculate inner product\n\t\t\tc_ij = 0\n\t\t\tfor k=1 to n\n\t\t\t\tc_ij += a_ik * b_jk\n\t\t\tend for\n\t\tend for\n\tend for\nalg. Parallel Matrix Multiplication.\ndef PMatMult(A, B)\n\tparallel for i=1 to n\n\t\tparallel for j=1 to n\n\t\t\tc_ij = 0\n\t\t\tfor k=1 to n\n\t\t\t\tc_ij += a_ik * b_jk\n\t\t\tend for\n\t\tend for\n\tend for\nalg. Parallel Recursive Matrix Multiplication. A Divide-and-Conquer algorithm.\nIdea:\n\nC=(C11â€‹C21â€‹â€‹C12â€‹C22â€‹â€‹),A=(A11â€‹A21â€‹â€‹A12â€‹A22â€‹â€‹),B=(B11â€‹B21â€‹â€‹B12â€‹B22â€‹â€‹),\n(C11â€‹C21â€‹â€‹C12â€‹C22â€‹â€‹)=(A11â€‹A21â€‹â€‹A12â€‹A22â€‹â€‹)(B11â€‹B21â€‹â€‹B12â€‹B22â€‹â€‹)=(A11â€‹B11â€‹+A12â€‹B21â€‹A21â€‹B11â€‹+A22â€‹B21â€‹â€‹A11â€‹B12â€‹+A12â€‹B22â€‹A21â€‹B12â€‹+A22â€‹B22â€‹â€‹)\ndef PRMatMult(A, B, C)\n \n\t# base case\n\tif n=1\n\t\treturn a * b\n\t\t\n\t# parallel recursion\n\tspawn PRMatMult(A_11, B_11, D_11)\n\t...# 8 parallel threads\n\tspawn PRMatMult(A_22, B_22, E_22)\n\tsync\n \n\t# add matricies D and E together\n\tparallel for i=1 to n\n\t\tparallel for j=1 to n\n\t\t\tc_ij = d_ij + e_ij\n\nSpan Tâˆâ€‹(n)â‰¤Tâˆâ€‹(2nâ€‹)+O(1)=O(logn)\nWork Wâˆâ€‹(n)â‰¤8â‹…Wâˆâ€‹(2nâ€‹)+O(n2)=O(n3)\n"},"Maxima-of-Point-Set-Algorithm":{"title":"Maxima of Point Set Algorithm","links":[],"tags":["Computing/Algorithms"],"content":"Maxima of a point set - Wikiwand\nProblem. Let P=(x1,y1),(x2,y2),â€¦,(xn,yn) be a set of n points in the two-dimensional Euclidean plane. A point (xi,yi) dominates another point (xj,yj) if xi&gt;xjÂ andÂ yiâ‰¥yjÂ orÂ xiâ‰¥xjÂ andÂ yi&gt;yj (that is, if it is up and to the right). A point is maximal if it is not dominated by any other point.\nIdea:\n# A[(int, int)] is the structure of the array\n \nfunction FindMaximal()\n\tmax_y = -Infinity\n\t\n\t\n\t# Sort the points in decreasing order by x-coordinate\n\tReverseMergeSort(A[])\n\tmax_y = A[0]\n\tresult = [A[0]]\n\t\n\t# traverse in reverse x direction (right to left)\n\tfor p in A\n\t\t# if y is bigger than anything seen before it&#039;s maximal\n\t\tif p.y &gt; max_y then\n\t\t\tresult.append(p)\n\t\t\tmax_y = p.y\n\t\t\t\n\treturn result\n\nReverseMergeSort O(nlogn)\nFindMaximal T(n)=O(n)+O(nlogn)=O(nlogn)\nCorrectness (Brief argument):\n\nThe rightmost element must be the maximal element\nIf the current element has a higher y value than any other element on the right side of it, it must be a maximum\nIf the current element has a lower y value than another point on the right of it, it is dominated by that point and thus cannot be a maximum\n\n\n"},"Maximum-Flow-Problem":{"title":"Maximum Flow Problem","links":["Directed-Graph","Depth-First-Search","Shortest-Path"],"tags":["Computing/Algorithms"],"content":"Q. Maximum Flow Problem. Given a Directed Graph whose edges are labeled with flow capacity, what is the maximum flow that can be pushed from vertex s to t?\nQ. Minimum Cut Problem. Given a Directed Graph whose edges are labeled with flow capacity, and a source and target vertex s,t, how do you partition the graph into A,AË‰ such that the flow capacity from Aâ†’AË‰ is minimized?\nâ‡’ The two questions give the same answer. i.eâ€¦\n\nthe flow rate between Aâ†’AË‰ is the maximum flow rate of the graph\nFor the edges cut by the min-cutâ€¦\n\nall forward edges operate at full capacity. (The sum of forward edges is the maximum flow capacity of the whole graph.)\nall backward edges operate at zero capacity\n\n\n\nalg. Ford-Fulkerson Flow Maximization. (FFF-Max) Worked Example\n\nIdea: Choose some suboptimal flow, then increamentally find a better solution.\n\n\nChoose some suboptimal flow through the graph.\nConstruct a residual network.\n\nFor edges who have residual capacity, keep those edges but labeled with that residual capacity.\nFor every edge, construct a reversed edge with the used capacity (this is useful later)\n\n\nIf there is still a path from sâ†’t in the residual network, then more flow can be pushed.\n\nThis path is called the â€flow augmenting pathâ€\nThe minimum capacity of any edge in the augmenting path is the â€bottleneckâ€ of the path.\n! Choice of the augmenting path is important. Discussed below.\nRewire the original graph so thatâ€¦\n\nforward edges have their flow decreased by the bottleneck amount\nbackward edgesâ€”decrease flow of the forward edge represented by that backward edge by that bottleneck in the original graph\n\n\n\n\nRepeat calculation until there is no path sâ†’t in the residual graph.\n\n\nalg. Minimum Cut. How to remove the minimum number of edges such that there is no flow from source s to sync t?\n\nRun the Flow Maximization algorithm\nConstruct a residual graph of the final max-flow graph.\nFrom the source vertex, perform a search (DFS/BFS) and mark all reachable edges.\nâ‡’ The edges between reachable and unreachable verticies is the min-cut edges.\n\n\n\nValue of a cut is the sum of forward edges (=edges in the direction reachable â†’ unreachable)\n\nIn case of a min-cut one needs to minimize this value\n\n\nValue of Min-cut v is equal to the maximum flow f thru the graph\n\n(â‡’) Given a min cut sâ†’t and its value v, maximum flow thru sâ†’t is fâ‰¥v because backward edges (15 is graph above) is\n\n\nA min-cut may not be unique\n\nTo find all of them, residual â†’ run reachability â†’ traverse cut edges to the nodes (may be multiple!)â†’ run reachability\n\n\n\nalg. Choice of Augmenting Path. There are three common options:\n\n! Assumptions:\n\nAll capacities are integers\nfâˆ— is the ideal flow rate\n\n\n\n\nNaive Method\n\nFinding any path using BFS takes O(E) time (fully connected graph)\nIteration count: O(fâˆ—)\nTotal: O(Efâˆ—)\n\n\nAugmenting path with largest bottleneck.\n\nCan use modified Shortest Path algorithm with O(ElogV) time complexity\nIteration count: O(Elogfâˆ—)\nTotal: O(E2logfâˆ—)\n\n\nBFS shortest augmenting path (Edmond-Karp)\n\nTakes O(E)\nIteration count: O(VE)\nTotal: O(VE2)\n\n\nState of the art: O(VElogV), and even O(E+Ïµ)\n\nDiscussion Â§\nFormalization Â§\n\nthe answer is given as a flow function f:Eâ†¦R&gt;0.\n\ni.e. â€œassign each edge a flow valueâ€\n\n\nall vertices except the source and target vertices s,t must have net zero divergence (=net zero inflow/outflow)\n\ni.e. â€œthe water canâ€™t disappear or appear randomly in any vertex.â€\n\n\n\nApplied Problems Â§\n\n\n                  \n                  k things with a separate set of l things, suspect flow/cut problem.\n                  \n                \n\nQ. Edge Matching Problem. (=Maximum Cardinality Matching) Given an undirected, partitioned graph, return the maximum number of edges that donâ€™t share a vertex \n\nIdea: reduce to a max-flow problem. \nalgorithm:\n\nFor a graph partitioned A,B, make all edges Aâ†’B directed.\nConstruct start and end node s,t, and construct sâ†’aâˆˆA, tâ†bâˆˆB\nCalculate the max-flow from sâ†’t\nThe edges that are used in the max-flow problem is the solution.\n\n\nComplexity: O(VE)\n\nQ. Advertiser and Viewer Demographic Matching Problem\nQ."},"Maximum-Likelihood-Estimator":{"title":"Maximum Likelihood Estimator","links":["Likelihood-(Statistics)"],"tags":["Math/Statistics"],"content":"def. The Maximum Likelihood (Statistics) Estimator is an estimator Î¸^ that maximizes L.\n\nIt also works for log likelihood, because the natural log is a monotonic function:\n\nÎ¸^MLEâ€‹â€‹=Î¸maxâ€‹Â Lnâ€‹(Î¸;x1â€‹,...,xnâ€‹)=Î¸maxâ€‹Â lnLnâ€‹(Î¸;x1â€‹,...,xnâ€‹)â€‹\nUnder certain regularity conditions, we can find the MLE by finding stationary points in the log likelihood. These are called the likelihood equation:\nâˆ‚Î¸âˆ‚lnLnâ€‹(Î¸)â€‹=setÂ to0\nTo consider whether this stationary point is the maximum (as opposed to a miminum) either:\n\ntake the second derivativeâ€¦\nâ€¦or find out via other means\n\n\n\n                  \n                  Properties of MLEs: \n                  \n                \n\n\nMLEs are always a function of a sufficient statistic.\nMLEs are not necessarily unbiased.\nMLEs may not reach the CRLB in variance.\n\nthm. Functional Equivariance of MLE: Given parameter Î¸ and let Î±=g(Î¸). Then:\ng(Î¸^MLEâ€‹)=gÂ invertibleÎ±^MLEâ€‹\nâ‡’ the estimator for any function over the parameter can then be found easily.\nthm. Asymptotic Normality of MLE. [=Fisherâ€™s Approximation]\nlet data generated by a univariate single parameter distribution X1â€‹,â€¦,Xnâ€‹âˆ¼iidf(x1â€‹,â€¦,xnâ€‹,Î¸).\nlet also that Î¸^MLEâ€‹ is found by the likelihood equation âˆ‚Î¸âˆ‚sâ€‹=0. Then both are equivalently true:\nÎ¸^MLEâ€‹âŸ¶nâ†’âˆâ€‹N(Î¸0â€‹,I(Î¸0â€‹)1â€‹)\nnâ€‹(Î¸^MLEâ€‹âˆ’Î¸0â€‹)âŸ¶nâ†’âˆâ€‹N(0,I(Î¸0â€‹)1â€‹)"},"Mean-Squared-Error":{"title":"Mean Squared Error","links":[],"tags":["Math/Statistics"],"content":"def. Loss function is a function that encapsulates the â€œclosenessâ€ of the estimate and ground truth. For example a loss function may measured the geometric closeness by:\nL(Î¸,e)=(Î¸âˆ’a)2\ndef. Mean Squared Error (MSE) is the arithmetic mean of the loss function defined:\nMSE(Î¸^)â€‹=EXâ€‹[(Î¸^âˆ’Î¸)2]=âˆ«x=âˆ’âˆâˆâ€‹(Î¸^âˆ’Î¸)2fXâˆ£Î¸=Î¸^â€‹(x)â€‹\n\n\n                  \n                  Info \n                  \n                \n\nThe following shows why MSE is useful; it is just a sum of variance and bias squared.\n\n\n&gt;EXâ€‹[(Î¸^âˆ’Î¸)2]=Var[Î¸^]+Bias[Î¸^]2&gt;"},"Measuring-Security-Performance":{"title":"Measuring Security Performance","links":["Risk-(Finance)","Measuring-Security-Performance","Market-Beta"],"tags":["Economics/Finance"],"content":"Measurment Metrics. The following are used commonly to measure performance of funds. It does not imply, however, that they are meaningful, useful, or correct. Most of them compare risk to return\n\nMeasuring Security PerformanceMeasuring Security Performanceio]]\nJensonâ€™s Alpha. Measures performance against CAPMâ€™s Predictions.\n\nÎ±=(riâ€‹âˆ’rfâ€‹)âˆ’Î²(rmâ€‹âˆ’rfâ€‹)\nSharpe Ratio Â§\ndef. Sharpe Ratio. The sharpe ratio for portfolio with return Rpâ€‹\nSPâ€‹=Ïƒpâ€‹E[Rpâ€‹âˆ’Î¼fâ€‹]â€‹=Ïƒpâ€‹Î¼pâ€‹âˆ’Î¼fâ€‹â€‹â€‹â€‹\n\nUsed to compare securities given their risk &amp; returns\nMeasures the â€œrisk-normalized returnâ€\nHigher means a better risk/return profile\n\nTreinorâ€™s Ration Â§\nMeasures against Systematic (=market) Risk.\nTM=Î²E[ExcessÂ return]â€‹\nReminder: Market Beta is about how correlated the asset is to the market."},"Memory-Access-Control":{"title":"Memory Access Control","links":[],"tags":["Computing"],"content":"\nRead\n\nConcurrent Read\nExclusive Read\n\n\nWrite\n\nConcurrent Write\nExclusive Write\n\n\n"},"Merton-Jump-Diffusion-Model":{"title":"Merton Jump Diffusion Model","links":[],"tags":["Economics/Finance"],"content":""},"Methodology-of-Queer-Theory":{"title":"Methodology of Queer Theory","links":["Queer","Space-(Queer-Theory)","(Book)-Kids-on-the-Street","Chosen-Family","Microphysics-of-Power","Oral-History","Dialectical-Synthesis","Existentialism","(Philosopher)-Edmund-Husserl","Standpoint-Theory","Reification","GLAAD"],"tags":["Philosophy/Queer-Theory"],"content":"Conceptual Framework Â§\n\nQueer: Anything out of the ordernary, normal, cis-hetero-normal mainstream society\n\nQuare: â€¦and also intersectionality w.r.t. race/ethnicity\nanti-monolithic \n\n\nSpace (Queer Theory): formalized camaraderies. Examples\n\nTenderloins ((Book) Kids on the Street)\nChosen Family â† alternative formulation of family\n\n\nMicrophysics of Power\n\nâ€œConditioned onâ€ patriarchy, politics, etc. Not fully determined by, but conditioned by.\n\n\nGeneralized colonization\n\ncolonization, but of queer spaces and people (bodies) by mainstream people.\n\n\n\nMethology Â§\n\nOral History\n\nLinguistic Anthropology: â€œreinterpretationâ€ or â€œreclaimingâ€ of a term\n\n\nDialectical Synthesis\n\nCreating something new out of\nAnti-essentialist, Anti-reductionist\n\nLike Existentialism; existence preceeds essence; rejection of reduction/essentialism of (Philosopher) Edmund Husserl\n\n\n\n\nStandpoint Theory\n\nAgainst Reification of perspectives\n\n\n\nActivism Â§\nSince queer-ness is by definition a subaltern identity thereâ€™s ongoing efforts to rectify repression.\n\nGLAAD: Media advocacy groupâ€”advises on pressures media representation of queer people\n\n"},"Michel-Foucault":{"title":"Michel Foucault","links":["Postmodernism","Centralized-Power","Checks-and-Balances","Dialectical-Synthesis","Social-Institution"],"tags":["Philosophy","People"],"content":"Notes from What Power Is â€” Michel Foucault\nBasics\n\n20C thinker\nPostmodernism\n\nMisconceptions of Power\n\nHierarchical power is only a part\n\nâ†’ instead, power is an oceanic force of nature\n\n\nTheoretical vs Empirical\n\nFocault talks both about theoretical and empirical power\nEmperical: sexuality, prison systems, etc. (historical crystallizations)\nTheoretical: generalized, abstract conception, a â€œtheory of powerâ€\n\n\nPrior political analyses of power: misconception\n\ne.g. 1984, Leviathan, Marxâ€™s class relations\ncharacterized as the struggle between powerful vs not powerful\nmost power here is negative power (punishes)\noriginates probably from the western legalistic tradition\nâ†’ but majority of power is not this (misrepresentation)\n\n\n\nImmanent â€œmicrophysicsâ€ of power\n\ninvisible, but real and measurable\npower is a quality of the social world (not metaphysical, natural force like Nietzche)\nintentional &amp; non-subjective (e.g. party DJ putting on â€œKilling me softlyâ€)\n\nintentional: you are technically free.\nnon-subjective: people will find you uncool\n\n\n\nResistance\n\nResistance is not exterior to power, but is intrinsic\nrevolutionaries â†’ if there is no resistance, there is no power\nrelations of power is only allowed in a free society\n\nâ€œfreeâ€ in that youâ€™re technically free to resist\n\n\n\nFull Definition of Power\n\nâ€œPower must be understood in the first instance as the multiplicity of force relation imminent in the sphere in which they operateâ€\ne.g. dressing for school\n\nlegal, etc. (traditional)\nschool clique\nâ€œwhatâ€™s coolâ€\n\n\nâ‡’ They all operate simultaneously\n\nRelations of Power\n\nLocal force relations act on each other (even in the absence of the individual to act on)\n\ne.g. war. Discipline &amp; punish: perpetual battle\n\n\nstruggle, strengthen, weaken. etc\nThey can also bond &amp; combine\n\ne.g. fashion + peers, school + parents kinda match\n\n\n\nInstitutional Crystallization (social)\n\nâ€œtacticsâ€ of power\nlocal micro-physics of power â†’ coalesce to create school &amp; state, bigger power\nnobody individually can predict the effects of micro-power\ne.g. legal, agreement, new forms of government\n"},"Microeconomic-Market-Equilibrium":{"title":"Microeconomic Market Equilibrium","links":["Profit-Function","Utility-Maximization"],"tags":["Economics/Micro-Economics"],"content":"Perfect Competition Â§\nConditions:\n\n\nZero profit condition: Ï€=pxâˆ’c(x)=0\n\n\nPricing at marginal cost:\n\n! only when MC is constantâ€¦\np=MC\n\n\n\nTheory of the Firm but withâ€¦\n\nFixed costs, i.e. Ï€=pxâˆ’wlâˆ’rkâˆ’FC\nFirms will enter and exit\n\nâ‡’ supply price and quantity is at Ï€=0\n\n\nâ†’ market price and individual firmâ€™s quantity supplied are determined by this formula.\nThis is equivalent to the minimum average cost condition minxâ€‹AC(x).\n\n\n\nUtility Maximization butâ€¦\n\nConsider only one good, x1â€‹\nThere are more than one consumers. x1marketÂ demandâ€‹=x1â€‹Ã—#Â ofÂ consumers\n\n\n\nMarket equilibrium: \n\nPrice is set at pâˆ— because it is fully determined by the firm.\n\nThe quantity supplied changes by firms entering and exiting (not by individual firms ramping up or cutting down on production!)\n\n\nQuantity demanded (=aggregate quantity supplied) of xâˆ— is fully determined by the consumer.\n\n\n\nShort Run Â§"},"Microeconomics":{"title":"Microeconomics","links":["Philosophy,-Political-Science,-Economics","Decentralization"],"tags":["Economics/Micro-Economics"],"content":"\nCourse process.\nEconomics as a Science Â§\nEconomics is a science as it creates hypotheses and conducts experiments if they are correct.\n\nSince you canâ€™t often create tests IRL, econometrics deals with interpreting real-world data as a substitute for an experiment\nExperimental economics is a small discipline where you actually conduct experiments\n\n(This is not as scientific as it seems. See Philosophy, Political Science, Economics)\nBuilding Blocks of Microeconomics Â§\nAssume: People are rational in their pursuit of perceived self-interests. Such people are called economic agents.\nâ†’ â€¦thus people respond to incentives\nâ†’ â€¦then as a consequence of multiple economic agents interacting, there will emerge social consequences.\nEconomic Modeling Â§\nModeling in economics is a process of distilling the essence of a real-world phenomenon, in order to make predictions about the real world.\n\n\n                  \n                  Model â†’ Optimization â†’ Equilibrium \n                  \n                \n\n\nModel: form a model that describes an economic phenomena (make assumptions, Ceteris Paribus)\nOptimization: consider how economic agents will interact within such assumptions &amp; models. Use math if necessary.\nEquilibrium: predict what will ultimately happen in such a model? What is the ending point? (make predictions)\n\n(Economically, an equilibrium (=Pareto Equilibrium) is a point where no agent can be better off without making another agent worse off)\n\n\n                  \n                  doesnâ€™t need to have realistic assumptions. It just needs to predict reality really well.\n                  \n                \n\nâ†’ Consider: A good pool player doesnâ€™t need to know kinematics to score well. Similarly an economic model doesnâ€™t need realistic assumptions if it can realistically predict real-world economic phenomena.\nOther Key Points Â§\n\nThe world isnâ€™t a zero sum game. Adam Smith: think of purchasing a piece of bread at 2.Yougetthebread,andyouarebetteroff.Thebreadmakervaluesthebreadatlessthan2, so theyâ€™re better off.\nAttribution Bias. Peopleâ€™s actions are due more to the sum of the incentives acting on them, rather than their inherent quality. Donâ€™t attribute it to their personality.\nDecentralization. The rules of the economic game shapes a bottom-up spontaneous order that shapes the world and rations limited resources.\n"},"Microphysics-of-Power":{"title":"Microphysics of Power","links":["Michel-Foucault"],"tags":["Philosophy/Political-Philosophy"],"content":"Michel Foucault"},"Minimal-Spanning-Tree-Problem":{"title":"Minimal Spanning Tree Problem","links":["Graph","Tree","Priority-Queue","Disjoint-Set","Greedy-Algorithm","Shortest-Path"],"tags":["Computing/Data-Structures","Computing/Algorithms"],"content":"Q. Minimum Spanning Tree. From a connected, undirected, edge-weighted Graph, make a subset graph that:\n\nconnects all vertices together\nminimum possible total edge weight\nâ‡’ will always be a Tree\nâ†’ there could be multiple spanning tree (MST is not unique)\n\nalg. Primâ€™s Algorithm\n\nIdea: Gradually build one big tree\n\nChoose random vertex, then add all edges connected to it to a Priority Queue.\nUse the lightest edge in the priority queue and connect to that vertex.\n\n\n\nalg. Kruskalâ€™s Algorithm.\n\nIdea: Build many trees, and gradually combine them.\n\nChoose lightest edge, then create a tree with that (using a Disjoint Set)\nIf the vertices are already part of a small treeâ€¦\n\nif theyâ€™re different trees, combine the two trees with that edge\nif theyâ€™re same trees, donâ€™t connect.\n\n\n\n\nTime complexity: O(ElogV)\n\nlem. Exchange Argument. Correctness proof for both Primâ€™s and Kruskalâ€™s algorithm.\n\nIdea: If we have MST, choosing the lightest edge to connect them (greedily) is MST.\n\nAssume MST Tâˆ—.\nSplit into two components C1â€‹,C2â€‹.\nAmong edges that connect C1â€‹,C2â€‹ you choose the lightest edge eâˆ—.\nâ‡’ Then, C1â€‹,C2â€‹,e is a minimum spanning tree.\n\n\n\nDiscussion Â§\n\nPrimâ€™s and Kruskaâ€™s algorithms are both Greedy Algorithms\nIf edge weights are distinct, there is a unique minimum spanning tree\nDoesnâ€™t have anything to do with Shortest Path algorithms.\n\nApplications Â§\nQ. Minimal Edge Removal to Acyclic Graph. Given a connected, undirected, weighted graph G=V,E we will remove edges F such that the remaining graph will have no cycles. What is F with the minimum total weight sum?\n\nCompute maximum spanning tree on G\n\nthis can be done by modifying Primâ€™s or Kruskalâ€™s algorithmâ€¦\n2â€¦.or by running minimum spanning tree on a new graph with negated edge weights\n\n\nF is the set of edges not contained by this MST\n"},"Moment-(Probability)":{"title":"Moment (Probability)","links":["Distribution-(Math)"],"tags":["Math/Statistics"],"content":"â†’ An alternative way to get an estimator quick and dirty.\nMethod of Moments Â§\nalg. Method of Moments (MOM):\nlet X1â€‹,â€¦,Xnâ€‹âˆ¼iidf(x;Î¸1â€‹,â€¦,Î¸pâ€‹). Then to get estimators for Î¸1â€‹,â€¦,Î¸pâ€‹:\n\nlet Î¼iâ€‹=E[Xi]=giâ€‹(Î¸1â€‹,â€¦,Î¸nâ€‹)\ngather data on XË‰i to get an emperical estimate miâ€‹\n\nObserve that because E[Xi]â‰ˆXË‰i, this means that Î¼iâ€‹â‰ˆmiâ€‹\n\nlet function giâ€‹ which maps Î¸1â€‹,â€¦,Î¸nâ€‹â†¦giâ€‹â€‹miâ€‹ can be inverted\nGet system of equations for as many iâ€™s as necessary\nSolve the system of equations as Î¸^iâ€‹=giâˆ’1â€‹(m1â€‹,â€¦)\n\n\n\n                  \n                  Limitations on MoM: \n                  \n                \n\n\nEstimators may not make sense (negative numbers, complex number, etc.)\nIllegal\n\ndef. Moment Generating Functions\n(alternative specification of pdf. Makes it easy to calculate things.)\nMoment generating functions are defined as such:\nMXâ€‹(t)=E[exp(tX)]\nâ€¦where MXâ€‹ is differentiable k-times around zero to be able to generate the k-th moment.\nYou can build an MGF from a pmf of pdf:\n\nfor pmfs: MXâ€‹(t)=âˆ‘â€‹etxiâ€‹p(xiâ€‹)\nfor pdfs: MXâ€‹(t)=âˆ«âˆ’âˆâˆâ€‹etxf(x)dx\n\nIt can generate the k-th moment like such:\nE(Xk)=âˆ‚xkâˆ‚kâ€‹MXâ€‹(0)=MX(k)â€‹(0)\n\n\n                  \n                  MGFs are unique to each distribution. If an RV has the same MGF, they are distributed identically. \n                  \n                \n\nthm. Linear Combination of MGFs. Given r.v. W=X1â€‹,â€¦,Xnâ€‹, and Xiâ€‹ are iid,:\nMWâ€‹(t)=MX1â€‹â€‹â‹…MX2â€‹â€‹â‹¯MXnâ€‹â€‹"},"Monetary-Policy":{"title":"Monetary Policy","links":[],"tags":["Economics/Macro-Economics"],"content":""},"MongoDB-Reference":{"title":"MongoDB Reference","links":["Regular-Expressions"],"tags":["Computing/Data-Science"],"content":"All You Need isâ€¦ Â§\n{json}db.bib.find({ title:/[dD]atabase/, price:{$lt:50} })\n\nRegex enclosed in /regex/\nthe argument for find is\nSyntax error: NoSQL queries will return none. SQL will return error\nMongoDB (NoSQL!)\n\nSchema: DocumentâŠ‚CollectionâŠ‚Database\n\ndocument is a single json object (with _id as unique identifier in collection)\n\n\n\n\n\nIf You want moreâ€¦ Â§\n\n{json}mydb.mycollection.find() â† all documents\nSelection in {js}find(â€¦)\n\n{js}find({ title: &quot;databases&quot; }) â† accepts JSON.\nstring pattern matching is in Regular Expressions. {js}title: /[dD]atabase/\nmultiple patterns: and operation by default.\n\nâ†’ but JSON must have unique keys. {price:â€¦, price:â€¦} doesnâ€™t work (silent error)\nalternative: $and: [â€¦, â€¦]\n\n\nwhen there arrays: an âˆƒ operation.\n{js}$elemMatch: { title: /Section/ } â† performs match per array element\n{js}&quot;arr.0&quot;: &quot;match&quot; â† index matching for array\nbuilt-in functions\n\n{$lt:â€¦}\n{$and:[â€¦, â€¦]}\n\n\n\n\nProjection in {js}find(â€¦, { _id: false, attr1: true, â€¦})\nSort by {js}find().sort({ ISBN: 1 })\n\n1 is ascending (0 â†’ âˆ, a â†’ z)\n-1 is descending\n\n\n\nMisc Facts Â§\n\nQuery strings are valid JSON objects\nprint it to console:{js}printjson(db.collections.find().toArray())\n\nEven More: Aggregation Pipeline Â§\n\nEach step of the pipeline transforms the json object in some way.\nAggregation steps can include:\n\nSelection: {js}$match\nProject: {js}$project\nSort: {js}$sort\n{js}$addFields\n{js}$unwind\n{js}$lookup\n{js}$group\n\n\n\n"},"Monopoly":{"title":"Monopoly","links":["Market-Power","Uncompensated-Demand-curve","Cost-Function","Unconstrained-Maximization","Price-Elasticity-of-Demand","Pareto-Efficiency","Compensating-and-Equivalent-Variation"],"tags":["Economics/Micro-Economics"],"content":"Definitions Â§\n\nMonopoly is when a single firm has all the Market Power. Monopolies normally have:\n\nHigh barriers to entry\nProduction in elastic portion of demand\nSingle firm with market power\n(usually) economies of scale\n\n\nA Natural Monopoly is when itâ€™s hard for firms to achieve break-even without a monopoly market strucutre\n\nMarket Demand for Monopolies Â§\n\n\n                  \n                  MR &gt; 0, i.e. where Îµ &gt; 1\n                  \n                \n\n\nMonopolies face the whole market demand curve.\nMarginal Revenue (MR) curve will slope down with the same intercept and twice the gradient of the Demand curve.\nVisual Profit Maximization when MC=MR (See below for math)\n\nFirm produces xM (=monopoly quantity)\nMarket price settles at pM (=monopoly price)\nFirm makes profit of c+d\nDeadweight loss is e\n\nDWL happens because monopolist increase price more than optimum\n\n\n\n\n\n\nProfit Maximization for Monopolies Â§\nProfit maximization for monopolies:\nmaxxâ€‹p(x)â‹…xâˆ’C(w,r,x)\n\np(x) is the inverse of the Ordinary Demand of goods\nC(x) is the Cost Function that is derived w.r.t x\n\n! Not simply wl+rk!\n\n\nTo solve, use Unconstrained Maximization\n\nFirst Order Condition: âˆ‚xâˆ‚Ï€â€‹=0\n\nThis is the same condition as MR=MC condition.\n! In third-degree price discrimination, MR=MC can only be used if MC is constant.\n\n\nWhen elasticity is constant â‡’ Use the Elasticity condition: p(x)=1+Ïµdâ€‹1â€‹MCâ€‹\n\nElastic: p&gt;MC thus excess profit\nUnit elastic: p=MC thus zero profit\nInelastic: p&lt;MC thus negative profit (monopolist doesnâ€™t produce)\n\n\n\n\n\n\nPrice Discrimination for Monopolies Â§\nFirst Degree Price Discrimmination Â§\nEverybody pays exactly how much theyâ€™re willing to pay.\n\n\nDemand curve is same as marginal revenue curve\nPareto efficient because there is no deadweight loss; everybody pays exactly as they want to pay, and no extra profit is lost\n\nâ†’ but the benefit goes to the monopolist only\n\n\n\nTwo-part Tariff Â§\n\n\nConsumers are made to pay amount A to enter the market\nThen charge consumers p=MC\nSame as Equivalent Variation\n\nProcess of enforcing the tariff\n\nConsumers at utility u1â€‹Ë‰â€‹ and only buys good x2â€‹\nFirm enters the market and starts selling good x1â€‹ at price p=MC. The consumer gains utility u2â€‹Ë‰â€‹\nFirm realizes they could get more profit. They charge amount A to enter the market. Thus the consumer loses amount of difference.\nConsumers are back to u1â€‹, but theyâ€™re still buying x1â€‹ because theyâ€™re just as happy as when they only bought x2â€‹.\n\nYou can get market ticket price by either\n\nusing Equivalent Variation on the right graph\nusing integration on the left graph\n\nThird Degree Price Discrimination Â§\n\nIdea: Charge differently based on consumer characteristics (=based on Price Elasticity of Demand)\nâ‡’ Split consumers into two groups A,B with elasticity ÏµDAâ€‹,ÏµDBâ€‹ andâ€¦\n\nIf MC is constant â†’ use the elasticity condition\nIf MC is not constant â†’ use normal profit maximization:\nmaxxAâ€‹,xBâ€‹â€‹Ï€=pA(xA)â‹…xA+pB(xB)â‹…xBâ€‹TotalÂ Revenueâ€‹âˆ’C(xA+xB)\n\n\nYou will eventually get MRA=MC and MRB=MC\n"},"Monotonic-Transformation":{"title":"Monotonic Transformation","links":["Utility-Function"],"tags":["Math","Economics"],"content":"def. Monotonic Transformation. A transformation of a Utility Function is one that preserves the order of preferences of the original function. i.e., f is a monotomic transformation of utility function u(x) iff:\nâˆ€(xA,xB),Â ifÂ u(xA)&gt;u(xB)âŸ¹fâˆ˜u(xA)&gt;fâˆ˜u(xB)\nSimple monotonic transformations:\n\nAdding or subtracting a constant\nMultiplying or dividing by a positive constant\nFor always positive functions, exponentiation to a constant\nFor always positive functions, logarithm to a constant base\n\nthm. monotonic transformation equivalence. If one utility function is a monotonic transformation of another, you may treat it for all practical purposes as the same utility function."},"Mooreâ€™s-law":{"title":"Mooreâ€™s law","links":[],"tags":["Computing/Computer-Architecture"],"content":"\n\nMooreâ€™s law is the observation that the number of transistors in an integrated circuit (IC) doubles about every two years. Mooreâ€™s law is an observation and projection of a historical trend. Rather than a law of physics, it is an empirical relationship linked to gains from experience in production.\nThe observation is named after Gordon Moore, the co-founder of Fairchild Semiconductor and Intel (and former CEO of the latter), who in 1965 posited a doubling every year in the number of components per integrated circuit, and projected this rate of growth would continue for at least another decade. In 1975, looking forward to the next decade, he revised the forecast to doubling every two years, a compound annual growth rate (CAGR) of 41%. While Moore did not use empirical evidence in forecasting that the historical trend would continue, his prediction held since 1975 and has since become known as a â€œlawâ€.\nMooreâ€™s prediction has been used in the semiconductor industry to guide long-term planning and to set targets for research and development, thus functioning to some extent as a self-fulfilling prophecy. Advancements in digital electronics, such as the reduction in quality-adjusted microprocessor prices, the increase in memory capacity (RAM and flash), the improvement of sensors, and even the number and size of pixels in digital cameras, are strongly linked to Mooreâ€™s law. These ongoing changes in digital electronics have been a driving force of technological and social change, productivity, and economic growth.\nIndustry experts have not reached a consensus on exactly when Mooreâ€™s law will cease to apply. Microprocessor architects report that semiconductor advancement has slowed industry-wide since around 2010, slightly below the pace predicted by Mooreâ€™s law. In September 2022 Nvidia CEO Jensen Huang considered Mooreâ€™s law dead, while Intel CEO Pat Gelsinger was of the opposite view.\nWikipedia\n"},"Moral-Hazard":{"title":"Moral Hazard","links":[],"tags":["Economics/Game-Theory"],"content":"e.g. Insurance. People with insurance tend to take more risks because they know theyâ€™re insured."},"Multinomial-Distribution":{"title":"Multinomial Distribution","links":["Binomial-Distribution"],"tags":["Math/Common-Distributions"],"content":"def. Multinomial Distribution. For outcome space Î©, k mutually exclusive events each with probabilities p1â€‹,â€¦,pkâ€‹ s.t. âˆ‘i=1kâ€‹piâ€‹=1, let random variables Xiâ€‹ denote the number of outcomes whose probability is piâ€‹, when n trials are done:\nX1â€‹,...,Xkâ€‹âˆ¼Multinomial(n,k,p1â€‹,...,pkâ€‹)P(X1â€‹=x1â€‹,...,Xkâ€‹=xkâ€‹)=x1â€‹!,...,xkâ€‹!n!â€‹â‹…p1x1â€‹â€‹Ã—â‹¯Ã—pkxkâ€‹â€‹\nâ‡’ Multinomial is a generalization of the Binomial Distribution."},"Multivariate-Ordinary-Least-Squares-Regression":{"title":"Multivariate Ordinary Least Squares Regression","links":["Omitted-Variables","Bivariate-Ordinary-Least-Squares-Regression"],"tags":["Math/Statistics"],"content":"Yiâ€‹=Î²0â€‹+Î²1â€‹X1iâ€‹+Î²2â€‹X2iâ€‹+Î²3â€‹X3iâ€‹+Ïµiâ€‹\n\n\n                  \n                  Omitted Variables in the regression. Refer to the document in that case.\n                  \n                \n\nVariance of Parameter Estimators Â§\nIn this multivariate model the variance of Î²1â€‹^â€‹ is:\nVar(Î²1â€‹^â€‹)=Nâ‹…Var(X1â€‹)â‹…(1âˆ’R12â€‹)Ïƒ^2â€‹\nwhere\n\nÏƒ^2 is the variance of the regression\nR1â€‹ is the coefficient of determination in the auxiliary regression X1iâ€‹=Î³0â€‹+Î³1â€‹X2iâ€‹+Î³2â€‹X3iâ€‹+Ïµiâ€‹. It measures multicolinearity\n\n&amp; It measures how much of X1â€‹ can be explained by X2â€‹,X3â€‹\nIn perfect multicolinearity R1â€‹=1 then X2â€‹,X3â€‹ will perfectly determine X1â€‹, thus X1â€‹ is not relevant anymore.\n&amp; Equivalently R2â€‹ is the coefficient of determination from X2iâ€‹=Î³0â€‹+Î³1â€‹X1iâ€‹+Î³2â€‹X3iâ€‹+Îµiâ€‹, etc. etc.\n\n\n1âˆ’R12â€‹1â€‹ is known as the variance inflation factor. The higher the multicollinearity, the more inflated is the variance of parameter estimators.\nMulticollinearity is not a problem iff:\n\nit occurs only between control variables\nVar(Î²1â€‹^â€‹) is small enough; i.e. Î²1â€‹^â€‹ is statistically significant.\n\n\nN is the sample size\n\nCoefficient of Determination Â§\nIn multivariate situations (as opposed to bivariate) the coefficient of determination of the whole regression (R2) is more troublesome because\n\nAdding more variables will only increase R2\nThus one is incentivized to increase the number of (possibly irrelevant) independent variables.\nTo mitigate this, we report the adjusted R2 values instead, with a penalty for each additional independent variables used.\n\nHypothesis Testing regarding Coefficients Â§\nStandardizing Coeffiefficients Â§\nExample. In the model GDP=Î²0â€‹+Î²1â€‹LifeÂ Expectancy+Î²2â€‹LiteracyÂ Rate, if we want to compare the effects of life expectancy and literacy, we cannot simply compare the values of Î²1â€‹,Î²2â€‹. This is because their units are different, i.e. Î²1â€‹ is in YearDollarsâ€‹ and literacy is in PercentageÂ PointDollarsâ€‹. Thus we need to standardize them:\nÎ²istdâ€‹^â€‹=Var(Î²iâ€‹^â€‹)â€‹Î²iâ€‹^â€‹âˆ’E(Î²iâ€‹^â€‹)â€‹\nwhich shows â€œhow much Y increase in units of ÏƒYâ€‹ does one unit ÏƒXiâ€‹â€‹ increase in X cause?â€\nRemark. Only X1â€‹ and X2â€‹ need be standardized to compare Î²1â€‹^â€‹ and Î²2â€‹^â€‹â€™s effects. Y need not be standardized.\nHypothesis Testing about Coefficients Â§\nLet the model Yiâ€‹=Î²0â€‹+Î²1â€‹X1,iâ€‹+Î²2â€‹X2,iâ€‹+Î²3â€‹X3,iâ€‹+Ïµiâ€‹. Sometimes we may want to check if Î²1â€‹^â€‹=?Î²2â€‹^â€‹, or Î²1â€‹^â€‹=Î²2â€‹^â€‹=?0. In these cases we use a hypothesis test. Let Runrestricted2â€‹ be the R2 of this regression. Now, before we do anything we need toâ€¦\n\n\n                  \n                  X_{1},X_{2}.\n                  \n                \n\nCase 1: H0â€‹:Î²1â€‹^â€‹=Î²2â€‹^â€‹=0. Then the model under null would change to:\nYiâ€‹=Î²0â€‹+Î²3â€‹X3,iâ€‹+Ïµiâ€‹\nWe run regression on this new model and get Rrestricted2â€‹\nRemark. This is not equivalent to running a t-test on HAâ€‹:Î²1â€‹^â€‹î€ =0âˆ§^Î²2â€‹î€ =0 because X1â€‹,X2â€‹ may be multicollinear.\nCase 2: H0â€‹:Î²1â€‹^â€‹=Î²2â€‹^â€‹. Then the model under null would change to:\nYiâ€‹=Î²0â€‹+Î²1â€‹(X1,iâ€‹+X2,iâ€‹)+Î²3â€‹X3,iâ€‹\nWe run regression on this to also get Rrestricted2â€‹.\nWe can observe that in both cases, Runrestricted2â€‹&gt;Rrestricted2â€‹, always, because â€œrestrictingâ€ the model will lead only to less (coefficient of-) determination. Now, the bigger this difference is, the more likely that the null is false. We formalize this using the F-test:\ndef. F-Test. For the F-statistic defined as:\nFq,Nâˆ’kâ€‹:=(1âˆ’Runres2â€‹)/(Nâˆ’k)(Runres.2â€‹âˆ’Rrestr.2â€‹)/qâ€‹\nwhere\n\nq is â€œhow many equal signs in null hypothesisâ€\nk is the degrees of freedom (=number of coefficients in the _un_restricted model)\nThen:\n\n{H0â€‹H1â€‹â€‹elseifÂ F&gt;Kâ€‹\nwhere K is the critical value. The critical values are:\n\nK=3.00 in case 1 (H0â€‹:Î²1â€‹^â€‹=Î²2â€‹^â€‹=0)\nK=3.84 in case 2 (H0â€‹:Î²1â€‹^â€‹î€ =Î²2â€‹^â€‹)\n"},"Murakami-Haruki":{"title":"Murakami Haruki","links":[],"tags":["People"],"content":""},"Music-190FS-Music-and-Medicine-in-European-Renaissance":{"title":"Music 190FS Music and Medicine in European Renaissance","links":["assets/190---Analysis-of-Penelope-Gouk.pdf","assets/190---Renaissance-in-Medieval-Korea.pdf"],"tags":["Courses"],"content":"Writing Assignments Â§\n\n190 - Analysis of Penelope Gouk.pdf\n190 - Renaissance in Medieval Korea.pdf\n\nCourse Readings Â§\n\nIntroductions and Origins\n\nSelections from Plato, Aristotle, and Saint Augustine, in Oliver Strunk, ed., Source Readings in Music History (New York: W. W. Norton, 1950), pp. 3â€“24 and 73â€“75.\n\n\nAntiquity and the Middle Ages: number in celestial and social harmony\n\nMartin West, â€œMusic Therapy in Antiquity,â€ in Music as Medicine, ed. Peregrine Horden (Aldershot: Ashgate, 2000), pp. 51â€“67.\nMarsilio Ficino. The Book of Life, trans. Charles Boer (Irving, TX: Spring Publications Inc., 1980), pp. 3â€“20 and 158â€“164.\n\n\nRenaissance perspectives I: Marsilio Ficino\n\nSelections from The Letters of Marsilio Ficino, trans. members of the Language Department of the School of Economic Science, London (London: Shepheard-Walwyn, 1975â€“2015), vol. 1: No. 5 â€œMedicina corpus, musica spiritum, theologia animam curatâ€ pp. 39â€“40; No. 7 â€œDe divino furore,â€ pp. 42â€“48; No. 92, â€œDe musica,â€ pp. 141â€“144.\nMarsilio Ficino, All Things Natural: Ficino on Platoâ€™s Timaeus, trans. Arthur Farndell (London: Shepheardâ€“Walwyn, 2010), chapters 29â€“33, pp. 51â€“71.\nD.P. Walker, Spiritual and Demonic Magic: From Ficino to Campanella (Notre Dame: University of Notre Dame Press, 1975), pp. 3â€“29.\n\n\nRenaissance perspectives II: music and melancholy\n\nPeter Amman, â€œMusic and Melancholy: Marsilio Ficinoâ€™s Archetypal Music Therapy,â€ Journal of Analytical Psychology 43 (1998): 571â€“588.\nPenelope Gouk, â€œMusic, Melancholy, and Medical Sprits in Early Modern Thought,â€ in Music as Medicine, ed. Peregrine Horden (Aldershot: Ashgate, 2000), pp. 173â€“194.\n\n\nEarly modern science and sound I: the philosophy of human and celestial bodies\n\nStillman Drake, â€œMusic and Philosophy in Early Modern Science,â€ in Music and Science in the Age of Galileo, ed. Victor Coelho (Dordrecht: Kluwer Publishers, 1992), pp. 3â€“16.\nRoseen Giles, â€œThe Inaudible Music of the Renaissance: From Marsilio Ficino to Robert Fludd,â€ Renaissance and Reformation 32, no. 2 (2016): 129â€“166.\n\n\nEarly modern science and sound II: Kepler, Galileo, and the Scientific Revolution\n\nPenelope Gouk, â€œThe role of harmonics in the scientific revolution,â€ in The Cambridge History of Western Music Theory, ed. Thomas Christensen (Cambridge: Cambridge University Press, 2002), pp. 223â€“ 245.\nOwen Gingerich, â€œKepler, Galilei, and the Harmony of the World,â€ in Music and Science in the Age of Galileo, ed. Victor Coelho (Dordrecht: Kluwer Publishers, 1992), pp. 45â€“63.\n\n\nMusic, healing, and the senses\n\nRobert E. Butts, â€œTickles, Titillations, and the Wonderful Accidents of Sound: Galileo and the Consonances,â€ in Music and Science in the Age of Galileo, ed. Victor Coelho (Dordrecht: Kluwer Publishers, 1992), pp. 115â€“127.\nLinda Phyllis Austern, â€œMusical Treatments for Lovesickness: The Early Modern Heritage,â€ in Music as Medicine, ed. Peregrine Horden (Aldershot: Ashgate, 2000), pp. 213â€“245.\n\n\nMedicine and art in the age of the Enlightenment: pills to purge melancholy\n\nPenelope Gouk, â€œMusicâ€™s Pathological and Therapeutic Effects on the Body Politic: Doctor John Gregoryâ€™s Views,â€ in Representing Emotions: New Connections in the Histories of Art, Music, and Medicine, eds. Penelope Gouk and Helen Hills (Farnham: Ashgate, 2005), pp. 191â€“ 207.\nCharles Brotman, â€œThe Undulating Self: The Rhythmic Conception of Music and the Emotions,â€ in Representing Emotions: New Connections in the Histories of Art, Music, and Medicine, eds. Penelope Gouk and Helen Hills (Farnham: Ashgate, 2005), pp. 209â€“221.\n\n\nHealth and physiognomy: music and the body Â \n\nMartha Feldman, The Castrato: Reflections on Natures and Kinds (Berkeley: University of California Press, 2015), preface [e-book available via library catalogue]\nBelcastro, Todero, Fornaciari, and Mariotti, HFI and castration: the case of the famous singer Farinelli, Journal of Anatomy 219 (2011): 632â€“37.\nSigma Xi, Medical Insights into the Castrati in Opera, American Scientist 75, no. 6 (1987): 578â€“83.\n\n\nMedicine, art, and science: the 19th century\n\nDavid Gentilcore, â€œRitualized Illness and Music Therapy: Views of Tarantism in the Kingdom of Naples,â€ in Music as Medicine, ed. Peregrine Horden (Aldershot: Ashgate, 2000), pp. 255â€“272.\nCheryce Kramer, â€œMusic as Cause and Cure of Illness in Nineteenth- Century Europe,â€ in Music as Medicine, ed. Peregrine Horden (Aldershot: Ashgate, 2000), pp. 338â€“352.\nJames Kennaway, Bad Vibrations: the history of the idea of music as cause of disease (Burlington, VT: Ashgate 2012), excerpts from chapters 1 and 2.\n\n\nContemporary perspectives in music therapy\n\nMichael P. Steinberg, â€œMusic and Melancholy,â€ Critical Inquiry 40, no. 2 (2014): 288â€“310.\nBjÃ¶rn Lemmer, â€œThe rhythm of the heartâ€”the tempus of musicâ€”Mozart, Ligeti, and the Rat,â€ in Music that Works: Contributions of Biology, Neurophysiology, Psychology, Sociology, Medicine and Musicology, ed. R. Haas and V. Brandes (Vienna: Springer, 2009), pp. 167â€“178.\nPeter Burke, â€œRituals of Healing in Early Modern Italy, â€œin The Historical Anthropology of Early Modern Italy (Cambridge: Cambridge University Press, 1987), pp. 207â€“220.\n\n\n"},"Nash-Equilibrium":{"title":"Nash Equilibrium","links":[],"tags":["Economics/Game-Theory"],"content":"def. Nash Equilibrium is a set of strategies (one for each player) which is the best response strategy of each otherâ€™s move; i.e. you canâ€™t deviate without destabilizing the equilibrium\nalg. Finding the Nash Equilibrium in a payoff matrix.\nCorner Method to find NE in payoff matrix.\n1. For each player:\n2. For each other playerâ€™s move; highlight the line of the best response\nâ†’ When both the left and top lines are highlighted that is NE.\nPure Strategy Nash Equilibirum Â§\ndef. PSNE. s=(s1â€‹,s2â€‹) is PSNE for two players 1,2 iff:\ns1â€‹s1â€‹â€‹=argminsâˆˆS1â€‹â€‹c1â€‹(s,s1â€‹)=argminsâˆˆS2â€‹â€‹c2â€‹(s1â€‹,s)â€‹â€‹\nHow to Find NE Â§\n\nIn Simultaenous Games: Use the Corner method\nIn Sequential Games: Make the Decision Tree into a Payoff Matrix, and use the Corner method:\n\ne.g. Driving left or Right\n\n\nSubgame Perfect Nash Equilibrium (SPNE) Â§\ndef. A Non-credible threat is when the follower in a sequential move game says: â€œIf I canâ€™t win, Iâ€™ll take you down no matter how much it costs to me.â€\n\nIn the above game, (R,R) is an example of a non-credible threat because when Player 1 chooses L, Player 2â€™s best response is Lâ€”but Player 2 threatens to go R. This is because they want the best possible outcome for them, R,(R,R)\n\ndef. Subgame Perfect Nash Equilibria (SPNE) are NE where the follwer will only choose strategies that are best for them, and canâ€™t threaten the leader beforehand with non-credible threats.\nTo find the SPNE of a game, use Backwards Induction:\n\nDetermine the last playerâ€™s best strategy\nThe second-last player knows what the last player will do. Then determine what the second-last player will do.\nContinue solving until the first player.\n\n\nSPNE={(d,d),(d,d)}, payoff is (1,0) which is a lot worse off that global optimal."},"Natural-Experiments":{"title":"Natural Experiments","links":[],"tags":["Math/Statistics"],"content":"Need not true randomness, only exogenity\ne.g. crime vs police; terror alerts cause police assignment to increase; terror is exogenous."},"Neoliberalism":{"title":"Neoliberalism","links":[],"tags":["Philosophy/Political-Philosophy","Economics"],"content":""},"Nimf-Anthy-installation":{"title":"Nimf-Anthy installation","links":[],"tags":["Computing"],"content":"Nimf-Anthy Installation Â§\nHow do I restore the default repositories?\ní•˜ëª¨ë‹ˆ ê³µì§€ - í•˜ëª¨ë‹ˆì¹´ ì €ì¥ì†Œ ê³µê°œí‚¤ ì„œëª… ë¬¸ì œ í•´ê²°ë°©ë²•\ní•˜ëª¨ë‹ˆì¹´(HamoniKR) í•˜ëª¨ë‹ˆ - apt updateì‹œ ì¸ì¦ì„œ ë¬¸ì œ\nInstallation\nsoftware-properties-gtk # open the gui repsitories \ncurl -sL https://apt.hamonikr.org/setup_hamonikr.jin | sudo -E bash - # add the Hamonikr repos to apt sources\nsudo apt install ca-certificates # update certificate authority files\nsudo apt install update # update apt cache\nsudo add-apt-repository ppa:hodong/nimf # add nimf dev&#039;s repo to apt source\n# and the logout and back in.\nThe hamonikr repo and ppa:hodong/nimf has different versions names. The binaries are probably the same but apt will complain about dependency versions. Installing the hodong/nimf repo will resolve the dependency issue."},"No-Arbitrage":{"title":"No-Arbitrage","links":[],"tags":["Economics/Finance"],"content":"def. Arbitrage Portfolio. Portfolio with value Î (t) at time t is an arbitrage portfolio if:\nÎ (t)=0âŸ¹Â priceÂ doesnâ€™tÂ goÂ downÂ P(Î (T)â‰¥0)=1â€‹â€‹Â andÂ Â priceÂ guarateedÂ toÂ riseÂ P(Î (T)&gt;0)&gt;0â€‹â€‹\nAlternatively we can define it as:\nÂ ifÂ startedÂ negative...Â Î (t)&lt;0â€‹â€‹âŸ¹Â ...willÂ beÂ non-negativeÂ P(Î (T)â‰¥0)=1â€‹â€‹\ndef. Law of One Price (LOP). Two portfolios with the same future value must have the same value to begin with. if time t&lt;T then:\nÎ Aâ€‹(T)=Î Bâ€‹(T)âŸ¹Î Aâ€‹(t)=Î Bâ€‹(t)\nthm. (Arbitrage is equivalent to LOP) If there is no arbitrage portfolio, then the law of one price holds.\nProof. Contrapositive: If law of one price doesnâ€™t hold, there is an arbitrage portfoilo. Let portfolios A,B such that\nÎ Aâ€‹(T)=Î Bâ€‹(T)Â andÂ Î Aâ€‹(t)&lt;Î Bâ€‹(t)\nThen construct the following new portfolio that:\n\nLong position on A\nShort position on B\nThen\n\n\nAt time t, value is Â AssetÂ Î Aâ€‹(t)â€‹â€‹âˆ’Â CashÂ DebtÂ Î Aâ€‹(t)â€‹â€‹âˆ’Â AssetÂ DebtÂ Î Bâ€‹(t)â€‹â€‹+Â CashÂ Î Bâ€‹(t)â€‹â€‹=Â AssetsÂ Î Aâ€‹(t)âˆ’Î Bâ€‹(t)â€‹â€‹=0\nAt time T, value is Â AssetÂ Î Aâ€‹(T)â€‹â€‹âˆ’Â CashÂ DebtÂ Î Aâ€‹(t)er(Tâˆ’t)â€‹â€‹âˆ’Â AssetÂ DebtÂ Î Bâ€‹(T)â€‹â€‹+Â CashÂ Î Bâ€‹(t)er(Tâˆ’t)â€‹â€‹=Â =0Â Î Aâ€‹(T)âˆ’Î Bâ€‹(T)â€‹â€‹+Â &gt;0Â (Î Bâ€‹(t)âˆ’Î Aâ€‹(t))er(Tâˆ’t)â€‹â€‹&gt;0\n\nThe cash investments are risk free, thus this is determined.\n\n\nTherefore this portfolio is an arbitrage portfolio.â– \n\nOne can similarly prove the other way. Thus LOB is equivalent to No Arbitrage condition."},"No-Regret-Dynamics":{"title":"No-Regret Dynamics","links":[],"tags":["Economics/Game-Theory"],"content":"Motivation. Suppose you have to choose which route to take every day driving to work. You devise a complicated strategy, but one day your neighbor and coworker, who takes the same route to work every day, says â€œI donâ€™t have a strategy, I just take this one route every day.â€ Wouldnâ€™t it be regretful if it turns out, in total, your route took more time than your co-worker?\ndef. Online Decision Making Game.\n\nPlayer has N actions to choose from, X={1,â€¦,N}\nAt time tâ€¦\n\nPlayer constructs a distribution pt over the set of actions X\nAdversary chooses a loss for each action taken, liâ€‹âˆˆ{0,1}, for every action iâˆˆX where 0 represents no loss and 1 represents a loss. (In our example, think of it as traffic conditions causing a delay.)\nPlayerâ€™s distribution pt is realized into action ktâˆˆX. The player incurs a loss of lkttâ€‹.\n\n\nThe playerâ€™s goal is to minimize total loss, which we will define shortly.\nWe play for time t=0,â€¦,T. Number of iterations T is predetermined.\n\nWe characterize the loss if we always chose action i (like how our neighbor always takes the same route) for time t=1,â€¦,T as:\nLiTâ€‹:=t=1âˆ‘Tâ€‹litâ€‹\nThus we can define also:\n\nLminTâ€‹ is the minimum total loss if we could only choose one action every time\nLALGTâ€‹:=âˆ‘t=1Tâ€‹lALGtâ€‹ is the total loss of player playing strategy of ALG, lALGt=1â€‹,lALGt=2â€‹,â€¦.\n\ndef. External Regret. For a player playing strategy ALG, the regret for this strategy is:\nRALGâ€‹:=LALGTâ€‹âˆ’LminTâ€‹\ni.e. the difference between total loss of algorithm and the best total loss of one-action-every-time strategy.\nAlgorithms for Online Games Â§\nalg. Greedy algorithm. This algorithm chooses the action whose one-action-fits-all-time loss is smallest\n\nInitially: x1=1\nAt time t, choose xiâ€‹ such that we take the minimum possible LiTâ€‹. In other words:\n\nxitâ€‹Â suchÂ thatÂ =argminiâ€‹LiTâ€‹\n\nBreaks ties determinimistically, with the action with lowest index.\n\nMotivation. This algorithm is really bad. Instead, we can try to confuse our adversary by mixing our strategy, i.e. a randomized algorithm.\nalg. Randomized Weighted Majority.\n\nInitially, play i with probability pi1â€‹=N1â€‹ for all iâˆˆX\nAt time tâ€¦\n\nwitâ€‹={witâˆ’1â€‹(1âˆ’Î·)witâˆ’1â€‹â€‹ifÂ incurredÂ loss,Â i.e.Â litâˆ’1â€‹=1ifÂ incurredÂ loss,Â i.e.Â litâˆ’1â€‹=1â€‹\n\nwhere Î· is the discount factor\n\n\nCalculate this new weight for every strategy i, and then play i with probability\n\n\n\nwhere Wt:=âˆ‘iâˆˆXâ€‹witâ€‹\n\nThis is a much better algorithm; in fact we can show how small its regret is.\nthm. (Regret Bound of Randomized Weighted Majority) For Î·â‰¤21â€‹, the loss of RWM algorithm satisfies:\nLRWMTâ€‹â‰¤(1+Î·)LminTâ€‹+Î·lnNâ€‹\nProof. Let Ft denote the fraction of weights that are discounted because they incurred a loss. We show this is equal to the expected loss at timestep t:\nFtâ€‹:=Wtâˆ‘i;liâ€‹=1â€‹witâ€‹â€‹=i;liâ€‹=1âˆ‘â€‹Wtwitâ€‹â€‹=iâˆˆXâˆ‘â€‹Wtwitâ€‹â€‹litâ€‹=iâˆˆXâˆ‘â€‹pitâ€‹litâ€‹=E(lt)â€‹â€‹\nNow, we can express Wt+1 using Ft way, by splitting the summation into those that incurred a loss and those that didnâ€™t.\nWt+1â€‹:=iâˆˆXâˆ‘tâ€‹witâ€‹=(1âˆ’Î·)âˆ‘i;liâ€‹=1â€‹witâ€‹i;liâ€‹=1âˆ‘â€‹witâ€‹(1âˆ’Î·)â€‹â€‹Wtâˆ’âˆ‘i;iliâ€‹=1â€‹i;liâ€‹=0âˆ‘â€‹witâ€‹â€‹â€‹=(1âˆ’Î·)FtWt+(Wtâˆ’FtWt)=Wtâˆ’Î·FtWt=Wt(1âˆ’Î·Ft)â€‹â€‹\nWe can now construct the inequality:\nmaxiâ€‹wit+1â€‹(1âˆ’Î·)LminTâ€‹LminTâ€‹ln(1âˆ’Î·)â€‹â‰¤Wt+1â‰¤Wt+1=W1(1âˆ’nF1)Ã—â‹¯Ã—(1âˆ’nFT)=Nt=1âˆTâ€‹(1âˆ’Î·Ft)=lnN+t=1âˆ‘Tâ€‹ln(1âˆ’Î·Ft)â‰¤lnN+t=1âˆ‘Tâ€‹Î·Ft=lnN+Î·t=1âˆ‘Tâ€‹Ft=lnN+Î·LRWMTâ€‹â€‹sumÂ isÂ greaterÂ thanÂ maxmaxÂ weightÂ isÂ oneÂ withÂ minÂ lossW1=NTakingÂ logÂ onÂ bothÂ sidesâˆ€xâˆˆR,ln(1âˆ’x)â‰¤âˆ’xâ€‹â€‹\nAnd with some algebra and inequality: âˆ€zâˆˆR,âˆ’ln(1âˆ’z)â‰¤z+z2\nLrwmTâ€‹â‰¤Î·lnNâ€‹âˆ’Î·LminTâ€‹ln(1âˆ’Î·)â€‹â‰¤Î·lnNâ€‹âˆ’(1+Î·)LminTâ€‹\nâ– "},"Noam-Chomsky":{"title":"Noam Chomsky","links":["Chompsky-Heirarchy","Chompsky-Normal-Form"],"tags":["People"],"content":"From the\n\nChompsky Heirarchy\nChompsky Normal Form\n"},"Nonlinear-Models":{"title":"Nonlinear Models","links":[],"tags":["Math/Statistics"],"content":"Polynomial Models Â§\nYiâ€‹=Î²0â€‹+Î²1â€‹X1iâ€‹+Î²2â€‹X1i2â€‹+â‹¯+Ïµiâ€‹\n\nThis is still bivariate! itâ€™s just Y vs X1â€‹\n\nLogarithmic Models Â§\n\nLinear-Log: Yiâ€‹=Î²0â€‹+Î²1â€‹lnXiâ€‹+Ïµiâ€‹\nLog-Linear: lnYiâ€‹=Î²0â€‹+Î²1â€‹Xiâ€‹+Ïµiâ€‹\nLog-Log: lnYiâ€‹=Î²0â€‹+Î²1â€‹lnXiâ€‹+Ïµiâ€‹\nBe careful since:\n\n\nUnits of coefficients are different\nVariables must all be positive\nThere isnâ€™t a statistical test to choose which model to use\n\nExample: Wage vs Height Â§\nRegression Table: \n\nNo Log: â€œWage increases by \\0.412per\\text{inch}$ increase in heightâ€\nLinear-Log: â€œWage increases by \\frac{29.316}{100}=\\0.293per1%$ increase in heightâ€\nLog-Linear: â€œWage increases by 0.033Ã—100=3.3% per inch increase in heightâ€\nLog-Log: â€œWage increases by 2.362% per 1% increase in heightâ€\n"},"Normal-Distribution":{"title":"Normal Distribution","links":["Normal-Distribution","Approximating-Distributions","Standardizing-a-Random-Variable","Chebyshev's-Inequality"],"tags":["Math/Common-Distributions"],"content":"def. Normal Distribution. A random variable X distributed over a Normal distribution with mean Î¼ and standard deviation Ïƒ is denoted:\nXfXâ€‹(x)P(a&lt;X&lt;b)â€‹âˆ¼Normal(Î¼,Ïƒ)=Ïƒ2Ï€â€‹1â€‹â‹…eâˆ’21â€‹(Ïƒxâˆ’Î¼â€‹)2=âˆ«abâ€‹Ïƒ2Ï€â€‹1â€‹â‹…eâˆ’21â€‹(Ïƒxâˆ’Î¼â€‹)2dxâ€‹\ndef. Cumulative Distribution Function (CDF) of a Normal Distribution\nÎ¦(z):=âˆ«âˆ’âˆzâ€‹2Ï€â€‹eâˆ’t2/2â€‹dt\nObserve:\n\nzâ†’+âˆ,Î¦(z)â†’1\nzâ†’âˆ’âˆ,Î¦(z)â†’0\nÎ¦(âˆ’z)=1âˆ’Î¦(z)\n\ndef. Standard Normal Distribution. A standard normal distribution is a normal distribution where Î¼=0,Ïƒ=1\nXâˆ¼Normalstd.â€‹(0,1)\n\n\n                  \n                  Tip \n                  \n                \nYou can approximate a bunch of distributions using the Normal.\n\nrmk. Linear Transformation of Normal Distribution. If Xâˆ¼N[Î¼,Ïƒ2], then\n\nE(aX+b)=aE(X)+b=aÎ¼+b\nVar(aX+b)=a2Var(X)=a2Ïƒ2\n\n\nâ‡’ Thus (aX+b)âˆ¼Normal(aÎ¼+b,a2Ïƒ2)\n\n\n\nremark. Exponentiating Transformation of Normal Distribution. If Xâˆ¼N(Î¼,Ïƒ2)\nE[eX]=eÎ¼+2Ïƒ2â€‹\n(using Law of Unconscious Statistician)\nrmk. Standardizing the Normal Distribution. Given Xâˆ¼N(Î¼,Ïƒ2):\n\nY=ÏƒXâˆ’Î¼â€‹ has the standard normal distribution\nThe pdf is as follows:\n\nP(a&lt;X&lt;b)=âˆ«abâ€‹Ïƒ2Ï€â€‹1â€‹â‹…eâˆ’21â€‹(Ïƒxâˆ’Î¼â€‹)2dxÂ Â Â â‡’Â Â Â âˆ«Ïƒaâˆ’Î¼â€‹Ïƒbâˆ’Î¼â€‹â€‹Ïƒ2Ï€â€‹eâˆ’x2/2â€‹dz\n\nSee also Standardizing a Random Variable\n\nrmk. Empirical Rule: Rule of thumb for calculating probabilities (integrals) of normal distributions\n\n! Generalized version: Chebyshevâ€™s Inequality\n1 std. dev. away is â‰ˆ66%; 2 std.dev. away is â‰ˆ0.95%\n\nEstimators Â§\nlet\n\nXâˆ¼N(Î¼,Ïƒ2)\nX1â€‹,â€¦,Xnâ€‹âˆ¼iidN(Î¼,Ïƒ2)\nâ‡’ Log likelihood:\n\nlnLnâ€‹(Î¼,Ïƒ2âˆ£x1â€‹,...,xnâ€‹)=âˆ’2nâ€‹ln(2Ï€)âˆ’2nâ€‹ln(Ïƒ2)âˆ’2Ïƒ21â€‹i=1âˆ‘nâ€‹(xiâ€‹âˆ’Î¼)2\nScore Â§\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOne R.V.Multiple Datas(Î¼)=Ïƒ2xâˆ’Î¼â€‹snâ€‹(Î¼)=Ïƒ2nÎ¼âˆ’âˆ‘i=1nâ€‹xiâ€‹â€‹s(Ïƒ)=Ïƒ3(xâˆ’Î¼)2â€‹âˆ’Ïƒ1â€‹snâ€‹(Ïƒ)=Ïƒ3âˆ‘i=1nâ€‹(xiâ€‹âˆ’Î¼)2â€‹âˆ’Ïƒnâ€‹\nMLEs Â§\nÎ¼^â€‹=n1â€‹i=1âˆ‘nâ€‹xiâ€‹\nÏƒ^2=n1â€‹i=1âˆ‘nâ€‹(xiâ€‹âˆ’xË‰)2\nFisher Information Â§\n\nUnknown Î¼, known Ïƒ2\n\nI(Î¼)=Ïƒ21â€‹Inâ€‹(Î¼)=Ïƒ2nâ€‹\n\nKnown Î¼ unknown Ïƒ2\n\nI(Ïƒ2)=2Ïƒ21â€‹Inâ€‹(Ïƒ2)=2Ïƒ2nâ€‹"},"Oligopoly":{"title":"Oligopoly","links":["Bertrand-Price-Competition","Cornout-Quantity-Competition"],"tags":["Economics/Macro-Economics","Economics/Game-Theory"],"content":"Definitions Â§\n\nBest Response Curve: A function that determines oneâ€™s best response value of the strateigic variable, given the opponentâ€™s strategic variable value.\n\nThis is equivalent to the pure strategy function (see definition)\n\n\nDr denotes residual demand for one firm\n\nAssumptions Â§\n\nAssume that products are identical [=no differentiation]\nAssume there are two firms in the market\nAssume that MC is constant\n\nTypes Â§\n\nBertrand Price Competition\n\nProduct Differentiation\n\n\nCornout Quantity Competition\n\nSequential (=Stackleberg)\n\n\n\n\nThere are thus 2 ways to fill in the gap between 2-firm oligopoly and perfect compeition:\n\nN-firm Oligopoly as an extension of Cornoutâ€™s 2-firm oligopoy analysis\nMonopolistic Competition, where firms strategically set differentiation and price\n"},"Omitted-Variables":{"title":"Omitted Variables","links":[],"tags":["Math/Statistics"],"content":"Motivation. What if there are external variables that are related to Y? We want to characterize how off we might be if we omitted a variable.\nOmitting a Variable from a True 2-var Model Â§\nAssume the true model should have the following:\nYiâ€‹=Î²0â€‹+Î²1â€‹Xiâ€‹+Î²2â€‹Â OmittedÂ Ziâ€‹â€‹â€‹+Ïµiâ€‹\nWe didnâ€™t take into account Z, and we mistakenly used the following model:\nYiâ€²â€‹=Î²0omitâ€‹+Î²1omitâ€‹X1,iâ€‹+Ïµiâ€‹\nThen, our estimators Î²0â€‹^â€‹omit and Î²1â€‹^â€‹omit will be different from Î²0â€‹^â€‹,Î²1â€‹^â€‹. We can state precisely how off they will be (=Omitted Variable Bias):\nÎ²1â€‹^â€‹omit=Î²1â€‹^â€‹+Â BiasÂ Î²2â€‹^â€‹Î´1â€‹^â€‹â€‹â€‹\nwhere Î´1â€‹^â€‹ is from the auxiliary regression\nZiâ€‹=Î´0â€‹^â€‹+Î´1â€‹^â€‹Xiâ€‹+Ï„iâ€‹\nOmitting a Variable from a 3-var Model Â§\n\nTrue model: Yiâ€‹^â€‹=Î²0â€‹^â€‹+Î²1â€‹^â€‹X1,iâ€‹+Î²2â€‹^â€‹X2,iâ€‹+Î²3â€‹^â€‹X3,iâ€‹+Ïµiâ€‹^â€‹\nOmitted model: Yiâ€²â€‹^â€‹=Î²0â€²â€‹^â€‹X1,iâ€‹+Î²2â€²â€‹^â€‹X2,iâ€‹+Ïµiâ€²â€‹^â€‹\nEstimator relationships:\n\nÎ²1â€²â€‹^â€‹=Î²1â€‹^â€‹+Î²3â€‹^â€‹Î´1â€‹^â€‹\nÎ²2â€²â€‹^â€‹=Î²2â€‹^â€‹+Î²3â€‹^â€‹Î´2â€‹^â€‹\n\n\nAuxiliary regression: X3â€‹=Î´0â€‹^â€‹+Î´1â€‹^â€‹X1â€‹+Î´2â€‹^â€‹X2â€‹\n\nGeneral Form Â§\nFor true model:\nYiâ€‹^â€‹=Î²0â€‹^â€‹+Î²1â€‹^â€‹X1,iâ€‹+â‹¯+Î²nâˆ’1â€‹^â€‹Xnâˆ’1,iâ€‹+Î²nâ€‹^â€‹Xnâ€‹\nwhere Xnâ€‹ is the omitted variable. Our omitted model:\nYiâ€‹^â€‹\nÎ²iâ€²â€‹^â€‹=Î²iâ€‹^â€‹+Î²^â€‹omitâ€‹Î´iâ€‹^â€‹\nwhere\nXomitâ€‹=Î´0â€‹^â€‹+Î´1â€‹^â€‹X2â€‹+â‹¯+Î´^nâˆ’1â€‹Xnâˆ’1â€‹"},"Online-Matching":{"title":"Online Matching","links":["Matching-Problems"],"tags":["Computing/Algorithms","Economics/Game-Theory"],"content":"Motivation. Suppose you are Google. Many advertisers come to you and want to advertise on google searches by users. Now, users come it throughout the day, one by one, searching for whatever they want to search. You can show them one advertisement. How do you maximize the advertisement to show to the users?\n\ndef. Optimal Online Matching Algorithm. The optimal algorithm is just one that knows in advance what all users will search, and thus simply finds a maximum partition matching.\nWhole Online Matching Â§\ndef. Greedy Online Matching algorithm. When a new user from R comes in and declares its edges, it simply matches to any valid advertiser L.\n\nThis simply finds the maximal (not maximum) matching.\nThis is in the worst case two times worse than optimal online matching. Proof:\n\nWhen a new edge v comes available, ALG matching it to the â€œwrongâ€ vertex uâ€² will at most block two â€œcorrect matchingsâ€ (from optimal).\nTherefore OPTALGâ€‹â‰¤2 â– \n\n\n\n\nFractional Online Matching Â§\nWe may sometimes allow for fractional matchings, i.e. consider an edge â€œfullâ€ at weight 1, but the weight can be anywhere from [0,1]. We still benchmark fractional online matching with the original optimal whole matching algorithm.\ndef. Greedy Fractional Online Matching Algorithm. let râˆˆR encountering nrâ€‹ edges. For every unfilled edge, equally fill nrâ€‹1â€‹ to each.\nThis algorithm is pretty bad. Consider the following worst case scenario:\n\n\nEach set A,B,C,D have n verticies\nAppears in order: c1â€‹,â€¦,cnâ€‹,d1â€‹,â€¦,dnâ€‹\nOPT=2n which matches all of A to C, and all of B to D.\nFor ALG:\n\nconsider the time when ciâ€‹ is matching:\n\nequally gives n+11â€‹ to all of b1â€‹â€¦bnâ€‹s and aiâ€‹.\nThis happens for ever ciâ€‹, i.e. n times\nAfter the last vertex in C, total n finishes matching, all of b1â€‹â€¦bnâ€‹ have filled n+1nâ€‹.\n\n\nNow, each of diâ€‹ only has n1â€‹ of biâ€‹ to match with.\nTotal fully matches ciâ€‹âˆˆC, and n1â€‹ of diâ€‹âˆˆD. Thus ALG=n+(nâ‹…n1â€‹)=n+1\n\n\nThus OPTALGâ€‹=n+12nâ€‹&lt;2. Pretty bad.\ndef. Water-filling Algorithm. The algorithm works like this: for every râˆˆR that appears, it outputs water at a constant rate. Fill the vertices with least water first at equal rate:\n\nIn the example above of the worst-case greedy algorithm, water-filing does a better job.\nFirst consider ciâ€‹ filling aiâ€‹ and all of b1â€‹â€¦bnâ€‹.\nb1â€‹â€¦bnâ€‹ is already filled up to level x (we know they are all filled up to equal amounts, because B and C are fully connected.)\naiâ€‹ is empty because it is only connected to ciâ€‹\nTotal water output by ciâ€‹ is 1.\nTotal n+1 verticies.\nWe know that water level will rise above x for everybody (until some yiâ€‹) because aiâ€‹ canâ€™t hold that much\n\nThen, denoting the rate of water output by ciâ€‹ as dtdxâ€‹:\n\nÂ filledÂ byÂ aiâ€‹Â xâ€‹â€‹+Â filledÂ byÂ allÂ vertexÂ dtdxâ€‹(n+1)â€‹â€‹dtdxâ€‹â€‹=Â totalÂ waterÂ 1â€‹â€‹=n+11âˆ’xâ€‹â€‹â€‹\nThen, let y be the height of water on b1â€‹â€¦bnâ€‹ after c1â€‹â€¦cnâ€‹ are done filling. Summing this up for all c1â€‹â€¦cnâ€‹ from x=0â€¦y and t=0â€¦n:\nâˆ«x=0yâ€‹1âˆ’x1â€‹dx[âˆ’ln(1âˆ’x)]0yâ€‹ln(1âˆ’y)yâ€‹=âˆ«t=0nâ€‹n+11â€‹dx=n+1n+1â€‹=1=âˆ’1=1âˆ’e1â€‹â€‹â€‹\nAnd then the remaining e1â€‹ for each biâ€‹ will be matched to diâ€‹. Total matched is:\nALGOPTALGâ€‹â€‹=Â byÂ CÂ nâ€‹â€‹+Â byÂ DÂ n(e1â€‹)â€‹â€‹=n(1+e1â€‹)=2nn(1+e1â€‹)â€‹=2ee+1â€‹â€‹â€‹\n(Note that we still compare with whole matching optimum.)\ndef. Ranking Algorithm.\ndef. Bid Scaling Algorithm."},"Optimal-Stopping-Problem":{"title":"Optimal Stopping Problem","links":[],"tags":["Economics/Game-Theory"],"content":"Motivation. Imagine a gambling situation, where there is a sequence of prizes inside boxes. The gambler knows the distribution of these boxes, but is only shown one at a time. They can claim only one box, and once a box is opened the prize must be claimed or trashed. How can the gambler act?\n\ndef. (Optimal stopping problem) let prizes of random variables X1â€‹,X2â€‹â€¦,Xnâ€‹ be distributed F1â€‹,F2â€‹,â€¦,Fnâ€‹. The gambler only knows the distribution of each of these boxes, and the order in which the boxes are shown is shuffled randomly.\nthm. Prophet Inequality. There is a strategy for the gambler to achieve at least 21â€‹ of the optimal revenue, i.e.:\nE(payoff)â‰¥21â€‹E(maxi=1nâ€‹Xiâ€‹)\nwhereâ€¦\n\npayoff is the payoff to the gambler\nlet Xâˆ—:=maxi=1nâ€‹Xiâ€‹, a random variable. This is what the â€œProphetâ€ gets, i.e. a optimal strategy.\nAdditionally, the theorem states that this strategy is a optimal cutoff strategy, which is one that stops if the payoff from the current opened box is larger than predetermined cutoff w.\n\nProof. We know that payoff=baseÂ payoff+excessÂ payoff where\n\nbase payoff is w\nexcess payoff is Xjâ€‹âˆ’w, where Xjâ€‹ is the box we stop at\nWe also know that these two are random varibles:\n\nw={w0â€‹ifÂ Xâˆ—â‰¥welseâ€‹\nexcessÂ payoff={E((Xjâ€‹âˆ’w)+)0â€‹ifÂ stoppedÂ atÂ Xjâ€‹ifÂ neverÂ stoppedâ€‹\nNow, the expected payoff is:\nE(payoff)=Â expectedÂ baseÂ P(Xâˆ—â‰¥w)â‹…wâ€‹â€‹+Â expectedÂ excessÂ j=1âˆ‘nâ€‹P(stoppingÂ atÂ Xjâ€‹)â‹…E((Xjâ€‹âˆ’w)+)â€‹â€‹â€‹â€‹\nWe know that the probability of stopping at Xjâ€‹ (from the first case of excess payoff) is:\nP(stoppingÂ atÂ Xjâ€‹)â€‹=P(maxi=1jâˆ’1â€‹Xiâ€‹&lt;w)â‰¥P(maxi=1nâ€‹Xiâ€‹&lt;w)=P(Xâˆ—&lt;w)â€‹...thatÂ boxesÂ beforeÂ jÂ whereÂ &lt;w...thatÂ allÂ boxesÂ areÂ &lt;wbyÂ definitionÂ ofÂ Xâˆ—â€‹â€‹\nThus:\nE(payoff)â‰¥P(Xâˆ—â‰¥w)â‹…w+Â takeÂ outÂ sinceÂ Xâˆ—Â isÂ notÂ relevantÂ toÂ jÂ P(Xâˆ—&lt;w)â‹…j=1âˆ‘nâ€‹E((Xjâ€‹âˆ’w)+)â€‹â€‹\n(lemma 1)\nOn the other hand, the expected prophet payoff is\nE(Xâˆ—)â€‹=E(w+maxj=1nâ€‹(Xjâ€‹âˆ’w))â‰¤w+E(maxj=1nâ€‹(Xjâ€‹âˆ’w)+)â‰¤w+j=1âˆ‘nâ€‹E((Xjâ€‹âˆ’w)+)â€‹byÂ definitionÂ ofÂ (â€¦)+sumÂ greaterÂ thanÂ maxâ€‹â€‹\n(lemma 2)\nNoticing lemma 1 and lemma 2 both have term âˆ‘j=1nâ€‹E((Xjâ€‹âˆ’w)+), we can organize for that:\nP(Xâˆ—&lt;w)E(payoff)âˆ’wâ‹…P(Xâˆ—â‰¥w)â€‹â‰¥j=1âˆ‘nâ€‹E((Xjâ€‹âˆ’w)+)â‰¥E(Xâˆ—)âˆ’w\nSimplifying we get\nE(payoff)â‰¥21â€‹E(Xâˆ—)\nâ– "},"Optimistic-Nihilism":{"title":"Optimistic Nihilism","links":[],"tags":["Philosophy"],"content":""},"Options-(Finance)":{"title":"Options (Finance)","links":["Derivatives-(Finance)","No-Arbitrage","Binomial-Option-Pricing-Model"],"tags":["Economics/Finance"],"content":"An option is a contract that gives the holder the right to exercise the option (=buy/sell a stock) at the strike price at or before the strike date.\n\nIt is a type of Derivative\nThe person who gives out the option contract is the writer.\nThe person who gets the option contract is the holder.\n\nTypes of Options Â§\n\nExercise timing\n\nAmerican option: anytime on or before the strike date.\nEuropean option: at the strike date only.\n\n\nExercise type\n\nCall option: you hold the right to sell the stock at the strike price.\nPut option: you hold the right to buy the stock at the strike price.\n\n\n\nDefinitions Â§\n\nS(t): price of underlying asset, at time t\nC(t): price of a call option, at time t\nP(t): price of a put option, at time t\nK: strike price of a call or put option\n\nIntuition. (Payoff Diagram for Options)\n\nCall Option Â§\nAssume continuous compounding at rate r between time period [t0â€‹,t1â€‹]. Assume No-Arbitrage.\n\nPayoff: max[S(t1â€‹)âˆ’K,0]\n\n0 is when the stock price as decreased, so you donâ€™t decide to sell.\naccording to the law of one price, must equal to =C(t1â€‹)\n\n\nProfit: max[S(t1â€‹)âˆ’K,0]âˆ’C(t0â€‹)exp[r(t1â€‹âˆ’t0â€‹)]\n\nFirst term is the payoff\nSecond term is because you borrowed money at the risk-free rate r to buy the call option.\nWe donâ€™t know what C(t0â€‹) is yetâ€¦see Binomial Option Pricing Model\n\n\n\nthm. Put-Call Parity. let call option entered at time t0â€‹ and put at time t0â€‹. Then\nÂ CallÂ C(t0â€‹)â€‹â€‹+Â CashÂ Keâˆ’r(t1â€‹âˆ’t0â€‹)â€‹â€‹=Â PutÂ P(t0â€‹)â€‹â€‹+Â eâˆ’q(t1â€‹âˆ’t0â€‹)Â unitsÂ ofÂ underlyingÂ S(t0â€‹)eâˆ’q(t1â€‹âˆ’t0â€‹)â€‹â€‹\nIntuition. You can always use a stock plus a put option to simulate an equivalent call option, and v.v.\nProof Outline. let Î Aâ€‹ long 1 call, have Keâˆ’r(t1â€‹âˆ’t0â€‹) units of cash. Let Î Bâ€‹ long 1 put, have eâˆ’q(t1â€‹âˆ’t0â€‹) units of underlying stock. At time t1â€‹ they will have equivalent value, thus at time t0â€‹ their value must be same by LOP.\nthm. Put-Call-Forward Relation.\n\nForward entered at t=0 and ends at t=T, with strike price K\nC(t),P(t) are call and put entered at time t, with strike price K\n\nC(t)âˆ’P(t)=FTâ€‹(t)\nProof Outline. \nVarious Portfolios that Can Be Constructed from Options Â§\ndef. Moneyness of Option. A call optionâ€™s moneyness at time t is: \n\nIf Stâ€‹&gt;K: call is in (=on) the money\nIf Stâ€‹=K: Call is at the money\nIf Stâ€‹&lt;K: Call is out of the money, i.e. worthless.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStrategyWhen you predictâ€¦Profit Diagrams (Not Payoff)StraddleUnderlying will move up/down a littleStrangleUnderlying will move up/down a lotBull/Bear SpreadUnderlying will go up (bull) / down (bear)Butterfly SpreadUnderlying will not move much (long) / move a lot (short)"},"Ordinal-Allocation":{"title":"Ordinal Allocation","links":["Utility-Function","Fairness-(Economics)","tags/task"],"tags":["Economics/Game-Theory","task"],"content":"Motivation. We move on from cardinal allocations where the Utility Function is numerically defined, into a situation where there is only an ordinal ranking by the agents. This is more realistic in real life, since most people are able to identify which item they prefer even if they canâ€™t assign it a numerical utility value.\nIn order for any of this to be remotely fair, we need to allow probabilistic allocation. This means that the allocation solution P is for each item a and agent i, gives a probability Pi,aâ€‹ that the item is allocated to the agent:\nPi,aâ€‹:=P(aÂ isÂ allocatedÂ toÂ i)Â s.t.âˆ€aâˆ‘â€‹Piâ€‹=1\nFor convenience, letâ€™s also define a cumulative distribution function, for each agent.\nPiâ€‹(t)=aâª¯tâˆ‘â€‹P(a)\nWe might visualize two different allocation P,Q for which for agent i the cumulative allocation function Piâ€‹,Qiâ€‹ is visualized like this:\n\nNow we can define a few properties of baysian allocations.\ndef Stochastic Dominance (SD). Allocation Piâ€‹ stoastically dominates distribution Qiâ€‹ for agent i iff\nâˆ„aÂ suchÂ thatÂ Â probabilityÂ toÂ getÂ atÂ leastÂ aÂ orÂ betterÂ aâ€²&gt;aâˆ‘â€‹Piâ€‹(aâ€²)â€‹â€‹&lt;aâ€²&gt;aâˆ‘â€‹Qiâ€‹(aâ€²)\nExample. Agents 1..4 want items a,b with the preferences shown below.\n\n\nFirst allocation P is stochastically dominated by second allocation Q for agents 1,2 because:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProbability under..aaâˆ¨baâˆ¨bâˆ¨âˆ… (=get sth)P125â€‹126â€‹1Q21â€‹21â€‹1There is no item where getting P gets clearly better than Q. Therefore Q stochastically dominates P.\ndef. (Preferences in Ordinal Allocation) This is how we define preferences in ordinal situations. P stochastically dominates Q for i is equivalent to saying Pâ‰»iâ€‹Q.\n\n! But note that we cannot say anything about indifference. Stochastic dominance is defined over a partial ordering (we wonâ€™t go into more detail) which means there cannot be two different sets i is indifferent about.\n\nWe define Fairness (Economics) in the following ways:\ndef Ordinal Efficiency (OE). Allocation P is pareto-optimal when there does not exist any other allocation Q which is a pareto improvement than P:\n\nNobody are worse off: âˆ€i,Qiâ€‹âª°Piâ€‹\nSome are improved: âˆƒiâˆ—Qiâˆ—â€‹â‰»Piâˆ—â€‹\n\ndef. Ex-Post Pareto Optimality. Allocation P is Ex-post PO when every possible matching in the distribution P is Ordinally Efficient.\nThere are two definitions of envy-freeness in probabilistic allocations:\n\ndef. Weak Envy-Free (WEF). Allocation P is WEF when there exists no Pjâ€‹ that stochastically dominates for Piâ€‹.\ndef. Strong Envy-Free (SEF). Allocation P is SEF when it stochastically dominates all other agentâ€™s allocation.\n\nRandom Dictatorship Â§\n\n Proofs of various ordinal allocation schemes#task\n\nthm. RD is DSIC. Trivially. You are best off when you choose your item on the first try. Induction.\nthm. RD is Ex-post PO. Trivially. If there are at least as many agents as items, then every agent picks their favorite among thatâ€™s left, and nobody can really improve by swapping. Induction.\nthm. RD is WEF. (will not prove)\nthm. (Not strong envy-free.) Counterexample.\n\n\nagent 1â€™s allocationâ€™s cumulative allocation is (21â€‹,64â€‹,1)\nagent 3â€™s allocationâ€™s cumulative allocation w.r.t. 1â€™s preferences is (0,65â€‹,1)\n\nthm. (RD is not ordinally efficient.) Counterexample. (Same example from above)\n\nProportional Eating Â§\nthm. PE is not truthful. Counterexample.  \nthm PE is SEF if all agents have different preference orderings (WEF if exists two agents with same ordering). Proof sketch by induction:\n\nLet S1â€‹ be the timepoint a1â€‹ is fully eaten, S2â€‹ when a2â€‹ is fully eaten, and so on.\nLet agent i have preference a1â€‹â‰»a2â€‹â‰»â‹¯â‰»amâ€‹ of m items of set T.\nThen, agent i eats a1â€‹ first. Everybody eats at the same rate, so there is no agent who can eat even more than agent i. Agent i eats it from time 0 to S1â€‹:\n\nâˆ€j,S1â€‹=Pi,a1â€‹â€‹â‰¥Pj,a1â€‹â€‹\nThen, i moves on to eat a2â€‹ from time S1â€‹ to S2â€‹. No other agent can eat more of a1â€‹ AND a2â€‹ than agent i (unless they both eat identically):\nâˆ€j,Pi,a1â€‹â€‹+Pi,a2â€‹â€‹&gt;Pj,a1â€‹â€‹+Pj,a2â€‹â€‹\nInduce into all m items:\nâˆ€j,âˆ€aâˆ‘â€‹Pi,aâ€‹&gt;âˆ€aâˆ‘â€‹Pj,aâ€‹\n(equality when i,j have identical preferences). Considering all of these cases together:\nâˆ€a,âˆ€jaâ€²&gt;aâˆ‘â€‹Pi,aâ€‹&gt;aâ€²&gt;aâˆ‘â€‹Pj,aâ€‹\nTherefore i does not envy anybody else. â– \nthm PE is Ex-Post PO. We will go through a lemma first.\ndef. In allocation P, call a2â€‹â†’Ï„a1â€‹ (â€a2â€‹ tau-s a1â€‹â€) iff there exists an agent i which prefers a2â€‹ over a2â€‹, but has also eaten some of a1â€‹ (and obviously ate a2â€‹ beforehand). Allocation-wise, a2â€‹â‰»iâ€‹a2â€‹ and Pi,a1â€‹â€‹&gt;0.\nLemma. If an allocation P is not Ex-Post PO, then there exists a cycle, i.e. a1â€‹â†’Ï„a2â€‹â†’Ï„â€¦â†’Ï„a1â€‹\nThen Proof by contradiction. Assume PE produces and allocation P that is not EX-post PO; by the lemma this allocation must have a tau-cycle:\nFor the tauâ€™ing aÎ³âˆ’1â€‹â†’Ï„aÎ³â€‹ in this cycle, Find the agent iÎ³â€‹ that tauâ€™ed these items. Let the timepoint when i starts eating aÎ³â€‹ be SÎ³â€‹. By this time aÎ³âˆ’1â€‹ must have been fully eaten; thus SÎ³âˆ’1â€‹&lt;SÎ³â€‹.\nWe can do this for every tauâ€™ed agent in the cycle. But then S1â€‹&lt;SÎ³â€‹, but by cycle S1â€‹&gt;SÎ³â€‹. This is a contradiction. Thus allocation P which is produced by PE must be Ex-Post PO. â– \nProof Sketch of Lemma. Assume allocation P which is not ex-post PO, i.e. there exists another allocation Q where some agent i is better off in Q, i.e. Qiâ€‹â‰»Piâ€‹ (=Qiâ€‹ stochastically dominates Piâ€‹.) Focus on this agent i.\nThen, there must exist for this agent a pair of items (call them a2â€‹,a1â€‹) where:\n\na2â€‹â‰»iâ€‹a1â€‹\nQi,a2â€‹â€‹&gt;Pi,a2â€‹â€‹ because for i Q is better because it eats more of the better one.\nQi,a1â€‹â€‹&lt;Pi,a1â€‹â€‹ because probability for each row must both sum to 1.\n\nThus Pi,a2â€‹â€‹&gt;0 and in alloc. P, a2â€‹â†’Ï„a1â€‹. Then, find another agent j that Qj,a2â€‹â€‹&lt;Pj,a2â€‹â€‹. This j exists because probability of each column sums to 1 (for each allocation).\nNow, for this agent j, find item a3â€‹ that satisfies:\na3â€‹â‰»jâ€‹a2â€‹\nPj,a3â€‹â€‹&lt;Qj,a3â€‹â€‹\nThis item a3â€‹ must exist because row must sum to one. Then Pj,a2â€‹â€‹&gt;0 and in alloc. P, a2â€‹â†’Ï„a1â€‹\nWe can continue on but we must form a cycle of tau-ing because there are finite number of items. â– \n"},"Ordinary-Least-Squares-Regression":{"title":"Ordinary Least Squares Regression","links":[],"tags":["Math/Statistics"],"content":"Motivation. Letâ€™s say that there is a relationship between GDP per capita and life expectancy. Maybe god has declared a perfect formula describing this relationship:\n\\text{GDP Per Capita}=200\\cdot \\text{Life Expectancy}+1000+\\text{Noise}\n$$While we humans may never truly know the parameters of the formula, $200$ and $1000$, we can still make a good guess about it. Therefore, assuming this is a linear relationship, we have the Bivariate Ordinary Least Squares Model.\n\nY_{i}=\\beta_{0}+\\beta_{1}X_{i}+\\epsilon_{i}\nwhere $(X_{1},Y_{1}),\\dots,(X_{n},Y_{n})$ are observations (=regressors). \n\nthm. **Parameter OLS Estimator** for $N$ observations $(X_{i},Y_{i})$:\n\\begin{align}\n\\hat{\\beta_{1}}&amp;\\coloneqq \\frac{\\sum_{i=1}^n(X_{i}-\\bar{X})(Y_{i}-\\bar{Y})}{\\sum_{i=1}^nX_{i}-\\bar{X}} \\\n\\hat{\\beta_{0}}&amp;\\coloneqq \\bar{Y} - \\hat{\\beta_{1}}\\bar{X} \\\n\\end{align}\n**Properties.**\n- Predictor: $\\hat{Y_{i}}=\\hat{\\beta_{0}}+\\hat{\\beta_{1}}X_{i}$\n- Residual: $\\hat{\\epsilon}\\coloneqq Y_{i}-\\hat{Y}$ is the estimator for the error term, i.e. how good the predictor is.\n- *Regression Variance*: $\\hat{\\sigma}^2=\\frac{\\sum_{i=1}^N\\hat{\\epsilon_{i}}^2}{N-k}=\\frac{\\sum_{i=1}^N(Y_{i}-\\bar{Y})^2}{N-k}$ where $k$ is the number of parameters ($k=2$ in this case)\n\t- basically the [[Mean Squared Error]]. The lower the better.\n\t- This is also the *standard error of the residuals*.\n\t- In *Stata*, it&#039;s called the `Root MSE`.\n\n**Evaluation of Estimators.**\n- Mean of $\\hat{\\beta_{1}}$: $\\mathbb{E}(\\hat{\\beta_{1}})=\\beta_{1}+\\rho_{X,\\epsilon}\\frac{\\sigma_{\\epsilon}}{\\sigma_{X}}$\n\t- Thus *bias* is $\\rho_{X,\\epsilon}\\frac{\\sigma_{\\epsilon}}{\\sigma_{X}}$\n\t- If $\\rho_{X,\\epsilon}=0$ then exogenous (good!)\n\t- If $\\rho_{X,\\epsilon}&gt;0$ then there&#039;s some 3rd factor positively correlated with $X$, thus bias is positive.\n\t- If $\\rho_{X,\\epsilon}&lt;0$ then v.v.\n\t- &amp; Thus the bias characterizes exogeniety\n- Variance of $\\hat{\\beta_{1}}$: $\\text{Var}(\\hat{\\beta_{1}})=\\frac{\\hat{\\sigma}^2}{N\\cdot \\text{Var}(x_{i})}$\n\t- This is also called *precision*\n\t- $\\sqrt{ \\text{Var}(\\hat{\\beta_{1}}) }$ is also called *standard error* of $\\hat{\\beta_{1}}$.\n\t- ! For random variables, $\\sqrt{ \\text{Var}(X) }$ is called standard deviation. For estimator random variables, it is called standard error. An abuse of terminology.\n## Confidence Intervals and Hypothesis Testing\n\nSee also: [[Confidence Intervals]] and [[Hypothesis Testing]] \n\n**Motivation.** Assume we have our estimators for our sample size $N$ using OLS, $\\hat{\\beta_{0},\\hat{\\beta_{1}}}$. Now, assuming we have the true population data (impossible in real life) and take $100$ samples of size $N$ from the whole population, we get $100$ different tuple of estimators $(\\hat{\\beta_{0}},\\hat{\\beta_{1}})$. If we plot these on a graph, we get an approximate bell curve. This is due to the [[Central Limit Theorem]]. Knowing this fact, we can deduce if there is a correlation between $X$ and $Y$.\n![[Ordinary Least Squares Regression-20240213172422991.png|416]]\n\n**Remark.** $N\\geq 30$ is the minimum required for CLT. $N\\geq 100$ is a conservative requirement for CLT to apply.\n**Remark**. We will only look at $\\hat{\\beta_{1}}$ since it is the more important parameter.\n### Hypothesis Testing\n\ndef. The **Null hypothesis** in regression is $H_{0}:\\beta_{1}=0$, i.e. there is no correlation.\n\ndef. **Regression T-test.** See [[Student&#039;s t-test]]. A T-test is a test for rejecting the null hypothesis. let the T-statistic $T=|\\frac{\\hat{\\beta_{1}}-\\beta_{1}^\\text{Null}}{\\sqrt{ \\text{Var}(\\hat{\\beta_{1}}) }}|$. Then\n\\begin{cases}\nH_{0} &amp; \\text{if } T&gt;K \\\nH_{1}  &amp; \\text{otherwise}\n\\end{cases}\n- The cutoff value $K$ is determined by how powerful (=$\\alpha$) you want the test to be. This is determined by the [[Student&#039;s T-Distribution]].\n\t- This is because $T=_{d}t_{N-1}$\n- This is [[Student&#039;s t-test]] but with only one random variable.\n- Normally, we set the cutoff $K=2$, i.e. two standard deviations away. This is around an $\\alpha=0.05$ test.\n\n### Confidence Interval\n\n\n\nIntuition. \n\n\n\nBias: \n\nstandard error of regression: mean squared of residuals; also the estimator for the error\n\nStandard error of...\n- Residuals â†’ standard error of regression\n- $be$\nVaraince of $\\hat{\\beta_{1}}$ is also the variance of CLT limit with the *same sample size*\n\n\n## Omitted Variables"},"Parallel-Algorithms":{"title":"Parallel Algorithms","links":["Memory-Access-Control"],"tags":["Computing/Algorithms"],"content":"Terminology\n\nTpâ€‹(n): span; time taken for p-processes with input size n\n\nYou may choose p=âˆ i.e. Tâˆâ€‹(n) to analyze if unlimited parallelism was possible.\n\n\nWpâ€‹(n): work; total time by all individual process; Wpâ€‹(n)â‰¤pâ‹…Tpâ€‹(n)\nspeedup: speedup factor compared to a single-process algorithm\nspawn: start a new process\nsync: wait until all processes are finished\n\nParallel algorithmsâ€¦\n\nFor Memory Access Control we will concern ourselves with concurrent read &amp; exclusive write model of computation\nare easy to make from recursive algorithms.\n\nalg. PSum. Normal algorithm is O(n). Following is a parallel algorithm:\nfunction psum(l, r)\n\tif l=r\n\t\treturn A[l]\n\tspawn ls = psum(l, m)\n\tspawn rs = psum(m+1, r)\n\tsync\n\treturn ls + rs\n\nSpan: Tâˆâ€‹(n)â‰¤T(2nâ€‹)+1=O(logn)\nParallel algorithm recursion tree: \n\ndepth is logn, each takes constant time â‡’ Tâˆâ€‹(n)=O(logn)\n\n\nâ€¦if number of processors are limited to p, then: \n\nTpâ€‹(n)=O(pnâ€‹+logp) where pnâ€‹ is the time for subproblems that cannot be parallelized (problem size is pnâ€‹) and logp is the parallel algorithm runtime.\nWpâ€‹(n)=O(p(pnâ€‹+logp))=O(n+plogp)\n\n\nâ€¦if number of processros p=lognnâ€‹, then:\n\nTpâ€‹(n)=O(logn)\nWpâ€‹(n)=O(n)\n\n\n"},"Pareto-Efficiency":{"title":"Pareto Efficiency","links":["Utility"],"tags":["Economics"],"content":"Pareto Efficiency is a state where you cannot make one person better off without making another person worse off.\nWe will define pareto efficiency when there are n divisible items and n agents.\ndef. Pareto Efficiency. Allocation x1â€‹â€‹,â€¦,xnâ€‹â€‹ is pareto efficiet where there exists no alternative allocation y1â€‹â€‹,â€¦,ynâ€‹â€‹ such that both:\nâ€‹âˆƒiâˆ—Â s.t.Â âˆ€i,â€‹yiâˆ—â€‹â€‹âª°iâˆ—â€‹xiâˆ—â€‹â€‹yiâ€‹â€‹âª°iâ€‹xxâ€‹â€‹Â oneÂ agentÂ benefitsothersÂ stillÂ notÂ worseâ€‹â€‹"},"Path-Alignment":{"title":"Path Alignment","links":[],"tags":["Computing/Algorithms"],"content":"Homework"},"Percieved-valueâ€”Real-value":{"title":"Percieved valueâ€”Real value","links":[],"tags":["Philosophy/Marxism"],"content":"Percieved valueâ€”Real Value Â§\n(Use-value vs Exchange-value)\nDiscrepency decreases in the long run.\nPeople will notice that you brought value to their lives, but it may take time."},"Performance-(Computing)":{"title":"Performance (Computing)","links":[],"tags":["Computing/Computer-Architecture"],"content":"Perfomance measurement: Execution Time and Throuput/Bandwidth. (Decreasing execution time always improves thruput) And intuitively performance is inversly related to execution time: Performance=ExecutionÂ Time1â€‹.\nMeasuring Performance Â§\n\nProgram Execution Time (is the sum ofâ€¦)\n\nCPU Time (e.g. 10 picoseconds)\n\nUser CPU Time\nSystem CPU Time\n\n\nI/O Time\n\n\nClock Cycle (= tick, clocks, cycles) e.g. one tick on this CPU is 250 picoseconds.\nInstruction Count: Number of instructions in a program.\n\nâ‡’ Clock Per Instruction (CPI) / IPC (Instructions Per Clock)\nThus\nCPUÂ TimeÂ (s)=#Â ofÂ cyclesÃ—TickÂ TimeÂ (s)#Â ofÂ cycles=#Â ofÂ InstructionsÃ—avg.Â CPI\nAnd:\nCPUÂ TimeÂ (s)=ClockÂ RateÂ (Hz)#Â ofÂ InstructionsÃ—CPIâ€‹\nThe Three Factors of Performance: Clock Rate / Instruction Count / CPI\n$$\n\\text{Performance}= \\frac{\\text{Seconds}}{\\text{Program}}\\\\=\\frac{\\text{Instructions}}{\\text{Program}}\\times \\frac{\\text{Clock Cycles}}{\\text{Instruction}}\\times \\frac{\\text{Seconds}}{\\text{Cycle}}\\\\\\\\\n=\\text{Instruction Count} \\times \\text{CPI} \\times \\text{Clock Rate}\n\n\n$$\n\nList of Common Misconcpetions Performance Â§\n\nImproving one aspect doesnâ€™t improve overall performance porportionally\n\nAmdahlâ€™s Law:\nExecutionÂ timeafterÂ improvmentâ€‹=AmountÂ ofÂ improvmentExecutionÂ timeaffectedÂ byÂ improvementâ€‹â€‹Ã—ExecutionÂ timeafterÂ improvmentâ€‹\nâ†’Some perfomance targets are impossible with partial improvements. See example on p.50."},"Performative-Gender":{"title":"Performative Gender","links":["Judith-Butler","Social-Construct","Microphysics-of-Power"],"tags":["Philosophy/Queer-Theory"],"content":"\nJudith Butlerâ€™s Theory of Gender Performativity, Explained - YouTube\nJudith Butlerâ€™s Gender Performativity, Part 2: What is â€œPerformativity?â€ - YouTube\n\n\n\n                  \n                  Definition of Gender \n                  \n                \nGender is the stylized repetition of acts through time.\n\nKey Points Â§\n\nJudith Butler, Gender Trouble.\nâ€œPerformanceâ€!= â€œPerformativeâ€\n\nâ†’ Performative means that gender is not like a wardrobe of â€œgenderâ€ you can choose from every day.\nâ‡’ Instead, it means gender is constructed into being. It is not something that you can easily choose, due to Microphysics of Power and other things\n\n\nImagine gender as something like â€œI am a Duke student.â€ You are not born a duke student, nor is Duke a real physical fact of reality.\n\nYou partially chose, partially was embraced by Duke, the socially constructed organization.\nThen gender is perfectly severed from biology (=disproves biological essentialism).\n\n\n"},"Permutation-Test":{"title":"Permutation Test","links":[],"tags":["Math/Statistics"],"content":""},"Perpetuity":{"title":"Perpetuity","links":["Sequence-Summation"],"tags":["Economics/Finance"],"content":"Aâˆâ€‹=(1+r/k)Pâ€‹+(1+r/k)2Pâ€‹+â‹¯=r/kPâ€‹\n(Geometric Sequence Summation)"},"Personal-Computing":{"title":"Personal Computing","links":["Tools-and-Structures-Define-Your-Capacity","Living-With-the-Internet","Lifelong-Learning","Decentralization","Multidependence","Everything-is-a-File","Reliable-and-Scalable","(Article)-Evergreen-notes"],"tags":["Computing/Human-Interface","Logistics"],"content":"\nThe Personal Computer is an extension of the brain, a Bicycle of the Mind.\nThe personal computer is not a tool. Instead, it is a person you have a relationship with.\n\nThis is because you do not fully control your computer (!=definition of a tool). You influence your computer, and the computer influences you back.\nThe relationship can be positive or negative.\n\n\nThe personal computer is the interface and vehicle with which you explore the internet universe.\n(DevonThink) How To Become A Hacker This is the gospel for behaving within a culture of hackers. Things that particularly stand out is about asking good questions, discipline and competence, and Lifelong Learning.\n\nPrinciples Â§\n\nLifelong Learning\n\n(DevonThink) How do you remember all the Linux commands? - Quora\n(DevonThink) Why Windows Causes Stupidity - Why It Matters\n\n\nDecentralization\n\nKey components of your computer systems should follow decentralized models\ne.g. ActivityPub &gt; Twitter\ne.g. IPFS &gt; HTTPS\nThis also comes out of the principle of multidependence.\nOpen-source instead of closed-source\n\ne.g. Linux &gt; macOS\n\n\n\n\nOwn Your data\n\nServices that pay for you to access your own data will eventually disappear. Own your data.\nYour disk space should be ~1/3 empty. Keep it at that to allow for flexibility but not wasted space.\nPlaintext is the best format.\n\n\nEverything is a File\n\nDonâ€™t use Windows objects, proprietary databases for notes or databases that you donâ€™t own. Systems that donâ€™t embrace this approach will eventually likely fail.\n\n\nSoftware Maturity\n\nInstall mature software only (Operating Systems, etc.)\nan extension of having Reliable and Scalable things\n\n\nUse Software As Theyâ€™re Intended\n\nespecially: business software shouldnâ€™t be used for personal things.\ne.g. Obsidian &gt; Notion (business pivot)\n\n\nKnow to Surface Data\n\nPhotos go into where you view photos the most (Apple Photos library). Documents go where documents are surfaced the most (DevonThink).\nâ‡’ Data should be surface-able, like (Article) Evergreen notes\n\n\nLiving with Generative AI\n\nA â€œlanguage calculatorâ€\nEverybody gets a 100 interns. (GPT: The Second Renaissance - No Boilerplate)\n\n\n"},"Phenomenology":{"title":"Phenomenology","links":["Celine-Wei","Phenomenology","(Philosopher)-G.-W.-F.-Hegel","(Philosopher)-Edmund-Husserl","(Philosopher)-Martin-Heidegger","Maurice-Merleau-Ponty","Jean-Paul-Satre","Michel-Foucault","Judith-Butler","Jacques-Derrida","Plato","meditation"],"tags":["Philosophy"],"content":"\n\n                  \n                  Celine Wei: It Feels Right.\n                  \n                \n\nNotes from What is Phenomenology? The Philosophy of Husserl and Heidegger - YouTube\nHistory of Phenomenology\n\n18C Kant proposed, and briefly picked up by Hegel\nBut only until (Philosopher) Edmund Husserl did it become mainstream\n\nStudent: (Philosopher) Martin Heidegger\n\n\nGermany â†’ France\n\nMaurice Merleau-Ponty, Jean-Paul Satre\n\n\nModern philosophers: Michel Foucault, Judith Butler, Jacques Derrida\n\nDefining Phenomenology\n\n\nGreek word for â€œAppearsâ€\n\n\nFocus on the first hand experience\n\n\nexperientialist &gt; rationalist\n\n\ne.g. time\n\nrationalist: measurement of numerical time\nexperientialist: subjective personal time\n\ne.g. the â€œpretty girl minuteâ€\n\n\n\n\n\ne.g. fear\n\nrationalist: physiological change, observable behavior of beings in fear\nexperientialist: how fear colors perceptions, the conscious experience of fear\n\n\n\nReversal of Plato\n\nMost of philosophy until Husserl has been about following Plato\nRepresentational Theory\n\nPlatoâ€™s Cave analogy(representational theory)\nHumans have\nItâ€™s a tragedy; our senses only allow incomplete access to reality\nPeaked in Decartesâ€™ mind-body dualism\n\n\n\n\n\nHusserlâ€™s â€Transcendental Phenomenologyâ€\n\nObjective study of the subjective\nTheory of â€œIntentionalityâ€ = â€œabout-nessâ€\n\nCoined by Brentano (teacher)\nconsciousness cannot be isolated; itâ€™s always interacting with its subjects\nstudy of how the object of consciousness interacts with the structure of consciousness\n\n\nwhether the object is a fantasy/reality/dream/memory doesnâ€™t matter\nPhenomenological method\n\nBracketing: setting aside judgements, filters, and gathering the raw experience;\nEidetic reduction (â‰ˆimaginary variation): reduce to essence\n\nMess with the attributes of the phenomenon\ne.g. Fear â‡’ attributes: lack of choice, freeze\n\n\nEnd goal of phenomenology: getting to the universal, objective understanding of the concept\n\n\n\n\n\nHeidegger disagrees: â€Existential Phenomenologyâ€\n\nHusserl: trying to make a science of the consciousness\nHeideggerâ€™s ontological twist:\n\nthe goal is instead understanding the nature of being\nexperience and consciousness cannot be separated\nentanglement varies between people\ne.g. fear of you, an animal, or an Aztec warrior is different\n\n\n\n\n\nEastern connection (China, India)\n\ne.g. Meridian system by China, Chakra by India\nLooks stupid from rationalist perspective\nâ‡’ but itâ€™s the mapping of the first-person experience of the body\ne.g. meditation: observe the experience\n\na form of bracketing (stopping judgement, and just experiencing thoughts and emotions)\nZen buddism\nDaoism may have influenced Husserl directly too\n\n\n\n\n"},"Philips-Curve":{"title":"Philips Curve","links":[],"tags":["Economics/Macro-Economics"],"content":""},"Philosophy,-Political-Science,-Economics":{"title":"Philosophy, Political Science, Economics","links":["Economics/MicroEconomics/Game-Theory"],"tags":["Economics/Game-Theory","Philosophy/Political-Philosophy"],"content":"Why? Â§\nLack of Scientific Rigour in Economics Â§\nEconomics doesnâ€™t have predicting power (the test of correctness for scientific theories)â€¦\n\ncouldnâ€™t predict recessions\ndoesnâ€™t pursue distributive justice\nbetter for designing economics/social institutions, maintaining social order, or incentivizing individuals in society\n\nThis is because in economics the strategy of people are not considered:\n\n\n                  \n                  parametric agents.\n                  \n                \nâ†’ In reality, individuals act based on how they think others may act; i.e. they are strategic agents.\n\nâ†’ Conventional economic theory is useless as a predictorâ€”itâ€™ll only satisfy oneâ€™s curiosity\nâ†’ The correct/better theory for modeling economics is Game Theoryâ€”the theory of strategic interactions\n"},"Physical-Data-Organization":{"title":"Physical Data Organization","links":[],"tags":["Computing/Data-Science"],"content":"\nStorage ranges from Fast &amp; Small â†’ Slow &amp; Big \n(DevonThink) Numbers Every Programmer Should Know By Year\n\nIdea: a trip to the next hierarchy is orders of magnitude slower.\n\n\n\nAnatomy of a Hard Drive Â§\n\nParts of a mechanical hard drive: \n\nAccessÂ Time=Seek+Rotation+Transfer\nAll data is transfered in blocks! (512B~4KB)\nRecords (=Tuples) can be fixed length of dynamic length\n\nBLOB fields: e.g. images. These link out to external locations\n\n\n\nStoring Many Tuples in One Block Â§\n\nOften many tuples will fit in one block. There are multiple schemes to lay them out.\n\nN-ary Storage Model (NSM) Â§\n\nData stored from the beginning of the block\nIndex stored at the end of the block\nEvery update/delete operation will reorganize everything! â†’ Use gaps inbetween records (=sparse block)\nHard to cache, because queries will often only access a few columns\n\n\nPartition Attributes Across (PAX) Â§\n\nCluster columns together\nVariable length columns will have index at the end\nKeep the fields together (=dense block)\n\n\nColumn Stores Â§\n\nStore the whole table by columns\ne.g. Apache Parquet\n"},"Pipelining":{"title":"Pipelining","links":[],"tags":["Computing/Computer-Architecture"],"content":"\nIn computing, a pipeline, also known as a data pipeline, is a set of data processing elements connected in series, where the output of one element is the input of the next one. The elements of a pipeline are often executed in parallel or in time-sliced fashion. Some amount of buffer storage is often inserted between elements.\nComputer-related pipelines include:\nInstruction pipelines, such as the classic RISC pipeline, which are used in central processing units (CPUs) and other microprocessors to allow overlapping execution of multiple instructions with the same circuitry. The circuitry is usually divided up into stages and each stage processes a specific part of one instruction at a time, passing the partial results to the next stage. Examples of stages are instruction decode, arithmetic/logic and register fetch. They are related to the technologies of superscalar execution, operand forwarding, speculative execution and out-of-order execution.\nGraphics pipelines, found in most graphics processing units (GPUs), which consist of multiple arithmetic units, or complete CPUs, that implement the various stages of common rendering operations (perspective projection, window clipping, color and light calculation, rendering, etc.).\nSoftware pipelines, which consist of a sequence of computing processes (commands, program runs, tasks, threads, procedures, etc.), conceptually executed in parallel, with the output stream of one process being automatically fed as the input stream of the next one. The Unix system call pipe is a classic example of this concept.\nHTTP Pipelining, the technique of issuing multiple HTTP requests through the same TCP connection, without waiting for the previous one to finish before issuing a new one.Some operating systems may provide UNIX-like syntax to string several program runs in a pipeline, but implement the latter as simple serial execution, rather than true pipeliningâ€”namely, by waiting for each program to finish before starting the next one.\nWikipedia\n"},"Poisson-Distribution":{"title":"Poisson Distribution","links":["Poisson-Limit-Theorem"],"tags":["Math/Common-Distributions"],"content":"See also: Poisson Limit Theorem\ndef. Poisson Distribution. A random variable X which model the number of events in a fixed interval of time, where each event is rare and there is a large number of events, is well modeled by a Poisson Distribution with the intensity of the event Î»:\nXâˆ¼Poisson(Î»)P(X=k)=eâˆ’Î»k!Î»kâ€‹\n\nE(X)=Î»\nSD(X)=Î»â€‹\nP(X&lt;n)=âˆ‘k=0nâˆ’1â€‹eâˆ’Î»k!Î»kâ€‹\n\nEstimators Â§\nlet X1â€‹,â€¦,Xnâ€‹âˆ¼Poi(Î»)\nlnLnâ€‹=âˆi=1â€‹xiâ€‹!Î»âˆ‘i=1nâ€‹xiâ€‹enÎ»â€‹\nsnâ€‹=Î»âˆ‘i=0nâ€‹xiâ€‹â€‹âˆ’n\nÎ»^MLEâ€‹=nâˆ‘i=1nâ€‹xiâ€‹â€‹=XË‰nâ€‹\n\n\n\n\n\n\n\n\n\n\n\n\n\nsinglemultipleI=Î»1â€‹Inâ€‹=Î»nâ€‹"},"Poisson-Limit-Theorem":{"title":"Poisson Limit Theorem","links":["poisson-distribution"],"tags":["Math/Probability"],"content":"Poisson Limit Theorem (Simplified) Â§\nthm. Poisson Limit Theorem. With a random variable Xâˆ¼Binom(n,p), as nâ†’âˆ,pâ†’0, Xâ‰ˆPoi(np), since:\nX=I1â€‹+â‹¯Inâ€‹ where each is an indicator of success of the i-th event, and as limnâ†’âˆ,pâ†’0â€‹ this defines the poisson distribution.\nPoisson Scatter Theorem Â§\ndef. An experiment process which adheres to the following creteria is a Poisson Scatter process.\n\nNumber of hits are finite\nNo multiple hits on one point\nHits are homogenous and independent (any non-overlapping regionâ€™s hit number is independent.)\n\nTHM Poisson Scatter Theorem. In a poisson scatter process:\n\nNumber of hits over area R is a Poisson Random variable\nThe number of hits in each disjoint region is independent of each other (definiiton #3)\nThe rate of hits (Î») is proportional to its area\n\nPoisson Addition Rule Â§\nthm. If Xâˆ¼Poi(Î»Xâ€‹) and Yâˆ¼Poi(Î»Yâ€‹) and XâŠ¥Y then:\nX+Yâˆ¼Poi(Î»Xâ€‹+Î»Yâ€‹)\n\n\n                  \n                  Info \n                  \n                \nNote also that the bionmial distribution as something like this too. If Xâˆ¼Bi(nXâ€‹,p) and Y\\sim \\text{Bi}(n_Y,p)\n$$Y\\sim \\text{Bi}(\\lambda_Y) and XâŠ¥Y then $X+Y\\sim \\text{Bi}(n_X+n_Y,p)\n\n\n## Poisson Point Process\n\ndef. Memory-less-ness (continuous). $X$ is memoryless iff:\n\\forall s,t&gt;0,\\ \\ \\mathbb{P}(X&gt;s+t|X\\geq s)=\\mathbb{P}(X&gt;t)\n\n&gt; [!info] Read it like this:\n&gt; \nLHS: â€œprobability of waiting $t$ **more** minues, given that youâ€™ve **already** waited $s$ minutes.â€\nRHS: â€œprobability of just waiting $t$ minutes in total.â€\n\nGeometric and **_Exponential_** distributions satisfy this property. See the following.\n\ndef. **Poisson Point Process (PPP)**. PPP can be described in the following _three equivalent definitions_ in region $R$ with intensity $\\lambda$ _(per unit)_:\n\n1. Given a region $R_i$, let random variable $N(R_i)$ be defined as the number of events in the region. If..:\n\t- $\\forall i\\in R, \\ \\ N(I_i)\\sim \\text{Poi}(\\lambda\\cdot {|R_i|})$, where $|R_i|$ is the â€œsizeâ€ of the region and $\\lambda$ the intensity\n\t- $N(R_i)$ are all independent of each other\n\t- â‡’ â€¦then the event occurs in a PPP\n2. A process where the waiting time $W_i$ between two sequential events is distributed as an exponential distribution $\\forall i\\in R,\\ \\ W_i\\sim \\text{Exp}(\\lambda)$\n3. Total region size $X$ for $r$ events is distributed over gamma $X\\sim\\Gamma(r,1/\\lambda)$"},"Portfolio-Theory":{"title":"Portfolio Theory","links":["Efficient-Market-Hypothesis","Dividend-Discount-Model","Random-Variable","Risk-(Finance)"],"tags":["Economics/Finance"],"content":"Assume the Efficient Market Hypothesis.\n\n\n                  \n                  Info \n                  \n                \nHow to maximize returns while minimizing risk [=volatility =std. dev.]?\nâ†’ Since risk/return is proportional to each other, you choose one optimization goal.\n\n\nSingle Stock (See Dividend Discount Model)\nPrice of stock i at time t: Siâ€‹(t)\nReturn of stock i at time t: Riâ€‹(t)=Siâ€‹(t0â€‹)Siâ€‹(t)âˆ’Siâ€‹(t0â€‹)â€‹+Siâ€‹(t0â€‹)Diâ€‹â€‹\n\nSiâ€‹,Diâ€‹,Riâ€‹ are all Random Variables\n\n\nExpected Return of stock i: Î¼iâ€‹=E[Riâ€‹]\nVolatility (=Risk) of Stock i: Ïƒiâ€‹=Var[Riâ€‹]â€‹\n\nTwo-stock Portfolios Â§\n\nCovariance of stocks i,j: Ïƒi,jâ€‹=Cov[Riâ€‹,Rjâ€‹]\nCorrelation of stock i,j: Ïi,jâ€‹=Ïƒiâ€‹,â‹…Ïƒjâ€‹Ïƒi,jâ€‹â€‹ such that âˆ’1â‰¤Ïâ‰¤1\nWeights w,1âˆ’w for (R1â€‹,Î¼1â€‹,Ïƒ1â€‹),(R2â€‹,Î¼2â€‹,Ïƒ2â€‹)\nPortfolio Expected Return: Î¼pâ€‹=wÎ¼1â€‹+(1âˆ’w)Î¼2â€‹\nPortfolio Variance:\n\nÏƒp2â€‹â€‹=w2Ïƒ12â€‹+(1âˆ’w)2Ïƒ22â€‹+2w(1âˆ’w)Ïâ‹…Ïƒ1â€‹Ïƒ2â€‹=(Ïƒ12â€‹âˆ’2ÏÏƒ1â€‹Ïƒ2â€‹+Ïƒ22â€‹)w2+2(ÏÏƒ1â€‹Ïƒ2â€‹âˆ’Ïƒ22â€‹)w+Ïƒ22â€‹â€‹functionÂ ofÂ wâ€‹â€‹\n\nMinimum Variance Portfolio:\n\nW1âˆ’Wâ€‹=Ïƒ12â€‹âˆ’2ÏÏƒ1â€‹Ïƒ2â€‹+Ïƒ22â€‹Ïƒ22â€‹âˆ’ÏÏƒ1â€‹Ïƒ2â€‹â€‹=Ïƒ12â€‹âˆ’2ÏÏƒ1â€‹Ïƒ2â€‹+Ïƒ22â€‹Ïƒ12â€‹âˆ’ÏÏƒ1â€‹Ïƒ2â€‹â€‹â€‹â€‹\nN-Stock Portfolio Â§\nR=â€‹R1â€‹â‹®RNâ€‹â€‹â€‹Â Â Î¼â€‹=â€‹Î¼1â€‹â‹®Î¼Nâ€‹â€‹â€‹Â Â w=â€‹w1â€‹â‹®wNâ€‹â€‹â€‹Â Â V=â€‹Ïƒ1â€‹â‹®ÏƒN,1â€‹â€‹â€¦â‹±â€¦â€‹Ïƒ1,Nâ€‹â‹®ÏƒN,Nâ€‹â€‹â€‹\n\nKnown information: Ïƒiâ€‹,Ïƒijâ€‹,Ïijâ€‹,Î¼iâ€‹ are all known\nMultiple Stocks (=Portfolio)\n\nPosition of portfolio p at time t (=amount invested): Vpâ€‹(t)=âˆ‘i=1Nâ€‹niâ€‹Siâ€‹(t)\nPortfolio Return at time t Rpâ€‹(t)=wTâ‹…R\nPortfolio Expected Return at time t: Î¼pâ€‹(t)=wâ‹…Î¼â€‹\nPortfolio Variance: Ïƒp2â€‹=âˆ‘i=1Nâ€‹wi2â€‹Ïƒi2â€‹+2âˆ‘1â‰¤i&lt;jâ‰¤Nâ€‹wiâ€‹wjâ€‹Â ÏÂ Ïƒiâ€‹Ïƒjâ€‹=wTVw\n\n\n\ndef. Feasible Portfolios. Set of tuples (Ïƒ=risk,Î¼=expectedÂ return) given we have many assets weighted w.\n\nFpâ€‹={(Ïƒpâ€‹,Î¼pâ€‹)âˆ£wâˆˆR} â† Short-selling is allowed\nLower the correlation [= the more negatively correlated] âˆ the better diversification is.\n\nWhen two stocks have perfectly negative correlation Ï=âˆ’1, the efficient frontier touches the y-axis (=Ïƒpâ€‹=0)\n\n\n\nEfficient Frontier Â§\nminwâ€‹Â Ïƒpâ€‹=wTVwâ€‹Â suchÂ thatÂ wT1=1,Â wTÎ¼â€‹=Î¼pâ€‹\n\nâ€œMinimize the variance Ïƒ such that the sum of weights are 1 and the portfolio return is Î¼ (a constant)â€\nKey Assumption: neither the returns Î¼iâ€‹ or risks Ïƒiâ€‹ are identical, and there is no perfect correlation Ïi,jâ€‹=Â±1\nMinimum for given return level Î¼pâ€‹ at:\n\nw=ACâˆ’B2Câˆ’BÎ¼pâ€‹â€‹Vâˆ’1e+ACâˆ’B2Î¼pâ€‹Aâˆ’Bâ€‹Vâˆ’1Î¼â€‹\n\nEfficient Frontier:\n\n{(Ïƒpâ€‹,Î¼pâ€‹)âˆ£Ïƒp2â€‹=ACâˆ’B2AÎ¼p2â€‹âˆ’2BÎ¼_p+Câ€‹}\n\nâ€¦where A,B,C are scalars:\n\nA=eVâˆ’1e\nB=Î¼â€‹TVâˆ’1e=eTVâˆ’1Î¼â€‹\nC=Î¼â€‹TVâˆ’1Î¼â€‹\n\n\n\n\n"},"Positive-Leisure":{"title":"Positive Leisure","links":["(Youtube)-Spaceship-You","CGP-Grey","Positive-Leisure","ç†(ã“ã¨ã‚ã‚Š)","tags/Logistics/Productivity","Slack","ê°ì„±","ì„±ë¯¼ì„","Gratitude","Well-Timed-Breaks","Importance-of-Inputs","Emergent-Phenomena","Hedonism","(Book)-How-to-Be-Miserable---Randy-J-Paterson","Creation-Station"],"tags":["Emotion","Logistics/Productivity","Economics","Logistics"],"content":"Leisure in economics is simply â€œnot working.â€ Instead, I define positive leisure as:\ndef. Positive Leisure. Positive leisure means two things:\n\nCreating at Leisure. Youâ€™re doing â€œworkâ€ that benefits you/others. CGP Grey definition\nLeisurely Pace. Making sure life is not rushed, and there is space.\nUneconomic Leisure. Leisure that is not about consumption (i.e. buying things/spending money).\n\n\n\n                  \n                  Leisure is about making sure you&#039;re life is full of &quot;doing things at your leisure,&quot; or going through life at a &quot;leisurely pace.&quot; \n                  \n                \n\nPositive leisure understandsâ€¦\n\nâ€¦that resting in the modern world means mental, not physical relaxation\nâ€¦that leisure is derived from structure\nâ€¦that not doing anything may also be draining\n\nPositive leisure implements the following:\n\nDo things at your leisure (=do things as slowly as you want.)\n\nMost things can stand being done later\nSometimes you have to not give a shit\nYouâ€™re not rushing because you need to, youâ€™re rushing because society pressures you to.\nForcibly Slow Down, Set a Very Long Time Slot, etc. Using deliberate slowing down as a strategy for managing stress or overwhelming situations.\n\n\nProductivity#Logistics/Productivity is not against leisure. In fact, productivity is about doing things well and at your leisure.\n\nMove between tasks at a leisurely pace\nWhen you do this, you have more Slack.\nProcrastination happens when you fail to combine productivity and leisure well.\n\n\nê°ì„± cannot exist without emotional peace.\n\nEven in turmoil you can have emotional peace, and time to reflect on those feelings.\nì„±ë¯¼ì„ says ê°ì„± is what makes life worth living. And it is for you too.\n\n\nPositive leisure often leads to Gratitude\n\nItâ€™s easier to enjoy the things (=physical things &amp; immaterial things) you already have.\n\n\n\nCreating Positive Leisure Â§\n\nBreathe\nMoving slowly through life\nIf you have too much things to do, eitherâ€¦\n\nâ€¦remove the offender\nâ€¦increase productivity (get the simple things done fast)\n\n\n\nStructured Relaxation (=Leisurely Relaxation) Â§\nFind Leisure that either:\n\nRelaxes you fully\n\nSleep, Music, Movie\nRelaxing on a couch doing nothing\n\n\nYou feel good having done it\n\nReading a book or magazine article\nNew content, e.g. on Netflix, subscribed Youtubers, Mastodon, etc.\n\nâ†’ These should be your own curation, from people/sources youâ€™ve chosen\n\n\n\n\n\nFun and Pleasure is derived from Structure\n\nPleasure and pain is derived not from absolutes [=it isnâ€™t a sliding scale from pleasure to pain] but is an Emergent Phenomena from structures in life.\n\nHedonistic Adaptation and the reverse for pain evidences this.\n\n\nStructure is essential, and doesnâ€™t harm pleasure. It more often actually enhances it.\n\nspice and honey is enhanced at duke, as Celine does.\n(Book) How to Be Miserable - Randy J Paterson: taking part in â€œhedonismâ€ is ineffective because impulses!= whatâ€™s good for you. â€œThose who eschew impulses are better hedonists than you are.â€\n\n\nThis is fotunate, because this means that Creation Station is not mutually exclusive from pleasure. To achieve both, aim to maintain separation between locations.\n\nFlow Work Â§\n\nHappiness Through Achieving the State of â€˜Flowâ€™: Seeking happiness in the immersion and engagement of tasks.\n"},"Post-Treatment-Variable":{"title":"Post-Treatment Variable","links":[],"tags":["Math/Statistics"],"content":"Post-treatment variables are variables that confound the â€œcontrolling for endogenous factors by including them in the regressionâ€ technique. They can cause problems is two ways:\nMediator Â§\nMotivation. Suppose regressing Earnings vs Tutoring:\nEarningsiâ€‹=Î²0â€‹+Î²1â€‹isTutored+Ïµiâ€‹\nBut secretly, there was a correlation where:\n\nTherefore, E[Î²0â€‹^â€‹]=Î³1â€‹+Î±Î³2â€‹\nNow, simply controlling for reading scores like this:\nEarningsiâ€‹=Î²0â€‹+Î²1â€‹isTutored+Î²2â€‹readingScores+Ïµiâ€‹\nIs not effective, because thereâ€™s a multicollinearity between isTutored and readingScores. In this case, E[Î²1â€‹^â€‹]=Î³1â€‹, and this doesnâ€™t capture the Î±Î³2â€‹ portion.\nConfounder Â§\nCollider Bias Â§\nCollider bias\n\nA stupid model:\nYiâ€‹=Î²0â€‹+Î²1â€‹X1iâ€‹+Î²2â€‹X2iâ€‹\nwill have biases:\n\nE[Î²1â€‹^â€‹]=Î³1â€‹+Î±Ï1â€‹Ï2â€‹â€‹\nE[Î²2â€‹^â€‹]=Î³2â€‹+Ï1â€‹Ï2â€‹â€‹\n\nExample. Suppose we are regressing: Flu vs. Car accident. We also try to control for being being infected while being hospitalized:\nFluiâ€‹=Î²0â€‹+Î²1â€‹hadAccident+Î²2â€‹isHospitalized+Ïµiâ€‹\nSuppose, however, reality went like this:\n\nCar accidents lead to hospitalization, but donâ€™t cause the flu\nFevers lead to both hospitalization and cause flu testing\nThen:\n\n\nE[Î²1â€‹^â€‹]=Î³1â€‹âˆ’Î±Ï1â€‹Ï2â€‹â€‹ i.e. accident and flu is\nE[Î²2â€‹^â€‹]=Î³2â€‹+Ï1â€‹Ï2â€‹â€‹\n"},"Postmodernism":{"title":"Postmodernism","links":[],"tags":["Philosophy"],"content":""},"Postructuralism":{"title":"Postructuralism","links":["Decentralization","Michel-Foucault","Jacques-Derrida","Jean-Baudrillard","Noam-Chomsky"],"tags":["Philosophy/Epistemology"],"content":"\nPoststructuralism is Decentralization (of power, ofâ€¦)\nâ€œMicrophysics of power is too strong. We shouldnâ€™t trust social institutions as they are agents of power. Everything is relative and a social construction.â€\nMoral relativism\n\nRelated People\n\nMichel Foucault, Jacques Derrida, Jean Baudrillard\nNoam Chomsky hates it. See Debate Noam Chomsky &amp; Michel Foucault - On human nature [Subtitled] - YouTube\n"},"Potential-Game":{"title":"Potential Game","links":["Traffic-Routing"],"tags":["Economics/Game-Theory"],"content":"def. Potential Game. A game is a potential game iff there exists a potential function that satisfies the following, for any player i that changes their strategy from siâ€‹â†’siâ€²â€‹:\nChangeÂ inÂ PotentialÏ•(siâ€²â€‹,sâˆ’iâ€‹)âˆ’Ï•(siâ€‹,sâˆ’iâ€‹)â€‹â€‹=ChangeÂ inÂ Costciâ€‹(siâ€²â€‹,sâˆ’iâ€‹â€‹)âˆ’ciâ€‹(siâ€‹,sâˆ’iâ€‹â€‹)â€‹â€‹\ndef. This function Î¦(siâ€‹,sâˆ’iâ€‹) is a potential function. \n\nsâˆ’iâ€‹ denotes the strategies of the remaining players.\n\nthm. Potential Games always has a PNE. Namely, for convex potential functions that have a global minima, that minima is the equilibrium.\n\nThis NE is also achievable; let the system run, and it will reach NE (best-response dynamics)\nEvery local minimum of the potential function is a NE\nIntuition. Consider:\n\n\nWhen a player improves their strategy to reduce their own costs, the potential decreases\nThis repeats until nobody can switch their strategy\n\nAn example of potential game analaysis for computing NE is Traffic Routing"},"Power-Consumption-(Computing)":{"title":"Power Consumption (Computing)","links":["Performance-(Computing)"],"tags":["Computing/Computer-Architecture"],"content":"1.7. The Power Wall Â§\nUntil recently power usage and clock rate have increased together. Recently limits were reached with cooling capacity, and thus processors cannot be designed consume more power. Power consumption is summarized as:\nPowerâˆ21â€‹Ã—CapacitiveÂ LoadÃ—Voltage2Ã—Frequency\n\nCapacitive load depends on each transistor\nNote the voltage is squared\nFrequncy is the CPU clock rate\n\nMisconceptions Â§\n\nComputers at low utilization donâ€™t always use little power\n\nPower doesnâ€™t really scale linearly with performance; even computers at idle use lots of power. e.g. Googleâ€™s servers use 33% of peak power at 10% utilization.\n\nPerformance helps energy efficiency\n\nDesigning for performance means the task takes less time, and thus total energy consumption decreases.\n\nUse all three performance metrics: frequency, CPI, Instruction count\n\ne.g. MIPS (million instructions per second) is a very bad metric for measuring performance. Itâ€™s defined as MIPS=ExecutionÂ timeÃ—106InstructionÂ countâ€‹. and is also equal to CPIÃ—106ClockÂ rateâ€‹. So MIPS will always not take into consideration at least one of the three performance metric, and thus can be very decieving."},"Present-Value-Calculations":{"title":"Present Value Calculations","links":["Security-(Finance)","Value-of-Money","Future-Value-Calculations","interest-rate","inflation"],"tags":["Economics/Finance"],"content":"In pricing the value of a security, we consider that humans discount future returns.\n\nReason we need to discount value: Value of Money\nThis is the reverse of Future Value Calculations.\n\ndef. Discounted Cash Flows (DCF) are used to price assets.\n\nEach cash flow is discounted by the discount rate. They are summed to get the present value of all the cash flows\nWe always want asset priceâ†‘, riskâ†“\nrate of return âˆ volatility â† knowing how to trade off these two is important\n\nTo calculate the DCF of some future cash flow FVâ€™s current present value PV:\nPVâ€‹=(1+krâ€‹)tÃ—kFVâ€‹=(1+q)nFVâ€‹â€‹\n\nr is the Annual Percentage Rate [= quoted rate]\nk is how many times to compound every year\n\nâ†’ thus r/k is the interest rate per compound period (=q)\n\n\nt is the number of years\n\nâ†’ thus tÃ—m is the number of **total compounding periods (=n)\n\n\n\nYou can calculate the present value of multiple identical cash flows of amount C:\nPVâ€‹=(1+r)1Câ€‹+(1+r)2Câ€‹+â‹¯+(1+r)nCâ€‹=rCâ€‹(1âˆ’(1+r)âˆ’n)â€‹\nWhat is the value of interest rate r?\n\nIn individual investments/loans, r determined usually by looking at similar assets in the market\nrâˆ inflation; if inflation is high, money isnâ€™t worth much in the future, so lender demands more interest rate\n\nNet Present Value Â§\nNPV(r)=PV(r)âˆ’InitialÂ Investment"},"Price-Controls":{"title":"Price Controls","links":[],"tags":["Economics/Micro-Economics"],"content":"Four types of price controls exist:\n\nPrice Floors\nPrice Ceilings\nTaxes\nSubsidies\n\n"},"Price-Elasticity-of-Demand":{"title":"Price Elasticity of Demand","links":[],"tags":["Economics/Micro-Economics"],"content":"ÏµDâ€‹â€‹:=%Î”p%Î”xâ€‹=pÎ”pâ€‹xÎ”xâ€‹â€‹=xpâ€‹Î”pÎ”xâ€‹â†’xpâ€‹dpdxâ€‹=dlnpdlnxâ€‹â€‹â€‹\n\nElasticity can be:\n\nâˆ£ÏµDâ€‹âˆ£&gt;1â€¦Elastic\nâˆ£ÏµDâ€‹âˆ£=1â€¦Unit Elastic\nâˆ£ÏµDâ€‹âˆ£&lt;1â€¦Inelastic\nReminder that elasticity is almost always negative (for a downward-sloping demand curve (=ordinary good))\n\n\nElasticity of demand can vary along a single demand curve\n\nThere is an â€œelastic portionâ€ and â€œinelastic portionâ€\nElasticity determines if a firm should produce more or less to increase revenue. \n\n\n"},"Price-Mechanism":{"title":"Price Mechanism","links":[],"tags":["Economics","Economics/Game-Theory"],"content":""},"Price-to-Earnings-Ratio":{"title":"Price to Earnings Ratio","links":["EBITDA-Multiple"],"tags":["Economics/Finance"],"content":"def. Price to Earnings Ratio (P/E Ration).\nP/E=EarningsÂ perÂ ShareShareÂ Priceâ€‹=NetÂ IncomeMCAPâ€‹\nâ‡’ Think: for two firmsâ€¦\n\nâ€¦if the market values the shares higher,\nâ€¦even though the earnings are low,\nâ€¦the market thinks the firm has growth potential.\n\nHow Good is the P/E Ratio? Â§\n\nThe P/E ratio contains finance information so itâ€™s a noisier measure compared to the EBITDA Multiple.\nItâ€™s a better measure for the pure returns you get on the share.\nâ†’ EBITDA is a bigger, general rule of thumb, while P/E could be better for a small invester.\n\n\n\n                  \n                  fundamental analysis.\n                  \n                \n\n\n\n                  \n                  \\frac{\\text{Company Size}}{\\text{Profitability}}, thus measuring the growth of the company.\n                  \n                \n"},"Priority-Queue":{"title":"Priority Queue","links":[],"tags":["Computing/Data-Structures"],"content":"Time Complexity Â§\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOperationfind-maxdelete-maxinsertincrease-keyMergeBinary-HeapÎ˜(1)Î˜(logn)O(logn)O(logn)Î˜(n)Fibbonacci HeapÎ˜(1)O(logn)Î˜(1)Î˜(1)Î˜(1)\nTournament Tree Â§\n\n\nGetting the largest item is O(n) which is same as the naive approach butâ€¦\nGetting the next-largest element after having built the tree is O(logn) time\n\nGetting the next-k largest elements is O(klogn) time\n\n\n"},"Prisoner's-Dillemma":{"title":"Prisoner's Dillemma","links":["Game-Theory","Econ-361-Distributive-Justice","Elinor-Ostrom","John-Rawls","Robert-Axelrod","Robert-Frank"],"tags":["Economics/Game-Theory"],"content":"Prisonerâ€™s Dillemma is a symmetric game where the dominant strategy for both players is to defect, but collaboration would have yielded greater results. It is one of the most important problems that Game Theory aims to solve, and have applications in many fields. It is also known as the collective action problem or the free-rider problem. It is the cause of the Tragedy of the Commons.\n\nEcon 361 Distributive Justice is a course that dealt with this in-depth, thru the lens of PPE.\nElinor Ostrom\nJohn Rawls\nRobert Axelrod\nRobert Frank\n"},"Private-Equity-Firms":{"title":"Private Equity Firms","links":["Initial-Public-Offering"],"tags":["Economics/Finance"],"content":"Funds that have a lot of money, and use that to buy out a public company to take it private â†’ improve its operations â†’ IPO again to sell it at a higher price (often a big failure)"},"Private-Property":{"title":"Private Property","links":["Proletatriat-(Marxism)"],"tags":["Philosophy/Marxism"],"content":"\nthe theory of the Communists may be summed up in the single sentence: Abolition of private property\n\n\nBut does wage-labour create any property for the labourer? Not a bit. It creates capital, i.e., that kind of property which exploits wage-labour, and which cannot increase except upon condition of begetting a new supply of wage-labour for fresh exploitation\n\n\nWhen, therefore, capital is converted into common property, into the property of all members of society, personal property is not thereby transformed into social property. It is only the social character of the property that is changed. It loses its class character.\n\n\nFinally, communism2 is the positive expression of the abolition of private property and at first appears as universal private property.\n"},"Probability":{"title":"Probability","links":["Cardinality"],"tags":["Math/Probability"],"content":"def. An Outcome Space (Î©) is the set of all possible outcomes of an experiment\ndef. An Event (A) is a subset of an outcome space. (die face is even)\nExample. For a 6-sided die:\nÎ©AAâ€‹={1,2,3,4,5,6}={2,4,6}Â âŠ‚Î©â€‹â€‹\ndef. Probability for countable sets. When all outcomes in Î© are equally likely, and Î© is a finite set,\nP(A)=#Î©#Aâ€‹\nwhere #A denotes the number of elements in set A (its cardinality).\nProperties.\n\nP(AC)=1âˆ’P(A)\nIfÂ AâŠ†BÂ thenÂ P(A)â‰¤P(B)\nIfÂ AâŠ†BÂ thenÂ P(Bâˆ©AC)=P(B)âˆ’P(A)\nP(AâˆªB)=P(A)+P(B)âˆ’P(Aâˆ©B)\nTrivial cases:\nP(âˆ…)=0\nP(Î©)=1\nAâŠ†B is equivalent to Aâ†’B (i.e. if A then B)\n\nMeasure Theory Definition Â§\n\n\n                  \n                  Probability is just an abuse of notation \n                  \n                \n\nMotivation. We need a sigma algebra to define a probability, because thereâ€™s problematic set theory problems with uncountably infinite sets.\ndef. Sigma Algebra. A sigma-algebra on a set Î© denoted Ïƒ(Î©) contains certain subsets of A, such that it follows the following properties\n\n{âˆ…,Î©}âŠ†Ïƒ(Î©)âŠ†2Î© (biggest and smallest possible sigma-algebras)\nlet A be a subset of Î©. If AâˆˆÏƒ(Î©) then ACâˆˆÎ©. (closed under complement)\nlet A,B a subset of Î©. If A,BâˆˆÏƒ(Î©) then AâˆªBâˆˆÏƒ(Î©) (closed under finite union)\n\ndef. Measure. let X,Ïƒ(X). A measure Î¼ is a function from measure space to to real numbers:\nÎ¼:Ïƒ(X)â†’R\nthat satisfies the following properties:\n\nNon-negative: âˆ€AâˆˆÏƒ(X), Î¼(A)&gt;0\nCountable Additivity: Î¼(AâˆªB)=Î¼(A)+Î¼(B)\nÎ¼(âˆ…)=0\n\nIntuition. Consider a measure as a means to measure the â€œsizeâ€ of the set (not Cardinality). On a real number line, the set (2,5)â‰¡{xâˆˆRâˆ£2&lt;x&lt;5} has length 3. The set (5,9) has length 4. Thus (2,5)âˆª(5,9)=(2,9) has length 3+4=7.\ndef. A Measure space is simply a set X and its sigma-algebra Î£ together in a tuple:\n(X,Î£)\nProbability Space Â§\ndef. A Probability measure on X,Ïƒ(X) is a special type of measure P:Ïƒ(X)â†’R that satisfies P(Î©)=1\ndef. A Probability Space is like a measurable space, but also together with the probability function:\n(Î©,F,P)\nInterpretations of Probability (Philosophically) Â§\nMotivation. What is probability? Interpretations of its definitions seem meaningless without real-life experiments.\nTwo main interpretations of probability are:\n\nThe Objectivist Interpretationâ€”relative frequency of occurrence, if the experiment is conducted indefinitely\nThe Subjectivist Interpretationâ€”degree of belief; how much you would bet on an event.\n"},"Production-Function":{"title":"Production Function","links":["Homogenous-Function"],"tags":["Economics/Micro-Economics","Economics/Macro-Economics"],"content":"xxâ€‹=f(l)=f(l,k)â€‹ShortÂ RunLongÂ Runâ€‹â€‹\nTerminology Â§\ndef. Marginal Product. The additional output in units of good x giving additional input (labor or capital)\nMPlâ€‹=dldfâ€‹,MPkâ€‹=dkdfâ€‹\ndef. Marginal Revenue Product. The additional output in units of dollars ($) given one unit of additional input (labor or capital)\ndef. Law of Diminishing Marginal Product. As the input increases over a certain point, the marginal product of the input decreases. This happens for both labour and capital in production functions.\n\nMathematically, There exists some lâˆ— such that:\n\nâˆ‚lâˆ‚MPlâ€‹â€‹â€‹lâˆ—â€‹&lt;0\nReturns to Scale Â§\nProduction functions are one of three types:\n\nDecreasing Returns to scale: tf(l,k)&lt;f(tl,tk)\nConstant Returns to scale: tf(l,k)=f(tl,tk)\nIncreasing Returns to scale: tf(l,k)&gt;f(tl,tk)\n\nMicro Production Function Â§\nShort Run Â§\ndef. SR Production function. f(l,k) where l denotes labor input, and k denotes capital input. Range is the units of output good.\n\nShort Run (SR) is defined as the timeframe where l can be varied, but k is fixed.\nAlso known as production frontiers or producer choice sets.\nWhile production frontiers can take on any shape, the most common shape is that of (b) (due to Law of diminishing marginal product).\n\n\ndef. SR Marginal Product of Labor (MPlâ€‹) The marginal change in output with a unit more of labor.\n\nIn the short-run production function, that is the gradient of the function, i.e. MPlâ€‹=dldfâ€‹.\n\n\nLong Run Â§\n\nMacro Production Function Â§\nHomogenous Function"},"Productive-Forces,-Relations-of-Production,-and-Historial-Materialism":{"title":"Productive Forces, Relations of Production, and Historial Materialism","links":["Proletatriat-(Marxism)"],"tags":["Philosophy/Marxism"],"content":"Productive Forces, RoP, Historical Progression Â§\n\n[Capitalism] has pitilessly torn asunder the motley feudal ties that bound man to his â€œnatural superiorsâ€, and has left remaining no other nexus between man and man than naked selfinterest, than callous â€œcash paymentâ€. [â€¦] It has resolved personal worth into exchange value, and in place of the numberless indefeasible chartered freedoms, has set up that single, unconscionable freedomâ€”Free Trade.\n\n\nIt has converted the physician, the lawyer, the priest, the poet, the man of science, into its paid wage labourers.\n\n\nProductive forces are the steady march of technology which drive economic growth through â€œgood ideasâ€ and efficiency.\nRelations of production are the social institutions that facilitate (or hinder) productionâ€”the context within which production occurs\nâ†’ Think: patent systems (transforming ideas into property), protection of proptery, chattle slavery\n\n\nDirection of History Â§\n\nOur epoch, the epoch of the bourgeoisie, possesses, however, this distinct feature: it has simplified class antagonisms. Society as a whole is more and more splitting up into two great hostile camps, into two great classes directly facing each otherâ€”Bourgeoisie and Proletatriat (Marxism).\n\nFeudalistic society i.e. guilds + birth-determined rank â†’ Capitalist Society i.e. private property, wage-labor\nâ†’ Productive forces has outgrown capitalismâ€”â€specture haunting Europeâ€\nâ‡’ Constant change in ideas, innovation, striving for growth, and societal thought, idealology changed to serve its mode of production\n\nAll fixed, fast-frozen relations, with their train of ancient and venerable prejudices and opinions, are swept away, all newformed ones become antiquated before they can ossify. All that is solid melts into air, all that is holy is profaned, and man is at last compelled to face with sober senses his real conditions of life, and his relations with his kind.\n\nâ‡’ BZ RoP destroys national boundaries, cosmopolitan nature of production as it brings together global supply of goods into global consumer demand (ultimately, the â€œepidemic of overproductionâ€)\n\nThe bourgeoisie has through its exploitation of the world market given a cosmopolitan character to production and consumption in every country.\n\n\nIt compels all nations, on pain of extinction, to adopt the bourgeois mode of production; it compels them to introduce what it calls civilisation into their midst, i.e., to become bourgeois themselves. In one word, it creates a world after its own image.\n\nâ‡’ Ultimately consuming the whole world economy into its RoP\n\nCommunism is the necessary form and the dynamic principle of the immediate future, but communism is not as such the goal of human developÂ­ ment - the form of human society.9\n\nand communism is thus inevitable:\n\nenough. In order to supersede private property as it actually exists, real communist activity is necessary. History will give rise to such activity, and the movement which we already know in thought to be a self-superseding moveÂ­ ment will in reality undergo a very difficult and protracted process.\n\nbecause the brotherhood of man is real\n\nThe brotherhood of man is not a hollow phrase, it is a reality, and the nobility of man shines forth upon us from their work-worn figures.\n\n\n\n[â€¦] in one word, the feudal relations of property became no longer compatible with the already developed productive forces; they became so many fetters. They had to be burst asunder; they were burst asunder.\n\n\na society that has conjured up such gigantic means of production and of exchange, is like the sorcerer who is no longer able to control the powers of the nether world whom he has called up by his spells.\n\nâ‡’ When PF outgrows RoP, naturally PF wins; i.e. communism is inevitable. Feudalism to Capitalism, Capitalism to Communism\nCurrently we observe this as the epidemic of overproduction:\n\n[â€¦] the epidemic of over-production. Society suddenly finds itself put back into a state of momentary barbarism [â€¦] And how does the bourgeoisie get over these crises? On the one hand by enforced destruction of a mass of productive forces; on the other, by the conquest of new markets, and by the more thorough exploitation of the old ones.\n"},"Profit-Function":{"title":"Profit Function","links":["Input-Demand-and-Output-Supply","Hotelling's-Lemma"],"tags":["Economics/Micro-Economics"],"content":"def. Profit Function. Given input and output prices, returns the maximum achievable profit.\nÏ€(w,r,p)\n(HowTo) Derive Profit Function Â§\n\nGet Input Demand and Output Supply.\nSubstitute into the profit equation\n\nÏ€=pâ‹…x(w,r,p)âˆ’wâ‹…l(w,r,p)âˆ’râ‹…k(w,r,p)\n\n\n\nProperties Â§\n\nHD1 in w,r,p\nIncreasing in p\nDecreasing in w,r\nHotellingâ€™s Lemma applies\n"},"Profit-Maximization":{"title":"Profit Maximization","links":["Cost-Minimization"],"tags":["Economics/Micro-Economics"],"content":"See also Cost Minimization\nShort Run (One-input) Â§\n\\text{max} ~ \\pi=px-wl-r \\bar{k} ~ \\text{such that} ~ x=f(l,\\bar{k})\n$$ ...where $\\bar{k}$ is fixed at the long run optimal point.\nMaximization of profit (reaching maximum iso-profit line) against the [[Production Function]]\n- Uses [[Constrained Optimization]]\n- Optimal is where the production function is tangent to the isoprofit line: $-\\frac{w}{r}=TRS$\n\t- reminder: [[Technical Rate of Substitution|TRS]] is the tangency of the isoprofit line.\n\t- the slope of the isocost line is $-\\frac{w}{r}$\n- Result is the [[Input Demand]]s and Output [[Supply Function]]\n- As in [[Utility Maximization]], you can substitute these results into profit formula $\\pi-px-wl$ to get the [[Profit Function]].\n\nAlternative Characterization\nmax_{x,l}~p\\cdot f(l,\\bar{k})-wl-r\\bar{k}\n- Where $c(w,x)$ is the reformulation of the production function into a function of input $l$, multiplied by $w$ (= $\\text{input quantity}\\times \\text{input price}$ given a certain level of output $x$)\n- Solvable simply by finding where tangent is zero.\n- You will get short run [[Input Demand]]s \n\n## Long Run (Multiple Input)\n\nmax_{x,l,k}~ \\pi=px-wl-rk ~ \\text{such that} ~ x=f(l,k)\n- First Order Condition (FOC) is equivalent to $pMP_{L}=w,pMP_{k}=r$\n\t- i.e. produce when the additional revenue is equal to price of inputs\n\t- i.e. $MR_{L}=MC_{L},MR_{k}=MC_{k}$\n- Gets you [[Input Demand]] functions\n- ! Beware returns to scale: If Increasing Returns/Constant Returns to scale, then only one of the inputs are used. (See below for more details)\n\n## Profit Maximization Problem\n\nThere are two main ways for profit maximization:\n\n- One-step: \n\t- $\\text{max}\\ \\pi=px-wl-rk \\ \\text{ s.t. } x=f(l,k)$ to get profit-maximization condition $p\\cdot \\text{MP}_l=w, \\ \\ p\\cdot MP=r$\n\t- This gets you the input demand functions $l(p,w,r), k(p,w,r)$ and output supply $x(p,w,r)$.\n- Two-step:\n\t  1. $\\text{min} \\ c=wl+rk \\ \\text{ s.t. } \\ x=f(l,k)$ to get cost-minimization condition $-\\frac{w}{r}=\\frac{\\text{MP}_l}{\\text{MP}_k}(=\\text{TRS})$\n\t\t This gets you conditional input demand functions $l(x,w,r), k(x,w,r)$\n\t  1. Solve $p=\\text{MC}^{\\text{LR}}$ by using above conditional input demand functions (recall $\\text{MC}=\\frac{\\delta C}{\\delta x}$)\n     This gets you output supply $x(p,w,r)$\n\n\n### Special Case: Labor and Capital Are Perfect Compliments\nf(x)=min(l^\\alpha,k^\\alpha)\n- When $0&lt;\\alpha&lt;1$ it has decreasing returns to scale\n\t- â†’ simply solve two [[Unconstrained Maximization]] problems:\n\t- $max_{l}\\pi =pl^a-wl-rk$, \n\t- $max_{k}\\pi =pk^a-wl-rk$,\n\t- $l^\\alpha = k^\\alpha$ &lt;- **dont forget!**\n\n### Special Case: Labor and Capital Are Perfect Substitutes\n$$f(l,k)=(l^\\alpha+k^\\alpha)^\\beta\n\nwhen 0&lt;Î±â‹…Î²&lt;1: decreasing returns to scale\nwhen Î±â‰¥1: Isoquant is bowed in the wrong direction\n\nâ†’ Use only one of the inputs (corner solution)\n\n\nwhen 0&lt;Î±&lt;1 but Î²â‰¥Î±: Isoquant may or may not be bowed in the wrong direction.\n\nâ†’ May or may not use only one input (corner solution)\n\n\n\nExample plot to demonstrate this\nManipulate[\n Plot3D[(l^alpha + k^alpha)^beta, {l, 0, 5}, {k, 0, 5}, \n  AxesLabel -&gt; {&quot;l&quot;, &quot;k&quot;, &quot;x&quot;}, PlotRange -&gt; All], {alpha, 0.1, \n  5}, {beta, 0.1, 5}]"},"Proletatriat-(Marxism)":{"title":"Proletatriat (Marxism)","links":[],"tags":["Philosophy/Marxism"],"content":"Defining the Proletatriat Â§\nMarx â€œcalling into beingâ€ the class of the proles. The process of their organization organically produces the communist party as a political power.\n\nThe proletariat goes through various stages of development. With its birth begins its struggle with the bourgeoisie\n\n\nDisorganized proles\nOrganized by BZ [=companies, etc.]\n\n\nAt this stage, the labourers still form an incoherent mass scattered over the whole country, and broken up by their mutual competition\n\n\nOrganized Unions\nSeparate, permanent unions to fight for wage\n\n\nNow and then the workers are victorious, but only for a time. The real fruit of their battles lies, not in the immediate result, but in the ever expanding union of the workers.\n\n\nNationally organized communist community\n\n\nIt was just this contact that was needed to centralise the numerous local struggles, all of the same character, into one national struggle between classes.\n\n\nUltimately the formation of the communist party\n\n\nThis organisation of the proletarians into a class, and, consequently into a political party\n\nIt is unfortunately for the bz that the prolesâ€”the class whose founding was caused by capitalâ€”will eventually be the ones to destroy them:\n\nBut not only has the bourgeoisie forged the weapons that bring death to itself; it has also called into existence the men who are to wield those weaponsâ€”the modern working classâ€”the proletarians.\n\n\nWhat the bourgeoisie therefore produces, above all, are its own grave-diggers. Its fall and the victory of the proletariat are equally inevitable.\n"},"Proof-Techniques":{"title":"Proof Techniques","links":["Mathematical-Induction"],"tags":["Math"],"content":"\nMathematical Induction\nBy Contradiction\nBy Contrapositive\n\nAlgebraic\n\nYou can split summations (even infinite ones)\nâˆiâ€‹eXiâ€‹=eâˆ‘iâ€‹Xiâ€‹\nEquivalently, ln(âˆiâ€‹Xiâ€‹)=âˆ‘iâ€‹(lnXiâ€‹) Pushing log thru product makes it a sum\nTelescoping sums and products\nBreak up summations âˆ‘âˆ€iâ€‹=âˆ‘iâ‰¤kâ€‹+âˆ‘i&gt;kâ€‹\nSummation of Squared âˆ‘âˆ€iâ€‹â€‹(aiâ€‹+biâ€‹)2=âˆ‘a2+âˆ‘b2+âˆ‘i&lt;jâ€‹2aiâ€‹biâ€‹iî€ =jâˆ‘â€‹aiâ€‹biâ€‹â€‹â€‹\n\nProbability\n\nTower property E(X)=E(E(Xâˆ£F))\nLinearity of expectation. You can switch expectation and summation\nDefinition of expectation is an integral (or summation)\n\nCalculus\n\nâˆ«xâ€‹âˆ«yâ€‹dydx=âˆ«yâ€‹âˆ«xâ€‹dxdy switch integrals\n\nInequalities\n\nSum greater than max\nMax greater than averages\nAverage greater than min.\nCombined:\n\n\nln(1âˆ’x)â‰¤âˆ’x always."},"Property-Exchange":{"title":"Property Exchange","links":["Directed-Graph"],"tags":["Economics/Game-Theory"],"content":"Motivation. Imagine a situation where n people each have their own house. They would like to exchange houses to be better off. How do we go about doing that?\nIn this setting we say:\n\nPreferences are strict (no agent is indifferent about two different items)\n\ndef. Stable allocation (=â€œin the coreâ€). An allocation a is stable there is no blocking coalition.\nA blocking coalition for allocation a is a subset of agents who, when trading amongest themselves, achieves a higher utility for at least one agent, and doesnâ€™t reduce the utility of anybody else in the subset. \ndef. Top Trading Cycles (TTC) algorithm.\n\nAlgorithm is in multiple rounds\nRound k:\n\nAgents point to favorite remaining house\nThis graph will always have a cycle, because all edges have out-degree 1 (thm)\nTake an arbitrary cycle, and swap houses according to that cycle\nEliminate these people from the graph\n\n\nRepeat\n\nthm. (TTC is strategy-proof w.r.t. individual agents). let allocation A be an allocation generated by TTC. Fixing all other agentâ€™s preferences, no one agent can benefit by lying about their preference ordering.\nProof sketch by induction\n\nRound 1: Agents point to favorite house.\n\nLet those who win in round 1 be W1â€‹; they donâ€™t lie, because they will win their favorite house if theyâ€™re truthful.\nThose who lose, will proceed to the next roundâ€¦\n\n\nRound 2: Agents not in W1â€‹ (=losers) have not gotten their favorite house; letâ€™s say a loser â„“âˆˆW2â€‹ (a round 2 winner) got their k-th favorite house as a result of the second round.\n\nSay â„“ prefers a house from someone in W1â€‹. â„“ will lie and point to that house to attempt to be included in the cycle.\nHowever, nobody in W1â€‹ pointed to our loser. Therefore the loser will not be able to form a cycle, as long as everybody else is truthful.\n\n\nInduction until final round (assume round 1..k is truthful, then round k+1 is truthful. â– \n\nthm. (TTC is stable). Allocation A generated by TTC has no blocking coalition.\nProof by contradiction. Suppose there was a blocking coalition they are the black dots. We list them by the rounds in which they won in TTC: W1â€‹,W2â€‹,â€¦\n\n\nIf there is a blocking coalition of agents separated in two disparate rounds of TTC i,j such that Wiâ€‹,Wjâ€‹,i&lt;j, then the coalitionâ€™s alternative trading cycle must have an agent who, in the informal trade, pointed from round i to round j. This doesnâ€™t make sense, because they chose their favorite in round i already and won. Thus such a coalition cannot exist.\n\nIt is trivial to see also that a coalition spread across three or more rounds of TTC is impossible.\n\n\nIf there is a blocking coalition of agents who are all in Wkâ€‹, the TTC algorithm already trades amongst them. Thus such a coalition cannot exist.\nâ– \nthm. (TTC is the only stable algorithm) let A be allocation by the TTC algorithm. There exists no other allocation Aâ€² that is stable. (=TTC is the only allocation in the core.)\nProof by Induction and Contradiction. Suppose TTC produced allocation A. Presume there was an alternative allocation Aâ€² that was also stable. Let the agents whose allocation differs between A and Aâ€² be S, the â€œswitchersâ€. \nRound 1: Let the switchers in W1â€‹ be S1â€‹âŠ†W1â€‹. Every switcher sâˆˆS1â€‹ would gotten switched to an alternative house in a latter round. But since in the TTC s pointed to another agent in W1â€‹, this is a contradiction. Therefore, no switcher exists in S1â€‹.\nRound 2: Let the switchers in W2â€‹ be S2â€‹. Switcher sâˆˆS2â€‹ cannot have switched with anybody in W1â€‹ because there are no switchers in W1â€‹. (equivalent)\nInduction until final round (assume there are no switchers until round i, then any switcher in round i+1 must have switched with latter round, but impossible.) â– \n\nKidney Exchange Â§\nMotivation. Letâ€™s think of an alternative situation. A patient needs a kidney, and the patientâ€™s family or friend wants to donate the kidney to them. However the donorâ€™s may not be compatible with the patient. Therefore we need to find other compatible donor(-patient pair) to do a cross-kidney swap.\n\nWhen there are lots of patient-donor pairs, we need to find a trading cycle with compatible donors. We model the situation such that each patient-donor entity has a compatibility list for all other patient-donor pairs. Think of each patient-donor as one entity. \nHowever, Unlike the swapping housing example above we cannot trade along long cycles because we need to operate on all patients simultaneously which is not feasible. Therefore, we only consider a matching; i.e. a pairs of patient-donors do a cross-kidney swap. This is equvalent an (unpartitioned) maximum graph matching problem. Construct an undirected graph:\n\nAll entities point to any subset of compatible entities (obviously not themselves)\nIf both entities point to each other, then create an undirected edge. Remove all other directed edges.\ndef Priority Matching. On an undirected graph G:\nRandomly fix an ordering of agents.\nlet M0â€‹:= set of all possible maximum matchings on G.\n\nObviously, these maximum matchings are of the same degree (=have same number of edge matchings in them)\n\n\nFor i=1â€¦n for every entity:\n\nZiâ€‹ â† subset of Miâˆ’1â€‹ that includes agent i in the matching\nIf Ziâ€‹=âˆ… then Miâ€‹â† Miâˆ’1â€‹ (if i cannot be included ever, then ignore i)\nIf Ziâ€‹î€ =âˆ… then Miâ€‹ â† Ziâ€‹ (make sure i is included in all subsequent matchings)\n\n\nThis will result in Mnâ€‹. Every matching mâˆˆMnâ€‹ is a matching.\n\nthm. (PM matchings always match same agents.) All matchings Mnâ€‹ returned by PM matches the same agents.\nProof Sketch. Inside the loop:\n\nIf Ziâ€‹=âˆ… then agent i is not included in any m.\nIf Ziâ€‹î€ =âˆ… then agent i is definitely included in all m.\n\nthm. (PM is DSIC) In PM, all agents will always report all of their compatible partners.\nProof Sketch. Reporting a lesser number of edges will only reduce the edges they are connected to, and thus only makes it less possible to be included in a matching."},"Prospectus":{"title":"Prospectus","links":[],"tags":["Courses"],"content":"Topic: Queer culture and sexual space in Tokyo, and their interaction with formal and informal mainstream cultural institutions, through the lens of linguistic anthropology.\n\nQueer culture is not yet accepted as mainstream in Japan, which still has heteronormative and bourgiosie family strucure as the default\nBut queer acceptance is making headway through general regard for empathy which I will examine as â€œAmaeâ€\n\nIdea that Japanese society operates on a culture of â€œopennessâ€ and â€œreliance,â€ a stronger motivation than capitalism for Japan yet\nRecently enshirned queer legislation (legal change in gender, same-sex marriage) includes these types of language that emphasize â€œharmonyâ€ and â€œacceptanceâ€ and â€œfeelings of safetyâ€â€”both a win in that mainstream Japan is willing to accomodate queer people, but also at the cost of normalizing and harmoginizing a diverse set of identities\n\n\nQueer people and organizations have mixed feelings about this. On one hand this is celebrated, but on the other hand it also opens up different avenues of exclusion, based on â€œmaking people uncomfortable.â€\n\nQueer organizations in Tokyo have existed for long. In most cases it is transgender women or effeminate gay men\n\nEstablished neighborhoods like Shinjuku-nicho-me\n\n\nQueer people have always sought a space, but in a different way than the western narrative of â€œmoving to the city where one can be freeâ€â€”the city to most Japanese queer people is still repressive and harmoginizing\n\nThere is simultanous desire to be free from this harmoginizing force and also to be accepted into the mainstream\n\n\nQueer celebrities have been on mainstream television (Matsuko Deluxe) but have been if not controversial, made fun of\n\nThe responses of these queer people to such legislation cause\n\n\n\n\n\nSources\n\nä¸‰æ©‹é †å­ Mitsuhashi Junkoâ€”æ–°å®¿ ã€Œæ€§ãªã‚‹è¡—ã€ã®æ­´å²åœ°ç† â€œShinjukuâ€™s History and Geography of A Sexual Neighborhoodâ€\nåœŸå±…å¥éƒ Doi Takeoâ€”Amae no Kouzou \nYue, Leungâ€”Notes towards the queer Asian city\nGraham Kolbeinsâ€”Queer Japan\n"},"Pushdown-Automata":{"title":"Pushdown Automata","links":[],"tags":["Computing/Formal-Languages"],"content":"def. Pushdown Autotmaton (PDA)\nM=(Q,Î£,Î“,Î´,q0â€‹,z,F)\nWhere:\n\nÎ“: stack alphabet\nz: stack bottom market\nÎ´ is a transition function where for q,qâ€²âˆˆQ,ÏƒâˆˆÎ£,Î³âˆˆÎ“\n\n(q,Ïƒ,Î³)â†¦{(qâ€²,Î³âˆ—),...}\nâ€¦where the destination set is a finite set.\nâ€¦and strings can be accepted by either final state xor an empty stack (equivalent)\n\n\n                  \n                  Weâ€™re going to deal mostly with nondeterministic pushdown automata (NPDA), as they are more useful. \n                  \n                \n\nDescribed mechanically:\n\nInput tape is read only once, left to right\nA read head has finite number of states\nA read head has a stack from which the top letter can be read off\n\n\ndef. the current Configuration of a PDA is described as a tuple\n(q,aw,bx)âŠ¢(qâ€²,w,x)\nwhere âŠ¢ represents a single step of a PDA.\n\n\n                  \n                  final state or an empty stack; these two definitions are equivalent.\n                  \n                \n"},"Python-Common-Operations":{"title":"Python Common Operations","links":[],"tags":["Computing","Computing/Algorithms"],"content":"\nInitialize integer as positive or negative infinity: {python} i: int = float(&#039;-inf&#039;|&#039;inf&#039;)\n\nCollections Â§\nSets Â§\n\nSet difference{python} set(list1) - set(list2)\n\nO(n)\n\n\nSet lookup {python}i in {1, 2, 3}\n\n==Constant time O(1) lookup==\n\n\n\nList Â§\n\nList Sort {python} list2 = sorted(list1)\n\nO(nlogn)\n\n\nDeduplication{python} list1 = list(set(list1))\n\nO(n)\n\n\nCounter {python}Counter(&quot;mississippi&quot;)\n\nreturns {python}{&#039;i&#039;: 4, &#039;s&#039;: 4, &#039;p&#039;: 2, &#039;m&#039;: 1}\nO(n)\n\n\nAccumulate{python} accumulate(list1)\n\nO(n)\n\n\n\nDictionary Â§\n\nDefault value for dictionary entries{python}dictionary = collections.defaultdict(list|int)\nHelps when you have a list of dicts, or accumulating a count in a dict.\n"},"Quantitative-Problem-Solving-Tips":{"title":"Quantitative Problem Solving Tips","links":[],"tags":["Math","Computing","Meta-Learning"],"content":"\nFind the invariant.\n\nWhat does not change? e.g. radius in a circle\n\n\nFind identities.\n\nCan we keep the problem, but invert our perspective?\n\n\n"},"Random-Variable":{"title":"Random Variable","links":[],"tags":["Math/Probability"],"content":"def. Random Variable A Random Variable X from probability space (Î©,F,P) to measurable space (R,B) is a function:\nX:Î©â†’R\n\nB is the Borel sigma-algebra on real numbers (=Borel set)\n\nThis is a set of open intervals on R that satisfies Ïƒ-algebra properties\n\n\nfor all BâˆˆB, it is true that Xâˆ’1(B)={Ï‰âˆˆÎ©âˆ£X(w)âˆˆB}âˆˆF\n\nYouâ€™re given an open interval (=set) B on real numbers\nGet all Ï‰ such that X(Ï‰) is within this range (=pre-image)\nThis set (a subset of Î©) must be in the sigma-algebra of Î©\nThis applies to any range B=(a,b)\n&amp; We can then say â€X is F-measurableâ€ or â€F has enough information to measure Xâ€œ.\nIntuition. Let there be other sigma-algebras G,H such that GâŠ‚FâŠ‚H, in addition to X being F-measurable. In this caseâ€¦\n\nX is H-measurable because H has more information than F.\nHowever, X is not G-measurable because G has less information than F.\n\n\n\n\n\ndef. Probability on a Random Variable. Probability function on random variable X is a function PXâ€‹:Râ†’[0,1] such that:\nPXâ€‹(B):=P(Xâˆ’1(B))=P({Ï‰âˆˆÎ©âˆ£X(Ï‰)âˆˆA})\n\n&amp; i.e., the probability we encounter daily P(Xâ€¦) is simply a shorthand notation PXâ€‹=Pâˆ˜Xâˆ’1\nYou put the interval B, and get the probability of all Ï‰ in that intervalâ€™s pre-image\nthus by abuse of notation we write: PXâ€‹(B)â‰¡P(XâˆˆB)â‰¡P(Xâˆ’1(B))\n\nExample. Let Î© is the trajectory of a coin toss. This is a very big set, and probably also infinite. On the other hand, let X a random variable for\nX={10â€‹ifÂ headsifÂ tailsâ€‹\n\n\n\nThis is much simpler and more useful.\n\n\nThis means Xâˆ’1(1)={AllÂ trajectoriesÂ thatÂ landÂ inÂ heads}.\nIf Xâˆ’1âˆˆF, then we can try to measure the probability of P(Xâˆ’1(1))=P({AllÂ trajectoriesÂ thatÂ landÂ inÂ heads})\nBecause we know the pre-image of 1 is in F, we know that P(Xâˆ’1(1)) is defined.\n\nthm. Addition Rule for Random Variables. For a discrete random variable X:\nP(aâ‰¤Xâ‰¤b)=k=aâˆ‘bâ€‹P(X=k)\nFunctions of Random Variables Â§\nMotivation. Functions can be made of random variables; for example let Y=âˆ£Xâˆ’1âˆ£. In order to investigate Y, need a way to derive the probability distribution of Y from X.\nExample. Let Y be a random variable defined by a function of another random variable X; Y=f(X). Then:\nP(Y=y)=P(f(X)=y)=allÂ xÂ s.t.Â f(x)=yâˆ‘â€‹P(X=x)\nthm. Random variables X,Y are equal when:\n\nRange(X)=Range(Y)\nâˆ€kâˆˆRangeâ€‹P(X=k)=P(Y=k)\n\nIndicator Functions Â§\ndef. Indicator Functions. For event AâŠ‚Î©, the indicator function IAâ€‹ is a random variable (i.e. function) such that:\nIAâ€‹:Î©â†’{0,1}s.t.IAâ€‹(Ï‰)={01â€‹Ï‰âˆˆ/AÏ‰âˆˆAâ€‹\nRemark.\n\nIndicator functions are useful in probability for solving problems, not for being a fundamental mathematical object.\nRemember that indicator functions are also random variables. All the rules for random variables apply, including the identities for expected values.\n\nProperties. let I an indicator function describing an event with probability p, then:\n\nE(I)=p\nVar(I)=p(1âˆ’p)\n"},"Rationality-(Economics)":{"title":"Rationality (Economics)","links":["Utility-Function","Monotonic-Transformation","HD","Marginal-Rate-of-Substitution-(MRS)"],"tags":["Economics"],"content":"Microeconomics Assumptions Â§\ndef. Rational Preference. Consider two basket of goods A,B. A rational preference is one that is all of the following:\n\nComplete: either Aâ‰»B,Bâ‰»A,orÂ Aâˆ¼B\n\nComparable: You have to choose either of the above three\n\n\nTransitive: ifÂ Aâ‰»BÂ andÂ Bâ‰»C,Â thenÂ Aâ‰»C\nMonotonic: x1â€‹âª°x2â€‹\n\nThe following are optional conditions\n\n\nConvexity: Averages are bette than extremes. (Preference of variety)\n\n\nThe rational preference assumption and the convexity assumption will together be enough to define an Utility Function.\n\n\nTwo tastes are same if they have the same utility function, or the utility functions are Monotonic Transformations of one another.\n\n\nNotation Â§\n\nAâˆ¼B: A is equally preferable with B\nAâ‰»B: A is strictly preferred to B\nAâ‰¿B: A is equally or more preferable to B\nAâˆ¼B: A is equally preferred to B (indifferent)\n\ndef. Homothetic Tastes. Two equivalent definitions\n\nTastes are homothetic if the utility function (or its Monotonic Transformation) is HD of degree k&gt;0\nTastes are homothetic if the MRS depends only on x1â€‹x2â€‹â€‹\n\nâ€‹u(x1â€‹,x2â€‹)Â isÂ homogenousÂ ofÂ degreeÂ kâŸ¹u(tx1â€‹,tx2â€‹)=tku(x1â€‹,x2â€‹)â€‹â€‹\n\nQuasilinear Taste Â§"},"Readers-Writer-Locking":{"title":"Readers-Writer Locking","links":[],"tags":["Computing/Algorithms"],"content":"Solution to concurrency control problem.\n\nThere are two locks: read lock and write lock\nOnly those with a read lock can read, and write lock can write\nThere must always be either\n\nMany reader locks, no writer lock\nOne writer lock, no reader lock\n\n\n"},"Recurrence-Relation":{"title":"Recurrence Relation","links":["most"],"tags":["Computing/Algorithms"],"content":"Table of Common Recurrence Relations Â§\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRecurrenceAlgorithmSolutionT(n)=T(2nâ€‹)+O(1)binary searchO(logn)T(n)=T(nâˆ’1)+O(1)sequential searchO(n)T(n)=2T(2nâ€‹)+O(1)tree traversalO(n)T(n)=T(2nâ€‹)+O(n)quick selectO(n)T(n)=2T(2nâ€‹)+O(n)mergesort, quicksortO(nlogn)T(n)=T(nâˆ’1)+O(n)Insertion or selection sortO(n2)\nQuick Bits Â§\n\nT(n)â‰¤T(aâ‹…n)+T(bâ‹…n)+cn where a+b&lt;1 is almost always O(n).\n\nMaster Theorem Â§\nSee Master theorem (analysis of algorithms) - Wikiwand\nâ‡’ Can be used to solve most recurrence relations.\nFirst, Identify the recurrence relation in the following form\nT(n)=aâ‹…T(bnâ€‹)+O(nclogkn)\nConsider three casesp\n\nCase 1: logbâ€‹a&lt;c\n\nâ‡’ T(n)=Î˜(nc)\n\n\nCase 2: logbâ€‹a=c\n\nâ‡’ T(n)=Î˜(nclogk+1n)\n\n\nCase 3: logbâ€‹a&gt;c\n\nâ‡’ T(n)=Î˜(nclogkn)\n\n\n\nRecurrence Tree Â§"},"Recursively-Enumerable-Languages":{"title":"Recursively Enumerable Languages","links":[],"tags":["Computing/Formal-Languages"],"content":"Section: Turing Machines\ndef. Language L is recursively enumerable iff there exists a TM M such that L=L(M).\nâ†’ The class of languages that TMs can represent is a recursively enumerable language. You can think of languages which are â€œcountable.â€\ndef. Language L is recursive iff there exists a TM M which, for every string w in L, it halts.\nâ†’ Recursive Languages are languages in which a TM always halts.\n\nDistinction between RE and R languages.\n\n\nlemma. If S is a countable set, then 2S [= the set of all subsets of S] may not be countable.\nthm. There exists languages over alphabet Î£ that are not recursively enumerable. (proof using lemma.)\nthm. If L is recursively enumerable, LË‰ may not be RE.\nthm. If L and LË‰ are both RE, then L and LË‰ is Recursive.\nthm. If L is recursive, LË‰ is recursive."},"Reduced-Price-of-Capital-Goods":{"title":"Reduced Price of Capital Goods","links":[],"tags":["Economics/Game-Theory"],"content":"The most significant thing about technological improvement is equality.\nNobody cares if you are or arenâ€™t from a noble family; if you have money itâ€™s fine.\n\nThinkâ€”pride and prejudice society was rejecting those who have gained prestige with just money.\nThink also: discussion with mom, when she says â€œtechnological improvement is irrelevant; where there are people, there is love and relationship.â€ Only those who are lucky enough to be born in the modern age has that prestige of emotion, etc. Also think: the hindsight paradox.\n\n(DevonThink) My Ordinary Life: Improvements Since the 1990s Â· Gwern.net (reader mode)"},"Reductionism":{"title":"Reductionism","links":[],"tags":["Philosophy/Analytic"],"content":""},"Refactoring-Reduces-Cognitive-Load":{"title":"Refactoring Reduces Cognitive Load","links":["Working-Memory"],"tags":["Computing"],"content":"Refactoring is useful in coding because it reduces the cognitive load to Working Memory."},"Refinancing":{"title":"Refinancing","links":["Federal-Funds-Rate"],"tags":["Economics/Finance"],"content":"e.g. refinancing a mortgage\nâ†’ When the Federal Funds Rate decreases and therefore the general interest rate decreases, your mortgage payments can be payed off by another new loan you take."},"Regression-Discontinuity":{"title":"Regression Discontinuity","links":["Dummy-Variables","Controlled-Experiments"],"tags":["Math/Statistics"],"content":"Regression Discontinuity analysis is useful when\n\nThe assignment variable (â‰ˆindependent variable) is continuous (not binary)\n\nâ€œTreatmentâ€ thus simply means after-cutoff\nWe canâ€™t just use Difference of Means because the assignment variable continuously changes in each groups too and thus affects the dependent variable too.\n\n\nNo other factors change when crossing the cutoff\nThen we can use the basic (constant-slopes) RD model:\n\nYiâ€‹=Î²0â€‹+Î²1â€‹Â treatmentÂ var.Â Tiâ€‹â€‹â€‹+Î²2â€‹Â assignmentÂ var.Â (X1iâ€‹âˆ’C)â€‹â€‹+Ïµiâ€‹\nwhere:\n\n\nC is the cutoff point\n\n\nT is 1 for post-cutoff, 0 for pre-cutoff. Simulates â€œtreatmentâ€\n\n\nX1â€‹ is the assignment variable (non-adjusted).\nwhere coefficients mean:\n\n\nÎ²1â€‹^â€‹ is the causality of treatment\n\n\nÎ²2â€‹^â€‹ is the causality of the assignment var\n\n\n\nError term shouldnâ€™t be jumping at the cutoff, i.e. we should have ÏX1â€‹,Ïµâ€‹=0\n\nIf ÏX1â€‹,Ïµâ€‹î€ =0 then Ïµ=ÏX1iâ€‹+Î½iâ€‹ thus the basic RD model from above becomes:\n\n\n\nYiâ€‹=Î²0â€‹+Î²1â€‹Tiâ€‹+Î²2â€‹(X1iâ€‹âˆ’C)+ÏX1iâ€‹+Î½iâ€‹\n- â†’ Thus even if $\\rho_{X_{1},\\epsilon}\\neq 0$, $\\hat{\\beta_{1}}$ is unbiased (i.e. still correctly indicates the causality between treatment and $Y$)!\n- But $\\hat{\\beta_{2}}$ no longer indicates causality between $X_{1}$ and $Y_{i}$, instead just indicates. overall correlation.\n\nAdvanced RD Â§\nWe donâ€™t need to limit ourselves to have the slopes be same before and after discontinuity by using the varying slopes model:\nYiâ€‹=Â interceptÂ beforeÂ Î²0â€‹â€‹â€‹+Î²1â€‹Tiâ€‹â€‹Â interceptÂ afterÂ â€‹+Â slopeÂ beforeÂ Î²2â€‹â€‹â€‹(X1iâ€‹âˆ’C)+Â slopeÂ afterÂ Î²3â€‹â€‹â€‹(X1iâ€‹âˆ’C)Ã—Tiâ€‹+Ïµiâ€‹\nSmaller windows â†’ probably linear\nIssues with RD Analysis Â§\n\nSmaller window (=bandwidth): We must look at variables close to the cutoff (because the farther away you go, the more endogenity there might be) But this isnâ€™t always possible because of limited sample size.\nProbably only estimates the Local Average Treatment Effect (LATE), meaning that you canâ€™t generalize the results. (â€œAre effects of drinking (vial legal age) on grades affect babies? old econometrics professors?â€œ)\nMultiple variables usually determine treatment or not. (medicare and age is clear-cut; SAT and college admission isnâ€™t) â†’ use Fuzzy RD model\n\nOr, we can use the Balace Test to see if the side of the cutoff is truly random\n\n\nError term jumps at discontinuity (the issue from above)\n\nTo check, make sure the frequency of the assignment variable is smooth at cutoff (e.g. the number of people (=samples) with SAT scores just below 1500 and just above 1500 isnâ€™t too different from the rest of the grade.)\n\nIf there is, it might mean that people under 1500 wanted to get into colleges with cutoff score at 1500, so studied a little bit harder.\n\n\nVisualization. \nAnother way to check this is to run regression between covariate (which we suspect to be in the error term) and the RD model: X2iâ€‹=Î³0â€‹+Â jumpÂ Î³1â€‹â€‹â€‹Tiâ€‹+Î³2â€‹(X1iâ€‹âˆ’C)+Î½iâ€‹\n\nA Statistically significant Î³1â€‹ indicates X2â€‹ is in the error term\n\n\n\n\n"},"Regular-Expressions":{"title":"Regular Expressions","links":["Finite-Automata","Regular-Languages"],"tags":["Computing/Formal-Languages"],"content":"Section: Finite Automata = Regular Languages\nRegular expressions have three operators:\n+Â Â âˆ—Â Â âˆ˜Â Â â€‹UnionZeroÂ orÂ MoreConcatâ€‹\n\nBegin with Ï•,Î»,Î£âˆˆRegEx\nAll above operators on the three, and the alphabet, is a regular expression\n\n\n\n                  \n                  Example \n                  \n                \nâ†’ Odd number of aâ€™s, and then even number of bâ€™s: a(aa)âˆ—(bb)âˆ—\nâ†’ 3 or less aâ€™s and ends in ab: bâˆ—(a+Î»)bâˆ—(a+Î»)bâˆ—ab\n\nRegEx â‰¡ DFA Â§\npf. RegEx â‡’ DFA\n\nFirst define the building blocks\n\n\nRepresentation of Ï•\nRepresentation of {a}\n\nRepresentation of Î»\n\n\nThen buid on them recursively:\n\n\npf. DFA â‡’ RegEx\n\nWith a DFA with one final state, convert into a generalized transition graph (GTG) [=edges can be a RegEx]\nIf the GTG has two states:\nUnique RegEx for this DFA: (riiâˆ—â€‹rijâ€‹rjjâˆ—â€‹rjiâ€‹)âˆ—riiâˆ—â€‹rijâ€‹rjjâˆ—â€‹\n\nIf GTG has three or more states it is in the form:\n\n\n"},"Regular-Grammar":{"title":"Regular Grammar","links":[],"tags":["Computing/Formal-Languages"],"content":"Section: Finite Automata\ndef. Right Linearity. A grammar G=(V,T,S,P) is right-linear iff all elements in the range of the production rules Range(P) only contain variables on the right side of the result; i.e.:\nSâ†’aPâˆ£aSPâ†’a\n\n\n                  \n                  Observe that a right-linear grammer is same as being able to extend it only on the right. Left-linear grammar is vice versa \n                  \n                \n\ndef. A Regular Grammar is a grammar that is exclusively either right-linear or left-linear.\nRegGrammar â‰¡ DFA Â§\npf. Regular Grammar â‡’ DFA\nfor G=(V,T,S,P), for each rule in P, convert a variable into a state; arcs identify the rightside (or leftside) terminal variable\npf. DFA â‡’ Regular Grammar"},"Regular-Languages":{"title":"Regular Languages","links":["Finite-Automata"],"tags":["Computing/Formal-Languages"],"content":"Equivalent to Finite Automata\ndef. Regular Languages are languages that can be described by either\n\nFinite Automata\nRegular Grammar\nRegular Expressions\n\nClosure of Regular Languages Â§\nRegular languages are closed under the following operations:\n\nUnion, Intersection\nConcatenation, Star\nCompliment\nQuotient\nL1â€‹/L2â€‹={wâˆ£âˆƒxâˆˆL2â€‹Â s.t.Â wxâˆˆL1â€‹} â† left quotient\nL1â€‹\\L2â€‹={wâˆ£âˆƒxâˆˆL2â€‹Â s.t.Â xwâˆˆL1â€‹} â† right quotient\nHomomorphism\n\nHomomorphism is a function h s.t.:\n\n\n\nh:\\Sigma\\mapsto\\Gamma^*\n$$So: $w=a_1a_2â€¦a_n \\Rightarrow$ $h(w)=h(a_1)h(a_2)â€¦h(a_n)$\n\n## Pumping Lemma and Disproving Regularity\n\nlem. **Pumping Lemma.** let regular language $L$, and $w\\in L$ whose length is $m$ or greater. Then $w$ can be decomposed s.t.:\n\n1. $w=x\\circ y \\circ z$\n2. $xy$ has a length no larger than pumping length $m$\n3. $y$ is not an empty string\n\nIn this case, a newly constructed string $wâ€™=x\\circ y^i \\circ z$ must also be in language $L$.\n\nProof by using the pumping lemma should be:\n\n1. Choose **any** single string $w$ in the language and express it in terms of a positive int. $m$\n2. Decompose the string into $x,y,z$, **where** $|xy|\\leq m$\n3. Show that $x\\circ y \\circ z$ is not in $L$, for a **certain** $i=0,1,â€¦$\n   â†’ i.e. pick an i, and show that it doesnâ€™t work if m is positive\n4. Contradiction!\n\n---\n\nIn general, you can disprove regular languages by knowing\n\n- Finite languages are always regular\n- the Pumping Lemma"},"Reification":{"title":"Reification","links":[],"tags":["Philosophy/Marxism"],"content":""},"Relational-Algebra":{"title":"Relational Algebra","links":["Turing-Machine","Database-Management-System","Monotonic-Transformation"],"tags":["Computing/Data-Science"],"content":"(DevonThink) 2. Relational Algebra\nMathematical formulation of operations on relational data.\n\nMade by E.F. Codd\nEquivalent to domain-independent relational calculus\n\nRelational calculus is a specialization of first-order logic\n\n\nIsnâ€™t Turing-complete because it lacks recursion.\n\nBut because of this, relational algebra is decidable\n\n\nHigh level and declarative (procedural implementation is left to DBMS)\nEasy to optimize by the DBMS\n\nDefinitions Â§\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDBMS jargonCommon-sense nameRelationTableAttributeColumnDomainData typeTupleRow\n\nA row is defined as a tuple\n\nDuplicate rows are not allowed\nA tuple is considered same if all attributes are same.\n\n\nSchema: the tuple of attribute names (â‰ˆclass)\nInstance: the instantiation of the schema (â‰ˆobject)\nKey (see below for formal definition):\n\ne.g. address(street_addr,city,state,zipcode)\n\nâ‡’ {street_addr,city,state} is a key\n\n..but {street_addr,state} is not a key\n\n\nâ‡’ {street_addr,zipcode is also a key\n\n\n\n\n\ndef. Superkey. A set of attributes K is a superkey of relation R if there exists a dependency:\n\ndef. Key. A superkey K is a key of relation R if there is no other superkey with smaller number of attribute elements. (=minimally identifies each tuple/row)\nalg. Determining if a superkey is a key.\n\nReduce one element and see if the key is superkey.\nIf a reduction of one element doesnâ€™t yield a smaller superkey, we got it.\nIf it does, recurse.\n\n\nRelational Operators Â§\nFundamental Operations Â§\n\nSelection: Ïƒpâ€‹â‹…R\n\nâ€œGive me the entries of relation R that satisfies condition pâ€\n\n\nProjection: Ï€Lâ€‹â‹…R\n\nâ€œGive me the attribute L for each entry of relation Râ€\nDuplicates are filtered out\n\n\nCross Product: RÃ—S\n\nSame as cross product of normal sets.\nâ‡’ Every row of R per every row of S\n\n\nUnion: RâˆªS\n\nR,S must have identical schema\nAll rows on R,S combined\nDuplicates are removed\n\n\nDifference: Râˆ’S\n\nR,S must have identical schema\nRows in R that are not in S\n\n\nRenaming: ÏSâ€‹â‹…R\n\nRename attribute S of relation R\n\n\n\nDerived Operators Â§\n\nJoin [=Theta Join]: â‹ˆpâ€‹\n\ndefinition: Ïƒpâ€‹(RÃ—S)\nâ€œCross Product the relations, and then filter by condition pâ€\ni.e. â€œJoin the two databases so based on conditionâ€\n\n\nNatural-Join: â‹ˆ\n\ndefinition: Ï€Lâ€‹(Râ‹ˆpâ€‹S)\n\nwhere p pairs common attributes\nwhere L is the union of the attribute names\n\n\nâ€œTheta join, but the duplicate attribute is removedâ€\n\n\nOuter-Join\n\nLeft outer join: RÂ âŸ•Â S (leave null entries from R)\nRight outer join: RÂ âŸ–Â S (leave null entries from S)\nFull outer join: RÂ âŸ—Â S (leave null entries from R,S both)\n\n\nIntersection: Râˆ©S\n\nR,S must have identical schema\n\ndefined as Râˆ’(Râˆ’S)â‰¡Sâˆ’(Sâˆ’R)\n\n\n\n\nSymmetric Difference: (Râˆ’S)âˆª(Sâˆ’R)\n\nMonotonicity Â§\n(Vaguely related to: Monotonic Transformation)\ndef. Monotonic Operation. If input adds more rows, does the output also only add more rows? i.e. f is a monotone operator iff:\nRâŠ†Râ€²âŸ¹f(R)âŠ†f(Râ€²)\n\nDifference (Râˆ’S) is the only non-monotone operator among simple operators\n\nMonotone for R but not for S\n\n\nIf an operation is not monotone, it must include the difference operator.\n\nExpression Tree Notation Â§\n\n\nSimpler to use and understand\nDesigned both bottom-up or top-down\n\nProperties of Relational Algebra Â§\n\n\nSelection Properties\n\nIdempotent: ÏƒAâ€‹(R)=ÏƒAâ€‹ÏƒAâ€‹(R)\nCommutative: ÏƒAâ€‹ÏƒBâ€‹(R)=ÏƒBâ€‹ÏƒAâ€‹(R)\nConjunction: ÏƒAâˆ§Bâ€‹(R)=ÏƒAâ€‹(ÏƒBâ€‹(R))=ÏƒBâ€‹(ÏƒAâ€‹(R))\nDisjunction: ÏƒAâˆ¨Bâ€‹(R)=ÏƒAâ€‹(R)âˆªÏƒBâ€‹(R)\nBreaking up: ÏƒAâ€‹(RÃ—P)=ÏƒBâˆ§Câˆ§Dâ€‹(RÃ—P)=ÏƒDâ€‹(ÏƒBâ€‹(R)Ã—ÏƒCâ€‹(P))\nDistribution over Difference: ÏƒAâ€‹(Râˆ–P)=ÏƒAâ€‹(R)âˆ–ÏƒAâ€‹(P)=ÏƒAâ€‹(R)âˆ–P\nDistribution over Union: ÏƒAâ€‹(RâˆªP)=ÏƒAâ€‹(R)âˆªÏƒAâ€‹(P)\nDistribution over Intersection: ÏƒAâ€‹(Râˆ©P)=ÏƒAâ€‹(R)âˆ©ÏƒAâ€‹(P)=ÏƒAâ€‹(R)âˆ©P=Râˆ©ÏƒAâ€‹(P)\n\n\n\nSelection and Projection Commutativity\n\nÏ€a1â€‹,â€¦,anâ€‹â€‹(ÏƒAâ€‹(R))=ÏƒAâ€‹(Ï€a1â€‹,â€¦,anâ€‹â€‹(R)) where fields in AâŠ†{a1â€‹,â€¦,anâ€‹}\n\n\n\nProjection Properties\n\nIdempotent: Ï€a1â€‹,â€¦,anâ€‹â€‹(Ï€b1â€‹,â€¦,bmâ€‹â€‹(R))=Ï€a1â€‹,â€¦,anâ€‹â€‹(R) where {a1â€‹,â€¦,anâ€‹}âŠ†{b1â€‹,â€¦,bmâ€‹}\nDistributing on Union: Ï€a1â€‹,â€¦,anâ€‹â€‹(RâˆªP)=Ï€a1â€‹,â€¦,anâ€‹â€‹(R)âˆªÏ€a1â€‹,â€¦,anâ€‹â€‹(P)\n! Projection doesnâ€™t distribute along difference:\n\nÏ€Aâ€‹({âŸ¨A=a,B=bâŸ©}âˆ–{âŸ¨A=a,B=bâ€²âŸ©})={âŸ¨A=aâŸ©}\nÏ€Aâ€‹({âŸ¨A=a,B=bâŸ©})âˆ–Ï€Aâ€‹({âŸ¨A=a,B=bâ€²âŸ©})=âˆ…\n\n\n! Projectio doesnâ€™t distribute along intersection:\n\nÏ€Aâ€‹({âŸ¨A=a,B=bâŸ©}âˆ©{âŸ¨A=a,B=bâ€²âŸ©})=âˆ…\nÏ€Aâ€‹({âŸ¨A=a,B=bâŸ©})âˆ©Ï€Aâ€‹({âŸ¨A=a,B=bâ€²âŸ©})={âŸ¨A=aâŸ©}\n\n\n\n\n\nRename Properties\n\nÏa/bâ€‹(Ïb/câ€‹(R))=Ïa/câ€‹(R)\nÏa/bâ€‹(Ïc/dâ€‹(R))=Ïc/dâ€‹(Ïa/bâ€‹(R))\nDistribution on Difference: Ïa/bâ€‹(Râˆ–P)=Ïa/bâ€‹(R)âˆ–Ïa/bâ€‹(P)\nDistribution on Union: Ïa/bâ€‹(RâˆªP)=Ïa/bâ€‹(R)âˆªÏa/bâ€‹(P)\nDistribution on Intersection: Ïa/bâ€‹(Râˆ©P)=Ïa/bâ€‹(R)âˆ©Ïa/bâ€‹(P)\n\n\n\nProduct and Union\n\nCartesian Product and Union: (AÃ—B)âˆª(AÃ—C)=AÃ—(BâˆªC)\n\n\n"},"Revenue-Maximizing-Auctions":{"title":"Revenue-Maximizing Auctions","links":[],"tags":["Economics/Game-Theory"],"content":"Motivation. Sometimes we aim to maximize revenue instead of social welfare.\n\nIn this case, we assume that we know a little bit about the bidderâ€™s private valuationsâ€”we know the distributions viâ€‹âˆ¼Fiâ€‹. (we call this a baysian auction.)\n\nThis is because unless we do this, the revenue maximization is impossible, since it is hard to guarantee DSIC.)\n\n\nThen, in a DSIC auction M=(x(b),p(b)), the revenue maximization goal can be phrased as:\n\nmaxx,pâ€‹Â E(âˆ€iâˆ‘â€‹piâ€‹(v))\nIn order to do to this, we introduce a new concept, and as we will see later it will simplify the above problem.\ndef. Virtual Value. For a biddersâ€™ true valuation viâ€‹ whose CDF is Fiâ€‹(viâ€‹), PDF is fiâ€‹(viâ€‹), the virtual value is defined as:\nÏ†(viâ€‹):=Â wantÂ toÂ collectÂ viâ€‹â€‹â€‹âˆ’Â informationÂ penaltyÂ fiâ€‹(viâ€‹)1âˆ’Fiâ€‹(viâ€‹)â€‹â€‹â€‹\nProperties.\n\nÏ†(viâ€‹)â‰¤viâ€‹\nÏ†(viâ€‹) may be negative\n\nIntuition. As annotated above, treat viâ€‹ as the amount of money we would like to collect from bidder i. But this is discounted by a certain factor (=â€œinformation penaltyâ€) because we know a bit of information about themâ€”their distribution.\nWe can rephrase the above revenue maximization problem in terms of virtual value as the following:\nthm. (expected virtual welfare is expected revenue)\nEâ€‹Â revenueÂ âˆ€iâˆ‘â€‹piâ€‹(v)â€‹â€‹â€‹=Eâ€‹Â virtualÂ welfareÂ âˆ€iâˆ‘â€‹Ï†iâ€‹(viâ€‹)xiâ€‹(v)Uâ€‹â€‹â€‹\nMotivation. Now the revenue maximization goal is simply to maximize expected virtual welfare. However, we still need to make sure the bidders are truthful, because we need to maximize over v.\n\nâ‡’ Using Myersonâ€™s lemma, we can create auctions that are truthful. The following are conditions of Myersonâ€™s lemma, applied in the context of virtual value.\nThen, we will give an example of this in a single-item many-bidder auction where these conditions hold.\n\ndef. Vickery Auction with Reserve \n\nCalculate virtual values Ï†1â€‹,â€¦,Ï†nâ€‹ for all bidderâ€™s bids b1â€‹,â€¦,bnâ€‹\nGive the item to the bidder with the highest virtual value Ï†1â€‹, unless the highest bidderâ€™s virtual value is below zeroâ€”Ï†1â€‹&lt;0.\n\nThe the highest bidderâ€™s virtual value is below zero, throw away the item. Auction is over.\n\n\nCalculate the reserve price r:=Ï†âˆ’1(0)\nCharge them max(v2â€‹,r)â€”either the reserve price, or the second-price\nThis auction will maximize revenue.\n\nVisual Interpretation. An example of three different cases where different distributions lead to different virtual value\n\nthm. (General case of revenue maximization.)\n\nAssuming Fiâ€‹ is regular for every bidder iâ€¦\n\n\nTransform the truthfully reported valuation viâ€‹ into corresponding virtual value Ï†iâ€‹(viâ€‹)\nAllocate by maximizing virtual welfare: x(v)=argmaxXâ€‹âˆ‘âˆ€iâ€‹Ï†iâ€‹(viâ€‹)â‹…xiâ€‹\nCharge payments p(v) according to the\n\ndef. Regular Distribution. A distribution is regular iff if its virtual value function is monotonic.\nthm. If all bidderâ€™s values follows an i.i.d. regular distribution, Vickery Auction with Reserve is DSIC."},"Riemannâ€“Stieltjes-integral":{"title":"Riemannâ€“Stieltjes integral","links":[],"tags":["Math/Calculus"],"content":"def. Riemann-Stieltjes Integral. let functions f(x),g(x):Râ†’R. Then the R-S integral with f(x) as the integrand and g(x) as the integrator is defined:\nâˆ«abâ€‹f(x)dg(x)=nâ†’âˆlimâ€‹i=0âˆ‘nâ€‹f(xiâ€‹)[g(xi+1â€‹)âˆ’g(xiâ€‹)]â€‹â€‹\nwhere a=x0â€‹â‰¤â‹¯â‰¤xnâ€‹=b\nVisualization. The value of the integral is the shadow projection of the purple fence (=from xâˆ’g plane to the intersecting line of f(x) and g(x)). The lower the slope of g(x), the denser the shadow is. See: Riemannâ€“Stieltjes integral - Wikiwand\n"},"Risk-(Finance)":{"title":"Risk (Finance)","links":["Distance-&-Expectation","Variance","Bond-Price"],"tags":["Economics/Finance"],"content":"def. Risk is related to the uncertainty in payment back when giving a loan.\n\nExample of a riskless investment is investing into the bank upto the federal deposit insurance (~$100K)\nTypes of risk include:\n\nDistance &amp; Expectation Risk (=counterparty risk): the counterparty can fail to make the payment\nInterest Risk: the market interest rate might change\nInflation Risk: the inflation is high so the money isnâ€™t worth much\n\n\nIncreased cash flow frequency usually means less risk.\n\ndef. Risk in finance is equivalent to Standard Deviation in mathematics.\n\nRisk is proportional to the duration of investment (See bond yield curve).\n"},"Risk-Neutral-Assumption":{"title":"Risk-Neutral Assumption","links":["Present-Value-Calculations","No-Arbitrage"],"tags":["Economics/Finance"],"content":"Motivation. A risk-neutral world is where there is no risk premium on return. This implies:\n\nAll Present Value Calculations are done at the risk-free rate\nAll assets have risk-free rate of return (=zero riNo-Arbitrageitrage Condition]] holds\n&amp; This is not really realistic, but simplifies calculations a lot.\n\nRisk-Neutral Measure Â§\nA risk-neutral measure is a probability measure such that E(S0â€‹)=ert, in other words, all securities have risk-free rate of return."},"Risk-Neutral-Derivation-of-BSM":{"title":"Risk-Neutral Derivation of BSM","links":[],"tags":["Economics/Finance"],"content":""},"Robert-Nozick":{"title":"Robert Nozick","links":[],"tags":["Economics/Game-Theory","People"],"content":""},"Rock-Paper-Scissors":{"title":"Rock Paper Scissors","links":[],"tags":["Economics/Game-Theory/Games"],"content":""},"Roy's-Identity":{"title":"Roy's Identity","links":["Utility-Function","Uncompensated-Demand-curve"],"tags":["Economics/Micro-Economics"],"content":"thm. Royâ€™s Identity. Relates income, price, and Indirect Utility Function to a own-price demand function.\nx1â€‹(p1â€‹,p2â€‹,I)â‰¡âˆ’âˆ‚v/âˆ‚Iâˆ‚v/âˆ‚p1â€‹â€‹x2â€‹(p1â€‹,p2â€‹,I)â‰¡âˆ’âˆ‚v/âˆ‚Iâˆ‚v/âˆ‚p2â€‹â€‹â€‹â€‹"},"SQL-Basics":{"title":"SQL Basics","links":["Relational-Algebra","assets/Screenshot-2023-10-13-at-15.18.16.png"],"tags":["Computing/Data-Science"],"content":"**## Based on Relational Algebra\nSQL is more readable than Relational Algebra.\nSPJ Query Â§\nSelect-Project-Join (SPJ) query. Is what almost all queries are. in the form of:\nÏ€attr1,Â attr2,Â ...â€‹(Ïƒconditionâ€‹(relation1Ã—relation2Ã—â€¦))\nâ€¦is equivalent toâ€¦\nSELECT attr1, attr2, ...\nFROM relation1, relation2, ...\nWHERE condition\nâ‡’ Think: you are checking {postgresql} condition on the whole cross product of relation1, relation2, â€¦\nCanonical form of a single query\nSELECT ... AS ..., ... AS ...\nFROM Relation_1 r1, Relation_2 r2 -- Rename the table.\nWHERE ... AND ... -- Where condition\n\t(NOT) IN, (NOT) EXISTS, ALL, SOME (subtable) -- Nested Query\n\t-- exist doesn&#039;t need an attribute\nORDER BY ASC|DESC\nJoins, Unions and Differences Â§\n\nSELECT ...\nFROM ...\n-- Join query\n[INNER, OUTER] [LEFT, RIGHT, FULL] JOIN \n-- INNER JOIN equivalent to JOIN\n-- LEFT|RIGHT JOIN equivalent to LEFT|RIGHT OUTER JOIN\n(subtable) T -- rename \nON join_condition\n\n-- optional WHERE clause\nWHERE ...\n\n-- Set/Bag operation query\n(subtable) UNION, INTERSECT, EXCEPT (ALL) (subtable)\n\n\ntable references scoping is like other languages\nsubtables can be one tuple &amp; one column (=scalar), where you can do a direct comparison: {postgresql}WHERE age [&gt;=&lt;] (subtable)\n\nâ€¦but this will cause runtime error if the subtable has more than one value.\n\n\n{postgresql}SELECT DISTINCT to remove duplicates\n{postgresql}EXCEPT/INTERSECT/UNION ALL is a bag operation that removes by count; Example data\n\nConditionals Â§\nSELECT\nFROM\n&#039;string literal&#039; -- should be enclosed in single quotes\nWHERE string LIKE &#039;%foobar%&#039;-- pattern matching strings\n\n-- Null checking\nWHERE attr IS NULL\nWHERE attr IS NOT NULL\n-- etc.\nNull Handling Rules. Â§\n\n\n                  \n                  NULL and Unknown as a 0.5 value\n                  \n                \n\n\nComparing NULL with any value will result in UNKNOWN\nValues as numbers:\n\nTRUE=1\nFalse=0\nUNKNOWN=0.5\n\n\nOperations as functions:\n\n{postgresql}x AND y=min[x,y]\n{postgresql}x OR y=max[x,y]\n{postgresql}NOT x=1âˆ’x\n\n\n\nWhat about handling null results?\n\nSolution 1: {postgresql}SELECT COALESCE(col,0.0)\n\nâ‡’ if {postgresql}col = NULL, will return 0.0\n\n\nSolution 2: {postgresql}SELECT NULLIF(col,&#039;n/a&#039;)\n\nâ‡’ if {postgresql}col = &#039;n/a&#039;, will return NULL\n\n\n\nSQL Extensions Â§\nAggregation Â§\nSELECT COUNT(*)|COUNT(DISTINCT col)|AVG(col)|MIN(col)|MAX(col)\nFROM ...\nWHERE ...;\n\nAn aggregation in a HAVING clause applies only to the tuples of the group being tested.\nAny attribute of relations in the FROM clause may be aggregated in the HAVING clause, but only those attributes that are in the GROUP BY list may appear unaggregated in the HAVING clause (the same rule as for the SELECT clause).\n\nGrouping Â§\nSELECT aggr_func FROM [JOIN ON | UNION | ...] WHERE\n-- Group By\nGROUP BY col1, col2 -- will group if *both* columns are same\nHAVING condition_on_group\n\nCompute Order:\n\n{postgresql}GROUP BY\n`{postgresql}HAVING\n{postgresql}SELECT\n\n\naggr_func is computed for each group\n\ne.g. {postgreSQL}SELECT age, AVG(pop) FROM User GROUP BY age computes the average popularity for each age.\ne.g. {postgresql} SELECT uid, MAX(pop) FROM User is wrong â† aggregate function and column cannot be used together (which uid?)\ne.g. {postgresql}SELECT uid, age FROM User GROUP BY age is wrong â† which uid?\nâ€œ\n\n\n\nVariables Â§\nTwo forms of â€œvariablesâ€\n\nNamed Subqueries (will evaluate by macro expansion)\nViews (is a window into a table)\n\nProvides Logical data independence\n\n\n\n-- Named subqueries\nWITH subtable_name AS (subquery)\n\n-- Views\nCREATE VIEW view_name AS (subquery)\nDROP VIEW -- dropping a view\nData Input/Output Â§\nINSERT INTO ... (subquery) ...\nDELETE FROM ... [WHERE ...]\nUPDATE ... SET ... [WHERE ...]\nAdvanced Topics Â§\n\nTransaction\n\nAllows multiple queries to be treated as one (helps when making new tables with foreign key relations)\n\n\nObject-Relational Mapping\n\nConvert between object-oriented languageâ€™s object data into SQL-compatible tuples, and vice versa\n\n\nCasting\n\nConvert between datatypes {postgresql}CAST(num AS FLOAT)\n\n\n\nRecursion Â§\n\nYou can define new subtables with recursion\n\n{postgresql}WITH RECURSIVE subtable AS (recursive_query)\n\n\nSQL does fixed point recursion\n\nâ€¦i.e. recurses until the table doesnâ€™t seem to change anymore\n\n\nLinear vs Non-linear recursion\n\nLinear: a single recursive call\nNon-linear: a tree-like recursion; multiple recursive calls\n\n\nMutual Recursion\n\nTwo tables are defined upon each other\n\n\n"},"SQL-Constraints":{"title":"SQL Constraints","links":[],"tags":["Computing/Data-Science"],"content":"Constraint Checking Â§\nSchema Declaration Â§\nCREATE TABLE User(\n\tuid INTEGER NOT NULL PRIMARY KEY, -- primary key\n\tage INTEGER NOT NULL UNIQUE -- not a key, but is unique\n\t\t    CHECK(age IS NULL OR age &gt; 0), -- constriant\n);\n\nCREATE TABLE Group(\n\tgid CHAR(10) NOT NULL PRIMARY KEY,\n\tname VARCHAR(100) NOT NULL UNIQUE\n);\n\nCREATE TABLE Member (\n\tuid INTEGER NOT NULL REFERENCES Group(uid), -- foreign key\n\tgid CHAR(10) NOT NULL, \n\tPRIMARY KEY(uid, gid) -- another way to write key\n\tFOREIGN KEY(gid) REFERENCES Group(gid) -- anoter foreign key\n);\n\nWhen constraint check fails during a query, will reject (maybe cascade, or set null)\nDeferred constraint checking: constraint check only happens for a full declaration or transaction\n{postgresql}CHECK will accept NULL values even if not clearly specified\n\nAssertions Â§\nCREATE ASSERTION assertion_name CHECK condition"},"SQL-Query-Optimization":{"title":"SQL Query Optimization","links":[],"tags":["Computing/Data-Science"],"content":"\n\n                  \n                  Problem: How to actually process this: \n                  \n                \n\n\nBasic Strategies Â§\n\nSQL Query rewriting\n\nMake everything into joins!\n\n\nDe-correlation: Correlated subqueries are de-correlated using â€œMagicâ€ de-correlation\nIterated (=pipelined) algorithm processes\n\nProcess one tuple, up the chain, one at a time\nWill start producing results faster, but may not be fast in total\n\n\nBottom-up Evaluation\n\nProcess the bottommost query, then up one level, etc.\nUse temporary files to store intermediate results\n\n\n\nHeuristics-based Optimization Â§\n\nIdea: estimate size of intermediate results to calculate total operation count\n\nCardinality estimation\n\n\nGiven knowledge: âˆ£Ï€Aâ€‹Râˆ£,âˆ£Râˆ£\nPrinciples:\n\nPreservation of Value\n\n\n\nSelection\nâˆ£ÏƒA=valâ€‹âˆ£âˆ£ÏƒA=valâ€‹âˆ£â€‹â‰ˆâˆ£Râˆ£â‹…âˆ£Ï€Aâ€‹Râˆ£1â€‹=DistictÂ AÂ valuesÂ inÂ RSizeÂ ofÂ Râ€‹â‰ˆâˆ£Râˆ£â‹…(1âˆ’âˆ£Ï€Aâ€‹Râˆ£1â€‹)â€‹â€‹\n\ndivide by the â€œselectivity factorâ€\n\nConjunction, Disjunction (AND, OR operations)\n\nBest when A,B are independent columns\n\nâˆ£ÏƒA=uâˆ§B=vâ€‹âˆ£âˆ£ÏƒA=uâˆ¨B=vâ€‹âˆ£â€‹â‰ˆâˆ£Râˆ£â‹…âˆ£Ï€Aâ€‹Râˆ£â‹…âˆ£Ï€Bâ€‹Râˆ£1â€‹â‰ˆâˆ£Râˆ£â‹…(âˆ£Ï€Aâ€‹Râˆ£1â€‹+âˆ£Ï€Aâ€‹Râˆ£1â€‹âˆ’âˆ£Ï€Aâ€‹Râˆ£â‹…âˆ£Ï€Bâ€‹Râˆ£1â€‹)â€‹ConjunctionDisjunctionâ€‹â€‹\nRange\n\nWithout max,min values: just say 31â€‹\nWith max=hi(R.A) and min=lo(R.B)\n\n&amp; sometimes, highest and lowest is â€œinvalidâ€ â†’ use second highest &amp; lowest\n\n\n\nâˆ£ÏƒA&gt;vâ€‹âˆ£â‰ˆâˆ£Râˆ£â‹…maxâˆ’minmaxâˆ’vâ€‹\nJoins Estimation Â§\nNatural Join\n\nAssumption: containmentâ€”every tuple in smaller table joins with bigger table\nâ‡’ selectivity factor is the bigger one one\n\nâˆ£Râ‹ˆSâˆ£â‰ˆâˆ£RÃ—Sâˆ£â‹…max(âˆ£Ï€Aâ€‹Râˆ£,âˆ£Ï€Aâ€‹Sâˆ£)1â€‹\nMulti-way Join\n\nAssumption: preservation of value setsâ€”non-join attribute doesnâ€™t lose values\nâ‡’ reduce by selectivity factor for every join\n\nâˆ£R(A,B)â‹ˆS(B,C)â‹ˆT(C,D)âˆ£â‰ˆâˆ£RÃ—SÃ—Tâˆ£â‹…selectivityÂ ofÂ firstÂ joinâˆ£Ï€Bâ€‹Râˆ£,âˆ£Ï€Bâ€‹Sâˆ£1â€‹â€‹â€‹â‹…selectivityÂ ofÂ secondÂ joinâˆ£Ï€Câ€‹Sâˆ£,âˆ£Ï€Câ€‹Tâˆ£1â€‹â€‹â€‹\nProjection over Join\n\nDue to assumption of preservation of value setsâ€¦\nâ€¦when R(A,B),S(B,C), A does not appear in S. Therefore we estimate:\n\nâˆ£Ï€Aâ€‹(Râ‹ˆS)âˆ£â‰ˆâˆ£Ï€Aâ€‹Sâˆ£\n\n\n                  \n                  Nowadays people use histograms and ML for better estimation \n                  \n                \n\nJoin Plans Â§\nQ. given n relations to join, how to join?\n\nBrute Force: (nâˆ’1)!(2nâˆ’2)!â€‹\nLeft-Deep Plan: n! \nGreedy: n2 \nDynamic Programming:\n\nNeed to consider: interesting orders (=sorted? deduped? etc.) need to be considered too!\n\n\n\n"},"SQL-Query-Processing-Algorithms":{"title":"SQL Query Processing Algorithms","links":["Sorting-Algorithms"],"tags":["Computing/Data-Science"],"content":"Notation Â§\n\nB(R): block count of table R\nâˆ£Râˆ£: tuple count of table R\n\nâˆ£Râˆ£&gt;&gt;B(R) because many tuples fit in a block\n\n\nM: number of available blocks in memory\nComplexity is always the number of I/Os\n\nSorting Based Algorithms Â§\nalg. External Merge Sort\n\nIdea: Merge Sort, but with limited memory \n\n\nWe are trying to sort relation R on disk with M blocks of main memory\nPass 0: we read M sequential blocks at a time, sort (using any Sorting Algorithms) and read onto disk into different runs. The number of runs is n.\nPass 1: We merge teach runs in memory. We need one block to write out the result, and n blocks to merge simultaneously.\n\nThus n=Mâˆ’1\n\n\nRepeat passes until there is only one output run. This is the sorted run.\n\n\nComplexity\n\nNumber of passes: =âŒˆlogMâˆ’1â€‹âŒˆMB(R)â€‹âŒ‰âŒ‰+1\nI/O Complexity: â‰ˆO(B(R)logMâ€‹B(R))\nMemory requirement: M (as much as possible)\n\n\n\nalg. Sort-Merge Join\nIdea: while sorting the table, simultaneously join them in the process: \n\nRun external merge sort passes until the no. of total runs to merge is less than or equal to Mâˆ’1\nMerge each table in-memory, and compare them to the condition. Join if necessary.\n\n\nComplexity for 2 passes:\n\nIO Complexity in 2 passes: O(B(R)+B(S))\nMemory requirement: M&gt;âŒˆMB(R)â€‹âŒ‰+âŒˆMB(S)â€‹âŒ‰=B(R)+B(S)â€‹\n\n\nComplexity for &gt;2 passes: same as external merge sort\n! May degrade complexity if, e.g. the whole table needs joining.\n\nHash Based Algorithms Â§\nalg. Hash Join\n\nIdea: use a O(1) hash function that partitions the table into block size Mâˆ’1 partitions, then merge: \n\n\nProbe: Partition both tables R,S into block size Mâˆ’1 different partitions using the same hash function\nLoad one partition of R into memory. Stream one block of S at a time, and join.\n\n\nComplexity\n\nI/O: 3(B(R)+B(S))\nMemory requirement: M&gt;min[B(R),B(S)]â€‹+1\n\n\n\nIndex Based Algorithms Â§\nEquality and Range: use B+ Trees\nIndex Nested Loop Join\nZigzag Join"},"SQL-Transaction-Guarantees":{"title":"SQL Transaction Guarantees","links":["Atomic","Directed-Acyclical-Graph","Readers-Writer-Locking"],"tags":["Computing/Data-Science","Computing/Algorithms"],"content":"SQL Transactions must be: ACID\n\nAtomic: Done or not done. Atomic\nConsistent: Donâ€™t do partial writes\nIsolated: Transaction Serializability:= transactions should seem like they are executed in isolation\nDurable: Crashes should be recoverable\n\nIsolation Â§\nConcepts Â§\n\nSerial Schedule: execute transactions in order. Donâ€™t interleave anything.\nConflicting Operations: two transactions conflict if any of the operations they have on same data conflict iff one of the operations is a write operation\n\nDirty Write: T1â€‹.r(A) â†’ T2â€‹.w(A)\nDirty Read: T1â€‹.w(A) â†’ T2â€‹.r(A)\n&amp; Two transactions are T1â€‹,T2â€‹ is conflict-serializable iff they have conflicts, but we can interleave some operations but still seems like itâ€™s a serial schedule. SEREALIZABLE guarantee above is equivalent to this.\n\n\nConflicting Transactions:\n\nSee Isolation (database systems) - Wikiwand\nNon-repeatable Reads: T1â€‹ reads Xâ†’ T2â€‹ writes X and commits â†’ T1â€‹ reads X again (different value!)\nPhantom Reads: T1â€‹ gets range â†’ T2â€‹ inserts between this range and commits â†’ T1â€‹ gets same range (different value!)\n\n\nPrecedence graph: a schedule with no cycles in the precedence graph (=graph is DAG) is conflict-serializable\n\nA path in an acyclic precedence graph is a conflict-serializable schedule\nExample: \n\n\n\nLevels of Isolation Guarantees Â§\n\nRead Uncommitted: lock &amp; release immediately\nRead Committed: donâ€™t release write locks until commit\nRepeatable Reads: long duration locks\nSerializable: long duration locks on ranges\n\n\nSerializable Guarantee Â§\nImplemented thru Strict 2-phase locking (S2PL). Rules:\n\nOne writer, multiple readers: Readers-Writer Locking\n2-Phase Locking: For each transaction, you must lock everything first (=locking phase) then unlock everything together (=unlock phase): \nStrict Locking: Release write-locks (=exclusive-locks) only at commit or abort time\n\nGuaranteed recoverable (no cascading rollbacks)\nExample:\n\n\nRigorous (=Strong) Locking: Release all locks only at commit or abort time.\n\nPrevents Deadlocks\nAlso Recoverable.\nExample:\n\n\n\nRecovery Â§\nComputation Model: \nNaive Recovery Â§\n\nForce: on commit, (â€œforceâ€) dirty flush to disk\nNo Steal: donâ€™t (â€œstealthilyâ€) flush before commiting\n\nSmarter: Undo/Redo Logging Â§\n\nlog start of transaction\nFor each write/delete, log the old and new values\nOn commit, write all logs to disk\nProperties\nWrite-ahead logging: before disk flush, log must be flushed first\nNo force: commit even without flushing\nSteal: flush to disk anytime (just log it!)\n\n\nFuzzy Checkpointing Â§\n\nLog begin checkpointing and log open transactions\n\nStart Checkpoint CHK1, Open transactions: S,T\n\n\nflush all current transactions (=transactions at â€œbeginâ€ point) at leisure\nLog finish checkpointing (and pointer for convenience)\n\n`Finish Checkpoint CHK1. Started at \n\n\n\nRecovery\n\nAnalyze &amp; Redo Phase\n\nFind last completed checkpoint Finished Checkpoint CHK1â€¦\nGo to the start of that checkpoint Start Checkpoint CHK1, Open: S,Tâ€¦\nAnalyze open transactions at time of crash U={S,T}\n\n! Start with checkpointâ€™s open transactions\nWhen you encounter close transactions Close S, remove from U={Sâ€‹,T..,U}\nWhen you encounter new open transactions Begin T, add that to U={S,T..,addedUâ€‹â€‹}\n\n\nAll operations between Start Checkpointâ€¦ and end of log is replayed\n\n\nUndo Phase\n\nFrom the last log item until whenever:\n\nFor each open transaction at time of crash TâˆˆU\n\nUndo all of its operations in reverse orderâ€¦\nUntil you reach Begin T\n\n\n\n\nStop when U is exhausted\n\n\n\nRecoverability Â§\nFor multiple transactions to be recoverable:\n\nT1 writes â†’ T2 reads, then must T1 commits â†’ T2 commits\nT1 writes â†’ T2 writes doesnâ€™t even matter\n\nEd discussion:\n"},"Scheduling-Problem":{"title":"Scheduling Problem","links":["Greedy-Algorithm","Dynamic-Programming","Subset-Sum"],"tags":["Computing/Algorithms"],"content":"Scheduling problem solution formulations\n\nSort by some quantity\nSchedule accordingly\nProve correctness by these strategies\n\nEvent Scheduling Â§\nQ. Interval Scheduling (Greedy Algorithm)\n\nDynamic Programming idea works\n\ndp[i] = max(dp[]+1\nO(n3) time\n\n\nGreedy Algorithm is even better\n\nIdea: sort by\n\n\n\nalg. Interval Scheduling with n rooms\nQ. Multiple Room Interval Scheduling\nQ. Interval Coloring\nQ. Interval Cover Problem\nJob Scheduling Â§\nQ. Minimize Makespan (=maximum time on any machine) of n machines\n\n\nNP-Hard problem (reduce from 21â€‹-Subset Sum)\n\nalg. Approximate Greedy Makespan: Always choose the least loaded machine\n\nIs a 2-level approximation \nalg. Better Approximate Greedy Makespan: Assign from longest to shortest job, to least loaded machine every time.\n\n\nalg. Minimize lateness of jobs\n\n\nInterval Scheduling\n\nschedule n jobs\n\nno dependencies\n\n\n=&gt; how many jobs can you complete? (total time doesnâ€™t matter!)\nconflict when:\n\nStart[i] &lt;\n\n\nDynamic Programming solution is easy\n\nOPT = max(1+OPT(jobs that donâ€™t conflict with job 1) vs OPT(2..n))\n\n\n=&gt; but O(n3) or even with improvement O(n2)!\n\n\n\nGreedy solution:\n\njob that finishes first = job that leaves the most amount of remaining time\nimplementation\n\nSort by finish time\nchoose earlyest finish time\nchoose next earliest finish time that doesnâ€™t conflict with most recently finished job\nDone!\n\n\n=&gt; O(nlogn) time (because sorting)!\nProof by induction: Exchange Argument\n\nbase: Yâˆ— optimal solution has y1â€‹inYâˆ—\n\nif you have x1â€‹ that finish time earlier than y1â€‹â€¦\nremoving y1â€‹ and adding x1â€‹ is also optimal solution\n\n\n\n\n\n\n\nTry: dp solution\n\n\nvariation: make span algorithm (greedy is close to optimal, but not optimal)\n\n\ninterval scheduling, but with n meeting rooms\n\ngreedy still words!\n\n\n\nminimum total completion time.\n\n\nminimize lateness\n\nsort by ascending lateness&lt;&lt;\n\n\n"},"Securities-and-Exchange-Commission":{"title":"Securities and Exchange Commission","links":[],"tags":["Economics/Finance"],"content":"\nThe SEC is an independent agency of the United States federal government, and it is responsible for enforcing federal securities laws, proposing securities rules, and regulating the securities industry.\n"},"Security-(Finance)":{"title":"Security (Finance)","links":["Bonds-(Finance)","Futures","Capital-(Marxism)","Valorization,-Surplus-Value"],"tags":["Economics/Finance"],"content":"Bonds (Finance)\nFutures\nBasically capital to be valorized. Interest is surplus value."},"Sensuous-Activity":{"title":"Sensuous Activity","links":["Alienation","Private-Property","Capital-(Marxism)","species-being"],"tags":["Philosophy/Marxism"],"content":"Sensuous Activity Â§\nSenses define realityâ€¦\n\nAll his human relations to the world - seeing, hearing, smelling, tasting, feeling, thinking, contemplating, sensing, wanting, acting, loving - in short, all the organs of his individuality, like the organs which are directly communal in form, are in their objective approach or in their approach to the object the appropriation of that object. This appropriation of human reality, their approach to the object, is the confirmation o f human reality.\n\nâ€¦but itâ€™s estranged for nowâ€¦\n\nThis material, immediately sensuous private property is the material, sensuous expression of estranged human life. Its moveÂ­ment - production and consumption - is the sensuous revelation of the movement of all previous production, i.e. the realization or reality of man.\n\nâ€¦and Private Property is a core â€œsensuousâ€ response by capitalismâ€¦\n\nPrivate property has made us so stupid and one-sided that an object is only ours when we have it, when it exists for us as Capital (Marxism) or when we directly possess, eat, drink, wear, inhabit it, etc., in short, when we use it. [â€¦] Therefore all the physical and intellectual senses have been replaced by the simple estrangement of all these senses - the sense of having.\n\nâ€¦and removal of private property is the â€œemancipationâ€ of our senses\n\nThe supersession of private property is therefore the complete emancipation of all human senses and attributes [â€¦] The senses have therefore become theoreticians in their immediate praxis. They relate to the thing for its own sake, but the thing itself is an objective human relation to itself and to man, and vice-versa.\n\nEmancipation of the Senses Â§\nThe socialized and trained â€œsensesâ€ determine the progress of the species-being\n\nTherefore this relationship reveals in a sensuous form, reduced to an observable fact, the extent to which the human essence has become nature for man or nature has become the human essence for man. It is possible to judge from this relationship the entire level of development of mankind. It follows from the character of this relationship how far man as a speciesbeing, as man, has become himself and grasped himself\n\nThis material, immediately sensuous private property is the"},"Sequence-Summation":{"title":"Sequence Summation","links":[],"tags":["Math/Calculus","Math"],"content":"Geometric Series: a,ar,ar2,â€¦,arn\nSnâ€‹=aâ‹…1âˆ’r1âˆ’rnâ€‹\nIf it converges, the infinite sum:\nSâˆâ€‹=1âˆ’raâ€‹\nArithmetic Sequence: a,a+d,a+2d,â€¦a+nd\nSnâ€‹=2nâ€‹â‹…(2a+(nâˆ’1)d)\nOther Summations: See Convergence tests - Wikiwand\nProperties of Summations Â§\n(i=0âˆ‘nâ€‹aiâ€‹)2=i=0âˆ‘nâ€‹ai2â€‹+iî€ =jâˆ‘nâ€‹aiâ€‹ajâ€‹"},"Set-Cover":{"title":"Set Cover","links":[],"tags":["Computing/Algorithms"],"content":"Q. Set Cover. We have a universe set U and a bunch of sets S1â€‹,â€¦,Snâ€‹ in the universe. (It is guaranteed that the union of all these sets will cover U). I want to cover all elements of the universe. Which sets should I choose do do this minimally?\n\ne.g. How many classes to visit to see all Duke students?\n\nalg. Approximate Set Cover.\n\nChoose the largest available set Siâ€‹\nRemove elements from that set from the universe\nRepeat until no element is left.\n"},"Set-Theory":{"title":"Set Theory","links":[],"tags":["Math"],"content":"Partitions and Probability Â§\ndef. Sets B1â€‹â€¦Bnâ€‹ is a partition of B if and only if:\n\nB1â€‹â€¦Bnâ€‹ are pairwise disjoint\nB1â€‹âˆªâ€¦âˆªBnâ€‹=B\n\nCOR. if B1â€‹â€¦Bnâ€‹ is pairwise disjoint P(B1â€‹âˆªâ€¦âˆªBnâ€‹)=P(B1â€‹)+â€¦+P(Bnâ€‹)\nCOR. if B1â€‹â€¦Bnâ€‹ is a partition of Î© then P(B1â€‹âˆªâ€¦âˆªBnâ€‹)=1\nSet Operations Â§\n\nâˆ£Aâˆ£ Cadinality of set A\nAÃ—B: Cartesian product of sets A,B\n2A: all the subsets of A [= power set of A]\n\n"},"Shepard's-Lemma":{"title":"Shepard's Lemma","links":["Expenditure-Minimization","Uncompensated-Demand-curve","Expenditure-Function","Cost-Minimization","Input-Demand-and-Output-Supply"],"tags":["Economics/Micro-Economics"],"content":"thm. Shepardâ€™s Lemma (Expenditure Minimization). Relates Hicksian Demand and Expenditure Function\nh1â€‹(p1â€‹,p2â€‹,uË‰)=âˆ‚p1â€‹âˆ‚Eâ€‹h2â€‹(p1â€‹,p2â€‹,uË‰)=âˆ‚p2â€‹âˆ‚Eâ€‹â€‹â€‹\nthm. Shepardâ€™s Lemma (Cost Minimization). Related conditional Input Demand and the Cost Function\nlcâ€‹(w,r,xË‰)kcâ€‹(w,r,xË‰)â€‹=âˆ‚wâˆ‚Câ€‹=âˆ‚râˆ‚Câ€‹â€‹â€‹"},"Short-selling":{"title":"Short-selling","links":[],"tags":["Economics/Finance"],"content":"= â€œselling an asset you donâ€™t oweâ€\n= you borrow the asset to immediately sell it on the market;\nâ†’ then when the price drops, you buy the share from the market to return it\n"},"Shortest-Path":{"title":"Shortest Path","links":["priority-queue","No-Arbitrage","Dynamic-Programming"],"tags":["Computing/Algorithms"],"content":"Summary of All Shortest Path Algorithms Â§\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nShortest Path (SP) AlgorithmsBFSA*Dijkstraâ€™sBellman FordFloyd WarshallComplexityO(V+E)O(ElogV)O((V+E)logV)O(VE)O(V3)Recommended graph sizeLargeLargeLarge/MediumMedium/SmallSmallAll-PairsOnly works on unweighted graphsNoOkBadYesCan detect negative cycles?---âœ“âœ“SP on graph with unweighted edgesâœ“(Best)âœ“âœ“âœ“(Bad)âœ“(Bad)SP on graph with weighted edgesMust expand graphâœ“(Best)âœ“âœ“âœ“(Bad)\nSingle Source Shortest Path (SSSP) Â§\nalg. BFS Shortest Path\n\nAssumption: Graph doesnâ€™t have weights\nIdea: BFS, but every time you encounter a tense edge, relax it\n\n\nalg. Dijkstraâ€™s Shortest Path\n\nAssumption. graph has non-negative edge weights\nIdea. BFS Shortest Path, but you choose the next vertex by how likely they are to be the shortest path (=maintain a priority queue based on path length)\n\nSee Dijkstraâ€™s Algorithm - Computerphile - YouTube\n\n\nComplexity\n\nTime: O((âˆ£Vâˆ£+âˆ£Eâˆ£)â‹…logâˆ£Vâˆ£)\n\n\n\nalg. A-Star (A*) Shortest Path\n\nAssumption. graph has non-negative edge weights\nIdea. Dijkstra using priority queue, but the priority is calculated on a heuristic\n\nSee A* (A Star) Search Algorithm - Computerphile - YouTube\n\n\nComplexity.\n\nTime: O(âˆ£Eâˆ£logâˆ£Vâˆ£) using binary heap\n\n\n\nalg. Bellmanâ€“Ford Shortest Path\n\nIdea:\n\nRepeat BFS edge relaxation for âˆ£Vâˆ£âˆ’1 times. Get shortest path\nRepeat BFS edge relaxation again, for âˆ£Vâˆ£âˆ’1 times. But this time, if any cost values are updated, the node is part of a negative cycle. Mark cost to that node as âˆ.\nSee Bellman Ford Algorithm | Graph Theory - YouTube\nAble to deal with negative edges/negative cycles\nOften used in finance for identifying No-Arbitrage opportunities.\n\n\nComplexity. Time: O(Vâ‹…E)\n\nAll Pairs Shortest Path (APSP) Â§\nalg. Floyd-Warshall Shortest Path\n\nIdea: Dynamically Programmed algorithm. from i to j, compare the two paths:\n\niâ†’j using only vertices 1,â€¦,kâˆ’1\niâ†’kâ†’j, but only using vertices 1,â€¦,kâˆ’1\nTake the smaller of the two.\n\n\nExample: \nDP Table: memo[k][i][j] is the shortest path from iâ†’j using nodes 1..k\nSee also: Floydâ€“Warshall algorithm - Wikiwand\n\n\nComplexity. Time: O(V3), Space O(V2) by retaining most recent only\n\nTips and Tricks Â§\n\nIf the problem demands you multiply edge weights instead of summing them, use log of weights instead to transform it back into a problem with summation of edge weights. (See Example)\n"},"Signaling-Game":{"title":"Signaling Game","links":[],"tags":["Economics/Game-Theory"],"content":"\nSignaling game because one is attempting to signal to another authentically.\nHandicap principle - Wikiwand is an instance of the signaling game. Animals will signal their sexual prowess at the cost of actual function."},"Simultaneous-Equation-Model":{"title":"Simultaneous Equation Model","links":["Two-Stage-Lease-Squares-Regression"],"tags":["Math/Statistics"],"content":"Simultaneous Equation Models use Two-Stage Lease Squares Regression to analyze circular causality.\n\n\nThe two dependent variables with circular causality is Y1â€‹,Y2â€‹\nY1â€‹,Y2â€‹ are caused respectively by Z1â€‹,Z2â€‹\nW cause both Y1â€‹,Y2â€‹.\nThe equation is thus:\n\nY1iâ€‹Y2iâ€‹â€‹=Î²0â€‹+Î²1â€‹Y2iâ€‹+Î²2â€‹Wiâ€‹+Î²3â€‹Z1â€‹+Ïµ1iâ€‹=Î³0â€‹+Î³1â€‹Y1iâ€‹+Î³2â€‹Wiâ€‹+Î³3â€‹Z1â€‹+Ïµ1iâ€‹â€‹â€‹\nThe process for regression is same as the Two-Stage Lease Squares Regression:\n\nFor the first equasion Y1iâ€‹:\n\nFirst stage: regress Y2â€‹without Y1â€‹:\n\n\n\nY2iâ€‹=Ï€0â€‹+Ï€1â€‹Wiâ€‹+Ï€2â€‹Z1â€‹+Î½iâ€‹\n2. Second stage: regress $Y_{1}$ againt $\\hat{Y_{2}}$ (the original equation):\n\nY1iâ€‹=Î²0â€‹+Î²1â€‹Y2iâ€‹^â€‹+Î²2â€‹Wiâ€‹+Î²3â€‹Z1â€‹+Ïµ1iâ€‹\n\nPerform the same 2SLS regression for the second equation as well\n"},"Ski-Rental-Algorithm":{"title":"Ski Rental Algorithm","links":[],"tags":["Economics/Game-Theory"],"content":"Motivation. At a ski resort you are trying to decide whether to buy a ski or rent:\n\nYou will be there for T days\nIt costs \\1torentaski,and$B$ to buy the ski\n\nBâ‰ªT\n\n\nOn day â„“ you will wake up and say: â€œI donâ€™t want to ski anymoreâ€ and go home\nWhat should be your strategy? An online algorithm answers this question.\nThe OPT algorithm is our benchmark, and it has information that we donâ€™t have. The OPT algorithm for this problem is:\n\ndef. Optimal Ski Rental Algorithm.\nOPT={ifÂ â„“&gt;BifÂ â„“&lt;Bâ€‹buyrentâ€‹=min{l,B}\nDeterministic Ski Renter Algorithm Â§\nExample. Suppose our strategy is to rent Bâˆ’1 days, and buy on the Bth day. Then:\n\nif â„“&gt;B then we will have rented for Bâˆ’1 days, and bought on the B-th day so the total cost is 2Bâˆ’1\nif â„“&lt;B then we end up just renting for â„“ days, so the total cost is â„“\n\nOPTALGâ€‹â€‹={ifÂ â„“&gt;BifÂ â„“&lt;Bâ€‹B2Bâˆ’1â€‹&lt;2â„“â„“â€‹=1â€‹&lt;2â€‹â€‹\nSo even in the worst case, the algorithm will be less than 2â‹…OPT.\nthm. (Deterministic Algorithm Bound) Let a ALGkâ€‹ algorithm denote a deterministic algorithm that rents for kâˆ’1 days, and buys the ski at day k. For any k:\nALGkâ€‹â‰¥2â‹…OPT\nProof. Knowing k from the algorithm design, adversarial input â„“â†k will be ALG(k)â‰¥(2âˆ’B1â€‹)OPT(k). The deterministic algorithm is to rent until kâˆ’1th day, and buy on the k-th day.\n\nThe worst case adversarial situation for â„“ is â„“=k because this will force the user to rent for the maximum kâˆ’1 days, and then to buy as well.\n\nOPT=min{k,B}\nALG=(kâˆ’1)+b\nTherefore:\n\nOPTALGâ€‹â€‹=min{k,B}kâˆ’1+Bâ€‹=max{1+Bkâˆ’1â€‹,1+KBâˆ’1â€‹}=1+â‰¥1max{Bkâˆ’1â€‹,kBâˆ’1â€‹}â€‹â€‹â‰¥2â€‹â€‹\nSo even the best deterministic algorithm pays â‰¥2â‹…OPT. â– \nThis is devastating; we canâ€™t get past two-times better than the optimal. Instead, we should mix our strategies to overcome the adversary.\nProbabilistic Ski Rental Algorithm Â§\nExample. Let us imagine a probabilistic rental algorithm that:\n\nWith probability 21â€‹, stops renting and buys at day 43â€‹B\nWith probability 21â€‹, stops renting and buys at day B\nThis algorithm behaves differently depending on the true day you stop skiing, â„“:\n\n\nCase â„“&lt;43â€‹B:\n\nOPT=â„“\nE[ALG]=â„“\nOPTE[ALG]â€‹=1\n\n\nCase 43â€‹B&lt;â„“&lt;B:\n\nOPT=B\nE[ALG]=21â€‹buyÂ atÂ 43â€‹B(43â€‹B+B)â€‹â€‹+21â€‹buyÂ atÂ B(B+B)â€‹â€‹=815â€‹B\nOPTE[ALG]â€‹=815â€‹\n\n\nCase B&lt;â„“:\n\nOPT=â„“\nE[ALG]=21â€‹Â rentÂ â„“â€‹â€‹+21â€‹Â rentÂ thenÂ buyÂ (43â€‹B+B)â€‹â€‹\nOPTE[ALG]â€‹=Â thisÂ isÂ caseÂ B&lt;â„“21â€‹+78â€‹â„“Bâ€‹â‰¤21â€‹+78â€‹â€‹â€‹=711â€‹\nTherefore we have the worst of these cases bound:\n\n\n\nOPTE[ALG]â€‹â‰¤815â€‹\nWhich is slightly better than deterministic. This is, however, nowhere close to how good we can be:\ndef. Optimal Probabilistic Ski Algorithm. The optimal algorithm is to, on waking up every day:\nâ©â¨â§â€‹IfÂ day&lt;BIfÂ day=Bâ€‹thenÂ {BuyÂ withÂ probabilityÂ B1â€‹RentÂ withÂ probabilityÂ 1âˆ’B1â€‹â€‹Â thenÂ justÂ buyâ€‹\nThis algorithm will have:\nOPTE[ALG]â€‹â‰¤eâˆ’1eâ€‹â‰ˆ1.58\n(We wonâ€™t prove this)"},"Sliding-Window-Technique":{"title":"Sliding Window Technique","links":[],"tags":["Computing/Algorithms"],"content":"â€œMaximum consecutive somethingâ€/â€œMaximum Substringâ€ â‡’ think sliding window.\n\nSliding windows can stretch or shrink in length\nItâ€™s a kind of greedy algorithm\nyou can do many things in O(1) time.\nIt can do flipping and stuff too!\n\nExample of complex sliding window problem:\n#1004 - Maximum Consecutive Ones with Flipping"},"Sociology-110D":{"title":"Sociology 110D","links":[],"tags":["Courses"],"content":"EQUIRED COURSE TEXTS AND TECHNOLOGY:\n(1) Conley, Dalton. 2015. You May Ask Yourself: An Introduction to Thinking Like a Sociologist (4th\nEdition). New York: W.W. Norton.\nAvailable at reduced cost as an e-book or online rental\n(http://books.wwnorton.com/books/webad.aspx?id=4294989745). There are many inexpensive\nused copies of the fourth and third editions at Amazon.com, etc.\nA list of required pages/sections will be available on Sakai.\nHenslin, James (Editor). 2007. Down to Earth Sociology: Introductory Readings (14__th Edition).\nNew York: Free Press"},"Solipcism":{"title":"Solipcism","links":["The-Environment","Saint-maur"],"tags":["Sociability","Philosophy"],"content":"Every thought about giving advice # We are all different people\n\nPeople differ a lot in their levels of conscientiousness, extraversion, energy, ambition, curiosity, independence, risk-seeking, fame-seeking, neuroticism, conflict-aversion, obsessiveness, etc. By default, high conscientiousness people donâ€™t understand low conscientiousness people. High extraversion people donâ€™t understand low extraversion people. High energy people donâ€™t understand low energy people. Itâ€™s actually worse than that because â€œhigh neuroticismâ€ or â€œhigh ambitionâ€ can actually mean a ton of different things.\n\n\nWhile all theories dictate solitude is important for you in that it allows for space to think, to introspect, and generally to maneuver, when you are lacking The Environment that allows you to be by yourself you need to strategize with the resources available. Understanding exactly when and how you feel free and alone helps determine the environments you can generate to fulfill this need. These are the variables of solitude.\n1. The Environment Â§\n\nThe less people in The Environment, and the less they know you, you feel more free. In a train full of people youâ€™re perfectly free to think any thought you want. The more anonymous they are the better.\nFamiliarity allows more freedom. When you have expectations fulfilled there is less need for processingâ€”everything is as-is. This is why you can think better in a room that you completely control and design. You are perfectly familiar with all the furniture, and all the tools required for thinking are accessible.\nAccessible Thinking Tools. Notebooks. Phones. Computers.\n\n2. Perceptions Â§\n\nThe more anonymous the better. The less they know you the less you have to care for them. When they become mere background characters in your perception this is ideal\nBlock visual and auditory noise. Simply blocking noise out of sight and hearing helps generate a sense of freedom and solitude. Noise-canceling headphones and curtains will help in this regard.\n\n3. Interpretation Â§\n\nNotice how little people actually care about what youâ€™re doing. Fundmental Misunderstanding; Self-Attention. The portion of thought assigned to you in another personâ€™s brain is miniscule.\n\n\nThe woled isfounded on imperfection and misinformation\nWhen youâ€™re Finally Comfortable Being Alone, then You Are Able toâ€¦ Â§\nWhen youâ€™re Finally Comfortable Being Alone, then You Are Able to Enjoy Company. Â§\nSaint maur 12 grade.\nDuke beginning. Vic? Zoe."},"Sorting-Algorithms":{"title":"Sorting Algorithms","links":["Priority-Queue"],"tags":["Computing/Algorithms"],"content":"\n\n                  \n                  Abstract \n                  \n                \nBest sort algorithm (merge sort) will take O(nlogn) at worst.\n\nQuick Sort Â§\nIdea:\n\nChoose pivot\nEverything left of pivot is smaller, everything right of it is bigger (O(n))\nCall quicksort on the left side and right side\n\nChoosing a good pivot\n\nRandom\n\nWith high probability pivot within 31â€‹âˆ¼32â€‹\nLikely Complexity: T(n)â‰¤T(32â€‹n)+cn=O(n)\n\n\nDSelect i.e. Median of medians approach \n\nRank is guaranteed to be between 41â€‹âˆ¼43â€‹ of the array slice\nComplexity: T(n)â‰¤T(5nâ€‹)+T(43â€‹n)+cn=O(n) â€¦â€¦first term: DSelect, second term quicksort\n\nâ†’ T(n)&lt;Aâ‹…n for some Aâ‰¥20c (=O(n))\n\n\n\n\n\nMerge Sort Â§\nIdea:\n\nSplit into two\nCall mergesort on each left, right side\nmerge left, right side in O(n) time\n\nalg. Parallel Merge\nIdea: For the 8 elements shown below, can we find out how to place the element in parallel (8 simultaneous processes)? â†’ We can!\n\nLeft half: binary search on right half for correct place\nRight half: binary search on left half for correct place\n\n\ndef PMerge(A[1..n], m)\n\t# Ind[i] stores the final index of the i-th element\n\t\n\t# left half\n\tparallel for i=1 to m\n\t\t# search in right half\n\t\tInd[i] &lt;- BinarySearch(in A[m+1..n] for A[i]) + i\n\t# right half\n\tparallel for j=m+1 to n\n\t\t# search in left half\n\t\tInd[i] &lt;- BinarySearch(in A[1..m] for A[j]) - m + j\n\tsync\n \n\t# place each item in their ordered location\n\tparallel for i=1 to n\n\t\tB[Ind[i]] &lt;- A[i]\n\tparallel for i=1 to n\n\t\tA[i] &lt;- B[i]\n\t\n\nSpan O(logn)\n\nthen we haveâ€¦\nalg. Parallel Merge Sort\ndef PMergeSort(A[1..n])\n\t# base case\n\tif n &gt; 1\n\t\tm = ceiling(n/2)\n\tspawn PMergeSort(A[1..m])\n\tspawn PMergeSort(A[m+1..n])\n\tsync\n\tPMerge(A[1..m],A[m+1..n])\n\nSpan Tâˆâ€‹(n)â‰¤Tâˆâ€‹(2nâ€‹)+O(logn)=O(log2n)\nWork Wâˆâ€‹â‰¤2Wâˆâ€‹(2nâ€‹)+O(nlogn)=O(nlog2n)\n\nSecond term is work done by parallel merge procedure: correctly placing n items, each takes O(logn).\n\n\n\nalg. Inversion Counting. In an unsorted array A[1..n] count how many pairs A[i],A[j] are not in the correct order\n\nIdea: Mergesort, but during the merge step check how many times you need to reverse the pairs\n\n\nPartially Sorted Â§\nUses of partially sorted arrays:\n\nTop k items: e.g. Google Search, College Admissions\nk-th largest/smallest item\n\nk-th smallest item (=item of rank k) =&gt; use Tournament Tree"},"Species-being":{"title":"Species-being","links":["Humanism"],"tags":["Philosophy/Marxism"],"content":"= Marxist Humanism\n\nMan is a species-being, not only because he practically and theoretically makes the species - both his own and those of other things - his object, but also - and this is simply another way of saying the same thing - because he looks upon himself as the present, living species, because he looks upon himself as a universal and therefore free being.\n\n\nFor in the first place labour, life activity, productive life itself appears to man only as a means for the satisfaction of a need, [But] the whole character of a species, its species-character, resides in the nature of its life activity, and free conscious activity constitutes the species-character of man. Life itself appears only as a means of life.\n\n\nThe object of labour is therefore the objectification of the specieslife of man: for man reproduces himself not only intellectually, in his consciousness, but actively and actually, and he can thereÂ­ fore contemplate himself in a world he himself has created.\n"},"Sponsored-Search-Auction":{"title":"Sponsored Search Auction","links":[],"tags":["Economics/Game-Theory"],"content":"def. Sponsored Search Auction. This is a different game layout. Imagine a search engine selling advertisement slots. \n\n\nThere are k ad slots, with click-thru rate, largest to smallest: Î±1â€‹,â€¦,Î±kâ€‹\nThere are n bidders, for whom the value-per-click is v1â€‹,â€¦,vnâ€‹. Each bids biâ€‹ to get any slot.\nThen, if bidder i is assigned slot l and charged piâ€‹(b) \n\nAllocation matrix is x and xilâ€‹=1\nprice matrix is p and pilâ€‹ is the price charged\n\n\n\ndef. Generalized Second Price Auction."},"Spontaneous-Organization":{"title":"Spontaneous Organization","links":["Value-of-Money"],"tags":["Economics/Game-Theory","Philosophy/Political-Philosophy"],"content":"Money is an example of spontaneous organization: Devonthink"},"Stable-Marriage-Problem":{"title":"Stable Marriage Problem","links":["CS535-HW5"],"tags":["Computing/Algorithms","Economics/Game-Theory"],"content":"def. Stable Marriage Problem. Given equal number of heterosexual men and women, where each person has ranked all members of the opposite sex in order of preference, how can we marry the men and women together such that there are no non-married pair (m,w) who would both marry each other than their current partners (=in a unstable marriage)?\nExamples.\n\nResidentâ€”hospital matching\nhigh schoolâ€”student matching\n\ndef. Galeâ€“Shapely Stable Matching Algorithm (GSSMA) (=propose-accept algorithm) \n\nEvery dayâ€¦\n\nEach man who isnâ€™t engaged proposes to their top women that didnâ€™t reject them before\nEvery women who gets proposed to by m1â€‹,m2â€‹,â€¦\n\nâ€¦if theyâ€™re already engaged to some m0â€‹: accept max[m0â€‹,â€¦], reject everybody else.\nâ€¦if theyâ€™re not engaged to some m0â€‹: accept max[m1â€‹,â€¦], reject everybody else\n\n\n\n\nRepeat until completes\n\nthm. (GS always terminates at full matching)\nLemma. If woman w rejects man m, in all future scenarios w is engaged to mâ€² who she likes better than m.\nProof by Contradiction. Suppose there is a man m who is not matched; i.e. m is rejected by everybody.\n\nBy the lemma, all women are engaged to somebody better than m.\nBut if all women are engaged, and there are equal number of men and women, m cannot exist. â– \n\nthm. (GS matching is stable)\nProof by contradiction. Assume there exists an unstable match (m1â€‹,w2â€‹),(m2â€‹,w1â€‹), but w1â€‹â‰»m1â€‹â€‹w2â€‹ and m1â€‹â‰»w1â€‹â€‹m2â€‹:\n\n\nm1â€‹ must have proposed to w1â€‹ and been rejected before proposing to w2â€‹ by the structure of the algorithm\nBy lemma above, w1â€‹â€™s final fiancÃ©, m2â€‹, must have been preferable to m1â€‹. But this is not true. This is a contradiction.â– \n\ndef. Valid Partner. w is a valid partner of m if there exists any stable matching where (m,w) is a match (doesnâ€™t have to be found by GS).\nthm. (Proposer wins in GS). GS where men propose, men get the best valid partner possible. In other words all men m with their set of valid partners Smâ€‹âŠ†Women, never get rejected by any women in Smâ€‹.\nProof by Contradiction. Assume there exists a valid rejection of a manâ€™s proposal by a woman. Consider the first timepoint when a man m gets rejected by a valid partner w.\n\nw must have rejected m because she is already engaged with mâ€² who she prefers more. (â€¡)\nw is engaged to man mâ€². mâ€²â€™s most preferred partner in Smâ€‹ is w by definition of this timepoint (â€ )\n\nNow, consider a completely different stable match (not by GS). There must exist a stable matching where (m,w) is a match because w is a valid partner of m. In this matching, let wâ€² be mâ€²â€™s match.\nNow, wâ€² is not the most preferred valid partner Smâ€²â€‹ because mâ€² prefers w the most, as we saw in (â€ ). w also is unsatisfied with m because she prefers mâ€² more (â€¡). Therefore this is not a stable matching; this is a contradiction. â– \n\nRemark. Extensions of this stable matching problem is done in CS535 HW5."},"Standardizing-a-Random-Variable":{"title":"Standardizing a Random Variable","links":["Normal-Distribution"],"tags":["Math/Probability"],"content":"\nAny random variable X can be standardized\n\n! It doesnâ€™t have to be normally distributed\n\n\nFor a single random variable:\n\nY=SD(X)Xâˆ’E(X)â€‹\n\nFor X1â€‹â€¦Xnâ€‹\n\n"},"Standpoint-Theory":{"title":"Standpoint Theory","links":[],"tags":["Philosophy/Queer-Theory"],"content":"(DevonThink) Feminist Standpoint Theory | Internet Encyclopedia of Philosophy"},"Stat-230-Probability":{"title":"Stat 230 Probability","links":["Probability","Conditional-Probability","Independence-(Math)","Random-Variable","Expected-Value","Variance","Distribution-(Math)","Exponential-Family","Binomial-Distribution","Multinomial-Distribution","Hypergeometric-Distribution","Poisson-Distribution","Exponential-Distribution","Uniform-Distribution","Normal-Distribution","Gamma-Distribution","Approximating-Distributions","Central-Limit-Theorem","Poisson-Limit-Theorem","Confidence-Intervals","Change-of-Variable-(Probability)","Joint-Distributions","Covariance","Correlation","Conditional-Distribution"],"tags":["Courses"],"content":"Probability Basics Â§\n\nProbability\nConditional Probability\nIndependence (Math)\nRandom Variable\nExpected Value, Variance Identities\n\nDistribution Manipulation Â§\n\nDistribution (Math)\n\nDistribution (Math)\nExponential Family\n\n\nDiscrete Distributions\n\nBinomial Distribution\nMultinomial Distribution\nHypergeometric Distribution\nPoisson Distribution\n\n\nContinuous Distributions\n\nExponential Distribution\nUniform Distribution\nNormal Distribution,\nGamma Distribution\n\n\nApproximating Distributions\nCentral Limit Theorem\nPoisson Limit Theorem\n\nAdvanced Probability Â§\n\nConfidence Intervals\nChange of Variable (Probability)\nJoint Distributions\nCovariance, Correlation\nConditional Distribution, Conditional Expectation\n"},"Stat-432-Statistics":{"title":"Stat 432 Statistics","links":["Estimator","Sufficiency","Likelihood-(Statistics)","Fisher-Information","Maximum-Likelihood-Estimator","Consistency","Chebyshev's-Inequality","Moment-(Probability)","Confidence-Intervals","Hypothesis-Testing","Student's-t-test","Wilcoxon-Signed-Rank-Test","Wilcoxon-Rank-Sum-Test","Permutation-Test","Bernouilli-Distribution","Chi-Squared","Student's-T-Distribution"],"tags":["Courses"],"content":"\n\n                  \n                  All models are wrong, but some models are useful. \n                  \n                \n\nBasic Statistics Â§\n\nEstimator\nSufficiency\nLikelihood (Statistics)\nFisher Information\n\nEstimators Â§\n\nMaximum Likelihood Estimator\nConsistency\n\nChebyshevâ€™s Inequality\n\n\nMethod of Moment (Probability)\n\nStatistical Testing Â§\n\nConfidence Intervals\nHypothesis Testing\n\nStudentâ€™s t-test\nWilcoxon Signed Rank Test\nWilcoxon Rank Sum Test\nPermutation Test\n\n\n\nNew Distributions Â§\n\nBernouilli Distribution\nChi-Squared\nStudentâ€™s T-Distribution\n"},"Statistical-Triple":{"title":"Statistical Triple","links":[],"tags":["Math/Statistics"],"content":"A probability triple where the outcome space is instead a sample space, defines a statistical experiment.\n(Î©,F,P) where Î© is the sample space, F=2Î©, and P:Fâ†’[0,1]\n\n\n                  \n                  Relationship between probability and statistics \n                  \n                \n\n"},"Stochastic-Calculus":{"title":"Stochastic Calculus","links":["Riemannâ€“Stieltjes-integral","Reimann-Integral","Stochastic-Process"],"tags":["Math/Calculus"],"content":"def. Ito Integral. Let the following:\n\nBrownian Motion B={Bsâ€‹âˆ£sâ‰¥0}, an Ito process X={Xsâ€‹âˆ£sâ‰¥0}\n0=t1â€‹&lt;t2â€‹&lt;â‹¯&lt;tnâ€‹=t and thus tiâ€‹=ntâ€‹i\nThen the Ito integral Ytâ€‹ of X(t) with respect to B(t) is defined as such:\n\nY(t)=âˆ«0tâ€‹X(s)dB(s):=nâ†’âˆlimâ€‹i=0âˆ‘nâ€‹X(tiâˆ’1â€‹)[Btiâ€‹â€‹âˆ’Btiâˆ’1â€‹â€‹]\n\nVisualization. Think of the 3D visualization of the Riemannâ€“Stieltjes integral, but both f(x) and g(x) are zigzags.\nThe solution to the Ito integral is also a stochastic process Y={Ytâ€‹âˆ£tâ‰¥0}. It also has the following properties because the integrator is Btâ€‹\n\nYtâ€‹ is a martingale\nE(Ytâ€‹)=0\nlet Ztâ€‹=âˆ«0tâ€‹X(s)2dB(s)\n\nIto Isometry: Var(Ytâ€‹)=E(Ztâ€‹) \nYtâ€‹âˆ¼N(0,E(Ztâ€‹))\n\n\n\n\n\nRemark. We often use shorthand notation (abuse of notation) to write an integral term like this:\n\ndBtâ€‹:=âˆ«0tâ€‹1dBsâ€‹:=âˆ‘i=1âˆâ€‹1â‹…(Btiâ€‹â€‹âˆ’Btiâˆ’1â€‹â€‹)\nXtâ€‹dBtâ€‹:=âˆ«0tâ€‹Xsâ€‹dBsâ€‹:=âˆ‘i=0âˆâ€‹Xtâ€‹(Btiâ€‹â€‹âˆ’Btiâˆ’1â€‹â€‹)\ndt:=âˆ«0tâ€‹1dt:=âˆ‘i=0âˆâ€‹1(ti+1â€‹âˆ’tiâ€‹)=t by definition of the Reimann Integral\nXtâ€‹dt:=âˆ«0tâ€‹Xsâ€‹ds:=\nNow, these also exist but they are trivial (Ito Isometry):\ndBdt=dtdB=0\n(dt)2=0\n(dB)2=dt\n\nReference Table of Common Ito Integrals\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStochastic IntegralResultVarianceâˆ«0tâ€‹dBsâ€‹Btâ€‹tâˆ«0tâ€‹sdBsâ€‹tBtâ€‹âˆ’âˆ«0tâ€‹Bsâ€‹ds31â€‹t3âˆ«0tâ€‹Bsâ€‹dBsâ€‹21â€‹Bt2â€‹âˆ’21â€‹t21â€‹t2âˆ«0tâ€‹Bs2â€‹dBsâ€‹31â€‹Bt3â€‹âˆ’âˆ«0tâ€‹Bsâ€‹ds3t2âˆ«0tâ€‹eBsâ€‹âˆ’21â€‹sdBsâ€‹eBtâ€‹âˆ’21â€‹tâˆ’1etâˆ’1\nMotivation. Unfortunately we cannot calculate ito intergrals directly. For example, as we saw in the above example finding âˆ«0tâ€‹B(s)dB(s) using just the definition was a laborious process. In order to make this easier, we use the following lemma.\nthm. Itoâ€™s Lemma. (Itoâ€™s Chain Rule) The stochastic calculus chain rule. Stated in two ways.\n\nX(t) is an Ito process dX(t)=a(X,t)dt+b(X,t)dB\nf(X,t) is a normal function\nThen:\n\ndf(X,t)=(ftâ€‹+afxâ€‹+2b2â€‹fxxâ€‹)dt+bfxâ€‹dB\n\nfxâ€‹=âˆ‚xâˆ‚fâ€‹âˆ£x=Xâ€‹, ftâ€‹=âˆ‚tâˆ‚fâ€‹\n\nExample. Suppose we want to find the integral âˆ«0tâ€‹Bu2â€‹âˆ’udBuâ€‹. Since itâ€™s nearly impossible to find it from the definition of the Ito integral, let us use Itoâ€™s lemma. Arbitrarily set an ordinary function f(x,t)=3x3â€‹âˆ’tx.\n\n! Now, it is important to note that we normally donâ€™t know what function to use, but in this case assume we are given a nice f(x,t) that will lead to the answer. Given this function, we then have:\nfxâ€‹=x2âˆ’t, fxxâ€‹=2x, and ftâ€‹=âˆ’x\nBecause B is a standard brownian motion it conforms to the form dB=0â‹…dt+1â‹…dB which means for Itoâ€™s lemma a=0,b=1.\nThen, we use Itoâ€™s lemma:\n\ndf(B,t)f(Btâ€‹,t)âˆ’\\cancelto0f(B0â€‹,0)3Bt3â€‹â€‹âˆ’tBtâ€‹â€‹=(ftâ€‹+afxâ€‹+2b2â€‹fxxâ€‹)dt+bfxâ€‹dB=\\cancelto0(âˆ’x+0+21â€‹â‹…2x)dt+(x2âˆ’t)dB=(B2âˆ’t)dB=âˆ«0tâ€‹Buâ€‹âˆ’udBuâ€‹â€‹â€‹\nâ– \nReference.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMotion: Xtâ€‹Differential: dXtâ€‹=udt+udBtâ€‹Btâ€‹dBtâ€‹Bt2â€‹2Btâ€‹dBtâ€‹+dtBt2â€‹âˆ’t2Btâ€‹dBtâ€‹Bt3â€‹3Bt2â€‹dBtâ€‹+3Btâ€‹dteBtâ€‹eBtâ€‹dBtâ€‹+21â€‹eBtâ€‹dteBtâ€‹âˆ’21â€‹teBtâ€‹âˆ’21â€‹tdBtâ€‹e21â€‹tsinBtâ€‹e21â€‹tcosBtâ€‹dBtâ€‹e21â€‹tcosBtâ€‹âˆ’e21â€‹tsinBtâ€‹dBtâ€‹(Btâ€‹+t)eâˆ’Btâ€‹âˆ’21â€‹t(1âˆ’Btâ€‹âˆ’t)eâˆ’Btâ€‹âˆ’21â€‹tdBtâ€‹\nthm. Itoâ€™s Product Rule. for two stochastic processes Xtâ€‹,Ytâ€‹\nd(Xtâ€‹Ytâ€‹)=Xtâ€‹dYtâ€‹+Ytâ€‹dXtâ€‹+dXtâ€‹dtâ€‹\n\nIto Processes Â§\ndef. Ito Process. An Ito process X(t)={Xtâ€‹âˆ£tâ‰¥0} is a type of Stochastic Process that is defined by a certain a(Xtâ€‹,t),b(Xtâ€‹,t):\nX(t)=X(0)+âˆ«0tâ€‹a(Xsâ€‹,s)ds+âˆ«0tâ€‹b(Xsâ€‹,s)dB\n\na(Xtâ€‹,t) must be integrable in the ordinary sense\nb(Xtâ€‹,t) must be integrable in the stochastic sense\n\nIt actually needs to be integrable twice\nAs an abuse of notation we can write:\n\n\n\ndX=a(Xtâ€‹,t)â‹…ds+b(Xtâ€‹,t)â‹…dB\n\nThis is called a Stochastic Differential Equation (even if itâ€™s not actually a differential equation).\nEssentially, a function of an Ito process is also an Ito process.\n\nProperties.\n\nE(dYâˆ£Ftâ€‹)=(ftâ€‹+afxâ€‹+2b2â€‹fxxâ€‹)â‹…dt\nVar(dYâˆ£Ftâ€‹)=(bfxâ€‹)2\n"},"Stochastic-Process":{"title":"Stochastic Process","links":["Stochastic-Calculus","Quadratic-Variation"],"tags":["Math/Statistics"],"content":"def. Time Series is a stochastic process indexed by discrete (integer) time points.\n\nSee discussion: Is a time series the same as a stochastic process? - Cross Validated\n\ndef. Stochastic Process is simply the sum of the sequence of random variables: X1â€‹,â€¦,Xnâ€‹:\nWkâ€‹={âˆ‘i=1kâ€‹Riâ€‹w0â€‹â€‹ifÂ k&gt;0ifÂ k=0â€‹\n\n\nRiâ€‹ are identically distributed.: Stationary\n\n\nE(Wk+1â€‹âˆ£W1â€‹â€¦Wkâ€‹)=Wkâ€‹ then: Martingale\n\n\nP(Wk+1â€‹=wk+1â€‹âˆ£W1â€‹=w1â€‹,â€¦Wkâ€‹=wkâ€‹)=P(Wk+1â€‹=wk+1â€‹âˆ£Wkâ€‹=wkâ€‹): Markov\n\n\n                  \n                  random variable - Why do stochastic processes involve time? - Cross Validated\n                  \n                \n\n\n\nWeiner Process Â§\nStandard Weiner Process Â§\nMotivation. Assume there are random variables X1â€‹â€¦ as:\nXiâ€‹={nâ€‹1â€‹âˆ’nâ€‹1â€‹â€‹0.5Â probability0.5Â probabilityâ€‹\n\nlet Wkâ€‹ be a stochastic process such that:\n\nW(n)(t)=â©â¨â§â€‹0R1â€‹+â‹¯+Rtâ€‹affineÂ extensionÂ onÂ closestÂ intervalÂ â€‹ifÂ t=0ifÂ tâˆˆNelseâ€‹\nThen we get the Weiner process as:\nB(t)=nâ†’âˆlimâ€‹W(n)(t)\ndef. Brownian Motion. (=Weiner process) B(t) (written as Btâ€‹) is a set of random variables continuous-time indexed and has the following properties:\n\nIs a continuous process\nB0â€‹=0\nBtâ€‹âˆ’Bsâ€‹âˆ¼dâ€‹N(0,tâˆ’s)\n\nThus, Btâ€‹=dâ€‹N(0,t)\n\n\nAny interval Baâ€‹âˆ’Bbâ€‹ and Bcâ€‹âˆ’Bdâ€‹ where [a,b] and [c,d] do not overlap is independent.\nNotation wise, we think of B={Btâ€‹}tâ‰¥0â€‹, i.e. a set of random variables indexed by t.\n\nRemark. Brownian Motion can also be defined as an Ito Process that satisfies the following stochastic differential equation:\ndB=Î¼â‹…dt+Ïƒ2dB\nTrivially, in the case of standard brownian motion, Î¼=0,Ïƒ2=1 Thus dB=0â‹…dt+1â‹…dB.\nProperties. Brownian Motion satisfies the following properties:\n\nMartingale Property: Brownian motion is martingale: âˆ€sâ‰¤t,E(Btâ€‹âˆ£Fsâ€‹)=Bsâ€‹ where Fsâ€‹=Ïƒ(Bsâ€‹)\nMarkov Property:\n\nâˆ€sâ‰¥0,{Bs+tâ€‹,tâ‰¥0} is independent of Fsâ€‹ andâ€¦\n{Bs+tâ€‹,tâ‰¥0}=dâ€‹{Btâ€‹}\nAlternatively: P(Xuâ€‹âˆˆAâˆ£Ïƒ(Xsâ€‹))=P(Xuâ€‹âˆˆAâˆ£Xtâ€‹) where any combination sâ‰¤tâ‰¤u\n\n\nScaling Invariance: If Btâ€‹ is a brownian motion, then aB(a2t)â€‹ is also a brownian motion âˆ€a&gt;0\nQuadratic Variation property: [B]tâ€‹:=âˆ‘i=1nâ€‹(Btiâ€‹â€‹âˆ’Btiâˆ’1â€‹â€‹)2=t\n\nWith Scale and Drift Â§\ndef. Weiner Process with Drift and Scaling (WPDS). Such is a Weiner process X(t) that has the following properties:\n\nIs a continuous process\nX(0)=x0â€‹\nX(t+Î”t)âˆ’X(t)=dâ€‹N(Î¼Î”t,Ïƒ2Î”t)\nAny interval X(a)âˆ’X(b) and X(c)âˆ’X(d) where [a,b] and [c,d] do not overlap is independent.\n\n\nProperties:\n\nÎ¼: drift; the higher, the more it climbs \nÏƒ2: scaling; the higher, the more volatile (See y-axis:) \n\n\n\nthm. Standard WP to Scale and Drift. Given:\n\nB(t) is a standard Weiner process\nX(t) is a Weiner process with drift Î¼ and scaling Ïƒ2, with initial value x0â€‹\nâ‡’ Then the following relationship holds (two equivalent definitions)\n\nX(t)dX(t)â€‹=dâ€‹x0â€‹+Î¼t+ÏƒB(t)=Î¼â‹…dt+Ïƒâ‹…dB(t)â€‹â€‹\nGeometric Brownian Motion Â§\nthm. Geometric Brownian Motion. Given X(t) is a WPDS Î¼,Ïƒ2,x0â€‹ then the following is a geometric brownian motion with initial value S(0): (two equivalent definitions)\nG(t)dG(t)â€‹=G0â€‹exp[X(t)]=G0â€‹exp[x0â€‹+Î¼t+ÏƒB(t)]=(Î¼+2Ïƒ2â€‹)G(t)â‹…dt+ÏƒG(t)â‹…dB(t)â€‹â€‹\n\n\n                  \n                  Geometric to WPSD \n                  \n                \nThe following is equivalent:\n\ndS(t)S(t)â€‹=(Î¼+2Ïƒ2â€‹)S(t)â‹…dt+ÏƒS(t)â‹…dB(t)=S0â€‹exp[(Î¼âˆ’2Ïƒ2â€‹)t+ÏƒB(t)]â€‹â€‹\nProperties of Stochastic Processes Â§\ndef. Adapted process. A stochastic process {Xtâ€‹}tâ‰¥0â€‹ is adapted to filtration set {Ftâ€‹}tâ‰¥0â€‹ if âˆ€i,Xiâ€‹ is a Fiâ€‹-measurable function.\nIntuition. Recall that a sigma algebra F can be thought of as â€œresolution of informationâ€. Xiâ€‹ is realized and its information is Fiâ€‹. The series of filtrations F1â€‹âŠ‚F2â€‹âŠ‚â‹¯âŠ‚Ftâ€‹âŠ‚â‹¯âŠ‚F correspond to the series of random variables X1â€‹,X2â€‹,â€¦; for each timestep, the information gets higher and higher resolution.\nMartingale Process Â§\nMotivation. Many stochastic processes, including the standard brownian motion Btâ€‹ has the property that you canâ€™t predict future trajectory based on information from its past trajectory. We formalize this as a martingale.\ndef. Martingale. A stochastic process {Xtâ€‹}tâ‰¥0â€‹ on a filtered probability space (Î©,F,{Ftâ€‹},P) is a martingale w.r.t. its adapted filtration {Ftâ€‹} if:\nâˆ€sâ‰¤t,E(Xtâ€‹âˆ£Fsâ€‹)=Xsâ€‹\nThis is equivalent to saying\n\nâˆ€sâ‰¤t,E(Xtâ€‹)=E(Xsâ€‹) by taking expectation on both sides of above\nâˆ€sâ‰¤t,E(Xtâ€‹âˆ’Xsâ€‹)=0\n\nThis is a simple proof that brownian motion is a martingale; E(Btâ€‹âˆ’Bsâ€‹=dâ€‹N(0,tâˆ’s))=0\n\n\n\nQuadratic Variation Â§\nMotivation. Quadratic variation is not about variation of probability distributions. Itâ€™s a way to measure how â€œshakyâ€ a function (in this case, a Brownian motion) is in a given interval.\ndef. Quadratic Variation. For a stochastic process {Xtâ€‹}, its quadratic variation on interval [0,t], [X]tâ€‹ for 0=t0â€‹&lt;t1â€‹&lt;â‹¯&lt;tnâ€‹=t, is:\nnâ†’âˆlimâ€‹i=1âˆ‘nâ€‹(Xtiâ€‹â€‹âˆ’Xtiâˆ’1â€‹â€‹)2"},"Stonewall":{"title":"Stonewall","links":[],"tags":["Philosophy/Queer-Theory","History"],"content":"\nStonewall riots: A series of demonstrations by members of the LGBTQ+ community against a police raid that took place at the Stonewall Inn in Greenwich Village, New York City, in June 1969. This event is considered a pivotal moment in the fight for LGBTQ+ rights.\n"},"Stream-of-Content":{"title":"Stream of Content","links":[],"tags":["Computing/Internet"],"content":"In the internet, the problem is not finding content, but finding good content. Therefore, pick sparingly what you consume.\n\nUse RSS feeds to choose good sources to read\nWhen you have a list of content, pick out what you want, like how you would scoop a bucket from the river.\n\nDonâ€™t try to read the whole thing. Itâ€™s not efficient or useful.\nChoose what seems enticing or relevant\nApplies to articles, books, movies, tv shows, games, etc.\n\n\n"},"Strings-in-Rust":{"title":"Strings in Rust","links":[],"tags":["Computing"],"content":"\nAll rust string types use UTF-8\nstr is a string literal. You never use this\n\nEncoded into the program binary\n\n\n&amp;str is a string slice\n\nThis is the borrowed typ\n\n\nString is a string class\n\nIt has length, size, etc. all the information\nThis is the owned type\n\n\n"},"Student's-T-Distribution":{"title":"Student's T-Distribution","links":["Besset-Correction"],"tags":["Math/Common-Distributions"],"content":"def. Studentâ€™s T Distribution.\ntnâˆ’1â€‹âˆ¼Ïƒ^/nâ€‹âˆ‘i=0nâ€‹(Xnâ€‹Ë‰â€‹âˆ’Î¼)2â€‹\nwhere:\n\nXiâ€‹âˆ¼N(Î¼,Ïƒ2)\nÏƒ^ is the Besset-corrected standard deviation estimator\n\n\n\n                  \n                  Tip \n                  \n                \nItâ€™s called a Studentâ€™s t because it was from a beer brewery company, and the company didnâ€™t want the in-house statistician to publish it so he published it secretly.\nIntroduction to the t Distribution (non-technical) - YouTube\n"},"Student's-t-test":{"title":"Student's t-test","links":[],"tags":["Math/Statistics"],"content":"def. let X1â€‹,â€¦,Xnâ€‹âˆ¼iidN(Î¼,Ïƒ2). We are comparing two hypothesis:\n\n\nH0â€‹:Î¼â‰¤Î¼0â€‹\n\n\nH1â€‹:Î¼&gt;Î¼0â€‹\nThen, let T=Ïƒ^/nâ€‹XË‰nâ€‹âˆ’Î¼0â€‹â€‹ where Ïƒ^=nâˆ’1E[(XË‰nâ€‹âˆ’Xiâ€‹)]â€‹ is the besset-corrected variance estimator. We know that Tâˆ¼tnâˆ’1â€‹. Thus the Î³=1âˆ’Î±-level studentâ€™s (=Gossetâ€™s) t-test is:\n\n\nÎ´:{H0â€‹H1â€‹â€‹elseÂ ifÂ T&gt;tnâˆ’1â€‹(1âˆ’Î±)â€‹"},"Subset-Sum":{"title":"Subset Sum","links":["Common-Graph-Problems"],"tags":["Computing/Algorithms"],"content":"Q. Subset Sum Problem. Given a set of real numbers X={x1â€‹,â€¦,xnâ€‹} is there a subset of X that sum exactly to a certain integer k\n\nReduce from Vertex Cover\n"},"Substitution-Effect-(SE)":{"title":"Substitution Effect (SE)","links":[],"tags":["Economics/Micro-Economics"],"content":"Imagine you travel to the Cayman Islands with your twin. You both start with the same income. You choose to rent a car with upfront cost, while your brother chooses to take a taxi. Remember, you both have the same income; only different opportunity cost of miles traveled.\ndef. Substitution effect is when you change the consumption of a good due to a change in opportunity costs.\nObserve that you are still on the same indifference curve; the utility is the same.\n\nThe size of the effect has to do with how substitutable the two goods are; the more subsitutable the two goods, the bigger the substitution effect is (obvious verbally and graphically):\n"},"Sufficiency":{"title":"Sufficiency","links":["Exponential-Family"],"tags":["Math/Statistics"],"content":"Recall Exponential Family\nSufficiency Â§\ndef. let statistic T=T(X); and Xiâ€‹ depends on unknown parameter Î¸. Then T is a sufficient statistic for Î¸ if P[X=xâˆ£T=t] does not depend on Î¸.\n\n\n                  \n                  Info \n                  \n                \nIf the distribution of Xiâ€‹â€™s depends on unknown parameter Î¸, but the distribution of Xiâ€‹ given T=t does not depend on Î¸, it must be the case that all information about Î¸ is in T. Once the value of T is given, then Î¸ becomes irrelevant in determining the value of X.\n\n\n\n                  \n                  Info \n                  \n                \nThereâ€™s only one minimally sufficient statistic, and all other sufficient staistics are a function of this.\n\nthm. Fischer-Neymann factorization. T is a sufficient statistic iff:\n\ni.e. the joint density function can be factored into a a function of u,v where:\n\nu(X) does not depend on Î¸\nv(T(X),Î¸) depends on Î¸, and depend on X only through statistic T\nâ‡’ Intuitively, this menas when\n\n\n\n                  \n                  Info \n                  \n                \nVery convenient for determining if statistic is sufficient or not.\n\nlem 1. let Î¸^1â€‹ an estimator for Î¸ and T a sufficient statistic for Î¸\nthen Î¸^2â€‹=E[Î¸^1â€‹âˆ£T] is also a sufficient estimator.\nthm. Rao-Blackwell theorem. Continuing from above,\nMSE[Î¸^2â€‹]â‰¤MSE[Î¸^1â€‹]\n\n\n                  \n                  Info \n                  \n                \ni.e. if you throw more data into a statistic, it often becomes a better statistic.\n\n\nIn the exponential family of distributions, you can mostly do one iteration of Rao-Blackwell algorithm to get a pretty good estimator.\n\nBias of Î¸^ and Bias of Rao-Blackwellized E[Î¸^âˆ£T=t] is the same\n\n\nIf T is a minimally sufficient statistic, E[Î¸^âˆ£T=t] is the best you will do\n"},"Sustainable-Development-Goals":{"title":"Sustainable Development Goals","links":["United-Nations"],"tags":["Economics"],"content":"By the United Nations"},"Targeting-a-Niche":{"title":"Targeting a Niche","links":[],"tags":["Computing/Internet"],"content":"(DevonThink) &gt; The more precise and niche the words I input, the better the internet would maâ€¦ | Hacker News"},"Taxation":{"title":"Taxation","links":["Laffer-Curve"],"tags":["Economics"],"content":"Laffer Curve"},"Taylor-Approximation":{"title":"Taylor Approximation","links":[],"tags":["Math/Calculus"],"content":"f(x)â‰ˆf(a)+fâ€²(a)(xâˆ’a)+2!fâ€²â€²(a)â€‹(xâˆ’a)2+3!fâ€²â€²â€²(a)â€‹(xâˆ’a)3+â‹¯+n!f(n)(a)â€‹(xâˆ’a)n\nf(x)=n=0âˆ‘âˆâ€‹n!f(n)(a)â€‹(xâˆ’a)n"},"Technical-Notes-Index":{"title":"Technical Notes Index","links":["Nimf-Anthy-installation","Hacking-Flash-Apps","Yokosuka","Atsugi","lightdm---How-do-I-hide-a-particular-user-from-the"],"tags":["Computing"],"content":"Tasks for Atsugi-hamonikr Â§\n\n add volume keybindings to script\n make (sudo) script for nimf-anthy installation (see below)\n Wezterm configs (see)\n\n\nNimf-Anthy installation\nHacking Flash Apps\nSetting cinnamon settings in the command line\nMaizuru: Personal computer\nYokosuka: Personally managed server\nAtsugi: Remotely managed servers\nYokosuka\nAtsugi\nGeneral References Â§\nGitHub - tmux-plugins/tmux-resurrect: Persists tmux environment across system restarts.\nGitHub - pyoky/vimrc: The ultimate Vim configuration: vimrc\nHow To Configure WebDAV Access with Apache on Ubuntu 14.04 | DigitalOcean\nInstalling with Docker\nInstall Docker Engine on Ubuntu\nHTTP server on Docker with HTTPS\nlightdm - How do I hide a particular user from the"},"Technical-Rate-of-Substitution":{"title":"Technical Rate of Substitution","links":[],"tags":["Economics/Micro-Economics"],"content":"TRS=âˆ’âˆ‚f/âˆ‚kâˆ‚f/âˆ‚lâ€‹=âˆ’MPKâ€‹MPLâ€‹â€‹\nIsoquant\n\nSlope of isoquant is the technical rate of substitution\n\nIsocost\n\nc(l,k)=wl+rk\n"},"The-Human-Condition":{"title":"The Human Condition","links":[],"tags":["Philosophy"],"content":""},"The-Personal-Computer":{"title":"The Personal Computer","links":["Tools-and-Structures-Define-Your-Capacity","Living-With-the-Internet","Lifelong-Learning","Decentralization","Multidependence","Everything-is-a-File","Reliable-and-Scalable","(Article)-Evergreen-notes"],"tags":["Computing/Human-Interface","Logistics"],"content":"\nThe Personal Computer is an extension of the brain, a Bicycle of the Mind.\nThe personal computer is not a tool. Instead, it is a person you have a relationship with.\n\nThis is because you do not fully control your computer (!=definition of a tool). You influence your computer, and the computer influences you back.\nThe relationship can be positive or negative.\n\n\nThe personal computer is the interface and vehicle with which you explore the internet universe.\n(DevonThink) How To Become A Hacker This is the gospel for behaving within a culture of hackers. Things that particularly stand out is about asking good questions, discipline and competence, and Lifelong Learning.\n\nPrinciples Â§\n\nLifelong Learning\n\n(DevonThink) How do you remember all the Linux commands? - Quora\n(DevonThink) Why Windows Causes Stupidity - Why It Matters\n\n\nDecentralization\n\nKey components of your computer systems should follow decentralized models\ne.g. ActivityPub &gt; Twitter\ne.g. IPFS &gt; HTTPS\nThis also comes out of the principle of multidependence.\nOpen-source instead of closed-source\n\ne.g. Linux &gt; macOS\n\n\n\n\nOwn Your data\n\nServices that pay for you to access your own data will eventually disappear. Own your data.\nYour disk space should be ~1/3 empty. Keep it at that to allow for flexibility but not wasted space.\nPlaintext is the best format.\n\n\nEverything is a File\n\nDonâ€™t use Windows objects, proprietary databases for notes or databases that you donâ€™t own. Systems that donâ€™t embrace this approach will eventually likely fail.\n\n\nSoftware Maturity\n\nInstall mature software only (Operating Systems, etc.)\nan extension of having Reliable and Scalable things\n\n\nUse Software As Theyâ€™re Intended\n\nespecially: business software shouldnâ€™t be used for personal things.\ne.g. Obsidian &gt; Notion (business pivot)\n\n\nKnow to Surface Data\n\nPhotos go into where you view photos the most (Apple Photos library). Documents go where documents are surfaced the most (DevonThink).\nâ‡’ Data should be surface-able, like (Article) Evergreen notes\n\n\nLiving with Generative AI\n\nA â€œlanguage calculatorâ€\nEverybody gets a 100 interns. (GPT: The Second Renaissance - No Boilerplate)\n\n\n"},"Time-Complexity":{"title":"Time Complexity","links":["Recurrence-Relation"],"tags":["Computing/Algorithms"],"content":"Assumptions:\n\nRAM is constant time access\nMultiplication, addition, etc. are constant time\nConstant time operations are O(1)\nWe concern ourselves with asymptotic behavior, i.e. as nâ†’âˆ\n\nRecall there are only two models of computation\n\nTime complexity of loops: The time complexity of a loop is proportional to the number of iterations multiplied by the time complexity of the code inside the loop.\nTime complexity of recursion: The time complexity of a recursive function can be analyzed using a Recurrence Relation, which expresses the time complexity of the function in terms of its input size and the time complexity of its subproblems.\n\nRules of Computing Complexity Â§\n\nRule of sum: If an algorithm performs two precedural operations, and the total time taken by each operation is proportional to the size of the input n, then the time complexity is O(f(n)+g(n)), where f(n) and g(n) are the time complexities of the two operations.\nRule of product: If an algorithm performs two nested operations, and the time taken by the inner operation is proportional to the size of the input n, and the outer operation is performed n times, then the time complexity is O(f(n)âˆ—g(n)), where f(n) is the time complexity of the outer operation and g(n) is the time complexity of the inner operation.\nBig O notation ignores constant factors: When calculating the time complexity of an algorithm, we can ignore constant factors, such as the time taken by basic arithmetic operations, since they do not affect the overall growth rate of the function.\nBig O notation ignores lower-order terms: When calculating the time complexity of an algorithm, we can ignore lower-order terms, such as constants or logarithmic terms, since they become insignificant as n grows larger.\n\nNotation Â§\nComplexity is most often denoted in poly-logarithmic time:\nO(nklogjn)\nTypes of Complexity Analysis\n\nBest case analysis\nWorst case analysis\nAverage case analysis\nAmortized Analysis\n"},"Tradable-Inflation-Protected-Securities-(TIPS)":{"title":"Tradable Inflation-Protected Securities (TIPS)","links":[],"tags":["Economics/Finance"],"content":"Tradable Inflation-Protected Securities (TIPS) are a type of bond issued by the treasury that are like bonds (issued by govnâ€™t, pays coupon), but its principal changes based on inflation."},"Trade-Through":{"title":"Trade-Through","links":["Efficient-Market-Hypothesis"],"tags":["Economics/Finance"],"content":"is when a transaction occurs at a worse price than the market price. Itâ€™s usually prevented by regulation. A type of market inefficiency, a failure of the Efficient Market Hypothesis"},"Traffic-Routing":{"title":"Traffic Routing","links":["Maximum-Flow-Problem","Potential-Game","Nash-Equilibrium"],"tags":["Computing/Algorithms","Economics/Game-Theory"],"content":"Similar to Maximum Flow Problem. An instance of a Potential Game.\nAtomic Traffic Routing Â§\n\nThis time, there are n cars (not infinitesimally small). If player i chooses path Piâ€‹, then:\n\nmeâ€‹: traffic (=# of cars) flowing thru edge e\nIndividual cost: ciâ€‹(Piâ€‹,Pâˆ’iâ€‹â€‹)=âˆ‘eâˆˆPiâ€‹â€‹ceâ€‹(meâ€‹)\nPotential Function: Ï•(P)=âˆ‘âˆ€eâ€‹âˆ‘jâˆ’1meâ€‹â€‹ceâ€‹(meâ€‹)\n\nThis is similar to the integral of costs for each edge: \n\n\n\nthm. (Potential function minimization derives PNE) Minimizing the following potential function will give you the PNE.\nÎ¦(f)=Â OverÂ everyÂ edgeÂ eâˆˆEâˆ‘â€‹â€‹â€‹Â AreaÂ underÂ costÂ functionÂ i=1âˆ‘feâ€‹â€‹ceâ€‹(i)â€‹â€‹\nProof. The inner summation above is Intuitively the area under the cost, as illustrated above.\nThen, consider an agent i deviated from path Piâ€‹ to Piâ€‹^â€‹, which as a whole is a change from flow f to f^â€‹. Then the difference in potential of these two flows is:\nÎ¦(f^â€‹)Î¦(f^â€‹)âˆ’Î¦(f)â€‹=Î¦(f)+Â addÂ deviatedÂ edgesÂ eâˆˆPiâ€‹^â€‹âˆ–Piâ€‹âˆ‘â€‹ceâ€‹(f+1)â€‹â€‹âˆ’Â removeÂ undeviatedÂ edgesÂ eâˆˆPiâ€‹âˆ–Piâ€‹^â€‹âˆ‘â€‹ceâ€‹(f)â€‹â€‹=Â iÂ â€™sÂ costÂ atÂ Piâ€‹^â€‹eâˆˆPiâ€‹^â€‹âˆ‘â€‹ceâ€‹(f^â€‹)â€‹â€‹âˆ’Â ...atÂ Piâ€‹Â eâˆˆPiâ€‹âˆ‘â€‹ceâ€‹(f)â€‹â€‹â€‹â€‹\n\nThus, each userâ€™s goal is to minimize this potential function. Therefore the minimum of the potential function is the pure strategy nash eqilibirum. â– \nthm. (existence of PNE). Proof outline. This potential function will have one global minimum, if the cost functions are monotonically increasing (v.v. strictly increasing) and continuous, making Î¦ a (v.v. strictly) convex function which has a global minimum (v.v. a single global minimum). This shows that it PNE will always exist for monotonic cost functions. â– \nNonatomic Traffic Routing Â§\nDefinitions Â§\n\nflow on edge e is xeâ€‹\nCongestion Function ceâ€‹(xeâ€‹) i.e. time taken\nIndividual Delay for Path P: âˆ‘eâˆˆPâ€‹ceâ€‹(xeâ€‹)\nTotal Delay for all paths: âˆ‘âˆ€carsâ€‹âˆ‘eâˆˆPâ€‹xeâ€‹â‹…ceâ€‹(xeâ€‹)\n\nPigouâ€™s Example Â§\n\n\nNash Equilibrium when\n\nFor all users of edge a, caâ€‹(xaâ€‹)â‰¤cbâ€‹(xbâ€‹)\nFor all users of edge b, cbâ€‹(xbâ€‹)â‰¤caâ€‹(xaâ€‹)\n\n\nTotal delay =(0â‹…1)+(1â‹…1)=1\n\n\nGlobal Optimum when:\n\nTotalÂ Delayâ€‹=(xaâ€‹â‹…1)+(xbâ€‹â‹…xbâ€‹)=1âˆ’xbâ€‹+xb2â€‹â€‹â€‹\nâ‡’ Total delay minimized when half goes thru a, other half goes thru b\nBraessâ€™s Paradox Â§\ni.e. adding a new road may worsen outcome for Nash Equilibrium (but not in global minimum)\n\n\nConsider before and after adding edge from bâ†’a, a superhighway with zero delay cost.\nNE before adding blue edge:\n\n0.5 on top (sâ†’aâ†’t)\n0.5 on bottom (sâ†’bâ†’t)\nTotalÂ Delay=23â€‹\n\n\nNE after adding blue edge (superhighway):\n\nall passes thru green path (sâ†’bâ†’aâ†’t)\nTotalÂ Delay=2 (worse!)\n\n\n\nFor Social Plannerâ€¦ Â§\nObserve that congestion network is a convex optimization problem:\n\nTotal Delay function is a convex function\nConstraints (=conversation of flow) are linear:\n\nâˆ€v inflow = outflow\nâˆ‘ flow at source/target is 1\nfeâ€‹â‰¥0\n\n\n\nFor Obtaining Nash Equilibirumâ€¦ Â§\nthm. Routing NE Uniqueness. For every routing problem there is only one NE.\nthm. Obtaining NE of Congestion Network. Minimizing the following function Ï• will yield the unique NE of any congestion network:\nÏ•(fâ€‹)=eâˆˆEâˆ‘â€‹2aeâ€‹fe2â€‹â€‹+beâ€‹feâ€‹â€‹â€‹\nProof Sketch. The following definition of Ï• will satisfy the definition of a potential function\nÏ•(fâ€‹)â€‹:=eâˆˆEâˆ‘â€‹âˆ«0feâ€‹â€‹ceâ€‹(x)dx=eâˆˆEâˆ‘â€‹[2aâ€‹x2+bx]0feâ€‹â€‹=eâˆˆEâˆ‘â€‹2aeâ€‹fe2â€‹â€‹+beâ€‹feâ€‹â€‹â€‹\nâ– "},"Traveling-Salesperson-Problem":{"title":"Traveling Salesperson Problem","links":["Minimal-Spanning-Tree-Problem","Depth-First-Search"],"tags":["Computing/Algorithms"],"content":"\n\n                  \n                  Problem: \n                  \n                \nGiven a list of cities and the distances between each pair of cities, what is the shortest possible route that visits each city exactly once and returns to the origin city?\n\n\n\nBrute Force: O(âˆ£Vâˆ£!)\n\n\nHeldâ€“Karp algorithm: O(n2â‹…2n)\n\n\nRecord: O(1.728n)\n\n\nTSP is not in NP, and is NP-Hard\n\n\nMetric TSP (MTSP) Â§\nalg. Tree-MTSP Approximation.\n\nRun MST\nRun DFS on the MST, record pre-time\nTraverse the graph in the pre-time order\n\n\nIs 2-approximation\n\nalg. Christofids MTSP Approximation"},"Tree":{"title":"Tree","links":["graph"],"tags":["Computing/Data-Structures"],"content":"def. Tree. A Tree is an undirected connected acyclical graph\n\nBalanced Tree\nBinary Search Tree\n"},"Turing-Machine":{"title":"Turing Machine","links":["Limits-of-Math-and-Computing"],"tags":["Computing/Formal-Languages"],"content":"A Turing machine:\n\nIs most powerful type of automation (probably.)\nCannot solve the halting problem.\nCan be used to prove Limits of Math and Computing.\n\n\n\n                  \n                  Turing Machine \n                  \n                \n\n&gt;M=(Q,Î£,Î“,Î´,q0â€‹,B,F)&gt;\n\nwhere the previously unencountered symbols are:\n\nQ: States\nÎ£: Input Alphabet\nÎ“: Tape Alphabet (superset of Î£)\nq0â€‹: Start state\nF: Set of en states\nB: Blank (also written as â–¡)\nÎ´:QÃ—Î“â†’QÃ—Î“Ã—{L,R}\n\n\nConfiguration and transition of a TM is denoted:\nwqvâŠ¢wâ€²qâ€²vâ€²\nÎ´(q,v)=(qâ€²,v,R)\nâ†’ where the configuration is denoted as (state,Â writeÂ symbol,Â moveÂ left/right)\nIn this case the head is reading the first symbol of v, i.e. the right-side letter.\n\nTuring Machines as Language Recognizers/Acceptors Â§\nL(M)={wâˆ£q0â€‹wâŠ¢vqfâ€‹w}\nâ‡’ Then w is in the language of the TM.\nYou can also think of it as the turing machine â€œhaltingâ€ on the final state.\n\nIf TM halts on a final state, w is accepted\nIf TM halts on a non-final state w is not accepted\nIf TM doesnâ€™t halt, w is not accepted\n\nTuring Machines as a Transducer [= Transformation on a language] Â§\ndef. A function f(w) is Turing-Computable if:\nâˆ€w,Â Â q0â€‹wâŠ¢âˆ—qfâ€‹f(w)\nExample of a Turing Machine representing a turing-computable function:\n\nTuring Machine Building Blocks Â§\n\nM1â€‹â†’M2â€‹\nM1â€‹â†’xM2â€‹: run if x is the current output â† you can also have mutiple conditionals\n\nYou have the building blocks of commonly-used TMs.\n\ns: start, h: halt\nx: write symbol x onto tape\nL,R: Move left, right\nLaâ€‹,Raâ€‹: Move left or right until you see a in tape â† make sure there is an a on tape or it wonâ€™t halt\nLÂ¬aâ€‹,RÂ¬aâ€‹Move left or right until you donâ€™t see a in input\nâ†’a,b}â†’w: symbols a,b are represented as variable w â† avoids having to write two identical machines for each symbol\n\nSome more advanced building blocks:\n\nC: Copy with a zero in the middle. e.g. abbaâ†’abba0abba. Tape head starts and ends in the beginning symbol.\nSLâ€‹,SRâ€‹ Shift left what is on the right, v.v. The symbol on the head is erased.\n\nExample of using building blocks to simplify a turing machine:\n\nTuring Machine Equivalents Â§\n\nTM with Stay option: Î´:QÃ—Î“â†’QÃ—Î“Ã—{L,R,S}\nMultitrack TM: One tape, but split into n cells: Î´:QÃ—Î“nâ†’QÃ—Î“nÃ—{L,R}\n\nDiagram\n\n\n\nSemi-infinite TM: The tape is infinite only in one direction\nâ†’ Proof by â€œfolding overâ€ the standard TM into multi-track.\nMulti-tape TM: Î´:QÃ—Î“nâ†’QÃ—Î“nÃ—{L,R}n\nOff-line TM: Two-tape; one tape is input, the other the read/write tape. Î´:QÃ—Î“2â†’QÃ—Î“Ã—{L,R}2\nNon-deterministic TM\nNPDA with 2 stacks\n\nUniversal Turing Machine Â§\nEvery TM can be binary encoded by a binary number:\n\nThe Universal Turing Machine is a 3-tape turing machine that simulates a standard Turing Machine M. Each of the tapes are:\n\nTape A: Binary encoding of a simulation of M\nTape B: The tape of M\nTape C: Mâ€™s current state\n"},"Two-Stage-Lease-Squares-Regression":{"title":"Two-Stage Lease Squares Regression","links":["Consistency"],"tags":["Math/Statistics"],"content":"Motivation. Instrumental variables are an advanced way of removing endogenity. Suppose you want to see the effects of police on crime rates. But does crime cause more police to be hired, or does more police cause less crime? Because of this circularity, itâ€™s hard to isolate simply the causality from police to crime rates.\nSo to isolated the exogenous variation in police hiring (i.e. get the pure exogenity), we can use a proxy or instrumental variable: firefighters. Exogenous factors both cause firefighters and police to be hired (policy changes, citizen support) but they donâ€™t cause crime rates to increase.\n2-Stage Lease Squares Â§\nInstrumental variables are implemented using 2SLS.\n\nWe have the first stage (=reduced form), where we regress the independent variable (police) with instrumental variable (firefighters):\n\nÂ policeÂ X1iâ€‹^â€‹â€‹â€‹=Î³0â€‹+Î³1â€‹Â firefightersÂ Ziâ€‹â€‹â€‹+Î³2â€‹Â someÂ controlÂ X2iâ€‹â€‹â€‹+Î½iâ€‹\n\nThen we take the ==police estimator X^itâ€‹ (not the actual data!)== and then regress dependent (crime) against estimated independent (estimated police):\n\nYiâ€‹=Î²0â€‹+Î²1â€‹Â estimatedÂ X^1iâ€‹â€‹â€‹+Î²2â€‹Â controlÂ X2iâ€‹â€‹â€‹+Ïµiâ€‹\nVisualization. \nWhat Are Good Instrumental Variables? Â§\n\nInclusion condition: Z needs to have meaningful influence on X\n\nSatisfied when in the first stage Î³1â€‹ is significant at 1%.\n\n\nExclusion condition: Z needs to have no infludence on Y\n\nin other words, Z and Ïµ should not be correlated.\nBut this cannot be tested directly because Ïµ is not observed.\n\nâ†’ thus the exclusion condition is more of a â€œitâ€™s probably okayâ€ argument\n\n\n\n\n! running regression Y against Z might seem prudent but actually if Z is correlated with X^ and X^ with Y then it will always be significant\nThe best we can do is include more controls we assume are inside Ïµ that correlate with Z, such that the new Ïµ with more controls are not correlated to Z.\n\n\n\nMultiple Instruments Â§\nPerform the first stage with each instruments Z1â€‹,Z2â€‹,â€¦:\nX1iâ€‹=Î³0â€‹+Î³1â€‹Z1iâ€‹+Î³2â€‹Z2iâ€‹+â‹¯+Î½iâ€‹\nand then same for the second stage.\nOver-identification test tests the exclusion restriction. if youâ€™ve gotten the correct multiple instrumental variables. (Overidentification is a good thing.) If we want to see if Z1â€‹ and Z2â€‹ together satisfy the exclusion condition we test:\n\nFirst stage just with Z1â€‹ to get X1â€‹^â€‹Z1â€‹. Then the second stage to get Î²1â€‹^â€‹Z1â€‹\nFirst stage just with Z2â€‹ to get X1â€‹^â€‹Z2â€‹. Then the second stage to get Î²1â€‹^â€‹Z2â€‹\nIf Î²1â€‹^â€‹Z1â€‹â‰ˆÎ²1â€‹^â€‹Z2â€‹ then good!\n! but if theyâ€™re similar this might just mean that both are bad in similar waysâ€¦\nAnd If theyâ€™re different, thereâ€™s no way of knowing which one is the better one\nAlternatively, run\n\nÏµiâ€‹^â€‹=Î±0â€‹^â€‹+Î±1â€‹^â€‹Z1iâ€‹+Î±2â€‹^â€‹Z2iâ€‹+Î±3â€‹X2iâ€‹\nand then F-test: H0â€‹:Î±1â€‹=Î±2â€‹=0. A exclusion-condition compatible IV should not be jointly significant. But this is also inaccurate in the same way described above.\nComparison with Ordinary Least Squares Â§\nWe should use 2SLS instead of OLS when we know that X is very much endogenous, and we have found a good IV, Z that satisfies the inclusion and exclusion conditions. To test if X is endogenous enough for 2SLS to be useful, we use the following:\ndef. Durbin-Wu-Hausman Test of Xâ€™s endogenity. Observe first the fact that assuming Z is exogenous:\n\nif X is exogenous: Î²^â€‹OLSâ‰ˆÎ²^â€‹2SLS\n\ni.e. ÏX,Ïµâ€‹â‰ˆ0 already, so why use IV or 2SLS?\n\n\nif X is endogenous: Î²^â€‹OLSî€ =Î²^â€‹2SLS\n\ni.e. ÏX,Ïµâ€‹î€ =0 so we must use IV or 2SLS!\nThe test has null hypothesis H0â€‹:Î²^â€‹OLS=Î²^â€‹2SLS. If we reject the null, then we should use 2SLS.\n\n\n\nBias in 2SLS Â§\n\ndef. Quazi-instruments are instruments where there exists some (small) ÏZ,Ïµâ€‹î€ =0 (Usually okay, see below)\ndef. Weak Instruments are instruments where there exists some ÏZ,X1â€‹â€‹î€ =0. (Usually bad, see below)\nItâ€™s sometimes okay to have some correlation between Z and Ïµ, but having correlation between Z and X1â€‹ is pretty bad. To see why, observe the 2SLS bias of Î²1â€‹^â€‹\n\nnâ†’âˆlimâ€‹Î²1â€‹^â€‹2SLS=Î²1â€‹+Â biasÂ ÏZ,X1â€‹â€‹ÏZ,Ïµâ€‹â€‹ÏƒX1â€‹â€‹ÏƒÏµâ€‹â€‹â€‹â€‹\nCompare this to vanilla OLS (for Consistency ÏX,Ïµâ€‹=0):\nnâ†’âˆlimâ€‹Î²1â€‹^â€‹OLS=Î²1â€‹+Â biasÂ ÏX,Ïµâ€‹ÏƒXâ€‹ÏƒÏµâ€‹â€‹â€‹â€‹\nThis implies\n\nWhen it has a strong first stage relationship (=ÏZ,X1â€‹â€‹ is small) the 2SLSâ€™s Î²1â€‹^â€‹2SLSisbeer\n&amp; If ÏZ,X1â€‹â€‹ÏZ,Ïµâ€‹â€‹&lt;1 then 2SLS has less bias than vanilla OLS even if ÏZ,Ïµâ€‹î€ =0\n! If ÏZ,X1â€‹â€‹ÏZ,Ïµâ€‹â€‹&gt;1 then 2SLS amplified any small correlation ÏZ,Ïµâ€‹ and easily becomes worse than vanilla OLS\n\n\n\n                  \n                  Rule of Thumb for determining weak instruments \n                  \n                \nUse 2SLS with instrument Z when in the first stage regression the test\n\n{&gt;H1â€‹H0â€‹â€‹ifÂ Î³0â€‹=Î³1â€‹=Î³2â€‹=â‹¯ifÂ elseâ€‹&gt;\n\ni.e. an F-test, F&gt;10.\n\n\nEven when ÏZ,Ïµâ€‹=0, since the above equations are for limnâ†’âˆâ€‹, when n is small bias still exists (in the same direction as OLS).\n\nThis bias will eventually go away in bigger n (or, of ÏZ,Ïµâ€‹î€ =, go the opposite way!)\n\n\n\nPrecision of 2SLS Â§\nRecall multivariate OLS variance of coefficients is:\nVar(Î²1â€‹^â€‹)=Nâ‹…Var(X1â€‹)â‹…(1âˆ’R12â€‹)Ïƒ^2â€‹\nThe 2SLS variance of coefficient is:\nVar(Î²1â€‹^â€‹)=Nâ‹…Var(X1â€‹^â€‹)â‹…(1âˆ’RX1â€‹^â€‹NoZ2â€‹)Ïƒ^2â€‹\nThe differences are:\n\nÏƒ^2(=second stage regression variance) may be larger because Ïµ has been purged\n\nThis simplies that explainatory power in the observed X1iâ€‹ that were correlated with Ïµ is purged (=thus total reduced)\n\n\nVar(X1â€‹^â€‹), not Var(X1â€‹) because we use estimates (see above) not actual data during regression\n\nVar(X1â€‹^â€‹) is probably smaller because we purged Ïµ-related variance.\n\n\n! RX1â€‹^â€‹NoZ2â€‹ is the R-squared from the new regression\n\nX1,iâ€‹^â€‹=Ï€0â€‹+Ï€1â€‹X2iâ€‹+Î·iâ€‹\n- This regression determines how much does $X_{2}$, not $Z$, determines $\\hat{X_{1}}$.\n- $R^{2}$ in this regression thus measures the collinearity of $\\hat{X_{1}}$ and $X_{2}$ (=controls)\n    - btw, $R^{2}$ in the second regression doesn&#039;t mean shit.\n- The lower the explanatory power of $Z$ on $\\hat{X_{1}}$, the higher this value is, and the higher the variance of the 2SLS coefficient is.\n"},"Types-of-Demand-Curves-(MicroEcon)":{"title":"Types of Demand Curves (MicroEcon)","links":["Elasticity-of-Substitution","Uncompensated-Demand-curve","Marginal-Willingness-to-Pay","Cross-Price-Demand-Curve"],"tags":["Economics/Micro-Economics"],"content":"Demand Curves Â§\nDemand is a relationship between prices, income, and quantity consumed.\nExogenous:(p1â€‹,p2â€‹,I)â†”Endogenous:(x1â€‹,x2â€‹)\nProperties relating these variables are:\n\nx1â€‹â†”I: Income Elasticity of Demand (YED)\nx1â€‹â†”x2â€‹: Elasticity of Substitution (EoS)\np1â€‹â†”x1â€‹: Own-price Demand Curvesâ€¦\n\nUncompensated Demand curve\n\n= Ordinary Demand Curve\n= Marshalian Demand Curve\n\n\nCompensated Demand Curve\n\n= Marginal Willingness to Pay Curve\n= Hicksian Demand Curve\n\n\n\n\np1â€‹â†”x2â€‹: Cross-Price Demand Curve\n\np1â€‹â†”x2â€‹: Cross Elasticity of Demand (XED)\n\n\n"},"Types-of-Goods-(Economics)":{"title":"Types of Goods (Economics)","links":["Income-Effect-(IE)","Uncompensated-Demand-curve","Game-Theory","Prisoner's-Dillemma"],"tags":["Economics/Micro-Economics"],"content":"Economic Goods Â§\nNote:\n\nNormal Good âŠ‚ Ordinary Good\nGiffen Good âŠ‚ Inferior Good\n\nDepending on Price and Quantity Demanded Â§\n\nOrdinary Good: Follows the Law of Demand: Priceâˆ1/QDemandâ€‹\nGiffen Good: PriceâˆQDemandâ€‹\n\nâ‡’ Cause: Income Decrease â‡’ Buy cheaper Giffen Good\nIrish Famine. the price of potatoes and meat increased subsequently. Compared to meat, potatoes could be much cheaper as a staple food.\n\nâ‡’ Potatoes were a Giffen Good\n\n\n\n\n\nDepending on Income and Quantity Demanded Â§\n\n\n                  \n                  Notation: \n                  \n                \n\nYED:= Income elasticity of demand-\nIncome Effect (IE) is important in understanding economic goods\n\n\n\nNormal Good: IncomeâˆQDemandâ€‹\n\ni.e. âˆ‚Iâˆ‚x1â€‹(p1â€‹,p2â€‹,IË‰)â€‹&gt;0 (derivative from Marshallian Demand)\nNecessity Good (Necessities)\n\n0&lt;âˆ‚Iâˆ‚x1â€‹â€‹&lt;1\n\n\nLuxury Good\n\n1&lt;âˆ‚Iâˆ‚x1â€‹â€‹\nâ€¦i.e. a normal good for which the proportional consumption increase exceeds the proportional Increase\n\n\n\n\nInferior Good: Incomeâˆ1/QDemandâ€‹\n\ni.e. âˆ‚Iâˆ‚x1â€‹â€‹&lt;0\n\n\nQuasilinear Good: QDemandâ€‹ doesnâ€™t change on income change\n\ni.e. âˆ‚Iâˆ‚x1â€‹â€‹=0\n\n\n\nFor the set of all goods we can thus show the following Venn diagram:\n\nGame Theory Goods Â§\n\n\nCommon-pool resources are also called Common Goods.\nPublic Goods\n\nThe production of a public good is a Prisonerâ€™s Dillemma situation.\nBasic examples: national defense, street lighting, a good schooling district, etc.\n\n\n"},"Types-of-Loans":{"title":"Types of Loans","links":["Annuity"],"tags":["Economics/Finance"],"content":"Types of Loans\n\nAmortizing Loan (=Annuity): borrower regularly pays back interest and principal\nSimple interest: borrower regularly pays back only interest. Principal is paid back altogether at the end.\n"},"UI-Design-Tips":{"title":"UI Design Tips","links":["dont-make-the-user-think","(Article)-Magic-Ink---Information-Software-and-the-Graphical-Interface"],"tags":["Computing/Human-Interface"],"content":"Principles Â§\ndont make the user think\n(Article) Magic Ink - Information Software and the Graphical Interface\nStart here Â§\nDetermine a color pallette\n\nWhat â€œatmosphereâ€ are you going for? what\n"},"Uncompensated-Demand-curve":{"title":"Uncompensated Demand curve","links":["Homogenous-Function","Utility-Maximization","Types-of-Goods-(Economics)","Utility-Maximization-with-Endowments","Income-Effect-(IE)"],"tags":["Economics/Micro-Economics"],"content":"\n\n                  \n                  Abstract \n                  \n                \n\nThe canonical, standard demand curve when we normally say â€œdemand of good xâ€\nIn theory, it should be the actual demand curves of individuals\nAll Marshalian demand curves are HD0 in (prices,income)\n\n\nHow to Derive OPDC Â§\nVisually:\n\nPlot the indifference map and budget line for goods x1â€‹ and x_2=\\text{&quot;\\ of other goodsâ€}.Chooseanoptimalbundlex_1atpricep_1.Plotthisonthepriceâˆ’quantitygraph:A(x_1,p_1)$\nChange the price p1â€‹â†’p1â€²â€‹; i.e. change the gradient of the budget. See what substitution and income effects it produces.\nThen find the optimum bundle for the new price: C(x1â€²â€‹,p1â€²â€‹). Connect these points together.\n\nAnalytically:\n\nmaxx1â€‹,x2â€‹â€‹Â u(x1â€‹,x2â€‹)Â suchÂ thatÂ I=p1â€‹x1â€‹+p2â€‹x2â€‹ using Utility Maximization\nyou will get x1â€‹(p1â€‹,p2â€‹,I),x2â€‹(p1â€‹,p2â€‹,I)\n\ni.e. quantity demanded as a function of prices and income\nThis is the demand function â†’ plot this to get demand curve\n\n\n\nAs stated above: OPDC must be HD0; check if it is!\nAnalysis of Goods Â§\n\nIn a demand curve, Price is the negative gradient of the budget line. (âˆµg=âˆ’p2â€‹p1â€‹â€‹, and we defined p_2=\\1$)\n\nDepending on Price Â§\nâˆ‚p1â€‹âˆ‚x1â€‹â€‹Â &gt;0&lt;0â€‹âŸ¹OrdinaryÂ GoodâŸ¹GiffenÂ Goodâ€‹â€‹\n\nOrdinary goodsâ€™s demand functions x1â€‹ are homogenous in (p1â€‹,p2â€‹,I)\n\nâ†’ Inflation in all prices as well as income doesnâ€™t change anything\n\n\n\nDepending on Income Â§\nâˆ‚Iâˆ‚x1â€‹â€‹Â &gt;0=0&lt;0â€‹âŸ¹NormalÂ GoodâŸ¹QuasilinearÂ GoodâŸ¹InferiorÂ Goodâ€‹â€‹\n\n\nGraph (a) shows a normal goodâ€™s OPDC.\nGraph (b) and (c) shows a inferior goodâ€™s OPDC.\nGraph (c) is the strange Giffen Good.\n\nLabor Supply Curve Â§\nSee also Utility Maximization with Endowments\nDeriving the Labor Supply Curve works similarly to the OPDC, with the following differences:\n\np1â€‹ = (gradient of budget line) = (opportunity cost of leisure in dollars) = âˆ—âˆ—w (wage)**\nThereâ€™s no exogenous income. Youâ€™re endowed a bundle with zero consumption and certain hours of leisure.\n\nâ†’ You can â€œsell offâ€ your leisure hours at price w\n\n\n\nThus as wages increase (= price of leisure in dollars)\n\nâ†’ the shift in the budget line happens from blueâ†’pink in graph belowâ€¦\n\nâ€¦with a stationary leisure endowment at the x-intercept and a clockwise rotation.\n\n\nThen after you draw the OPDC for leisure, you flip the curve horizontally.\n(since endowment=leisureÂ hours+workÂ hours.)\n\n\n\nGraph (a) shows the case where leisure is a normal good, but IE &gt; SE.\nGraph (b) is Normal good, IE &lt; SE.\nGraph (c) shows when leisure is an inferior good.\n\n\n\n                  \n                  Warning \n                  \n                \n\nWhen discussing labor supply, the Income Effect (IE) is called the wealth effect (WE). Weâ€™re not discussing why.\nBackward Bending Supply of Labor Â§\nIn real life, labor supply curves look like this:\n\nThis is because workers will trade-off leisure and work hours.\nâ†’ the higher the personâ€™s wage, they will work more; but at some point their wage is large enough and they start to enjoy life more. This is called the Backward Bending Supply of Labor.\nInteresting IRL Analysis Â§\ncdixon | How bundling benefits sellers and buyers\nDeriving Uncompensated Demand Â§"},"Unconstrained-Maximization":{"title":"Unconstrained Maximization","links":["Critical-Point"],"tags":["Math/Calculus"],"content":"\n\nThe first-order necessary condition for a maximum or minimum. If a function has a maximum or minimum at a certain point, then its derivative at that point is zero\n\nIf f(x) has a maximum or minimum at x=c, then fâ€²(c)=0.\n\n\n\nThe second-order necessary condition for a maximum. If a function has a maximum at a certain point, then its second derivative at that point is less than or equal to zero:\n\nIf f(x) has a maximum at x=c, then fâ€²â€²(c)â‰¤0.\n\n\n\nThe second-order sufficient condition for a maximum. If a functionâ€™s first derivative is zero at a certain point and its second derivative at that point is less than zero, then the function has a maximum at that point:\n\nIf fâ€²(c)=0 and fâ€²â€²(c)&lt;0, then f(x) has a maximum at x=c.\n\n\n\nTo find the unconstrained maximum of a function, we can set its derivative equal to zero and solve for â€˜xâ€™. Then, we use the second derivative test to determine whether each solution is a maximum or minimum.\n\nFind unconstrained maximum of f(x)\n\nset fâ€²(x)=0 and solve for â€˜xâ€™.\nUse fâ€²â€²(x) to verify maxima.\n\n\n\n\n"},"Unemployment":{"title":"Unemployment","links":[],"tags":["Economics/Macro-Economics"],"content":"UnemploymentÂ u=N+UUâ€‹\nParticipationÂ RateÂ p=populationN+Uâ€‹\nVacancyÂ RateÂ v=U#vacanciesâ€‹\nMeasured using three variables:\n\nu the unemployment rate\np the participation rate\nv the vacancy rate\n\nâ€¦whereâ€¦\n\nU is the number of registered unemployed people\nN is the number of employed people\nThe labor market is tight when Dlaborâ€‹&gt;Slaborâ€‹ and loose vice versa.\n"},"Uniform-Distribution":{"title":"Uniform Distribution","links":[],"tags":["Math/Common-Distributions"],"content":"Uniform Distribution Â§\ndef. Uniform Distribution. X has uniform distribution of it has a uniform density on interval (a,b):\nXâˆ¼Unif(a,b)fXâ€‹(x)={bâˆ’a1â€‹0â€‹xâˆˆ(a,b)elseâ€‹FXâ€‹(t)=âˆ«âˆ’âˆtâ€‹fXâ€‹(x)dx=â©â¨â§â€‹bâˆ’atâˆ’aâ€‹10â€‹tâˆˆ(a,b)t&gt;bt&lt;aâ€‹â€‹\nE(X)=2a+bâ€‹Â Â Â Â Â Â Â SD(X)=23â€‹bâˆ’aâ€‹\nEstimators Â§\nlet\n\nXâˆ¼Unif(a,b)\nX1â€‹,â€¦,Xnâ€‹âˆ¼iidUnif(a,b)\n\nLog likelihood:\nlnLnâ€‹(a,bâˆ£x1â€‹,...,xnâ€‹)=ln(bâˆ’a)n1â€‹\nscore:\nsnâ€‹(a)=bâˆ’anâ€‹\nsnâ€‹(b)=bâˆ’aâˆ’nâ€‹\nMLEs:\na^MLEâ€‹=min(X1â€‹,...,Xnâ€‹)\nb^MLEâ€‹=max(X1â€‹,...,Xnâ€‹)"},"Univariate-Distribution-Relationship-Chart":{"title":"Univariate Distribution Relationship Chart","links":["Distribution-(Math)"],"tags":["Math/Statistics"],"content":"Useful resource for visualizing the relationship between distributions.\nURL: &lt;http://www.math.wm.edu/~leemis/chart/UDR/UDR.html&gt;\n"},"Unrestricted-Grammar":{"title":"Unrestricted Grammar","links":[],"tags":["Computing/Formal-Languages"],"content":"\n\ndef. If G is an Unrestricted Grammar, then L(G) is recursively enumerable [=TM equivalent]. This is equivalent to all productions following the form:\n\n\n(VâˆªT)+â†’(VâˆªT)âˆ—\ndef. G is a Context-Sensitive Grammar if its productions follow the form:\n(VâˆªT)+â†’(VâˆªT)âˆ—andâˆ£LHSâˆ£â‰¤âˆ£RHSâˆ£andthereÂ isÂ noÂ Î»Â inÂ theÂ RHS"},"Use-value,-Exchange-value":{"title":"Use value, Exchange value","links":["Use-value,-Exchange-value","Fetishization","Emergent-Phenomena"],"tags":["Philosophy/Marxism"],"content":"consumption. They constitute the material content of wealth, whatever its social form may be. In the form of society to be considered here they are also the material bearers [Triiger] of â€¦ exchange-value.\nThis common element exchange value cannot be a geometrical, physical, chemical or other natural property of commodities.\nBut clearly, the exchange relation of commodities is characterized precisely by its abstraction from their use-values.\nIf then we disregard the use-value of commodities, only one property remains, that of being products of labour.\nIf we make abstraction from its use-value, we abstract also from the material constituents and forms which make it a use-value. It is no longer a table, a house, a piece of yam or any other useful thing.\nWith the disappearance of the useful character of the products of labour, the useful character of the kinds of labour embodied in them also ~sappears; this in tum entails the disappearance of the different toncrete forms of labour.\netc. This is their plain, homely, natural form. However, they are only commodities because they have a dual nature, because they are at the same time objects of utility and bearers of value. Therefore they only appear as commodities, or have the form of commodities, in so far as they possess a double form, i.e. natural form and value form\nFetishization\nthing. But as soon as it emerges as a commodity, it changes into a thing which transcends sensuousness. It not only stands with its feet on the ground, but, in relation to all other commodities, it stands on its head, and evolves out of its wooden brain grotesque ideas far more wonderful than if it were to begin dancing of its own free will. 21\nThe mysterious character of the commodity-form consists therefore simply in the fact that the commodity reflects the social characteristics of menâ€™s own labour as objective characteristics of the products of labour themselves,\nreligion. There the products of the human brain appear as autonomous figures endowed with a life of their own, which enter into relations both with each other and with the human race. So it is in the world of commodities with the products of menâ€™s hands. I call this the fetishism which attaches itself to the products of labour as soon as they are produced as commodities, and is therefore inseparable from the production of commodities.\nformulas, which bear the unmistakable stamp of belonging to a social formation in which the process of production has mastery over man, instead of the opposite, appear to the political economistsâ€™ bourgeois consciousness to be as much a self-evident and nature-imposed necessity as productive labour itself.\nvalues. When they thus assume the shape of values, commodities strip off every trace of their natural and original use-value, and of the particular kind of useful labour to which they owe their creation, in order to pupate into the homogeneous social materialization of undifferentiated human labour.\ncrisis. There is an antithesis, immanent in the commodity, between use-value and value, between private labour which must simultaneously manifest itself as directly social labour, and a particular concrete kind of labour which simultaneously counts as merely abstract universal labour, between the conversion of things into persons and the conversion of persons into things*; the antithetical phases of the metamorphosis of the commodity are the developed forms of motion of this immanent contradiction.\nAs against this, the circulation of money as capital is an end in itself, for the valorization of value takes place only within this constantly renewed movement.\nCooperation\nmanufacture [Manufaktur] can hardly be distinguished, in its earliest stages, from the handicraft trades [Handwerksindustrie] of the guilds, except by the greater number of workers simultaneously employed by the same individual capital.\nWhen consumed in common, they give up a smaller part of their value to each single product; partly because the total value they part with is spread over a greater number of products, and partly because their value, although it is greater in absolute terms, is relatively Jess, looked at from the point of view of their sphere of action, than the value of separate means of production.\nJust as the offensive power of a squadron of cavalry, or the defensive power of an infantry regiment, is essentially different from the sum of the offensive or defensive powers of the individual soldiers taken separately, so the sum total of the mechanical forces exerted by isolated workers differs from the social force that is developed when many hands co-operate in the same undivided operation, such as raising a heavy weight, turning a winch or getting an obstacle out of the way. 4 In such cases the effect of the combined labour could either not be produced at all by isolated individual labour, or it could be produced only by a great expenditure of time, or on a very dwarf-like scale. Not only do we have here an increase in the productive power of the individual, by means of co-operation, but the creation of a new productive power, which is intrinsically a collective one. 5\nIf the labour process is complicated, then the sheer number of the co-operators permits the apportionment of various operations to different hands, and consequently their simultaneous performance. The time necessary for the completion of the whole work is thereby shortened. 9\nWhether the combined working day, in a given case, acquires this increased productivity because it heightens the mechanical force of labour, or extends its sphere of action over a greater space, or contracts the field of production relatively to the scale of production, or at the critical moment sets large masses of labour to work, or excites rivalry between individuals and raises their animal spirits, or impresses on the similar operations carried on by a number of men the stamp of continuity and manysidedness, or performs different operations simultaneously, or economizes the means of production by use in common, or lends to individual labour the character of average social labour - whichever of these is the cause of the increase, the special productive power of the combined working day is, under all circumstances, the social productive power of labour, or the productive power of social labour. This power arises from co-operation itself. When the worker co-operates in a planned way with others, he strips off the fetters of his his individuality, and develops the capabilities of his species.13 As a general rule, workers cannot co-operate without being brought together: their assembly in one place is a necessary condition for their co-operation. Hence wage-labourers cannot cooperate unless they are employed simultaneously by the same capital, the same capitalist, and therefore unless their labourpowers are bought simultaneously by him.\nHence, concentration of large masses of the means of production in the hands of individual capitalists is a material condition for the co-operation of wage-labourers, and the extent of co-operation, or the scale of production, depends on the extent of this concentration.\nproduction. That a capitalist should command in the field of production is now as indispensable as that a general should command on the field of battle.\nAs the number of the co-operating workers increases, so too does their resistance to the domination of capital, and, necessarily, the pressure put on by capital to overcome this resistance.\nwage-labourer. An industrial army of workers under the command of a capitalist requires, like a real army, officers (managers) and N.C.O.s (foremen, overseers), who command during the labour process in the name of capital.\nprocess.17 It is not because he is a leader of industry that a man is a capitalist; on the contrary, he is a leader of industry because he is a capitalist.\nHe pays them the value of 100 independent labour-powers, but he does not pay for the combined labour-power of the 100. Being independent of each other, the workers are isolated. They enter into relations with the capitalist, but not with each other.\nJust as the social productive power of labour that is developed by co-operation appears to be the productive power of capital, so co-operation itself, contrasted with the process of production carried on by isolated independent workers, or even by small masters, appears to be a specific form of the capitalist process of production.\nJameson\nAt this point, then, the quality of the various forms of human activity, their unique and distinct â€œendsâ€ or values, has effectively been bracketted or suspended by the market system, leaving all these activities free to be ruthlessly reorganized in efficiency terms, as sheer means or instrumentality.\nWhat is unsatisfactory about the Frankfurt School position is not its negative and critical apparatus, but rather the positive value on which the latter depends, namely the valorization of traditional modernist high art as the locus of some genuinely critical and subversive, â€œautonomousâ€ aesthetic production.\nFor all these reasons, it seems to me that we must rethink the opposition high culture/mass culture in such a way that the emphasis on evaluation to which it has traditionally given rise, and which-however the binary system of value operates (mass culture is popular and thus more authentic than high culture, high culture is autonomous and therefore utterly incomparable to a degraded mass culture)-tends to function in some timeless realm of absolute aesthetic judgment, is replaced by a genuinely historical and dialectical approach to these phenomena. S\nIndeed, this view of the emergence of mass culture obliges us historically to respecify the nature of the â€œhigh cultureâ€ to which it has conventionally been opposed: the older culture critics indeed tended loosely to raise comparative issues about the â€œpopular cultureâ€ of the past.\nThe above reflections by no means raise, let alone address, all the most urgent issues which confront an approach to mass culture today. In particular, we have neglected a somewhat different judgment on mass culture, which also loosely derives from the Frankfurt School position on the subject, but whose adherents number â€œradicalsâ€ as well as â€œelitistsâ€ on the Left today. This is the conception of mass culture as sheer manipulation, sheer commercial brainwashing and empty distraction by the multinational corporations who obviously control every feature of the production and distribution of mass culture today. If this were the case, then it is clear that the study of mass culture would at best be assimilated to the anatomy of the techniques of ideological marketing and be subsumed under the analysis of advertising. R\nRather, class struggle, and the slow and intermittent development of genuine class consciousness, are themselves the process whereby a new and organic group constitutes itself, whereby the collective breaks through the reified atomization (Sartre calls it the seriality) of capitalist social life.\nmaterial. To rewrite the concept of a management of desire in social terms now allows us to think repression and wish-fulfillment together within the unity of a single mechanism, which gives and takes alike in a kind of psychic compromise or horse-trading, which strategically arouses fantasy content within careful symbolic containment structures which defuse it, gratifying intolerable, unrealizable, properly imperishable desires only to the degree to which they can again be laid to rest. This model seems to me to permit a far more adequate account of the mechanisms of manipulation, diversion, degradation, which are undeniably at work in mass culture and in the media. In particular it allows us to grasp mass culture not as empty distraction or â€œmereâ€ false consciousness, but rather as a transformational work on social and political anxieties and fantasies which must then have some effective presence in the mass cultural text in order subsequently to be â€œmanagedâ€ or repressed.\nNow the content of the partnership between Hooper and Brody projected by the film may be specified socially and politically, as the allegory of an alliance between the forces of law-and-order and the new technocracy of the multinational corporations: an alliance which must be cemented, not merely by its fantasized triumph over the ill-defined menace of the shark itself, but above all by the indispensable precondition of the effacement of that more traditional image of an older America which must be eliminated from historical consciousness and social memory before the new power system takes its place. T\nThis is the context in which the ideological function of the myth of the Mafia can be understood, as the substitution of crime for big business, as the strategic displacement of all the rage generated by the American system onto this mirror-image of big business provided by the movie screen and the various tv series, it being understood that the fascination with the Mafia remains ideological even if in reality organized crime has exactly the importance and influence in American life which such representations attribute to it. T\nThompson\n? If the transition to mature industrial society entailed a severe restructuring of working habitsâ€”new disciplines, new incentives, and a new human nature upon which these incentives could bite effectivelyâ€”how far is this related to changes in the inward notation of time?\nIn a similar way labour from dawn to dusk can appear to be â€œnaturalâ€ in a farming community, especially in the harvest mo\nClearly hunters must employ certain hours of the night to set their snares. Fishing and seafaring people must integrate their lives with the tides.\nLet us return from the timepiece to the task. Attention to time in labour depends in large degree upon the need for the synchronization of labour\nThe work pattern was one of alternate bouts of intense labour and. of idleness, wherever men were in control of their own working lives (The pattern persists among some self-employedâ€”artists, writers, small farmers, and perhaps also with studentsâ€”today, and provokes the question whether it is not\nimposition. This remains true to this day, and, despite school times and television times, the rhythms of womenâ€™s work in the home are not wholly attuned to the measurement of the clock.\nWe are entering here, already in 1700, the familiar landscape of disciplined industrial capitalism, with the time-sheet, the timekeeper, the informers and the finest\nPowell, in 1772, also saw education as a training in the â€œhabit of industryâ€; by the time the child reached six or seven it should become â€œhabituated, not to say naturalized to Labour and Fati\nIn all these ways - by the division of labour; the supervision of labour; fines; bells and clocks; money incentives; preachings and schoolings; the suppression of fairs and sportsâ€”.new labour habits were formed, and a new time-discipline was imposed.) It sometimes took several generations (as in the Potteries), and we may doubt how far it was ever fully accomplished: irregular labour rhythms were perpetuated (and even institutionalized) into the present century, notably in London and in the great ports.114"},"Utilitarianism":{"title":"Utilitarianism","links":[],"tags":["Economics","Philosophy/Political-Philosophy"],"content":""},"Utility-Function":{"title":"Utility Function","links":["Indirect-Utility-Function","Rationality-(Economics)","Cobb-Douglas-Utility-(Two-Goods)","Monotonic-Transformation","Marginal-Rate-of-Substitution-(MRS)","utility-function","Utility-Function","Budget-Lines","assets/Untitled-2-10.png"],"tags":["Economics"],"content":"for mapping (p1â€‹,p2â€‹,I)â†¦u, see the Indirect Utility Function\ndef. Utility Function. a utility function maps n goods to utility (happiness) that satisfies the assumption of Rational Taste including convexity.\nU(x):R2â†¦R\nâ‡’ such that if x1â€‹â€‹â‰»x2â€‹â€‹ then u(x1â€‹â€‹)&gt;u(x2â€‹â€‹)\nTypes of Utility Functions Â§\nLet Siâ€‹ be the allocation bundle to agent i. Siâ€‹ contains items (â€jâ€) where xijâ€‹ defines what percentage of that item is allocated to j. Then iâ€™s utility Î¼iâ€‹ can take various forms.\n\ndef. Additive Utility. Î¼iâ€‹=âˆ‘jâ€‹Î¼ijâ€‹xjâ€‹ \ndef. Cobb-Douglas Utility. Î¼iâ€‹:=âˆjâ€‹Î¼ijâ€‹xjÎ±ijâ€‹â€‹ where âˆ‘Î±ijâ€‹=1\n(See the case for two goods)\ndef. Leontief Utility. Î¼iâ€‹:=minjâ€‹{Î¼ijâ€‹xjâ€‹}\n\nHomothetic, Quasilinear, Perfect Substitutes Â§\nIn addition to the constrains of Rational Taste we can also have these particular tastes that characterize a utility function.\ndef. Quasilinear Tastes. If a utility function has quasilinear tastes against good x1â€‹, then the function (or a Monotonic Transformation of the function) is linear against x1â€‹, e.g.:\nu(x1â€‹,x2â€‹)=x1â€‹+f(x2â€‹)\n\nSubstitutability Â§\ndef. Perfect Substitutes. If a utility function means goods x1â€‹ and x2â€‹ are perfect substitutes, then every indifference curve of the utility function is a linear function, e.g.\n\\displaylinesu(x1â€‹,x2â€‹)=x1â€‹+x2â€‹âŸ¹settingÂ u=uË‰,uË‰=x1â€‹+x2â€‹Â isÂ linearÂ betweenÂ x1â€‹,x2â€‹\n\ne.g. [[Untitled 7 2.png|5billsand10 bills]]\nSee Marginal Rate of Substitution (MRS)\n\nPerfect Compliments.\n\ne.g. ![[Untitled 6 2.png|Right shoe and left shoe|380]]\nFormula looks something like: u(x1â€‹,x2â€‹)=min(x1â€‹,2x2â€‹)\n\nIndifference Curves Â§\n\ndef. Indifference Curve. A set of bundles that an agent with rational taste is indifferent about\n\nIndifference curves are horizontal slices of a utility function.\n\ni.e. a level field of a scalar field defined by the utility function of two goodsâ€”u(x1â€‹,x2â€‹).\nIndifference curves from the same utility function cannot cross (obviously)\n\n\nNorth-east side is always better.\n\nâˆµ monotonic tasteâ€”if this is not the case, change the direction of the curve.\n\n\nThe convexity assumption causes ICs to bend to the origin\nMultiple indifference curves form one indifference map =[Utility Function].\nIndifference maps are considered the same when\n1. the order of the indifference curves is the same\n2. MRS at every point for every curve is the same\nBudget Lines are drawn on the same graph as ICs\nWhen tastes are strictly convex (a taste for variety) then:\n\nâ‡’ (Aâ‰¿B)âˆ§(Bâ‰¿C) in the Graph\n\n\n\nAnalyzing Indifference Curve Shapes Â§\nu(x1â€‹,x2â€‹)=x1Î±â€‹+x2â€‹\n"},"Utility-Maximization-with-Endowments":{"title":"Utility Maximization with Endowments","links":["Positive-Leisure","Cobb-Douglas-Utility-(Two-Goods)","Uncompensated-Demand-curve","Labor-Supply","Laffer-Curve"],"tags":["Economics/Micro-Economics"],"content":"Budget constraint with endowment\np1â€‹x1â€‹+p2â€‹x2â€‹=Endowmentsp1â€‹e1â€‹+p2â€‹e2â€‹â€‹â€‹+I\n\nâ‡’ Whether the change in price leads to a utility increase or decrease depends on where your original optimum is; i.e.\n\nWhether you are a net seller or net buyer of the good (optimum is left/right of endowment)\nWhich way the price ratio changes\n\nLeisureâ€”Consumption Utility Â§\nSame equation as above, but with Consumption-Positive Leisure tradeoff\nConsumptionwL+pcâ€‹=ExogenousÂ Income+Endowment=I+wT+peâ€‹â€‹\nâ€¦whereâ€¦\n\nLabor quantities:\n\nw: wage (=price of leisure)\nL: quantity of leisure, in unit hours\nT: total time endowment, in unit hours\n\n\nConsumption quantities:\n\np: price of composite consumption good\nc: quantity of composite consumption good\ne: consumption endowment\n\n\n\nCobb-Douglas:\nmaxL,câ€‹Â u=LÎ±c(1âˆ’Î±)Â suchÂ thatÂ wL+pc=I+wT+pe\ntherefore we can plot the Ordinary Demand of Leisure (=Labor Supply)\n\nc=pÎ±(I+wT+pe)â€‹ Ordinary Demand of Consumption\nL=wÎ±(I+wT+pe)â€‹ Ordinary Demand of Leisure\n\nN:=Tâˆ’L=Tâˆ’wÎ±(I+wT+pe)â€‹ ==Ordinary Supply of Labor==\n\n\n\nTaxation Â§\nPercentage tax t on wage (=price of leisure)\nâ‡’ removing t from the wage\nw(1âˆ’t)L+pc=I+w(1âˆ’t)+pe\n\nTax Revenue (Tâˆ’L)â€‹TimeÂ workedâ€‹Ã—wtHourlyÂ tax\nLaffer Curve\n"},"Utility-Maximization":{"title":"Utility Maximization","links":["Utility-Function","Budget-Lines","Lagrangian-Optimization","Monotonic-Transformation","Uncompensated-Demand-curve","Expenditure-Minimization","Homogenous-Function"],"tags":["Economics"],"content":"maxÂ u(x1â€‹,x2â€‹)Â suchÂ thatÂ I=p1â€‹x1â€‹+p2â€‹x2â€‹\nMaximization of the Utility Function against the Budget Constraints.\n\nUses Lagrangian Optimization\n&amp; If it makes it more convenient, do a Monotonic Transformation of the utility function. See Example.\nOptimal is where the budget line is the tangent to the Indifference Curve. This implies both gradients are same, i.e. âˆ’P2â€‹P1â€‹â€‹=MRS\nThe result is the Ordinary Demand functions (one for each good)\nSee Expenditure Minimization for the opposite case\n! Always check if the resulting x1â€‹,x2â€‹ are positive. If not, itâ€™s piecewise function to keep both positive.\n\nPerfect Substitutes Â§\nWith the form: u=(ax1â€‹k+bx2â€‹l)Î±\n\nâ‡’ Go to the corner that gives the highest utility (=buy only one good!)\nx1â€‹={p1â€‹Iâ€‹0â€‹ifÂ u(p1â€‹Iâ€‹,0)â‰¥u(p2â€‹Iâ€‹,0)elseâ€‹,Â x2â€‹={p2â€‹Iâ€‹0â€‹ifÂ u(0,p2â€‹Iâ€‹)â‰¥u(0,p1â€‹Iâ€‹)elseâ€‹\nPerfect Compliments Â§\nmaxx1â€‹,x2â€‹â€‹Â u(x1â€‹,x2â€‹)=min(x1â€‹,2x2â€‹)Â Â suchÂ thatÂ I=p1â€‹x1â€‹+p2â€‹x2â€‹\n\n\nGet the formula that is the set of all kinked points in the utility function â‡’ x1â€‹=2x2â€‹\nGet the Constraint formula â‡’ I=p1â€‹x1â€‹+p2â€‹x2â€‹\nSolve for the two equations (=get the intersection)\n\nx1â€‹=2p1â€‹+p2â€‹Iâ€‹Â ,Â x2â€‹=2p1â€‹+p2â€‹2Iâ€‹\nQuasilinear Optimization Â§\nUse Lagrangian optimization, but beware that the blue line might happen (=maximum point lies outside x1â€‹,x2â€‹&gt;0):\n\nâ‡’ In this case, go to the red (*) corner solution.\nKinked Budget Constraint Â§\n\nCase 1: Inner kink\n\nLagrangian for blue section\nLagrangian for red section\nChoose the better one\n\n\nCase 2: Outer Kink\n\nLagrangian for blue and red section\nIf both solutions are unaffordable (=ICAâ€‹,ICBâ€‹ in the graph i.e. x2â€‹&lt;0 in graph,), go to the kink.\n\n\n\nMore than Two Goods Â§\n\nCase 1: u(x1â€‹,x2â€‹,x3â€‹)=x1Î±â€‹x2Î²â€‹x31âˆ’Î±âˆ’Î²â€‹ â† Pure three-var cobb-douglas\n\nâ‡’ Use 3-var lagrangian\n\n\n==Case 2: u(x1â€‹,x2â€‹,x3â€‹)=x1Î±â€‹x21âˆ’Î±â€‹+x3â€‹==\n\nCheck that each term is Homogenous Degree of 1.\nTry the two-var lagrangian on the first term x1Î±â€‹x21âˆ’Î±â€‹ (assumping x3â€‹ isnâ€™t consumed)\nTry to maximize x3â€‹ (assuming x1â€‹,x2â€‹ isnâ€™t used)\nChoose the higher of the two utilities\n\nIf there is no concrete number, the cases differ on the conditions u(x1â€‹,x2â€‹,0)â‰¶u(0,0,x3â€‹)\n\n\n\n\n\nSolution for Case 2: \nmaxx1â€‹,x2â€‹,x3â€‹â€‹u=x1Î±â€‹x21âˆ’Î±â€‹+x3â€‹Â Â suchÂ thatÂ Â I=p1â€‹x1â€‹+p2â€‹x2â€‹\nâ©â¨â§â€‹â©â¨â§â€‹x1â€‹=p1â€‹Î±Iâ€‹x2â€‹=p2â€‹1âˆ’Î±Iâ€‹â€‹x1â€‹=x2â€‹=0Â andÂ maxÂ x3â€‹â€‹IfÂ p1Î±â€‹p21âˆ’Î±â€‹Î±Î±(1âˆ’Î±)1âˆ’Î±â€‹â‰¥p3â€‹1â€‹Otherwiseâ€‹\nGraphing a budget line with an indifference map, we can see that the bundle B1â€‹ is where the consumer can achieve the most possible utility; where what is affordable = most possible utility\nTo find the bundle(=point) of maximum utility that is affordable, you can rephrase the problem asâ€¦\nWorked Example: Constrained Optimization Problem Â§\nUsing the Lagrange Method for maxÂ u(x1â€‹,x2â€‹)Â s.t.Â (budgetÂ line),\nâˆ‡u(x1â€‹,x2â€‹)=Î»âˆ‡(p1â€‹x1â€‹+p2â€‹x2â€‹)p1â€‹x1â€‹+p2â€‹x2â€‹=I\nTo simplify further: âˆ‡u(x1â€‹,x2â€‹)=Î»âˆ‡(p1â€‹x1â€‹+p2â€‹x2â€‹âˆ’I) and thus let:\nL=âˆ‡u(x1â€‹,x2â€‹)âˆ’Î»âˆ‡(p1â€‹x1â€‹+p2â€‹x2â€‹âˆ’I)\nto construct a set of equations where:\nÎ´x1â€‹Î´Lâ€‹=0Î´x2â€‹Î´Lâ€‹=0p1â€‹x1â€‹+p2â€‹x2â€‹=I\nand solve the three equations. Note that the Lagrange method doesnâ€™t work when:\n\nOne or more goods are non-essential, meaning that the budget line crosses the axes\nâ†’ Itâ€™s a corner solution; i.e. the maximum point is at one of the intercepts, or at points where quantities of goods are negative\nTastes are non-convex, where there will be multiple solutions\nUtility Function are kinked or otherwise non-differentiable\n"},"Utility":{"title":"Utility","links":["Consumer-Surplus"],"tags":["Economics/Game-Theory"],"content":"Money. Utility. Consumer Surplus."},"VCG-Auction":{"title":"VCG Auction","links":[],"tags":["Economics/Game-Theory"],"content":"thm. VCG Mechanism Auction. The following mechanism is DSIC and Welfare Maximizing.\nCompute the optimum allocation S=(S1âˆ—â€‹,â€¦,Snâˆ—â€‹). Then for an agent i, let\n\nVâˆ—:=âˆ‘jî€ =inâ€‹vjâ€‹(Sjâˆ—â€‹) Optimal Social Welfare\nVâˆ’iâˆ—â€‹:=maxiî€ =jâ€‹âˆ‘j=1nâ€‹vjâ€‹(Sj,âˆ’iâ€‹)\n\nwhere sjâˆ’1â€‹ is the optimal allocation to j when i is simply removed from auction\nThus vâˆ’iâˆ—â€‹ is the optimal social welfare without i\n\n\nThus Vâˆ—â‰¥Vâˆ’iâˆ—â€‹\n\nbecause adding more bidders can only increase social welfare\n\n\n\nthm. The following allocation rule is DSIC and welfare-maximizing:\nAllocate by maxâˆ‘j=1nâ€‹vjâ€‹(Sjâ€‹)\nCharge price to i:\npiâ€‹=Â re-runÂ auctionÂ withoutÂ iÂ Vâˆ’iâˆ—â€‹â€‹â€‹âˆ’auctionâ€™sÂ welfareÂ âˆ’Â iâ€™sÂ welfare(Vâˆ—âˆ’viâ€‹(Siâˆ—â€‹))â€‹â€‹\nIntuition. This is similar to charging i the externality of joining the auction;\nProof.\nFirst, 0â‰¤piâ€‹&lt;viâ€‹(Siâ€‹), i.e. we donâ€™t charge negative prices, or a price higher than the bid:\n\nÂ withoutÂ iÂ Vâˆ’iâˆ—â€‹â€‹â€‹&gt;Â excludingÂ iÂ Vâˆ—âˆ’viâ€‹(Siâˆ—â€‹)â€‹â€‹ because, thus 0â‰¤piâ€‹\npiâ€‹=viâ€‹(Siâˆ—â€‹)+&lt;0Vâˆ’iâˆ—â€‹âˆ’Vâˆ—â€‹â€‹ because Vâˆ—&gt;Vâˆ’iâˆ—â€‹, i.e. adding more bidders cannot decrease welfare.\n\nSecond, fixing otherâ€™s bids bâˆ’iâ€‹, i will be incentivized to tell the truth of biâ€‹. Consider the situation where the auctioneer took these bids and allocated S^=(S1â€‹^â€‹,â€¦,Snâ€‹^â€‹).\npiâ€‹â€‹=Vâˆ’iâˆ—â€‹âˆ’(Vâˆ—âˆ’viâ€‹(Siâˆ—â€‹)):=maxSâ€‹jî€ =iâˆ‘â€‹bjâ€‹(Sjâ€‹^â€‹)âˆ’jî€ =iâˆ‘â€‹bjâ€‹(Sjâˆ—â€‹)â€‹â€‹\nNow, the goal of bidder i is to maximize their utility:\nÎ¼iâ€‹(b)â€‹=viâ€‹(Siâ€‹^â€‹)âˆ’piâ€‹(b)=viâ€‹(Siâ€‹^â€‹)âˆ’â€‹maxSâ€‹jî€ =iâˆ‘â€‹bjâ€‹(Sjâ€‹^â€‹)âˆ’jî€ =iâˆ‘â€‹bjâ€‹(Sjâˆ—â€‹)â€‹=Â iÂ canÂ maximizeÂ viâ€‹(Siâ€‹^â€‹)+jî€ =iâˆ‘â€‹bjâ€‹(Sjâˆ—â€‹)â€‹â€‹âˆ’Â iÂ cannotÂ controlÂ maxSâ€‹jî€ =iâˆ‘â€‹bjâ€‹(Sjâ€‹^â€‹)â€‹â€‹â€‹â€‹\nThus, the problem of i maximizing their utility Î¼iâ€‹ is equivalent, by design of the pricing mechanism, as maximizing viâ€‹(Siâ€‹^â€‹)+âˆ‘jî€ =iâ€‹bjâ€‹(Sjâˆ—â€‹), and this is equivalent to social welfare of the original auction.\nmaxbiâ€‹â€‹Î¼iâ€‹(biâ€‹,bâˆ’iâ€‹â€‹)âŸºmaxSâ€‹i=0âˆ‘nâ€‹bjâ€‹(Sjâ€‹)\nThus i is incentivized to tell the truth. â– "},"VSCode-Extensions":{"title":"VSCode Extensions","links":[],"tags":["Computing"],"content":"\nangular language service\ncode spell checker\ncompare folders\ncss property sorter\ncss var complete\nerror lens\neslint\ngit lens\nhtml scss support\nindent rainbow\nintellicode\nintellicode api usage examples\nintellicode completions\njapanese language pack for visual studio code\nprettier - code formatter\nscss intellisense\nstylelint\ntodo highlight\nvim\nvscode-icons\npowershell\n"},"Valorization,-Surplus-Value":{"title":"Valorization, Surplus Value","links":[],"tags":["Philosophy/Marxism"],"content":"Valorization is the addition of surplus value into capital.\n\nBegins with the curiosity:\n\nWhere did this M-C-Mâ€™ increase come from? â† magic! (actually capital?)\n\nPedagogical process of explaining valorization\n\nThe evolution of the money-owner to the capitalist\ncapitalistâ€™s rant\n\n\n\n                  \n                  \\Delta M is the capitalistâ€™s focus. C, or commodity, doensâ€™t matter â†’ overproduction, labor commoditization\n                  \n                \n\n\nHere is the answer:\n\nlaborâ€™s use-val &gt; ex-val [=wages]\nCapitalist pays ex-val to buy the labor-hours. But what the laborer gives [=capitalist gets] is use-val (The distinguished character) for the amount of hours bought (by-hours)\nSurplus value is this difference\nAâ†’Bâ†’C. C can be lengthened for abs. S-V. A-B can be shorted for rel. S-V\n\nImportance to marxâ€™s pedagogy\n\npol-econâ€™s idea that wage = value of labor is an illusory description (Ch.19), they confuse the value of labor-power and value of labor i.e., the commiditized ex-val labor and the actual use-val of labor.\nTo pol-econ, wage = price â‡’ det. by demand/supply; if not the â€œnatural price [=necessary price]â€\nâ†’ clarifies the source of M-C-Mâ€™, why is M&lt;Mâ€™ â† capital making capital\nâ†’ reveals the justification/lawful pursuit of surplus-value, but why it doesnâ€™t make sense on closer examination\n"},"Value-of-Money":{"title":"Value of Money","links":["Utility-Function","(Article)-Minimum-Viable-Superorganism--Melting-Asphalt","Future-Value-Calculations","Financial-markets","Gold-Standard"],"tags":["Economics/Finance"],"content":"\n\n                  \n                  A dollar now than a dollar tomorrow. \n                  \n                \n\nClass notes for detailed info.\nMoneyâ€™s Role Â§\n\nSolves the problem of the double coincidence of wants\n\nObserve the Edgeworth Box|420. This is a full barter system based on Indifference Curves.\n\n\nFunctions as a claim on future consumption (=store of value, claim on future consumption)\n\nI give you the perishable food now â‡’ you give me a claim on future consumption. \nDiscounting future value â† due to risk aversion and instant gratification (human psychology)\n\n\n\nSociology Perspective: Â§\nSee (Article) Minimum Viable Superorganism  Melting Asphalt\n\n\n                  \n                  Money is industrial-grade prestige status \n                  \n                \n\nTime Value of Money Â§\nâ‡’ Thus arises the time value of money and financial markets\n\nMoney is discounted using a discount rate (=interest)\nFinancial markets are essential for a store of value\n\nProperties Required in Physical Money Â§\n\nDivisible â‡’ numerical money. You can divide it into as much as reasonable in transaction\nScarce â‡’ gold/silver is often used\nDesirable â‡’ again, gold/silver.\nDurable â‡’ metallic goods\n\nSee the Gold Standard for more information"},"Variance":{"title":"Variance","links":["Covariance-&-Correlation"],"tags":["Math/Probability"],"content":"def. Variance of a random variable X:\nVar[X]=E[(Xâˆ’Î¼)2]=E(X2)âˆ’[E(X)]2\nVar(X):=E((Xâˆ’Î¼)2)â‰¡âˆ«âˆ’âˆâˆâ€‹(xâˆ’Î¼)2fXâ€‹(x)dx=E(X2)âˆ’[E(X)]2\nthm. (Variance Identities.)\n\nFor a single random variable X and constant n\n\nVar(nâ‹…X)=n2â‹…Var(X) Quadratic Scaling\nVar(X+n)=Var(X) Translation Invariance\n\n\nFor any two random variables X,Y:\n\nVar(X+Y)=Var(X)+Var(Y)+2â‹…E[(Xâˆ’Î¼xâ€‹)(Yâˆ’Î¼yâ€‹)]\n\n\nâ€¦if XâŠ¥Y (i.e. two are independent:\n\nVar(X+Y)=Var(X)+Var(Y)\n\n\nâ€¦.if Independent and Identically distributed (i.i.d) random variables I1â€‹,â€¦,Inâ€‹\n\nVar(I1â€‹+â‹¯+Inâ€‹)=nâ‹…Var(Iiâ€‹)\n\n\n\nSee also Covariance &amp; Correlation.\ndef. Standard Deviation of a random variable is:\nSD(X):=Var(X)â€‹=E(X2)âˆ’[E(X)]2â€‹\n\nFrom the properties of variance we have SD(aX+b)=âˆ£aâˆ£SD(X)+b\n\nStandardization. Â§\nMotivation. Sometimes itâ€™s nice to have random variables to have E(X)=0 and Var(X)=0. Using translation invariance and quadratic scaling we can take any random variable and standardize it.\nthm. (Standardization) For random variable X with E(X)=Î¼ and Var(X)=Ïƒ2,\nY=ÏƒXâˆ’Î¼â€‹\n\nIts expected value (mean) is 0; i.e. E(Y)=0\nIts standard deviation is 1; i.e. Var(Y)â€‹=1\n"},"Vickery-Auction":{"title":"Vickery Auction","links":["Ascending-Price-Auction","Sponsored-Search-Auction"],"tags":["Economics/Game-Theory"],"content":"Motivation. A first-price auction (=give the highest bidder the item, then charge them their bid) is a bad idea because, assuming the highest bidder was truthful (viâ€‹=biâ€‹) then their utility is viâ€‹âˆ’biâ€‹=0. Thus this is not DISC and not a good auction. Itâ€™s also very hard to reason about. Therefore we haveâ€¦ \ndef. Second Price Auction. (=Vickery Auction) Give to the highest bidder; charge them the second highest price. \n\nAn ascending bid auction (=an e-bay auction) is actually a second price auction if you think about it. The last two bidders (v1â€‹,b1â€‹)â‰¥(v2â€‹,b2â€‹) will increase their bids continually until they reach b2â€‹, and then bidder 1 bids just slightly above (b1â€‹=v2â€‹+Î´) to get the item.\n! Not to be confused with Ascending Price Auction; theyâ€™re ascending two different things.\n\nthm. Second Price Auction is DSIC.\nproof. There are only two cases where a bidder may lie.\n\nCase one: a bidder lies to reduce the price of the item. But piâ€‹(b) does not depend on v. Thus this is impossible\nCase two: a bidder lies to get the item. But lying to get the item results in negative utility. â—†\n\nSponsored Search Auction"},"Warrants-(Finance)":{"title":"Warrants (Finance)","links":["Black-Scholes-European-Option-Pricing-Formula","No-Arbitrage"],"tags":["Economics/Finance"],"content":"Warrants (=stock options) are a method that companies use to compensate employees (in addition to salary.) They can be priced using the BSM formula.\nSituation Â§\nAt time t=0, company issues warrants each with strike price K and expiration T.\n\nNoutâ€‹: number of outstanding shares\nNwâ€‹: number of warrants issued\nStâ€‹: stock value at time t\nV(0)=Noutâ€‹S0â€‹+Nwâ€‹W(0): Company value (=MCAP)\n\nWe currently donâ€™t know W(0)\nAt time t=T, suppose all warrant holders exercise their warrants:\n\n\nMCAPbeforeâ€‹(T)=Noutâ€‹ST,beforeâ€‹ before the warrants exercised\nMCAPafterâ€‹(T)=(Noutâ€‹+Nwâ€‹)ST,afterâ€‹ after the warrants exercised\nWe donâ€™t know ST,afterâ€‹=Noutâ€‹+Nwâ€‹MCAPbeforeâ€‹(T)+Nwâ€‹Kâ€‹=Noutâ€‹+Nwâ€‹MCAPafterâ€‹â€‹\n\nPricing Â§\nConsider two portfolios A and B.\n\nA is just a simple warrant that expires at time T with strike K\n\ntime t=0, VAâ€‹(0)=W(0)\ntime t=T, VAâ€‹(T)=max{Noutâ€‹+nwâ€‹MCAPafterâ€‹â€‹âˆ’K,0}\n\n\nB is a long of Noutâ€‹+Nwâ€‹Noutâ€‹â€‹ units of call option on the stock.\n\ntime t=0, VBâ€‹(0)=Noutâ€‹+Nwâ€‹Noutâ€‹â€‹C0Eâ€‹\ntime t=T, VBâ€‹(T)=Noutâ€‹+Nwâ€‹Noutâ€‹â€‹max{Noutâ€‹MCAPbeforeâ€‹â€‹âˆ’K,0}\nNow,\n\n\n\nVAâ€‹(T)â€‹=max{Noutâ€‹+Nwâ€‹MCAPafterâ€‹â€‹âˆ’K,0}=max{Noutâ€‹+Nwâ€‹MCAPbeforeâ€‹+Nwâ€‹Kâ€‹â€‹âˆ’Noutâ€‹+Nwâ€‹K(Noutâ€‹+Nwâ€‹â€‹)â€‹,0}=max{Noutâ€‹+Nwâ€‹MCAPbeforeâ€‹â€‹âˆ’Noutâ€‹+Nwâ€‹KNoutâ€‹â€‹,0}=Noutâ€‹+Nwâ€‹Noutâ€‹â€‹max{Noutâ€‹MCAPbeforeâ€‹â€‹âˆ’K,0}=VBâ€‹(T)â€‹â€‹\nBy the Law of One Price VAâ€‹(0)=VBâ€‹(0), meaning that:\nW(0)=Noutâ€‹+Nwâ€‹Noutâ€‹â€‹C0Eâ€‹\nâ– "},"Wealth-Effect-(WE)":{"title":"Wealth Effect (WE)","links":[],"tags":["Economics/Micro-Economics"],"content":"The Wealth effect is same as the income effect, except this time it is with endowments, so the math is a little different"},"Web-Dev":{"title":"Web Dev","links":[],"tags":["Computing"],"content":"Web Dev Â§\nThe Twelve-Factor App\nTop 5 Frontend Development Topics To Learn in 2019\ngetify/You-Dont-Know-JS\nTech stack rebuild for a new Facebook.com - Facebook Engineering\nLetâ€™s Define Exactly What Atomic CSS is | CSS-Tricks\nQuick Start\nMonthly Getting Started / Web Dev Career Thread"},"Welfare-Theorems":{"title":"Welfare Theorems","links":["Pareto-Efficiency","Rationality-(Economics)"],"tags":["Economics/Micro-Economics"],"content":"thm. First Welfare Theorem. Market Equilibria âŠ† Pareto Efficiency\nthm. Second Welfare Theorem. If Preferences are convex, the Pareto Efficient Point can be supported as a market equilibrium."},"Wilcoxon-Rank-Sum-Test":{"title":"Wilcoxon Rank Sum Test","links":[],"tags":["Math/Statistics"],"content":""},"Wilcoxon-Signed-Rank-Test":{"title":"Wilcoxon Signed Rank Test","links":[],"tags":["Math/Statistics"],"content":""},"Worker-vs-Machine":{"title":"Worker vs Machine","links":["Proletatriat-(Marxism)","Industrial-Revolution"],"tags":["Philosophy/Marxism"],"content":"Factories â† â†’ Workers inversion/subject-object inversion, a moral indignation\n\nHumans as organs of the machine â†’ machine dominates, is the agent; a quantity â†’ qualitative change\n\nDifference between tool and machine [= the factory]\n\n\ntrained since childhood as functions of organs; transforms the person as an appendage\n\nEffects on the human body/soul\n\nDeprives work of all content â† extended alienation, abstraction of labor\n\nRevolts &amp; Machines\n\nMachine â†’ labor revolt â†’ suppressed by machinery (labor is easily replacable, putting machine v. worker against each other)\n\n\n\n                  \n                  industrial machineâ€, or is it more abstract â€œtechnological systems/organization systemsâ€\n                  \n                \n\n\nit is the system not the machine that is at fault. Less of the literal machines, more of the productivity advantage/disadvantage\n"},"Writing-101-Myth-of-Meritocracy":{"title":"Writing 101 Myth of Meritocracy","links":["assets/101---Self-aware-Social-Capital.pdf","assets/101---Myth-of-Meritocracy-in-Korean-College-Admissions.pdf"],"tags":["Courses"],"content":"Writing Assignments Â§\n\n101 - Self-aware Social Capital.pdf\n101 - Myth of Meritocracy in Korean College Admissions.pdf\n\nReadings Â§\n\n(DevonThink) Alim, (De)Occupying Language Social Justice volume\n(DevonThink) Alim, Critical Language Awareness in the United States\n(DevonThink) Edday, Hogan, How and for Whoem Does Increasing Course Structure Work?\n(DevonThink) Garcia-Sanchez, Public School and the Politics of Inclusion (Ch. 5)\n(DevonThink) Gonzales, College-Goers\n(DevonThink) Haviland, Ideologies of Language and U.S. Law\n(DevonThink) Heath, What No Bedtime Story Means: Narrative Skills at Home and School\n(DevonThink) Invited Forum - Journal of Lingisutic Anthropology\n(DevonThink) Johnson, A critical interrogation of the â€œlanguage gapâ€\n(DevonThink) Kendall, White Privilege\n(DevonThink) King, Gods of the Upper Air\n(DevonThink) Kroskrity, Language Ideologies (Ch. 22)\n(DevonThink) Lake, An Indian Fatherâ€™s Plea\n(DevonThink) Maguire, Kelly Hogan\n(DevonThink) McElhinny, White Police Officers on Race and Affirmative Action Journal_of_Linguistic_Anthropology\n(DevonThink) Philips, Language and social inequality\n(DevonThink) Reeves, Hoarding the Dream\n(DevonThink) Welji, Reclaiming a Diverse Ummah for Writing 101.docx\n"},"XPath-and-XQuery":{"title":"XPath and XQuery","links":["Extensible-Markup-Language","Regular-Expressions"],"tags":["Computing/Data-Science"],"content":"Query language for XML\nXPath Â§\n\nConsists of node (=element) and attribute\nuses and, or for conditionals (not |, &amp;, etc.)\n{xpath}/EMPS/EMP/PHONE[@type] checks for the existence of an attribute\n/bibliography/book/@ISBN returns all attribute values (ISBNs)\nfunctions:\n\n{xquery}x+y,xâ€“y,x*y,x div y,x mod y\n{xquery}contains(a,b): a contains b\n{xquery}count($nodeset): number of child nodes in node set\n{xquery}position(): n-th node\nRegular Expressions matching {xquery}matches($string, $regex) e.g. {xquery}matches($input, &#039;H.*o W.*d&#039;)\n\n\nconditionals:\n\n{xquery}x=y note that one equals is fine, {xquery}x!=y\n{xquery}x&gt;y, {xquery}x &lt; y\n{xquery}and or not() works. (but &amp;,|,! does not!)\n\n\nAccess parent node as {xquery}child/.. without trailing backslash\nAccessing Attributes: {xquery}data($person/@name)\nFrequently used in conditions:\n\n{xquery}x + y\n{xquery}x - y\n{xquery}x * y\n{xquery}x div y\n{xquery}x mod y\n\n\nfunctions\n\n{xquery}contains(x, y): true if string x contains string y\n{xquery}count(node-set): counts the number of nodes in node-set\n{xquery}position(): returns the â€œcontext positionâ€ (roughly, the position of the current node in the node-set containing it)\n{xquery}last(): returns the size of the node-set containing the current node\n{xquery}name(): returns the tag name of the current element\n{xquery}sum(): returns sum of all matches\n\n\n\nXQuery Â§\nStandard format:\n&lt;result&gt;{\n\tfor $var in XPATH-QUERY (: Comments :)\n\tlet $var2 ...\n\twhere [condition]\n\tstable order by,\n\t\t$variable ascending,\n\t\t$variable descending\n\treturn &lt;elem&gt;{xquery}&lt;/elem&gt;\n}&lt;/result&gt;\nSort Â§\n\nConditionals Â§\n\nAxis Test Â§\n\n/: shorthand for child-or-self\n//: shorthand for descendant-or-self\n/..: shorthand for parent\none of self, attribute,\nparent, child, ancestor,â€  ancestor-or-self,â€  descendant, descendant-or-self,\nfollowing, following-sibling, preceding,â€  preceding-sibling,â€ \nnamespace\nâ€ : These are reverse axes (=produce resulting node-sets in reverse document order)\nUse like: \n\nExistential Conditions (Exists someâ€¦) Â§\n\nDate Operations Â§\n\nDates will be printed as P dD T hH iM sS\n\nP just a P.\nd: Number of Days. D: constant\nT: constant\nh: Number of Hours, H: constant\ni: Number of Minutes, M: is constant\ns: Number of Seconds S: is constant\n\n\nDates can be\n\nsubtracted: {xquery}xs:date(&quot;1933-06-22&quot;) - xs:date(&quot;2000-01-01&quot;)\ncompared: {xquery}xs:date(&quot;1933-06-22&quot;) &gt;= xs:date(&quot;2000-01-01&quot;)\n\n\n\nDate functions\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nyear-from-dateTimeday-from-dateTimeminutes-from-dateTimeyear-from-dateday-from-dateminutes-from-timeyears-from-durationminutes-from-durationdays-from-durationmonth-from-dateTimehours-from-dateTimeseconds-from-dateTimemonth-from-datehours-from-timeseconds-from-timemonths-from-durationhours-from-durationseconds-from-duration\nTips and Tricks Â§\n\nNaming elements using variables:\n"},"Yield-Maturity-Curve-(Bond)":{"title":"Yield-Maturity Curve (Bond)","links":["Bonds-(Finance)","Federal-Funds-Rate"],"tags":["Economics/Finance"],"content":"Relationship between yield and maturity of a bond.\nInterest Rate Changes Â§\nThe government can change the federal funds rate, which influences the y-intercept of the yield curve:\n\n\nInflation â‡’ interest rate â†‘ â‡’ firm borrowing â†“ â‡’ investment â†“\nRecession â‡’ interest rate â†‘ â‡’ firm borrowing â†‘ â‡’ investment â†‘\n\n\n\n                  \n                  An inverted yield curve occurs as the bond market: \n                  \n                \nexpects a recession â‡’ expectes the government to increase the interest rate â‡’ long-maturity bonds are more appealing.\n\nMaking Money off Bonds Â§\n\nCredit Curves Â§\n\nGovernment bonds have the highest credit rating\nWhen comparing other types of bonds (e.g. corporate bonds), any bond with the same maturity has a higher yield than government bonds.\nSpread is the difference in yield between it and government bonds.\n\nSpread âˆ 1/Credit âˆ maturity, and is related to industry\n\n\n\n\n"},"Zero-Sum-Game":{"title":"Zero Sum Game","links":["Equilibria-in-Game-Theory","Linear-Programming","Zero-Sum-Game"],"tags":["Economics/Game-Theory"],"content":"def. Zero Sum Game. When each box in the payoff (cost) matrix sums to zero.\nthm. Min-Max Theorem. The stackleberg solution in a zero-sum game for player one going first, is same for player two going first. Thus this is a mixed nash equilibirum. You can compute this using Linear Programming.\nExample. In the following game:\n\nRow player will aim to: \nmaxx1â€‹,x2â€‹â€‹columnâ€™sÂ expectedÂ strategyÂ min(Â columnÂ goesÂ left3x1â€‹âˆ’2x2â€‹â€‹â€‹,Â columnÂ goesÂ rightÂ âˆ’x1â€‹+x2â€‹â€‹â€‹)â€‹â€‹â€‹Â GivenÂ columnâ€™sÂ expectedÂ strategy,Â theÂ bestÂ responseÂ â€‹\nThis is also known as the Stackleberg solution. Letting z=min(3x1â€‹âˆ’2x2â€‹,âˆ’x1â€‹+x2â€‹) we have the following linear program: \nzz10â€‹â‰¤3x1â€‹âˆ’2x2â€‹â‰¤âˆ’x1â€‹+x2â€‹=x1â€‹+x2â€‹â‰¤x1â€‹,x2â€‹â€‹â€‹\nEquivalently, column player will aim to miny1â€‹,y2â€‹â€‹max(3y1â€‹âˆ’y2â€‹,âˆ’2y1â€‹+y2â€‹). Letting w=max(3y1â€‹âˆ’y2â€‹,âˆ’2y1â€‹+y2â€‹) We have the following linear program:\nww10â€‹â‰¥3y1â€‹âˆ’y2â€‹â‰¥âˆ’2y1â€‹+y2â€‹=y1â€‹+y2â€‹â‰¤y1â€‹,y2â€‹â€‹â€‹\nIn a Zero Sum Game like this game, the above two linear programs are dual problems to each other. The solution to both of these programs are:\n{x1â€‹=73â€‹,x2â€‹=74â€‹y1â€‹=72â€‹,y2â€‹=75â€‹â€‹"},"index":{"title":"index","links":["Auction-Theory","Maximum-Flow-Problem","Stochastic-Calculus","Publishable/assets/361-Final---Game-Theory,-Financial-Markets,-Distributive-Justice.pdf","CS-535-Algorithmic-Game-Theory","CS-330-Advanced-Algorithms","CS-334-Formal-Languages","CS-250-Architecture","CS-316-Database-Systems","ECON-205-Intermediate-Microeconomics-II","Math-581-Mathematical-Finance","Math-582-Financial-Derivatives","Econ-201-Intermediate-Microeconomics-I","Econ-204-Econometrics","Econ-210-Macroeconomics","Econ-371-Finance","Stat-432-Statistics","Stat-230-Probability","GSF-386-Politics-of-Sexuality","CulAnth-203-Marxism","Econ-361-Distributive-Justice","Writing-101-Myth-of-Meritocracy","English-190FS-Renaissance-Literature","Music-190FS-Music-and-Medicine-in-European-Renaissance","Sociology-110D","International-Baccalaureate-(IB)"],"tags":["Courses"],"content":"\n\n                  \n                  Highlights \n                  \n                \n\nAuction Theory\nMaximum Flow Problem\nStochastic Calculus\n361 Final - Game Theory, Financial Markets, Distributive Justice\n\n\nComputer Science Â§\n\nğŸŒŸ CS 535 Algorithmic Game Theory\nğŸŒŸ CS 330 Advanced Algorithms\nğŸŒŸ CS 334 Formal Languages\nCS 250 Architecture\nCS 316 Database Systems\nCS 230 Discrete Math for CS\n\nEconomics Â§\n\nğŸŒŸ ECON 205 Intermediate Microeconomics II\nğŸŒŸ Math 581 Mathematical Finance\nMath 582 Financial Derivatives\nEcon 201 Intermediate Microeconomics I\nEcon 204 Econometrics\nCS 535 Algorithmic Game Theory\nEcon 210 Macroeconomics\nEcon 371 Finance\nEcon 204 Econometrics\n\nPure Math Â§\n\nğŸŒŸ Stat 432 Statistics\nStat 230 Probability\nMath 221 Linear Algebra\nMath 212 Multivariable Calculus\n\nLiberal Arts Â§\n\nGSF 386 Politics of Sexuality\nCulAnth 203 Marxism\nEcon 361 Distributive Justice\nWriting 101 Myth of Meritocracy\nEnglish 190FS Renaissance Literature\nMusic 190FS Music and Medicine in European Renaissance\n\nOther Â§\n\nSociology 110D\nInternational Baccalaureate (IB)\n"},"main-diagonal":{"title":"main diagonal","links":[],"tags":["Math/Linear-Algebra"],"content":"Main Diagonal\n\nAnti-diagonal\n"}}